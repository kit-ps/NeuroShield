{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce30d3-e46a-45b4-9d02-a7ca01216378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 16\n",
      "Number of unique subjects: 15\n",
      "device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    InstanceNorm1d-1              [-1, 93, 500]               0\n",
      "            Conv2d-2         [-1, 256, 93, 500]           1,280\n",
      "              ReLU-3         [-1, 256, 93, 500]               0\n",
      "         MaxPool2d-4         [-1, 256, 93, 250]               0\n",
      "            Conv2d-5         [-1, 192, 93, 250]         196,800\n",
      "              ReLU-6         [-1, 192, 93, 250]               0\n",
      "         MaxPool2d-7         [-1, 192, 46, 250]               0\n",
      "            Conv2d-8         [-1, 128, 46, 250]          98,432\n",
      "              ReLU-9         [-1, 128, 46, 250]               0\n",
      "        MaxPool2d-10         [-1, 128, 46, 125]               0\n",
      "           Conv2d-11          [-1, 96, 46, 125]          49,248\n",
      "             ReLU-12          [-1, 96, 46, 125]               0\n",
      "        MaxPool2d-13          [-1, 96, 23, 125]               0\n",
      "           Conv2d-14          [-1, 64, 23, 125]          24,640\n",
      "             ReLU-15          [-1, 64, 23, 125]               0\n",
      "        MaxPool2d-16           [-1, 64, 23, 62]               0\n",
      "           Conv2d-17           [-1, 32, 23, 62]           8,224\n",
      "             ReLU-18           [-1, 32, 23, 62]               0\n",
      "        MaxPool2d-19           [-1, 32, 11, 62]               0\n",
      "           Conv2d-20           [-1, 16, 11, 62]           1,040\n",
      "             ReLU-21           [-1, 16, 11, 62]               0\n",
      "           Conv2d-22            [-1, 2, 11, 62]              66\n",
      "             ReLU-23            [-1, 2, 11, 62]               0\n",
      "          Flatten-24                 [-1, 1364]               0\n",
      "           Linear-25                  [-1, 128]         174,720\n",
      "================================================================\n",
      "Total params: 554,450\n",
      "Trainable params: 554,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.18\n",
      "Forward/backward pass size (MB): 355.54\n",
      "Params size (MB): 2.12\n",
      "Estimated Total Size (MB): 357.83\n",
      "----------------------------------------------------------------\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 1 Iteration 0: Loss = 4.844144821166992, Number of mined P N = 896 15360\n",
      "Epoch 1 Iteration 100: Loss = 4.077132701873779, Number of mined P N = 896 7718\n",
      "Epoch 1 Iteration 200: Loss = 3.4905507564544678, Number of mined P N = 864 5509\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "feature= \"raw\"\n",
    "sample_len = 500\n",
    "num_epochs=99\n",
    "batch_s= 128\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "from pytorch_metric_learning.distances import LpDistance, CosineSimilarity,SNRDistance\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "\n",
    "        # Access the data and labels from the HDF5 file\n",
    "        self.x_data = self.h5_file['data']  # EEG data (use memory-mapped access)\n",
    "        self.y_data = self.h5_file['labels'][:]  # Labels (load fully into memory)\n",
    "        self.s_data = self.h5_file['sessions'][:]  # Sessions (load fully into memory)\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Convert to torch tensor\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "    def close(self):\n",
    "        self.h5_file.close()\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path, num_subjects=None):\n",
    "        # Open the HDF5 file and keep it open for on-the-fly access\n",
    "        self.h5_file_path = h5_file_path\n",
    "        with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "            self.y_data = np.array(h5_file['labels'])  # Load labels into memory\n",
    "            self.s_data = np.array(h5_file['sessions'])  # Load sessions into memory\n",
    "\n",
    "            # Get unique subjects\n",
    "            unique_subjects = np.unique(self.y_data)\n",
    "\n",
    "            # If a specific number of subjects is requested, select a random subset\n",
    "            if num_subjects is not None and num_subjects < len(unique_subjects):\n",
    "                selected_subjects = np.random.choice(unique_subjects, size=num_subjects, replace=False)\n",
    "                mask = np.isin(self.y_data, selected_subjects)  # Filter data by selected subjects\n",
    "                self.indices = np.where(mask)[0]\n",
    "                self.y_data = self.y_data[mask]\n",
    "                self.s_data = self.s_data[mask]\n",
    "                unique_subjects = selected_subjects  # Update unique subjects to the selected subset\n",
    "            else:\n",
    "                self.indices = np.arange(len(self.y_data))  # Keep all indices if no filtering\n",
    "\n",
    "            # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "            self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}\n",
    "\n",
    "            # Map the y_data labels using the subject_map\n",
    "            self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "            # Convert labels to torch tensors\n",
    "            self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "            # Print the number of unique subjects (labels)\n",
    "            print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the global index in the HDF5 file\n",
    "        global_idx = self.indices[idx]\n",
    "\n",
    "        # Open the HDF5 file and fetch data on-the-fly\n",
    "        with h5py.File(self.h5_file_path, 'r') as h5_file:\n",
    "            x_data = h5_file['data'][global_idx]\n",
    "\n",
    "        # Convert data and labels into torch tensors\n",
    "        x_tensor = torch.tensor(x_data, dtype=torch.float32)  # Fetch EEG data\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Fetch the session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "h5_file_path_t = f'./data/train_{feature}.h5'\n",
    "h5_file_path_v = f'./data/valid_{feature}.h5'\n",
    "train_dataset = EEGDataset(h5_file_path_t,16)\n",
    "valid_dataset = EEGDataset(h5_file_path_v)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "subject_ids = train_dataset.targets  # Replace with train_dataset.targets\n",
    "session_ids = train_dataset.s_data          # Replace with train_dataset.s_data\n",
    "\n",
    "# Combine subject and session IDs into unique pairs\n",
    "pairs = list(zip(subject_ids.tolist(), session_ids.tolist()))\n",
    "\n",
    "# Create a mapping from pairs to unique IDs\n",
    "unique_pairs = list(set(pairs))  # Get unique pairs\n",
    "pair_to_id = {pair: idx for idx, pair in enumerate(unique_pairs)}\n",
    "\n",
    "# Map each pair to its unique ID\n",
    "unique_ids = torch.tensor([pair_to_id[pair] for pair in pairs])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate(model, loader, loss_func, mining_func, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_batches = 0\n",
    "    iteration_count = 0  # Initialize a counter for iterations\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "            if iteration_count >= 50:  # Break the loop after 5 iterations\n",
    "                break\n",
    "            inputs = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            embeddings = model(inputs)\n",
    "            miner_output = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, miner_output)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            iteration_count += 1  # Increment the iteration counter\n",
    "\n",
    "    return val_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet7, self).__init__()\n",
    "        # InstanceNorm1d normalizes each channel across its 500 values for each sample\n",
    "        self.norm = nn.InstanceNorm1d(93, affine=False)  # Normalizes across the 500 values in each of the 93 channels\n",
    "        self.act = nn.ReLU()  # or nn.SELU() , ReLU\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.conv1 = nn.Conv2d(1, 256, (1, 4), padding='same')\n",
    "        self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 192, (4, 1), padding='same')\n",
    "        self.pool2 = nn.MaxPool2d((2, 1))\n",
    "        self.conv3 = nn.Conv2d(192, 128, (1, 4), padding='same')\n",
    "        self.pool3 = nn.MaxPool2d((1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 96, (4, 1), padding='same')\n",
    "        self.pool4 = nn.MaxPool2d((2, 1))\n",
    "        self.conv5 = nn.Conv2d(96, 64, (1, 4), padding='same')\n",
    "        self.pool5 = nn.MaxPool2d((1, 2))\n",
    "        self.conv6 = nn.Conv2d(64, 32, (4, 1), padding='same')\n",
    "        self.pool6 = nn.MaxPool2d((2, 1))\n",
    "        self.conv7 = nn.Conv2d(32, 16, (1, 2), padding='same')\n",
    "        self.conv8 = nn.Conv2d(16, 2, (2, 1), padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.embedding = nn.Linear(1364, 128)  # Embedding layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #if x.dim() == 3:\n",
    "            #x = x.unsqueeze(1)  # Adding a channel dimension if input is 3D\n",
    "        x = self.norm(x)  # Apply InstanceNorm along the channel dimension (squeeze to 1D first)\n",
    "        x = x.unsqueeze(1)  # Reshape to 4D again for Conv2d\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.act(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        x = self.act(self.conv6(x))\n",
    "        x = self.pool6(x)\n",
    "        x = self.act(self.conv7(x))\n",
    "        x = self.act(self.conv8(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch, test_loader):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    print(f\"Total number of batches in train_loader: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use mixed precision training\n",
    "        with autocast():\n",
    "            embeddings = model(data)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        # Scales the loss, and backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales gradients and optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined P N = {} {}\".format(\n",
    "                    epoch, batch_idx, loss.item(), mining_func.num_pos_pairs, mining_func.num_neg_pairs  \n",
    "                )\n",
    "            )\n",
    "    val_loss = validate(model, test_loader, loss_func, mining_func, device)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"device\", device)\n",
    "trunk = EEGNet7().to(device)\n",
    "summary(trunk, (93, sample_len)) \n",
    "\n",
    "loss_func = losses.SupConLoss(temperature=0.1).to(device)\n",
    "#loss_func = losses.LiftedStructureLoss().to(device)\n",
    "\n",
    "#sampler = samplers.MPerClassSampler(unique_ids, m=1, batch_size=batch_s)\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=8, batch_size=batch_s)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_s, sampler=sampler)\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001)\n",
    "#mining_func = miners.PairMarginMiner(pos_margin=0.20, neg_margin=0.8)\n",
    "mining_func = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(trunk, loss_func, mining_func, device, train_loader, trunk_optimizer, epoch,valid_loader)\n",
    "    #test(trunk, loss_func, mining_func, device, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(trunk.state_dict(), './model/SupConLoss128_m4_e99_S16_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f8fc2-c562-4fcf-82b3-be130c01d33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "oml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
