{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ce30d3-e46a-45b4-9d02-a7ca01216378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 128\n",
      "Number of unique subjects: 15\n",
      "device cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    InstanceNorm1d-1              [-1, 93, 500]               0\n",
      "            Conv2d-2         [-1, 256, 93, 500]           1,280\n",
      "              ReLU-3         [-1, 256, 93, 500]               0\n",
      "         MaxPool2d-4         [-1, 256, 93, 250]               0\n",
      "            Conv2d-5         [-1, 192, 93, 250]         196,800\n",
      "              ReLU-6         [-1, 192, 93, 250]               0\n",
      "         MaxPool2d-7         [-1, 192, 46, 250]               0\n",
      "            Conv2d-8         [-1, 128, 46, 250]          98,432\n",
      "              ReLU-9         [-1, 128, 46, 250]               0\n",
      "        MaxPool2d-10         [-1, 128, 46, 125]               0\n",
      "           Conv2d-11          [-1, 96, 46, 125]          49,248\n",
      "             ReLU-12          [-1, 96, 46, 125]               0\n",
      "        MaxPool2d-13          [-1, 96, 23, 125]               0\n",
      "           Conv2d-14          [-1, 64, 23, 125]          24,640\n",
      "             ReLU-15          [-1, 64, 23, 125]               0\n",
      "        MaxPool2d-16           [-1, 64, 23, 62]               0\n",
      "           Conv2d-17           [-1, 32, 23, 62]           8,224\n",
      "             ReLU-18           [-1, 32, 23, 62]               0\n",
      "        MaxPool2d-19           [-1, 32, 11, 62]               0\n",
      "           Conv2d-20           [-1, 16, 11, 62]           1,040\n",
      "             ReLU-21           [-1, 16, 11, 62]               0\n",
      "           Conv2d-22            [-1, 2, 11, 62]              66\n",
      "             ReLU-23            [-1, 2, 11, 62]               0\n",
      "          Flatten-24                 [-1, 1364]               0\n",
      "           Linear-25                  [-1, 128]         174,720\n",
      "================================================================\n",
      "Total params: 554,450\n",
      "Trainable params: 554,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.18\n",
      "Forward/backward pass size (MB): 355.54\n",
      "Params size (MB): 2.12\n",
      "Estimated Total Size (MB): 357.83\n",
      "----------------------------------------------------------------\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 1 Iteration 0: Loss = 4.8434038162231445, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 100: Loss = 4.258803844451904, Number of mined P N = 384 10441\n",
      "Epoch 1 Iteration 200: Loss = 4.139577865600586, Number of mined P N = 384 10129\n",
      "Epoch 1 Iteration 300: Loss = 4.090562343597412, Number of mined P N = 384 9386\n",
      "Epoch 1 Iteration 400: Loss = 3.8966774940490723, Number of mined P N = 383 8100\n",
      "Epoch 1 Iteration 500: Loss = 3.65712833404541, Number of mined P N = 384 6261\n",
      "Epoch 1 Iteration 600: Loss = 3.576353073120117, Number of mined P N = 384 5966\n",
      "Epoch 1 Iteration 700: Loss = 3.501734972000122, Number of mined P N = 373 5522\n",
      "Validation loss:  3.663569884300232\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 2 Iteration 0: Loss = 3.703016519546509, Number of mined P N = 384 7366\n",
      "Epoch 2 Iteration 100: Loss = 3.552621841430664, Number of mined P N = 378 6103\n",
      "Epoch 2 Iteration 200: Loss = 3.706179618835449, Number of mined P N = 371 7334\n",
      "Epoch 2 Iteration 300: Loss = 3.5476291179656982, Number of mined P N = 382 6213\n",
      "Epoch 2 Iteration 400: Loss = 3.437194347381592, Number of mined P N = 376 5536\n",
      "Epoch 2 Iteration 500: Loss = 3.3955302238464355, Number of mined P N = 382 5573\n",
      "Epoch 2 Iteration 600: Loss = 3.451742649078369, Number of mined P N = 378 6281\n",
      "Epoch 2 Iteration 700: Loss = 3.3309805393218994, Number of mined P N = 383 4894\n",
      "Validation loss:  3.363037805557251\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 3 Iteration 0: Loss = 3.296468496322632, Number of mined P N = 379 4916\n",
      "Epoch 3 Iteration 100: Loss = 3.5547103881835938, Number of mined P N = 384 6194\n",
      "Epoch 3 Iteration 200: Loss = 3.215043306350708, Number of mined P N = 373 5213\n",
      "Epoch 3 Iteration 300: Loss = 3.3623533248901367, Number of mined P N = 376 4968\n",
      "Epoch 3 Iteration 400: Loss = 3.097489356994629, Number of mined P N = 379 4281\n",
      "Epoch 3 Iteration 500: Loss = 3.0756731033325195, Number of mined P N = 376 3904\n",
      "Epoch 3 Iteration 600: Loss = 3.191117286682129, Number of mined P N = 381 4870\n",
      "Epoch 3 Iteration 700: Loss = 3.1952412128448486, Number of mined P N = 374 4715\n",
      "Validation loss:  3.1024556732177735\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 4 Iteration 0: Loss = 2.895279884338379, Number of mined P N = 378 3585\n",
      "Epoch 4 Iteration 100: Loss = 3.118161678314209, Number of mined P N = 368 4639\n",
      "Epoch 4 Iteration 200: Loss = 2.974644184112549, Number of mined P N = 380 3635\n",
      "Epoch 4 Iteration 300: Loss = 3.138253927230835, Number of mined P N = 342 4286\n",
      "Epoch 4 Iteration 400: Loss = 2.958684206008911, Number of mined P N = 372 3646\n",
      "Epoch 4 Iteration 500: Loss = 2.910788059234619, Number of mined P N = 354 3539\n",
      "Epoch 4 Iteration 600: Loss = 3.123609781265259, Number of mined P N = 359 4354\n",
      "Epoch 4 Iteration 700: Loss = 2.9769232273101807, Number of mined P N = 371 4020\n",
      "Validation loss:  2.938624358177185\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 5 Iteration 0: Loss = 2.801739454269409, Number of mined P N = 342 3699\n",
      "Epoch 5 Iteration 100: Loss = 2.825270175933838, Number of mined P N = 370 3281\n",
      "Epoch 5 Iteration 200: Loss = 2.9225096702575684, Number of mined P N = 373 3536\n",
      "Epoch 5 Iteration 300: Loss = 2.9862613677978516, Number of mined P N = 370 4015\n",
      "Epoch 5 Iteration 400: Loss = 3.130841016769409, Number of mined P N = 367 4179\n",
      "Epoch 5 Iteration 500: Loss = 2.912287712097168, Number of mined P N = 352 3811\n",
      "Epoch 5 Iteration 600: Loss = 2.7884416580200195, Number of mined P N = 356 3250\n",
      "Epoch 5 Iteration 700: Loss = 2.9524052143096924, Number of mined P N = 360 3369\n",
      "Validation loss:  2.7751480293273927\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 6 Iteration 0: Loss = 3.067054510116577, Number of mined P N = 358 4178\n",
      "Epoch 6 Iteration 100: Loss = 2.6105105876922607, Number of mined P N = 356 2747\n",
      "Epoch 6 Iteration 200: Loss = 3.0841498374938965, Number of mined P N = 360 4129\n",
      "Epoch 6 Iteration 300: Loss = 2.829841136932373, Number of mined P N = 356 3177\n",
      "Epoch 6 Iteration 400: Loss = 2.5747857093811035, Number of mined P N = 357 2624\n",
      "Epoch 6 Iteration 500: Loss = 2.8332908153533936, Number of mined P N = 368 3308\n",
      "Epoch 6 Iteration 600: Loss = 2.503340244293213, Number of mined P N = 345 2713\n",
      "Epoch 6 Iteration 700: Loss = 2.911083698272705, Number of mined P N = 360 3214\n",
      "Validation loss:  2.685188179016113\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 7 Iteration 0: Loss = 2.6569628715515137, Number of mined P N = 343 2838\n",
      "Epoch 7 Iteration 100: Loss = 2.9108080863952637, Number of mined P N = 366 3572\n",
      "Epoch 7 Iteration 200: Loss = 2.623671293258667, Number of mined P N = 364 2931\n",
      "Epoch 7 Iteration 300: Loss = 2.5228209495544434, Number of mined P N = 333 2532\n",
      "Epoch 7 Iteration 400: Loss = 2.6380865573883057, Number of mined P N = 330 2605\n",
      "Epoch 7 Iteration 500: Loss = 2.7600789070129395, Number of mined P N = 368 3215\n",
      "Epoch 7 Iteration 600: Loss = 2.5416204929351807, Number of mined P N = 329 2523\n",
      "Epoch 7 Iteration 700: Loss = 2.587125778198242, Number of mined P N = 349 2635\n",
      "Validation loss:  2.6614531755447386\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 8 Iteration 0: Loss = 2.757380247116089, Number of mined P N = 337 3177\n",
      "Epoch 8 Iteration 100: Loss = 2.621415615081787, Number of mined P N = 342 2563\n",
      "Epoch 8 Iteration 200: Loss = 2.5589046478271484, Number of mined P N = 333 2520\n",
      "Epoch 8 Iteration 300: Loss = 2.9797351360321045, Number of mined P N = 331 3455\n",
      "Epoch 8 Iteration 400: Loss = 2.832897186279297, Number of mined P N = 356 3293\n",
      "Epoch 8 Iteration 500: Loss = 2.4717049598693848, Number of mined P N = 364 2406\n",
      "Epoch 8 Iteration 600: Loss = 2.590585470199585, Number of mined P N = 347 2434\n",
      "Epoch 8 Iteration 700: Loss = 2.2477171421051025, Number of mined P N = 341 1697\n",
      "Validation loss:  2.584745001792908\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 9 Iteration 0: Loss = 2.508816957473755, Number of mined P N = 337 2321\n",
      "Epoch 9 Iteration 100: Loss = 2.521944522857666, Number of mined P N = 339 2479\n",
      "Epoch 9 Iteration 200: Loss = 2.5201971530914307, Number of mined P N = 336 2276\n",
      "Epoch 9 Iteration 300: Loss = 2.533428430557251, Number of mined P N = 335 2580\n",
      "Epoch 9 Iteration 400: Loss = 2.572545051574707, Number of mined P N = 339 2416\n",
      "Epoch 9 Iteration 500: Loss = 2.5481443405151367, Number of mined P N = 341 2330\n",
      "Epoch 9 Iteration 600: Loss = 2.482163906097412, Number of mined P N = 342 2589\n",
      "Epoch 9 Iteration 700: Loss = 2.6847078800201416, Number of mined P N = 340 2704\n",
      "Validation loss:  2.5388193845748903\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 10 Iteration 0: Loss = 2.4544520378112793, Number of mined P N = 330 2004\n",
      "Epoch 10 Iteration 100: Loss = 2.516364812850952, Number of mined P N = 350 2390\n",
      "Epoch 10 Iteration 200: Loss = 2.3936333656311035, Number of mined P N = 339 2141\n",
      "Epoch 10 Iteration 300: Loss = 2.5696773529052734, Number of mined P N = 329 2314\n",
      "Epoch 10 Iteration 400: Loss = 2.597440719604492, Number of mined P N = 319 2415\n",
      "Epoch 10 Iteration 500: Loss = 2.398775815963745, Number of mined P N = 313 2317\n",
      "Epoch 10 Iteration 600: Loss = 2.5203440189361572, Number of mined P N = 323 2501\n",
      "Epoch 10 Iteration 700: Loss = 2.7152962684631348, Number of mined P N = 366 2763\n",
      "Validation loss:  2.501535677909851\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 11 Iteration 0: Loss = 2.357524871826172, Number of mined P N = 310 2111\n",
      "Epoch 11 Iteration 100: Loss = 2.5921196937561035, Number of mined P N = 311 2529\n",
      "Epoch 11 Iteration 200: Loss = 2.404172420501709, Number of mined P N = 331 2386\n",
      "Epoch 11 Iteration 300: Loss = 2.438070058822632, Number of mined P N = 314 2022\n",
      "Epoch 11 Iteration 400: Loss = 2.483234167098999, Number of mined P N = 312 2439\n",
      "Epoch 11 Iteration 500: Loss = 2.8054873943328857, Number of mined P N = 333 3055\n",
      "Epoch 11 Iteration 600: Loss = 2.407074213027954, Number of mined P N = 317 2305\n",
      "Epoch 11 Iteration 700: Loss = 2.4742465019226074, Number of mined P N = 309 2329\n",
      "Validation loss:  2.4485746955871583\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 12 Iteration 0: Loss = 2.5355448722839355, Number of mined P N = 351 2476\n",
      "Epoch 12 Iteration 100: Loss = 2.482299327850342, Number of mined P N = 313 2269\n",
      "Epoch 12 Iteration 200: Loss = 2.5026655197143555, Number of mined P N = 329 2369\n",
      "Epoch 12 Iteration 300: Loss = 2.49131178855896, Number of mined P N = 312 2182\n",
      "Epoch 12 Iteration 400: Loss = 2.4108011722564697, Number of mined P N = 319 2367\n",
      "Epoch 12 Iteration 500: Loss = 2.7221615314483643, Number of mined P N = 342 2607\n",
      "Epoch 12 Iteration 600: Loss = 2.4439125061035156, Number of mined P N = 338 2182\n",
      "Epoch 12 Iteration 700: Loss = 2.239830732345581, Number of mined P N = 307 1802\n",
      "Validation loss:  2.3720192289352418\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 13 Iteration 0: Loss = 2.3212950229644775, Number of mined P N = 292 1901\n",
      "Epoch 13 Iteration 100: Loss = 2.571122169494629, Number of mined P N = 322 2704\n",
      "Epoch 13 Iteration 200: Loss = 2.373656749725342, Number of mined P N = 328 1991\n",
      "Epoch 13 Iteration 300: Loss = 2.4977195262908936, Number of mined P N = 306 2167\n",
      "Epoch 13 Iteration 400: Loss = 2.2106592655181885, Number of mined P N = 310 1968\n",
      "Epoch 13 Iteration 500: Loss = 2.5688679218292236, Number of mined P N = 338 2565\n",
      "Epoch 13 Iteration 600: Loss = 2.1456024646759033, Number of mined P N = 307 1510\n",
      "Epoch 13 Iteration 700: Loss = 2.370039701461792, Number of mined P N = 312 2257\n",
      "Validation loss:  2.3469785547256468\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 14 Iteration 0: Loss = 2.396423816680908, Number of mined P N = 323 2150\n",
      "Epoch 14 Iteration 100: Loss = 2.240010976791382, Number of mined P N = 298 2017\n",
      "Epoch 14 Iteration 200: Loss = 2.003472089767456, Number of mined P N = 279 1427\n",
      "Epoch 14 Iteration 300: Loss = 2.463590145111084, Number of mined P N = 304 1849\n",
      "Epoch 14 Iteration 400: Loss = 2.152402400970459, Number of mined P N = 306 1546\n",
      "Epoch 14 Iteration 500: Loss = 2.3062896728515625, Number of mined P N = 320 1819\n",
      "Epoch 14 Iteration 600: Loss = 2.251668930053711, Number of mined P N = 302 1699\n",
      "Epoch 14 Iteration 700: Loss = 2.326416492462158, Number of mined P N = 343 1928\n",
      "Validation loss:  2.3220707845687865\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 15 Iteration 0: Loss = 2.5648372173309326, Number of mined P N = 321 2195\n",
      "Epoch 15 Iteration 100: Loss = 2.402660608291626, Number of mined P N = 312 1948\n",
      "Epoch 15 Iteration 200: Loss = 2.3830924034118652, Number of mined P N = 326 2202\n",
      "Epoch 15 Iteration 300: Loss = 2.4056122303009033, Number of mined P N = 303 1983\n",
      "Epoch 15 Iteration 400: Loss = 2.334961414337158, Number of mined P N = 317 1578\n",
      "Epoch 15 Iteration 500: Loss = 2.2955689430236816, Number of mined P N = 323 1721\n",
      "Epoch 15 Iteration 600: Loss = 2.1369829177856445, Number of mined P N = 305 1709\n",
      "Epoch 15 Iteration 700: Loss = 2.198096752166748, Number of mined P N = 303 1602\n",
      "Validation loss:  2.296417202949524\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 16 Iteration 0: Loss = 2.3953967094421387, Number of mined P N = 318 2098\n",
      "Epoch 16 Iteration 100: Loss = 2.523026704788208, Number of mined P N = 328 2375\n",
      "Epoch 16 Iteration 200: Loss = 2.679306983947754, Number of mined P N = 317 2647\n",
      "Epoch 16 Iteration 300: Loss = 2.4592716693878174, Number of mined P N = 341 2219\n",
      "Epoch 16 Iteration 400: Loss = 2.154423952102661, Number of mined P N = 287 1429\n",
      "Epoch 16 Iteration 500: Loss = 2.108250141143799, Number of mined P N = 288 1468\n",
      "Epoch 16 Iteration 600: Loss = 2.33079195022583, Number of mined P N = 301 2094\n",
      "Epoch 16 Iteration 700: Loss = 2.3436636924743652, Number of mined P N = 314 2017\n",
      "Validation loss:  2.2486351132392883\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 17 Iteration 0: Loss = 2.0698132514953613, Number of mined P N = 304 1429\n",
      "Epoch 17 Iteration 100: Loss = 2.266805410385132, Number of mined P N = 316 1802\n",
      "Epoch 17 Iteration 200: Loss = 2.3594353199005127, Number of mined P N = 304 1855\n",
      "Epoch 17 Iteration 300: Loss = 2.2419025897979736, Number of mined P N = 285 1632\n",
      "Epoch 17 Iteration 400: Loss = 2.129683256149292, Number of mined P N = 307 1505\n",
      "Epoch 17 Iteration 500: Loss = 2.059906482696533, Number of mined P N = 265 1405\n",
      "Epoch 17 Iteration 600: Loss = 2.18412709236145, Number of mined P N = 280 1434\n",
      "Epoch 17 Iteration 700: Loss = 2.1272506713867188, Number of mined P N = 262 1459\n",
      "Validation loss:  2.2097244811058045\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 18 Iteration 0: Loss = 2.1463239192962646, Number of mined P N = 295 1778\n",
      "Epoch 18 Iteration 100: Loss = 2.2281551361083984, Number of mined P N = 306 1730\n",
      "Epoch 18 Iteration 200: Loss = 2.2504985332489014, Number of mined P N = 308 1536\n",
      "Epoch 18 Iteration 300: Loss = 2.4711079597473145, Number of mined P N = 340 2219\n",
      "Epoch 18 Iteration 400: Loss = 1.9452600479125977, Number of mined P N = 256 1062\n",
      "Epoch 18 Iteration 500: Loss = 2.247081995010376, Number of mined P N = 253 1676\n",
      "Epoch 18 Iteration 600: Loss = 2.720106601715088, Number of mined P N = 291 2705\n",
      "Epoch 18 Iteration 700: Loss = 2.131063222885132, Number of mined P N = 309 1486\n",
      "Validation loss:  2.2005831480026243\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 19 Iteration 0: Loss = 2.6175696849823, Number of mined P N = 314 2545\n",
      "Epoch 19 Iteration 100: Loss = 2.3260982036590576, Number of mined P N = 314 1881\n",
      "Epoch 19 Iteration 200: Loss = 1.8735970258712769, Number of mined P N = 271 859\n",
      "Epoch 19 Iteration 300: Loss = 2.238765239715576, Number of mined P N = 300 1469\n",
      "Epoch 19 Iteration 400: Loss = 2.2625038623809814, Number of mined P N = 319 1822\n",
      "Epoch 19 Iteration 500: Loss = 2.062103271484375, Number of mined P N = 293 1349\n",
      "Epoch 19 Iteration 600: Loss = 2.2816712856292725, Number of mined P N = 309 1712\n",
      "Epoch 19 Iteration 700: Loss = 2.020564556121826, Number of mined P N = 300 1465\n",
      "Validation loss:  2.167896602153778\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 20 Iteration 0: Loss = 1.9766958951950073, Number of mined P N = 257 1299\n",
      "Epoch 20 Iteration 100: Loss = 2.0855891704559326, Number of mined P N = 256 1472\n",
      "Epoch 20 Iteration 200: Loss = 2.3098907470703125, Number of mined P N = 287 1958\n",
      "Epoch 20 Iteration 300: Loss = 2.242924451828003, Number of mined P N = 260 1442\n",
      "Epoch 20 Iteration 400: Loss = 2.1551780700683594, Number of mined P N = 312 1750\n",
      "Epoch 20 Iteration 500: Loss = 2.073761224746704, Number of mined P N = 285 1250\n",
      "Epoch 20 Iteration 600: Loss = 1.9999058246612549, Number of mined P N = 253 1156\n",
      "Epoch 20 Iteration 700: Loss = 2.1561760902404785, Number of mined P N = 296 1697\n",
      "Validation loss:  2.1643691182136537\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 21 Iteration 0: Loss = 1.9709930419921875, Number of mined P N = 257 1154\n",
      "Epoch 21 Iteration 100: Loss = 1.8505841493606567, Number of mined P N = 268 995\n",
      "Epoch 21 Iteration 200: Loss = 2.211236000061035, Number of mined P N = 285 1427\n",
      "Epoch 21 Iteration 300: Loss = 2.1842153072357178, Number of mined P N = 272 1474\n",
      "Epoch 21 Iteration 400: Loss = 1.992893099784851, Number of mined P N = 274 1134\n",
      "Epoch 21 Iteration 500: Loss = 2.112046957015991, Number of mined P N = 292 1467\n",
      "Epoch 21 Iteration 600: Loss = 2.1235833168029785, Number of mined P N = 261 1522\n",
      "Epoch 21 Iteration 700: Loss = 2.211555242538452, Number of mined P N = 291 1523\n",
      "Validation loss:  2.143043761253357\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 22 Iteration 0: Loss = 2.137686014175415, Number of mined P N = 253 1512\n",
      "Epoch 22 Iteration 100: Loss = 1.9313462972640991, Number of mined P N = 236 1204\n",
      "Epoch 22 Iteration 200: Loss = 1.9018810987472534, Number of mined P N = 256 1090\n",
      "Epoch 22 Iteration 300: Loss = 2.010335922241211, Number of mined P N = 271 1325\n",
      "Epoch 22 Iteration 400: Loss = 2.3021459579467773, Number of mined P N = 305 1659\n",
      "Epoch 22 Iteration 500: Loss = 2.1309030055999756, Number of mined P N = 325 1549\n",
      "Epoch 22 Iteration 600: Loss = 2.379537343978882, Number of mined P N = 289 1914\n",
      "Epoch 22 Iteration 700: Loss = 1.9584441184997559, Number of mined P N = 265 1096\n",
      "Validation loss:  2.064620056152344\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 23 Iteration 0: Loss = 1.9941356182098389, Number of mined P N = 251 1100\n",
      "Epoch 23 Iteration 100: Loss = 2.1380062103271484, Number of mined P N = 314 1465\n",
      "Epoch 23 Iteration 200: Loss = 2.188133478164673, Number of mined P N = 316 1631\n",
      "Epoch 23 Iteration 300: Loss = 2.0691370964050293, Number of mined P N = 284 1418\n",
      "Epoch 23 Iteration 400: Loss = 2.2681658267974854, Number of mined P N = 270 1343\n",
      "Epoch 23 Iteration 500: Loss = 2.0918686389923096, Number of mined P N = 258 1245\n",
      "Epoch 23 Iteration 600: Loss = 2.124173641204834, Number of mined P N = 284 1535\n",
      "Epoch 23 Iteration 700: Loss = 1.9441735744476318, Number of mined P N = 275 1263\n",
      "Validation loss:  2.1045592331886294\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 24 Iteration 0: Loss = 2.1443448066711426, Number of mined P N = 287 1545\n",
      "Epoch 24 Iteration 100: Loss = 1.8427493572235107, Number of mined P N = 280 894\n",
      "Epoch 24 Iteration 200: Loss = 2.208035945892334, Number of mined P N = 268 1404\n",
      "Epoch 24 Iteration 300: Loss = 1.9300473928451538, Number of mined P N = 260 1113\n",
      "Epoch 24 Iteration 400: Loss = 2.425435781478882, Number of mined P N = 300 2197\n",
      "Epoch 24 Iteration 500: Loss = 2.010061264038086, Number of mined P N = 300 1346\n",
      "Epoch 24 Iteration 600: Loss = 2.0748343467712402, Number of mined P N = 250 1207\n",
      "Epoch 24 Iteration 700: Loss = 2.222792148590088, Number of mined P N = 288 1423\n",
      "Validation loss:  2.1035183763504026\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 25 Iteration 0: Loss = 2.23659610748291, Number of mined P N = 287 1446\n",
      "Epoch 25 Iteration 100: Loss = 2.1456620693206787, Number of mined P N = 272 1542\n",
      "Epoch 25 Iteration 200: Loss = 1.8169461488723755, Number of mined P N = 200 999\n",
      "Epoch 25 Iteration 300: Loss = 2.180147647857666, Number of mined P N = 288 1506\n",
      "Epoch 25 Iteration 400: Loss = 2.2684109210968018, Number of mined P N = 296 1501\n",
      "Epoch 25 Iteration 500: Loss = 2.151334524154663, Number of mined P N = 276 1617\n",
      "Epoch 25 Iteration 600: Loss = 2.069397211074829, Number of mined P N = 270 1197\n",
      "Epoch 25 Iteration 700: Loss = 1.8164104223251343, Number of mined P N = 248 1067\n",
      "Validation loss:  2.08736172914505\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 26 Iteration 0: Loss = 2.1287527084350586, Number of mined P N = 270 1539\n",
      "Epoch 26 Iteration 100: Loss = 2.11790132522583, Number of mined P N = 273 1359\n",
      "Epoch 26 Iteration 200: Loss = 1.7399970293045044, Number of mined P N = 250 817\n",
      "Epoch 26 Iteration 300: Loss = 2.2920448780059814, Number of mined P N = 294 2119\n",
      "Epoch 26 Iteration 400: Loss = 1.9030640125274658, Number of mined P N = 269 977\n",
      "Epoch 26 Iteration 500: Loss = 1.7228456735610962, Number of mined P N = 224 869\n",
      "Epoch 26 Iteration 600: Loss = 1.8491833209991455, Number of mined P N = 246 1079\n",
      "Epoch 26 Iteration 700: Loss = 2.1789612770080566, Number of mined P N = 302 1749\n",
      "Validation loss:  2.043195140361786\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 27 Iteration 0: Loss = 1.8570636510849, Number of mined P N = 247 1143\n",
      "Epoch 27 Iteration 100: Loss = 2.4898691177368164, Number of mined P N = 311 2238\n",
      "Epoch 27 Iteration 200: Loss = 1.8961671590805054, Number of mined P N = 267 1034\n",
      "Epoch 27 Iteration 300: Loss = 2.0636351108551025, Number of mined P N = 267 1165\n",
      "Epoch 27 Iteration 400: Loss = 1.9949796199798584, Number of mined P N = 257 1057\n",
      "Epoch 27 Iteration 500: Loss = 2.1571898460388184, Number of mined P N = 302 1439\n",
      "Epoch 27 Iteration 600: Loss = 2.1246843338012695, Number of mined P N = 283 1309\n",
      "Epoch 27 Iteration 700: Loss = 2.0529251098632812, Number of mined P N = 266 1139\n",
      "Validation loss:  1.9924786591529846\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 28 Iteration 0: Loss = 1.9826576709747314, Number of mined P N = 283 1376\n",
      "Epoch 28 Iteration 100: Loss = 2.0986204147338867, Number of mined P N = 287 1410\n",
      "Epoch 28 Iteration 200: Loss = 2.0192418098449707, Number of mined P N = 237 1035\n",
      "Epoch 28 Iteration 300: Loss = 2.0197031497955322, Number of mined P N = 241 1181\n",
      "Epoch 28 Iteration 400: Loss = 2.318150043487549, Number of mined P N = 301 1672\n",
      "Epoch 28 Iteration 500: Loss = 2.249906063079834, Number of mined P N = 280 1582\n",
      "Epoch 28 Iteration 600: Loss = 2.223724603652954, Number of mined P N = 289 1379\n",
      "Epoch 28 Iteration 700: Loss = 1.9634358882904053, Number of mined P N = 283 1149\n",
      "Validation loss:  2.0335128021240236\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 29 Iteration 0: Loss = 2.0633535385131836, Number of mined P N = 239 1254\n",
      "Epoch 29 Iteration 100: Loss = 2.1347720623016357, Number of mined P N = 256 1281\n",
      "Epoch 29 Iteration 200: Loss = 2.030121088027954, Number of mined P N = 283 1327\n",
      "Epoch 29 Iteration 300: Loss = 2.2488210201263428, Number of mined P N = 279 1560\n",
      "Epoch 29 Iteration 400: Loss = 1.8533800840377808, Number of mined P N = 262 1011\n",
      "Epoch 29 Iteration 500: Loss = 1.9664710760116577, Number of mined P N = 279 1001\n",
      "Epoch 29 Iteration 600: Loss = 1.9116878509521484, Number of mined P N = 216 1132\n",
      "Epoch 29 Iteration 700: Loss = 1.8622863292694092, Number of mined P N = 262 931\n",
      "Validation loss:  2.028807005882263\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 30 Iteration 0: Loss = 1.8479835987091064, Number of mined P N = 271 1004\n",
      "Epoch 30 Iteration 100: Loss = 2.0285134315490723, Number of mined P N = 261 1117\n",
      "Epoch 30 Iteration 200: Loss = 2.0264830589294434, Number of mined P N = 278 1159\n",
      "Epoch 30 Iteration 300: Loss = 1.921544075012207, Number of mined P N = 234 1240\n",
      "Epoch 30 Iteration 400: Loss = 2.0466480255126953, Number of mined P N = 276 1371\n",
      "Epoch 30 Iteration 500: Loss = 1.8974684476852417, Number of mined P N = 247 913\n",
      "Epoch 30 Iteration 600: Loss = 2.035628080368042, Number of mined P N = 249 1223\n",
      "Epoch 30 Iteration 700: Loss = 1.9953621625900269, Number of mined P N = 241 1079\n",
      "Validation loss:  1.9873654532432556\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 31 Iteration 0: Loss = 2.001185417175293, Number of mined P N = 260 1099\n",
      "Epoch 31 Iteration 100: Loss = 2.1381962299346924, Number of mined P N = 250 1261\n",
      "Epoch 31 Iteration 200: Loss = 1.842345118522644, Number of mined P N = 257 996\n",
      "Epoch 31 Iteration 300: Loss = 2.0412604808807373, Number of mined P N = 271 1074\n",
      "Epoch 31 Iteration 400: Loss = 2.064155340194702, Number of mined P N = 249 1111\n",
      "Epoch 31 Iteration 500: Loss = 1.9569135904312134, Number of mined P N = 270 986\n",
      "Epoch 31 Iteration 600: Loss = 1.8646937608718872, Number of mined P N = 284 1036\n",
      "Epoch 31 Iteration 700: Loss = 2.0956010818481445, Number of mined P N = 284 1278\n",
      "Validation loss:  1.9824678921699523\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 32 Iteration 0: Loss = 1.7736132144927979, Number of mined P N = 234 731\n",
      "Epoch 32 Iteration 100: Loss = 2.0347607135772705, Number of mined P N = 268 1279\n",
      "Epoch 32 Iteration 200: Loss = 1.7892990112304688, Number of mined P N = 267 806\n",
      "Epoch 32 Iteration 300: Loss = 1.8169255256652832, Number of mined P N = 274 909\n",
      "Epoch 32 Iteration 400: Loss = 2.3335540294647217, Number of mined P N = 282 1791\n",
      "Epoch 32 Iteration 500: Loss = 1.9651283025741577, Number of mined P N = 247 1075\n",
      "Epoch 32 Iteration 600: Loss = 2.1327784061431885, Number of mined P N = 283 1628\n",
      "Epoch 32 Iteration 700: Loss = 2.0681324005126953, Number of mined P N = 233 1249\n",
      "Validation loss:  1.9307047843933105\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 33 Iteration 0: Loss = 1.8644013404846191, Number of mined P N = 244 936\n",
      "Epoch 33 Iteration 100: Loss = 1.854506015777588, Number of mined P N = 265 979\n",
      "Epoch 33 Iteration 200: Loss = 1.9799950122833252, Number of mined P N = 235 957\n",
      "Epoch 33 Iteration 300: Loss = 2.2589263916015625, Number of mined P N = 283 1582\n",
      "Epoch 33 Iteration 400: Loss = 2.1759321689605713, Number of mined P N = 283 1297\n",
      "Epoch 33 Iteration 500: Loss = 1.8360675573349, Number of mined P N = 254 834\n",
      "Epoch 33 Iteration 600: Loss = 2.1784799098968506, Number of mined P N = 255 1323\n",
      "Epoch 33 Iteration 700: Loss = 2.1265907287597656, Number of mined P N = 276 1327\n",
      "Validation loss:  1.9339546322822572\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 34 Iteration 0: Loss = 1.8194462060928345, Number of mined P N = 244 954\n",
      "Epoch 34 Iteration 100: Loss = 1.833918571472168, Number of mined P N = 255 894\n",
      "Epoch 34 Iteration 200: Loss = 2.00760817527771, Number of mined P N = 258 1168\n",
      "Epoch 34 Iteration 300: Loss = 1.64718759059906, Number of mined P N = 225 785\n",
      "Epoch 34 Iteration 400: Loss = 1.888777256011963, Number of mined P N = 259 1116\n",
      "Epoch 34 Iteration 500: Loss = 1.8638157844543457, Number of mined P N = 236 1034\n",
      "Epoch 34 Iteration 600: Loss = 1.7180083990097046, Number of mined P N = 234 818\n",
      "Epoch 34 Iteration 700: Loss = 2.02003812789917, Number of mined P N = 281 1315\n",
      "Validation loss:  1.9345291447639466\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 35 Iteration 0: Loss = 1.7936480045318604, Number of mined P N = 229 1038\n",
      "Epoch 35 Iteration 100: Loss = 1.7160115242004395, Number of mined P N = 244 730\n",
      "Epoch 35 Iteration 200: Loss = 2.133179187774658, Number of mined P N = 247 1337\n",
      "Epoch 35 Iteration 300: Loss = 2.1500966548919678, Number of mined P N = 252 1319\n",
      "Epoch 35 Iteration 400: Loss = 1.9934390783309937, Number of mined P N = 269 1385\n",
      "Epoch 35 Iteration 500: Loss = 1.981186866760254, Number of mined P N = 229 973\n",
      "Epoch 35 Iteration 600: Loss = 1.7358289957046509, Number of mined P N = 233 843\n",
      "Epoch 35 Iteration 700: Loss = 2.141918659210205, Number of mined P N = 234 1306\n",
      "Validation loss:  1.8949791550636292\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 36 Iteration 0: Loss = 1.9084951877593994, Number of mined P N = 254 930\n",
      "Epoch 36 Iteration 100: Loss = 1.8668087720870972, Number of mined P N = 258 873\n",
      "Epoch 36 Iteration 200: Loss = 1.9229586124420166, Number of mined P N = 244 752\n",
      "Epoch 36 Iteration 300: Loss = 1.8601115942001343, Number of mined P N = 235 1161\n",
      "Epoch 36 Iteration 400: Loss = 1.7430994510650635, Number of mined P N = 245 905\n",
      "Epoch 36 Iteration 500: Loss = 1.8872157335281372, Number of mined P N = 215 1015\n",
      "Epoch 36 Iteration 600: Loss = 1.6585043668746948, Number of mined P N = 218 670\n",
      "Epoch 36 Iteration 700: Loss = 1.879634976387024, Number of mined P N = 270 1142\n",
      "Validation loss:  1.876134717464447\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 37 Iteration 0: Loss = 2.467839479446411, Number of mined P N = 227 1739\n",
      "Epoch 37 Iteration 100: Loss = 1.74069082736969, Number of mined P N = 245 694\n",
      "Epoch 37 Iteration 200: Loss = 1.9103537797927856, Number of mined P N = 229 1048\n",
      "Epoch 37 Iteration 300: Loss = 1.740411639213562, Number of mined P N = 227 643\n",
      "Epoch 37 Iteration 400: Loss = 2.019191265106201, Number of mined P N = 221 1004\n",
      "Epoch 37 Iteration 500: Loss = 1.8455781936645508, Number of mined P N = 226 838\n",
      "Epoch 37 Iteration 600: Loss = 1.9113671779632568, Number of mined P N = 248 968\n",
      "Epoch 37 Iteration 700: Loss = 1.8348690271377563, Number of mined P N = 250 838\n",
      "Validation loss:  1.8704084801673888\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 38 Iteration 0: Loss = 2.1680781841278076, Number of mined P N = 249 1395\n",
      "Epoch 38 Iteration 100: Loss = 1.8216830492019653, Number of mined P N = 229 828\n",
      "Epoch 38 Iteration 200: Loss = 1.981373906135559, Number of mined P N = 210 927\n",
      "Epoch 38 Iteration 300: Loss = 1.495535135269165, Number of mined P N = 207 560\n",
      "Epoch 38 Iteration 400: Loss = 1.9745416641235352, Number of mined P N = 240 972\n",
      "Epoch 38 Iteration 500: Loss = 1.6588776111602783, Number of mined P N = 206 721\n",
      "Epoch 38 Iteration 600: Loss = 1.5542062520980835, Number of mined P N = 205 548\n",
      "Epoch 38 Iteration 700: Loss = 1.9715873003005981, Number of mined P N = 238 1082\n",
      "Validation loss:  1.9343570399284362\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 39 Iteration 0: Loss = 2.0755457878112793, Number of mined P N = 278 1173\n",
      "Epoch 39 Iteration 100: Loss = 2.0049831867218018, Number of mined P N = 233 1013\n",
      "Epoch 39 Iteration 200: Loss = 1.7665997743606567, Number of mined P N = 240 1049\n",
      "Epoch 39 Iteration 300: Loss = 1.8328489065170288, Number of mined P N = 207 1143\n",
      "Epoch 39 Iteration 400: Loss = 2.006938934326172, Number of mined P N = 220 1082\n",
      "Epoch 39 Iteration 500: Loss = 1.786166787147522, Number of mined P N = 257 1020\n",
      "Epoch 39 Iteration 600: Loss = 2.1405537128448486, Number of mined P N = 252 1291\n",
      "Epoch 39 Iteration 700: Loss = 2.186488389968872, Number of mined P N = 256 1242\n",
      "Validation loss:  1.8884193873405457\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 40 Iteration 0: Loss = 1.8588321208953857, Number of mined P N = 249 825\n",
      "Epoch 40 Iteration 100: Loss = 2.065589427947998, Number of mined P N = 268 1455\n",
      "Epoch 40 Iteration 200: Loss = 1.530871868133545, Number of mined P N = 208 674\n",
      "Epoch 40 Iteration 300: Loss = 1.747421383857727, Number of mined P N = 270 834\n",
      "Epoch 40 Iteration 400: Loss = 1.9048014879226685, Number of mined P N = 265 994\n",
      "Epoch 40 Iteration 500: Loss = 1.6235049962997437, Number of mined P N = 189 619\n",
      "Epoch 40 Iteration 600: Loss = 2.1771035194396973, Number of mined P N = 285 1395\n",
      "Epoch 40 Iteration 700: Loss = 2.047638416290283, Number of mined P N = 233 1325\n",
      "Validation loss:  1.8771623992919921\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 41 Iteration 0: Loss = 1.8048787117004395, Number of mined P N = 224 809\n",
      "Epoch 41 Iteration 100: Loss = 2.0497543811798096, Number of mined P N = 254 1005\n",
      "Epoch 41 Iteration 200: Loss = 2.074533700942993, Number of mined P N = 250 1286\n",
      "Epoch 41 Iteration 300: Loss = 1.8462578058242798, Number of mined P N = 215 801\n",
      "Epoch 41 Iteration 400: Loss = 1.6311657428741455, Number of mined P N = 200 674\n",
      "Epoch 41 Iteration 500: Loss = 1.6747164726257324, Number of mined P N = 220 655\n",
      "Epoch 41 Iteration 600: Loss = 1.8032057285308838, Number of mined P N = 245 876\n",
      "Epoch 41 Iteration 700: Loss = 1.5398471355438232, Number of mined P N = 186 589\n",
      "Validation loss:  1.8918688344955443\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 42 Iteration 0: Loss = 1.8422374725341797, Number of mined P N = 230 944\n",
      "Epoch 42 Iteration 100: Loss = 1.8994462490081787, Number of mined P N = 248 889\n",
      "Epoch 42 Iteration 200: Loss = 1.7961770296096802, Number of mined P N = 189 681\n",
      "Epoch 42 Iteration 300: Loss = 1.688218116760254, Number of mined P N = 240 717\n",
      "Epoch 42 Iteration 400: Loss = 1.948952317237854, Number of mined P N = 268 1103\n",
      "Epoch 42 Iteration 500: Loss = 1.9446754455566406, Number of mined P N = 245 1142\n",
      "Epoch 42 Iteration 600: Loss = 1.7237591743469238, Number of mined P N = 196 571\n",
      "Epoch 42 Iteration 700: Loss = 2.029367208480835, Number of mined P N = 259 1123\n",
      "Validation loss:  1.8531465172767638\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 43 Iteration 0: Loss = 2.0783257484436035, Number of mined P N = 284 1382\n",
      "Epoch 43 Iteration 100: Loss = 1.8945434093475342, Number of mined P N = 269 1022\n",
      "Epoch 43 Iteration 200: Loss = 1.593308925628662, Number of mined P N = 199 533\n",
      "Epoch 43 Iteration 300: Loss = 1.8848365545272827, Number of mined P N = 257 963\n",
      "Epoch 43 Iteration 400: Loss = 1.8530516624450684, Number of mined P N = 216 768\n",
      "Epoch 43 Iteration 500: Loss = 1.695419192314148, Number of mined P N = 227 598\n",
      "Epoch 43 Iteration 600: Loss = 1.927156925201416, Number of mined P N = 256 951\n",
      "Epoch 43 Iteration 700: Loss = 2.008068799972534, Number of mined P N = 248 1025\n",
      "Validation loss:  1.8432429718971253\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 44 Iteration 0: Loss = 2.017190456390381, Number of mined P N = 232 1204\n",
      "Epoch 44 Iteration 100: Loss = 1.8418636322021484, Number of mined P N = 286 1030\n",
      "Epoch 44 Iteration 200: Loss = 1.7737388610839844, Number of mined P N = 252 812\n",
      "Epoch 44 Iteration 300: Loss = 1.71188223361969, Number of mined P N = 239 788\n",
      "Epoch 44 Iteration 400: Loss = 1.8148677349090576, Number of mined P N = 215 718\n",
      "Epoch 44 Iteration 500: Loss = 1.7590000629425049, Number of mined P N = 233 823\n",
      "Epoch 44 Iteration 600: Loss = 1.9970908164978027, Number of mined P N = 224 973\n",
      "Epoch 44 Iteration 700: Loss = 2.162625312805176, Number of mined P N = 245 1348\n",
      "Validation loss:  1.850559859275818\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 45 Iteration 0: Loss = 1.617817997932434, Number of mined P N = 252 605\n",
      "Epoch 45 Iteration 100: Loss = 1.8003188371658325, Number of mined P N = 230 801\n",
      "Epoch 45 Iteration 200: Loss = 1.9449896812438965, Number of mined P N = 267 953\n",
      "Epoch 45 Iteration 300: Loss = 1.8747055530548096, Number of mined P N = 246 836\n",
      "Epoch 45 Iteration 400: Loss = 1.9978342056274414, Number of mined P N = 257 1203\n",
      "Epoch 45 Iteration 500: Loss = 1.891793131828308, Number of mined P N = 251 1079\n",
      "Epoch 45 Iteration 600: Loss = 1.6049933433532715, Number of mined P N = 216 583\n",
      "Epoch 45 Iteration 700: Loss = 1.716122031211853, Number of mined P N = 231 743\n",
      "Validation loss:  1.8247794103622437\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 46 Iteration 0: Loss = 1.6353118419647217, Number of mined P N = 244 662\n",
      "Epoch 46 Iteration 100: Loss = 1.9102551937103271, Number of mined P N = 243 987\n",
      "Epoch 46 Iteration 200: Loss = 1.6129214763641357, Number of mined P N = 210 675\n",
      "Epoch 46 Iteration 300: Loss = 2.0984206199645996, Number of mined P N = 228 1163\n",
      "Epoch 46 Iteration 400: Loss = 1.738599181175232, Number of mined P N = 175 570\n",
      "Epoch 46 Iteration 500: Loss = 1.932295322418213, Number of mined P N = 270 1032\n",
      "Epoch 46 Iteration 600: Loss = 1.9307019710540771, Number of mined P N = 240 997\n",
      "Epoch 46 Iteration 700: Loss = 1.908128261566162, Number of mined P N = 204 976\n",
      "Validation loss:  1.8162644171714784\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 47 Iteration 0: Loss = 1.589335322380066, Number of mined P N = 204 616\n",
      "Epoch 47 Iteration 100: Loss = 2.142857789993286, Number of mined P N = 280 1418\n",
      "Epoch 47 Iteration 200: Loss = 1.9134657382965088, Number of mined P N = 215 1045\n",
      "Epoch 47 Iteration 300: Loss = 1.825434923171997, Number of mined P N = 260 809\n",
      "Epoch 47 Iteration 400: Loss = 1.6303726434707642, Number of mined P N = 192 663\n",
      "Epoch 47 Iteration 500: Loss = 1.923675298690796, Number of mined P N = 245 998\n",
      "Epoch 47 Iteration 600: Loss = 1.5571990013122559, Number of mined P N = 177 614\n",
      "Epoch 47 Iteration 700: Loss = 1.7927793264389038, Number of mined P N = 228 861\n",
      "Validation loss:  1.7965190315246582\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 48 Iteration 0: Loss = 1.9291163682937622, Number of mined P N = 236 804\n",
      "Epoch 48 Iteration 100: Loss = 1.6061567068099976, Number of mined P N = 213 777\n",
      "Epoch 48 Iteration 200: Loss = 1.5790185928344727, Number of mined P N = 220 462\n",
      "Epoch 48 Iteration 300: Loss = 1.746798038482666, Number of mined P N = 239 841\n",
      "Epoch 48 Iteration 400: Loss = 1.7966043949127197, Number of mined P N = 216 906\n",
      "Epoch 48 Iteration 500: Loss = 1.9398210048675537, Number of mined P N = 215 967\n",
      "Epoch 48 Iteration 600: Loss = 2.154858112335205, Number of mined P N = 226 1363\n",
      "Epoch 48 Iteration 700: Loss = 1.8853453397750854, Number of mined P N = 204 725\n",
      "Validation loss:  1.8344049096107482\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 49 Iteration 0: Loss = 1.63009512424469, Number of mined P N = 209 522\n",
      "Epoch 49 Iteration 100: Loss = 1.7862024307250977, Number of mined P N = 211 829\n",
      "Epoch 49 Iteration 200: Loss = 1.9785972833633423, Number of mined P N = 256 959\n",
      "Epoch 49 Iteration 300: Loss = 2.1101973056793213, Number of mined P N = 246 1163\n",
      "Epoch 49 Iteration 400: Loss = 1.6924067735671997, Number of mined P N = 203 629\n",
      "Epoch 49 Iteration 500: Loss = 1.8467012643814087, Number of mined P N = 197 714\n",
      "Epoch 49 Iteration 600: Loss = 1.6410878896713257, Number of mined P N = 224 614\n",
      "Epoch 49 Iteration 700: Loss = 1.8989087343215942, Number of mined P N = 213 1113\n",
      "Validation loss:  1.804410207271576\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 50 Iteration 0: Loss = 1.8027769327163696, Number of mined P N = 237 830\n",
      "Epoch 50 Iteration 100: Loss = 1.5787811279296875, Number of mined P N = 194 622\n",
      "Epoch 50 Iteration 200: Loss = 1.6715947389602661, Number of mined P N = 191 580\n",
      "Epoch 50 Iteration 300: Loss = 1.9083911180496216, Number of mined P N = 211 915\n",
      "Epoch 50 Iteration 400: Loss = 1.8333982229232788, Number of mined P N = 233 854\n",
      "Epoch 50 Iteration 500: Loss = 1.8756824731826782, Number of mined P N = 261 895\n",
      "Epoch 50 Iteration 600: Loss = 1.9670448303222656, Number of mined P N = 268 1133\n",
      "Epoch 50 Iteration 700: Loss = 1.9144929647445679, Number of mined P N = 237 934\n",
      "Validation loss:  1.7997630643844604\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 51 Iteration 0: Loss = 1.8849056959152222, Number of mined P N = 245 925\n",
      "Epoch 51 Iteration 100: Loss = 1.822688341140747, Number of mined P N = 257 827\n",
      "Epoch 51 Iteration 200: Loss = 1.7534270286560059, Number of mined P N = 243 671\n",
      "Epoch 51 Iteration 300: Loss = 1.5313076972961426, Number of mined P N = 205 712\n",
      "Epoch 51 Iteration 400: Loss = 1.8835077285766602, Number of mined P N = 227 1023\n",
      "Epoch 51 Iteration 500: Loss = 1.5408985614776611, Number of mined P N = 223 499\n",
      "Epoch 51 Iteration 600: Loss = 1.7909772396087646, Number of mined P N = 237 883\n",
      "Epoch 51 Iteration 700: Loss = 1.7062169313430786, Number of mined P N = 219 710\n",
      "Validation loss:  1.7625834774971008\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 52 Iteration 0: Loss = 2.0140223503112793, Number of mined P N = 215 974\n",
      "Epoch 52 Iteration 100: Loss = 1.8013890981674194, Number of mined P N = 234 790\n",
      "Epoch 52 Iteration 200: Loss = 1.7487215995788574, Number of mined P N = 177 709\n",
      "Epoch 52 Iteration 300: Loss = 1.6318553686141968, Number of mined P N = 188 599\n",
      "Epoch 52 Iteration 400: Loss = 1.7602180242538452, Number of mined P N = 189 682\n",
      "Epoch 52 Iteration 500: Loss = 1.8887237310409546, Number of mined P N = 224 1268\n",
      "Epoch 52 Iteration 600: Loss = 1.5838454961776733, Number of mined P N = 204 576\n",
      "Epoch 52 Iteration 700: Loss = 1.933950662612915, Number of mined P N = 196 857\n",
      "Validation loss:  1.7629758310317993\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 53 Iteration 0: Loss = 1.8471863269805908, Number of mined P N = 205 711\n",
      "Epoch 53 Iteration 100: Loss = 1.982101321220398, Number of mined P N = 213 1109\n",
      "Epoch 53 Iteration 200: Loss = 1.755786657333374, Number of mined P N = 221 844\n",
      "Epoch 53 Iteration 300: Loss = 1.849137544631958, Number of mined P N = 263 912\n",
      "Epoch 53 Iteration 400: Loss = 1.6509150266647339, Number of mined P N = 192 535\n",
      "Epoch 53 Iteration 500: Loss = 1.6140613555908203, Number of mined P N = 199 709\n",
      "Epoch 53 Iteration 600: Loss = 1.7092491388320923, Number of mined P N = 212 577\n",
      "Epoch 53 Iteration 700: Loss = 1.5771363973617554, Number of mined P N = 218 583\n",
      "Validation loss:  1.7663626599311828\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 54 Iteration 0: Loss = 1.7285274267196655, Number of mined P N = 196 586\n",
      "Epoch 54 Iteration 100: Loss = 1.917722225189209, Number of mined P N = 237 893\n",
      "Epoch 54 Iteration 200: Loss = 1.9645698070526123, Number of mined P N = 234 1046\n",
      "Epoch 54 Iteration 300: Loss = 1.6151851415634155, Number of mined P N = 211 728\n",
      "Epoch 54 Iteration 400: Loss = 1.58768630027771, Number of mined P N = 159 504\n",
      "Epoch 54 Iteration 500: Loss = 1.6772323846817017, Number of mined P N = 254 772\n",
      "Epoch 54 Iteration 600: Loss = 1.8229068517684937, Number of mined P N = 215 855\n",
      "Epoch 54 Iteration 700: Loss = 1.6780637502670288, Number of mined P N = 210 802\n",
      "Validation loss:  1.8079000639915466\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 55 Iteration 0: Loss = 1.9446653127670288, Number of mined P N = 261 1100\n",
      "Epoch 55 Iteration 100: Loss = 1.602080225944519, Number of mined P N = 207 597\n",
      "Epoch 55 Iteration 200: Loss = 1.7653712034225464, Number of mined P N = 239 896\n",
      "Epoch 55 Iteration 300: Loss = 1.7660444974899292, Number of mined P N = 225 862\n",
      "Epoch 55 Iteration 400: Loss = 1.8100486993789673, Number of mined P N = 219 755\n",
      "Epoch 55 Iteration 500: Loss = 1.4501417875289917, Number of mined P N = 188 493\n",
      "Epoch 55 Iteration 600: Loss = 1.7513320446014404, Number of mined P N = 271 837\n",
      "Epoch 55 Iteration 700: Loss = 1.869357705116272, Number of mined P N = 230 877\n",
      "Validation loss:  1.756504168510437\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 56 Iteration 0: Loss = 1.9725645780563354, Number of mined P N = 193 1061\n",
      "Epoch 56 Iteration 100: Loss = 1.7906763553619385, Number of mined P N = 219 941\n",
      "Epoch 56 Iteration 200: Loss = 1.8820687532424927, Number of mined P N = 250 914\n",
      "Epoch 56 Iteration 300: Loss = 1.610081672668457, Number of mined P N = 203 569\n",
      "Epoch 56 Iteration 400: Loss = 1.4025152921676636, Number of mined P N = 167 366\n",
      "Epoch 56 Iteration 500: Loss = 1.889747977256775, Number of mined P N = 207 963\n",
      "Epoch 56 Iteration 600: Loss = 1.8197541236877441, Number of mined P N = 208 754\n",
      "Epoch 56 Iteration 700: Loss = 2.1070473194122314, Number of mined P N = 207 990\n",
      "Validation loss:  1.75980979681015\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 57 Iteration 0: Loss = 1.7177894115447998, Number of mined P N = 221 905\n",
      "Epoch 57 Iteration 100: Loss = 1.6088078022003174, Number of mined P N = 191 504\n",
      "Epoch 57 Iteration 200: Loss = 1.7280499935150146, Number of mined P N = 243 778\n",
      "Epoch 57 Iteration 300: Loss = 1.6249572038650513, Number of mined P N = 185 618\n",
      "Epoch 57 Iteration 400: Loss = 1.5727227926254272, Number of mined P N = 190 536\n",
      "Epoch 57 Iteration 500: Loss = 1.9132503271102905, Number of mined P N = 216 815\n",
      "Epoch 57 Iteration 600: Loss = 1.7324942350387573, Number of mined P N = 211 692\n",
      "Epoch 57 Iteration 700: Loss = 1.952085256576538, Number of mined P N = 225 1151\n",
      "Validation loss:  1.768846561908722\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 58 Iteration 0: Loss = 1.9204018115997314, Number of mined P N = 241 835\n",
      "Epoch 58 Iteration 100: Loss = 1.6075429916381836, Number of mined P N = 203 720\n",
      "Epoch 58 Iteration 200: Loss = 1.8100310564041138, Number of mined P N = 217 824\n",
      "Epoch 58 Iteration 300: Loss = 1.8407491445541382, Number of mined P N = 197 922\n",
      "Epoch 58 Iteration 400: Loss = 1.645939826965332, Number of mined P N = 208 634\n",
      "Epoch 58 Iteration 500: Loss = 1.5381659269332886, Number of mined P N = 168 562\n",
      "Epoch 58 Iteration 600: Loss = 1.744131088256836, Number of mined P N = 189 666\n",
      "Epoch 58 Iteration 700: Loss = 1.9487557411193848, Number of mined P N = 210 1082\n",
      "Validation loss:  1.7237843418121337\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 59 Iteration 0: Loss = 1.7954102754592896, Number of mined P N = 221 696\n",
      "Epoch 59 Iteration 100: Loss = 2.1291897296905518, Number of mined P N = 244 1417\n",
      "Epoch 59 Iteration 200: Loss = 1.6968914270401, Number of mined P N = 216 571\n",
      "Epoch 59 Iteration 300: Loss = 1.5541937351226807, Number of mined P N = 157 431\n",
      "Epoch 59 Iteration 400: Loss = 1.864607572555542, Number of mined P N = 221 894\n",
      "Epoch 59 Iteration 500: Loss = 1.6739397048950195, Number of mined P N = 222 691\n",
      "Epoch 59 Iteration 600: Loss = 1.6009098291397095, Number of mined P N = 191 559\n",
      "Epoch 59 Iteration 700: Loss = 1.5941729545593262, Number of mined P N = 223 726\n",
      "Validation loss:  1.757732789516449\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 60 Iteration 0: Loss = 1.9848227500915527, Number of mined P N = 219 992\n",
      "Epoch 60 Iteration 100: Loss = 1.7796441316604614, Number of mined P N = 247 841\n",
      "Epoch 60 Iteration 200: Loss = 1.6193383932113647, Number of mined P N = 173 529\n",
      "Epoch 60 Iteration 300: Loss = 1.8478200435638428, Number of mined P N = 247 861\n",
      "Epoch 60 Iteration 400: Loss = 1.5391052961349487, Number of mined P N = 207 563\n",
      "Epoch 60 Iteration 500: Loss = 1.8838653564453125, Number of mined P N = 280 987\n",
      "Epoch 60 Iteration 600: Loss = 1.8699307441711426, Number of mined P N = 222 911\n",
      "Epoch 60 Iteration 700: Loss = 1.7076687812805176, Number of mined P N = 196 620\n",
      "Validation loss:  1.7432437109947205\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 61 Iteration 0: Loss = 1.4666738510131836, Number of mined P N = 163 374\n",
      "Epoch 61 Iteration 100: Loss = 1.4852924346923828, Number of mined P N = 152 407\n",
      "Epoch 61 Iteration 200: Loss = 1.5779136419296265, Number of mined P N = 183 536\n",
      "Epoch 61 Iteration 300: Loss = 1.7246654033660889, Number of mined P N = 208 717\n",
      "Epoch 61 Iteration 400: Loss = 1.9436544179916382, Number of mined P N = 251 852\n",
      "Epoch 61 Iteration 500: Loss = 1.7879520654678345, Number of mined P N = 234 756\n",
      "Epoch 61 Iteration 600: Loss = 1.93121337890625, Number of mined P N = 207 792\n",
      "Epoch 61 Iteration 700: Loss = 1.8343623876571655, Number of mined P N = 218 826\n",
      "Validation loss:  1.7212833046913147\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 62 Iteration 0: Loss = 1.599302053451538, Number of mined P N = 246 687\n",
      "Epoch 62 Iteration 100: Loss = 1.4797037839889526, Number of mined P N = 172 422\n",
      "Epoch 62 Iteration 200: Loss = 1.6061413288116455, Number of mined P N = 201 568\n",
      "Epoch 62 Iteration 300: Loss = 1.593856692314148, Number of mined P N = 165 487\n",
      "Epoch 62 Iteration 400: Loss = 1.572818398475647, Number of mined P N = 224 610\n",
      "Epoch 62 Iteration 500: Loss = 1.4674816131591797, Number of mined P N = 191 568\n",
      "Epoch 62 Iteration 600: Loss = 1.5456570386886597, Number of mined P N = 168 504\n",
      "Epoch 62 Iteration 700: Loss = 1.6087212562561035, Number of mined P N = 198 579\n",
      "Validation loss:  1.6988482332229615\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 63 Iteration 0: Loss = 1.447430968284607, Number of mined P N = 166 522\n",
      "Epoch 63 Iteration 100: Loss = 1.6384683847427368, Number of mined P N = 210 615\n",
      "Epoch 63 Iteration 200: Loss = 1.6300840377807617, Number of mined P N = 233 669\n",
      "Epoch 63 Iteration 300: Loss = 1.8286079168319702, Number of mined P N = 198 724\n",
      "Epoch 63 Iteration 400: Loss = 2.137718439102173, Number of mined P N = 242 1402\n",
      "Epoch 63 Iteration 500: Loss = 1.6079896688461304, Number of mined P N = 194 576\n",
      "Epoch 63 Iteration 600: Loss = 1.7074378728866577, Number of mined P N = 216 690\n",
      "Epoch 63 Iteration 700: Loss = 1.70163893699646, Number of mined P N = 211 641\n",
      "Validation loss:  1.7016427612304688\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 64 Iteration 0: Loss = 1.7024933099746704, Number of mined P N = 217 773\n",
      "Epoch 64 Iteration 100: Loss = 1.7589112520217896, Number of mined P N = 228 759\n",
      "Epoch 64 Iteration 200: Loss = 1.8219295740127563, Number of mined P N = 227 832\n",
      "Epoch 64 Iteration 300: Loss = 1.7406915426254272, Number of mined P N = 264 771\n",
      "Epoch 64 Iteration 400: Loss = 1.7224664688110352, Number of mined P N = 197 719\n",
      "Epoch 64 Iteration 500: Loss = 1.6580151319503784, Number of mined P N = 209 608\n",
      "Epoch 64 Iteration 600: Loss = 1.8520712852478027, Number of mined P N = 226 1034\n",
      "Epoch 64 Iteration 700: Loss = 1.4433283805847168, Number of mined P N = 174 422\n",
      "Validation loss:  1.7002906465530396\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 65 Iteration 0: Loss = 1.5712114572525024, Number of mined P N = 216 465\n",
      "Epoch 65 Iteration 100: Loss = 1.656648874282837, Number of mined P N = 230 648\n",
      "Epoch 65 Iteration 200: Loss = 1.708845853805542, Number of mined P N = 199 596\n",
      "Epoch 65 Iteration 300: Loss = 1.8276019096374512, Number of mined P N = 236 823\n",
      "Epoch 65 Iteration 400: Loss = 1.9319981336593628, Number of mined P N = 241 813\n",
      "Epoch 65 Iteration 500: Loss = 1.5975258350372314, Number of mined P N = 182 538\n",
      "Epoch 65 Iteration 600: Loss = 2.0253422260284424, Number of mined P N = 255 1123\n",
      "Epoch 65 Iteration 700: Loss = 1.672704815864563, Number of mined P N = 196 660\n",
      "Validation loss:  1.6674093341827392\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 66 Iteration 0: Loss = 1.6231424808502197, Number of mined P N = 204 566\n",
      "Epoch 66 Iteration 100: Loss = 1.5670324563980103, Number of mined P N = 196 653\n",
      "Epoch 66 Iteration 200: Loss = 1.5823744535446167, Number of mined P N = 204 592\n",
      "Epoch 66 Iteration 300: Loss = 1.8343790769577026, Number of mined P N = 210 734\n",
      "Epoch 66 Iteration 400: Loss = 1.5927280187606812, Number of mined P N = 184 543\n",
      "Epoch 66 Iteration 500: Loss = 1.7626733779907227, Number of mined P N = 223 746\n",
      "Epoch 66 Iteration 600: Loss = 1.9909982681274414, Number of mined P N = 267 1022\n",
      "Epoch 66 Iteration 700: Loss = 1.634948968887329, Number of mined P N = 189 638\n",
      "Validation loss:  1.7224338269233703\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 67 Iteration 0: Loss = 1.5600321292877197, Number of mined P N = 191 511\n",
      "Epoch 67 Iteration 100: Loss = 1.6428499221801758, Number of mined P N = 213 631\n",
      "Epoch 67 Iteration 200: Loss = 1.7136186361312866, Number of mined P N = 233 788\n",
      "Epoch 67 Iteration 300: Loss = 1.6877093315124512, Number of mined P N = 223 643\n",
      "Epoch 67 Iteration 400: Loss = 1.850036382675171, Number of mined P N = 230 881\n",
      "Epoch 67 Iteration 500: Loss = 1.979429006576538, Number of mined P N = 218 1053\n",
      "Epoch 67 Iteration 600: Loss = 1.802109718322754, Number of mined P N = 262 778\n",
      "Epoch 67 Iteration 700: Loss = 1.5625807046890259, Number of mined P N = 194 597\n",
      "Validation loss:  1.6930914092063905\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 68 Iteration 0: Loss = 1.7615506649017334, Number of mined P N = 224 789\n",
      "Epoch 68 Iteration 100: Loss = 1.771078109741211, Number of mined P N = 212 761\n",
      "Epoch 68 Iteration 200: Loss = 1.7637542486190796, Number of mined P N = 232 803\n",
      "Epoch 68 Iteration 300: Loss = 1.5490739345550537, Number of mined P N = 220 531\n",
      "Epoch 68 Iteration 400: Loss = 1.830560326576233, Number of mined P N = 242 938\n",
      "Epoch 68 Iteration 500: Loss = 1.8578479290008545, Number of mined P N = 209 812\n",
      "Epoch 68 Iteration 600: Loss = 1.6722638607025146, Number of mined P N = 214 682\n",
      "Epoch 68 Iteration 700: Loss = 1.4801157712936401, Number of mined P N = 152 426\n",
      "Validation loss:  1.7066586756706237\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 69 Iteration 0: Loss = 1.8208518028259277, Number of mined P N = 191 803\n",
      "Epoch 69 Iteration 100: Loss = 1.6319607496261597, Number of mined P N = 207 589\n",
      "Epoch 69 Iteration 200: Loss = 1.8582215309143066, Number of mined P N = 156 702\n",
      "Epoch 69 Iteration 300: Loss = 1.7583755254745483, Number of mined P N = 186 706\n",
      "Epoch 69 Iteration 400: Loss = 1.8340065479278564, Number of mined P N = 222 759\n",
      "Epoch 69 Iteration 500: Loss = 1.3965975046157837, Number of mined P N = 136 416\n",
      "Epoch 69 Iteration 600: Loss = 1.6695756912231445, Number of mined P N = 227 679\n",
      "Epoch 69 Iteration 700: Loss = 1.5393489599227905, Number of mined P N = 189 557\n",
      "Validation loss:  1.7192663979530334\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 70 Iteration 0: Loss = 1.9023786783218384, Number of mined P N = 207 1007\n",
      "Epoch 70 Iteration 100: Loss = 1.6826345920562744, Number of mined P N = 184 638\n",
      "Epoch 70 Iteration 200: Loss = 1.8063207864761353, Number of mined P N = 237 736\n",
      "Epoch 70 Iteration 300: Loss = 1.8723011016845703, Number of mined P N = 239 1011\n",
      "Epoch 70 Iteration 400: Loss = 1.394292950630188, Number of mined P N = 196 448\n",
      "Epoch 70 Iteration 500: Loss = 1.7741155624389648, Number of mined P N = 232 824\n",
      "Epoch 70 Iteration 600: Loss = 1.478434681892395, Number of mined P N = 209 558\n",
      "Epoch 70 Iteration 700: Loss = 1.8533419370651245, Number of mined P N = 238 981\n",
      "Validation loss:  1.6737504386901856\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 71 Iteration 0: Loss = 1.905714511871338, Number of mined P N = 212 937\n",
      "Epoch 71 Iteration 100: Loss = 1.6276732683181763, Number of mined P N = 150 461\n",
      "Epoch 71 Iteration 200: Loss = 1.5336483716964722, Number of mined P N = 182 547\n",
      "Epoch 71 Iteration 300: Loss = 1.972251057624817, Number of mined P N = 216 920\n",
      "Epoch 71 Iteration 400: Loss = 1.9123637676239014, Number of mined P N = 206 928\n",
      "Epoch 71 Iteration 500: Loss = 1.8184248208999634, Number of mined P N = 194 737\n",
      "Epoch 71 Iteration 600: Loss = 1.8769972324371338, Number of mined P N = 226 970\n",
      "Epoch 71 Iteration 700: Loss = 1.814617395401001, Number of mined P N = 187 775\n",
      "Validation loss:  1.700757393836975\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 72 Iteration 0: Loss = 1.6777573823928833, Number of mined P N = 222 726\n",
      "Epoch 72 Iteration 100: Loss = 1.8145508766174316, Number of mined P N = 216 846\n",
      "Epoch 72 Iteration 200: Loss = 1.8225445747375488, Number of mined P N = 197 814\n",
      "Epoch 72 Iteration 300: Loss = 1.7290986776351929, Number of mined P N = 172 694\n",
      "Epoch 72 Iteration 400: Loss = 1.6505117416381836, Number of mined P N = 225 663\n",
      "Epoch 72 Iteration 500: Loss = 1.8055881261825562, Number of mined P N = 214 686\n",
      "Epoch 72 Iteration 600: Loss = 1.5496889352798462, Number of mined P N = 167 462\n",
      "Epoch 72 Iteration 700: Loss = 1.728291392326355, Number of mined P N = 192 717\n",
      "Validation loss:  1.6504792666435242\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 73 Iteration 0: Loss = 1.9418554306030273, Number of mined P N = 252 938\n",
      "Epoch 73 Iteration 100: Loss = 1.7664785385131836, Number of mined P N = 231 773\n",
      "Epoch 73 Iteration 200: Loss = 1.6624476909637451, Number of mined P N = 188 574\n",
      "Epoch 73 Iteration 300: Loss = 1.5556927919387817, Number of mined P N = 153 436\n",
      "Epoch 73 Iteration 400: Loss = 1.4602365493774414, Number of mined P N = 177 411\n",
      "Epoch 73 Iteration 500: Loss = 2.063913345336914, Number of mined P N = 244 1077\n",
      "Epoch 73 Iteration 600: Loss = 1.7401031255722046, Number of mined P N = 179 726\n",
      "Epoch 73 Iteration 700: Loss = 1.5041438341140747, Number of mined P N = 162 619\n",
      "Validation loss:  1.6383195638656616\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 74 Iteration 0: Loss = 1.7539514303207397, Number of mined P N = 202 755\n",
      "Epoch 74 Iteration 100: Loss = 1.4474433660507202, Number of mined P N = 142 413\n",
      "Epoch 74 Iteration 200: Loss = 1.7206040620803833, Number of mined P N = 216 779\n",
      "Epoch 74 Iteration 300: Loss = 1.8256471157073975, Number of mined P N = 230 795\n",
      "Epoch 74 Iteration 400: Loss = 1.843885898590088, Number of mined P N = 224 675\n",
      "Epoch 74 Iteration 500: Loss = 1.496249794960022, Number of mined P N = 198 529\n",
      "Epoch 74 Iteration 600: Loss = 1.6587389707565308, Number of mined P N = 203 617\n",
      "Epoch 74 Iteration 700: Loss = 1.5576289892196655, Number of mined P N = 214 520\n",
      "Validation loss:  1.660372145175934\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 75 Iteration 0: Loss = 1.7790473699569702, Number of mined P N = 228 738\n",
      "Epoch 75 Iteration 100: Loss = 1.6613713502883911, Number of mined P N = 150 520\n",
      "Epoch 75 Iteration 200: Loss = 1.7447694540023804, Number of mined P N = 230 684\n",
      "Epoch 75 Iteration 300: Loss = 1.6812487840652466, Number of mined P N = 199 601\n",
      "Epoch 75 Iteration 400: Loss = 1.7407464981079102, Number of mined P N = 189 561\n",
      "Epoch 75 Iteration 500: Loss = 1.4065780639648438, Number of mined P N = 189 388\n",
      "Epoch 75 Iteration 600: Loss = 1.7350528240203857, Number of mined P N = 210 635\n",
      "Epoch 75 Iteration 700: Loss = 1.8372645378112793, Number of mined P N = 205 817\n",
      "Validation loss:  1.696850492954254\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 76 Iteration 0: Loss = 1.5835436582565308, Number of mined P N = 168 486\n",
      "Epoch 76 Iteration 100: Loss = 1.5923304557800293, Number of mined P N = 197 518\n",
      "Epoch 76 Iteration 200: Loss = 1.358741044998169, Number of mined P N = 166 362\n",
      "Epoch 76 Iteration 300: Loss = 1.3332719802856445, Number of mined P N = 177 366\n",
      "Epoch 76 Iteration 400: Loss = 1.694759726524353, Number of mined P N = 234 656\n",
      "Epoch 76 Iteration 500: Loss = 1.797689437866211, Number of mined P N = 200 679\n",
      "Epoch 76 Iteration 600: Loss = 1.7729980945587158, Number of mined P N = 231 766\n",
      "Epoch 76 Iteration 700: Loss = 1.5463944673538208, Number of mined P N = 166 534\n",
      "Validation loss:  1.6670913696289062\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 77 Iteration 0: Loss = 1.61131751537323, Number of mined P N = 204 581\n",
      "Epoch 77 Iteration 100: Loss = 1.4452543258666992, Number of mined P N = 181 427\n",
      "Epoch 77 Iteration 200: Loss = 1.5461219549179077, Number of mined P N = 179 515\n",
      "Epoch 77 Iteration 300: Loss = 1.6970391273498535, Number of mined P N = 210 553\n",
      "Epoch 77 Iteration 400: Loss = 1.7015491724014282, Number of mined P N = 222 643\n",
      "Epoch 77 Iteration 500: Loss = 1.688454508781433, Number of mined P N = 206 711\n",
      "Epoch 77 Iteration 600: Loss = 1.7805746793746948, Number of mined P N = 214 711\n",
      "Epoch 77 Iteration 700: Loss = 1.5966174602508545, Number of mined P N = 177 514\n",
      "Validation loss:  1.642185664176941\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 78 Iteration 0: Loss = 1.6701635122299194, Number of mined P N = 197 587\n",
      "Epoch 78 Iteration 100: Loss = 1.488614797592163, Number of mined P N = 175 448\n",
      "Epoch 78 Iteration 200: Loss = 1.8076673746109009, Number of mined P N = 251 883\n",
      "Epoch 78 Iteration 300: Loss = 1.7144157886505127, Number of mined P N = 220 619\n",
      "Epoch 78 Iteration 400: Loss = 1.6529697179794312, Number of mined P N = 211 531\n",
      "Epoch 78 Iteration 500: Loss = 1.860558032989502, Number of mined P N = 214 773\n",
      "Epoch 78 Iteration 600: Loss = 1.783676266670227, Number of mined P N = 224 791\n",
      "Epoch 78 Iteration 700: Loss = 1.592499852180481, Number of mined P N = 206 587\n",
      "Validation loss:  1.642118010520935\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 79 Iteration 0: Loss = 1.7342751026153564, Number of mined P N = 187 653\n",
      "Epoch 79 Iteration 100: Loss = 1.6860350370407104, Number of mined P N = 159 701\n",
      "Epoch 79 Iteration 200: Loss = 1.6629247665405273, Number of mined P N = 212 618\n",
      "Epoch 79 Iteration 300: Loss = 1.764971375465393, Number of mined P N = 214 635\n",
      "Epoch 79 Iteration 400: Loss = 1.944899082183838, Number of mined P N = 208 833\n",
      "Epoch 79 Iteration 500: Loss = 1.7117624282836914, Number of mined P N = 249 734\n",
      "Epoch 79 Iteration 600: Loss = 1.5206822156906128, Number of mined P N = 177 411\n",
      "Epoch 79 Iteration 700: Loss = 1.419451355934143, Number of mined P N = 153 520\n",
      "Validation loss:  1.6516469311714173\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 80 Iteration 0: Loss = 1.796282172203064, Number of mined P N = 231 732\n",
      "Epoch 80 Iteration 100: Loss = 1.6544407606124878, Number of mined P N = 198 517\n",
      "Epoch 80 Iteration 200: Loss = 1.650925874710083, Number of mined P N = 181 691\n",
      "Epoch 80 Iteration 300: Loss = 1.6539584398269653, Number of mined P N = 166 551\n",
      "Epoch 80 Iteration 400: Loss = 1.6843129396438599, Number of mined P N = 198 490\n",
      "Epoch 80 Iteration 500: Loss = 1.5905179977416992, Number of mined P N = 216 542\n",
      "Epoch 80 Iteration 600: Loss = 1.4367494583129883, Number of mined P N = 187 503\n",
      "Epoch 80 Iteration 700: Loss = 1.6821985244750977, Number of mined P N = 224 725\n",
      "Validation loss:  1.6617652463912964\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 81 Iteration 0: Loss = 1.6164789199829102, Number of mined P N = 161 434\n",
      "Epoch 81 Iteration 100: Loss = 1.6595743894577026, Number of mined P N = 166 467\n",
      "Epoch 81 Iteration 200: Loss = 1.4285171031951904, Number of mined P N = 158 352\n",
      "Epoch 81 Iteration 300: Loss = 1.633853554725647, Number of mined P N = 187 522\n",
      "Epoch 81 Iteration 400: Loss = 1.6884112358093262, Number of mined P N = 234 744\n",
      "Epoch 81 Iteration 500: Loss = 1.7761420011520386, Number of mined P N = 211 843\n",
      "Epoch 81 Iteration 600: Loss = 1.7187308073043823, Number of mined P N = 183 698\n",
      "Epoch 81 Iteration 700: Loss = 1.755114197731018, Number of mined P N = 187 579\n",
      "Validation loss:  1.6416688585281372\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 82 Iteration 0: Loss = 1.745245099067688, Number of mined P N = 202 596\n",
      "Epoch 82 Iteration 100: Loss = 1.8353981971740723, Number of mined P N = 223 814\n",
      "Epoch 82 Iteration 200: Loss = 1.6725831031799316, Number of mined P N = 136 565\n",
      "Epoch 82 Iteration 300: Loss = 1.5634469985961914, Number of mined P N = 167 518\n",
      "Epoch 82 Iteration 400: Loss = 1.781812071800232, Number of mined P N = 200 662\n",
      "Epoch 82 Iteration 500: Loss = 1.5657213926315308, Number of mined P N = 189 411\n",
      "Epoch 82 Iteration 600: Loss = 1.7669920921325684, Number of mined P N = 201 697\n",
      "Epoch 82 Iteration 700: Loss = 1.552777647972107, Number of mined P N = 191 522\n",
      "Validation loss:  1.6619095516204834\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 83 Iteration 0: Loss = 1.6679210662841797, Number of mined P N = 183 580\n",
      "Epoch 83 Iteration 100: Loss = 1.7102679014205933, Number of mined P N = 196 570\n",
      "Epoch 83 Iteration 200: Loss = 1.6965279579162598, Number of mined P N = 208 738\n",
      "Epoch 83 Iteration 300: Loss = 1.587654709815979, Number of mined P N = 195 519\n",
      "Epoch 83 Iteration 400: Loss = 1.5678209066390991, Number of mined P N = 164 521\n",
      "Epoch 83 Iteration 500: Loss = 1.5925819873809814, Number of mined P N = 180 684\n",
      "Epoch 83 Iteration 600: Loss = 1.5938712358474731, Number of mined P N = 163 479\n",
      "Epoch 83 Iteration 700: Loss = 1.7745246887207031, Number of mined P N = 161 662\n",
      "Validation loss:  1.6408479356765746\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 84 Iteration 0: Loss = 1.3359264135360718, Number of mined P N = 171 373\n",
      "Epoch 84 Iteration 100: Loss = 1.8855623006820679, Number of mined P N = 168 657\n",
      "Epoch 84 Iteration 200: Loss = 1.458676815032959, Number of mined P N = 157 403\n",
      "Epoch 84 Iteration 300: Loss = 1.5853629112243652, Number of mined P N = 149 426\n",
      "Epoch 84 Iteration 400: Loss = 1.7238250970840454, Number of mined P N = 195 655\n",
      "Epoch 84 Iteration 500: Loss = 1.6476376056671143, Number of mined P N = 156 419\n",
      "Epoch 84 Iteration 600: Loss = 1.6863421201705933, Number of mined P N = 209 678\n",
      "Epoch 84 Iteration 700: Loss = 1.7963162660598755, Number of mined P N = 235 880\n",
      "Validation loss:  1.657167682647705\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 85 Iteration 0: Loss = 1.6680209636688232, Number of mined P N = 208 674\n",
      "Epoch 85 Iteration 100: Loss = 1.8843271732330322, Number of mined P N = 220 1070\n",
      "Epoch 85 Iteration 200: Loss = 1.3422619104385376, Number of mined P N = 147 407\n",
      "Epoch 85 Iteration 300: Loss = 1.4899709224700928, Number of mined P N = 157 410\n",
      "Epoch 85 Iteration 400: Loss = 1.5526849031448364, Number of mined P N = 196 488\n",
      "Epoch 85 Iteration 500: Loss = 1.682365894317627, Number of mined P N = 216 543\n",
      "Epoch 85 Iteration 600: Loss = 1.476469874382019, Number of mined P N = 120 364\n",
      "Epoch 85 Iteration 700: Loss = 1.7273486852645874, Number of mined P N = 190 660\n",
      "Validation loss:  1.6436100172996522\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 86 Iteration 0: Loss = 1.7201193571090698, Number of mined P N = 169 577\n",
      "Epoch 86 Iteration 100: Loss = 1.7007546424865723, Number of mined P N = 229 626\n",
      "Epoch 86 Iteration 200: Loss = 1.3364828824996948, Number of mined P N = 158 347\n",
      "Epoch 86 Iteration 300: Loss = 1.5298328399658203, Number of mined P N = 166 476\n",
      "Epoch 86 Iteration 400: Loss = 1.7758713960647583, Number of mined P N = 212 682\n",
      "Epoch 86 Iteration 500: Loss = 1.3663386106491089, Number of mined P N = 123 282\n",
      "Epoch 86 Iteration 600: Loss = 1.6390639543533325, Number of mined P N = 210 641\n",
      "Epoch 86 Iteration 700: Loss = 1.749043345451355, Number of mined P N = 153 579\n",
      "Validation loss:  1.607534646987915\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 87 Iteration 0: Loss = 1.5996739864349365, Number of mined P N = 178 583\n",
      "Epoch 87 Iteration 100: Loss = 1.8350679874420166, Number of mined P N = 207 714\n",
      "Epoch 87 Iteration 200: Loss = 1.6393969058990479, Number of mined P N = 198 620\n",
      "Epoch 87 Iteration 300: Loss = 1.6212056875228882, Number of mined P N = 205 579\n",
      "Epoch 87 Iteration 400: Loss = 1.5704796314239502, Number of mined P N = 186 537\n",
      "Epoch 87 Iteration 500: Loss = 1.4753741025924683, Number of mined P N = 148 404\n",
      "Epoch 87 Iteration 600: Loss = 1.739539384841919, Number of mined P N = 238 801\n",
      "Epoch 87 Iteration 700: Loss = 1.2349799871444702, Number of mined P N = 151 267\n",
      "Validation loss:  1.6038598537445068\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 88 Iteration 0: Loss = 1.8551830053329468, Number of mined P N = 225 822\n",
      "Epoch 88 Iteration 100: Loss = 1.4524853229522705, Number of mined P N = 149 393\n",
      "Epoch 88 Iteration 200: Loss = 1.5024946928024292, Number of mined P N = 194 495\n",
      "Epoch 88 Iteration 300: Loss = 1.7203283309936523, Number of mined P N = 231 675\n",
      "Epoch 88 Iteration 400: Loss = 1.7469499111175537, Number of mined P N = 241 870\n",
      "Epoch 88 Iteration 500: Loss = 1.8147797584533691, Number of mined P N = 214 715\n",
      "Epoch 88 Iteration 600: Loss = 1.6420998573303223, Number of mined P N = 202 768\n",
      "Epoch 88 Iteration 700: Loss = 1.590298056602478, Number of mined P N = 164 581\n",
      "Validation loss:  1.6370577597618103\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 89 Iteration 0: Loss = 1.766694188117981, Number of mined P N = 189 575\n",
      "Epoch 89 Iteration 100: Loss = 1.483265995979309, Number of mined P N = 193 455\n",
      "Epoch 89 Iteration 200: Loss = 1.6839678287506104, Number of mined P N = 218 618\n",
      "Epoch 89 Iteration 300: Loss = 1.983835220336914, Number of mined P N = 215 930\n",
      "Epoch 89 Iteration 400: Loss = 1.7975046634674072, Number of mined P N = 235 725\n",
      "Epoch 89 Iteration 500: Loss = 2.036695957183838, Number of mined P N = 267 918\n",
      "Epoch 89 Iteration 600: Loss = 1.6691993474960327, Number of mined P N = 172 533\n",
      "Epoch 89 Iteration 700: Loss = 1.6005160808563232, Number of mined P N = 150 527\n",
      "Validation loss:  1.637876842021942\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 90 Iteration 0: Loss = 1.4716744422912598, Number of mined P N = 200 467\n",
      "Epoch 90 Iteration 100: Loss = 1.8626611232757568, Number of mined P N = 208 739\n",
      "Epoch 90 Iteration 200: Loss = 1.4997557401657104, Number of mined P N = 156 439\n",
      "Epoch 90 Iteration 300: Loss = 1.4496150016784668, Number of mined P N = 150 381\n",
      "Epoch 90 Iteration 400: Loss = 1.4933139085769653, Number of mined P N = 151 474\n",
      "Epoch 90 Iteration 500: Loss = 1.7772248983383179, Number of mined P N = 205 655\n",
      "Epoch 90 Iteration 600: Loss = 1.6124162673950195, Number of mined P N = 181 528\n",
      "Epoch 90 Iteration 700: Loss = 1.5617802143096924, Number of mined P N = 186 700\n",
      "Validation loss:  1.6298425722122192\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 91 Iteration 0: Loss = 1.7864620685577393, Number of mined P N = 200 750\n",
      "Epoch 91 Iteration 100: Loss = 1.4000325202941895, Number of mined P N = 156 299\n",
      "Epoch 91 Iteration 200: Loss = 1.5773801803588867, Number of mined P N = 202 503\n",
      "Epoch 91 Iteration 300: Loss = 1.6798806190490723, Number of mined P N = 194 588\n",
      "Epoch 91 Iteration 400: Loss = 1.8592360019683838, Number of mined P N = 214 830\n",
      "Epoch 91 Iteration 500: Loss = 1.6742138862609863, Number of mined P N = 188 662\n",
      "Epoch 91 Iteration 600: Loss = 1.6947369575500488, Number of mined P N = 206 532\n",
      "Epoch 91 Iteration 700: Loss = 1.4386284351348877, Number of mined P N = 157 369\n",
      "Validation loss:  1.5789204192161561\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 92 Iteration 0: Loss = 1.4862048625946045, Number of mined P N = 183 505\n",
      "Epoch 92 Iteration 100: Loss = 1.3678556680679321, Number of mined P N = 179 332\n",
      "Epoch 92 Iteration 200: Loss = 1.2967921495437622, Number of mined P N = 160 444\n",
      "Epoch 92 Iteration 300: Loss = 1.7853716611862183, Number of mined P N = 205 757\n",
      "Epoch 92 Iteration 400: Loss = 1.5393590927124023, Number of mined P N = 162 385\n",
      "Epoch 92 Iteration 500: Loss = 1.7245543003082275, Number of mined P N = 193 644\n",
      "Epoch 92 Iteration 600: Loss = 1.7577459812164307, Number of mined P N = 221 614\n",
      "Epoch 92 Iteration 700: Loss = 1.413956880569458, Number of mined P N = 145 391\n",
      "Validation loss:  1.5985668802261352\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 93 Iteration 0: Loss = 1.7129731178283691, Number of mined P N = 199 585\n",
      "Epoch 93 Iteration 100: Loss = 1.312528371810913, Number of mined P N = 157 329\n",
      "Epoch 93 Iteration 200: Loss = 1.6746634244918823, Number of mined P N = 156 475\n",
      "Epoch 93 Iteration 300: Loss = 1.6348196268081665, Number of mined P N = 180 545\n",
      "Epoch 93 Iteration 400: Loss = 1.7610901594161987, Number of mined P N = 192 695\n",
      "Epoch 93 Iteration 500: Loss = 1.6220664978027344, Number of mined P N = 154 428\n",
      "Epoch 93 Iteration 600: Loss = 1.5092449188232422, Number of mined P N = 176 413\n",
      "Epoch 93 Iteration 700: Loss = 1.3282557725906372, Number of mined P N = 168 418\n",
      "Validation loss:  1.5961578726768493\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 94 Iteration 0: Loss = 1.5828285217285156, Number of mined P N = 153 354\n",
      "Epoch 94 Iteration 100: Loss = 1.4829097986221313, Number of mined P N = 187 498\n",
      "Epoch 94 Iteration 200: Loss = 1.5382429361343384, Number of mined P N = 177 455\n",
      "Epoch 94 Iteration 300: Loss = 1.5021237134933472, Number of mined P N = 172 474\n",
      "Epoch 94 Iteration 400: Loss = 1.7801368236541748, Number of mined P N = 233 701\n",
      "Epoch 94 Iteration 500: Loss = 1.7133276462554932, Number of mined P N = 168 657\n",
      "Epoch 94 Iteration 600: Loss = 1.1843323707580566, Number of mined P N = 111 232\n",
      "Epoch 94 Iteration 700: Loss = 1.5355477333068848, Number of mined P N = 173 517\n",
      "Validation loss:  1.5857276391983033\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 95 Iteration 0: Loss = 1.6196645498275757, Number of mined P N = 223 720\n",
      "Epoch 95 Iteration 100: Loss = 1.57166588306427, Number of mined P N = 171 419\n",
      "Epoch 95 Iteration 200: Loss = 1.2645059823989868, Number of mined P N = 118 222\n",
      "Epoch 95 Iteration 300: Loss = 1.700903058052063, Number of mined P N = 189 588\n",
      "Epoch 95 Iteration 400: Loss = 1.6682626008987427, Number of mined P N = 201 465\n",
      "Epoch 95 Iteration 500: Loss = 1.3313522338867188, Number of mined P N = 170 328\n",
      "Epoch 95 Iteration 600: Loss = 1.617942452430725, Number of mined P N = 211 537\n",
      "Epoch 95 Iteration 700: Loss = 1.738477349281311, Number of mined P N = 209 658\n",
      "Validation loss:  1.5957436633110047\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 96 Iteration 0: Loss = 1.7892334461212158, Number of mined P N = 159 698\n",
      "Epoch 96 Iteration 100: Loss = 1.548385500907898, Number of mined P N = 161 436\n",
      "Epoch 96 Iteration 200: Loss = 1.834609866142273, Number of mined P N = 172 624\n",
      "Epoch 96 Iteration 300: Loss = 1.5481233596801758, Number of mined P N = 190 509\n",
      "Epoch 96 Iteration 400: Loss = 1.7358291149139404, Number of mined P N = 169 596\n",
      "Epoch 96 Iteration 500: Loss = 1.6055598258972168, Number of mined P N = 185 509\n",
      "Epoch 96 Iteration 600: Loss = 1.686190128326416, Number of mined P N = 173 530\n",
      "Epoch 96 Iteration 700: Loss = 1.621187686920166, Number of mined P N = 204 551\n",
      "Validation loss:  1.6069635438919068\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 97 Iteration 0: Loss = 1.5105831623077393, Number of mined P N = 169 436\n",
      "Epoch 97 Iteration 100: Loss = 1.6368087530136108, Number of mined P N = 168 675\n",
      "Epoch 97 Iteration 200: Loss = 1.6608800888061523, Number of mined P N = 177 543\n",
      "Epoch 97 Iteration 300: Loss = 1.4111043214797974, Number of mined P N = 138 289\n",
      "Epoch 97 Iteration 400: Loss = 1.5715910196304321, Number of mined P N = 221 611\n",
      "Epoch 97 Iteration 500: Loss = 1.510567307472229, Number of mined P N = 183 543\n",
      "Epoch 97 Iteration 600: Loss = 1.5941270589828491, Number of mined P N = 192 592\n",
      "Epoch 97 Iteration 700: Loss = 1.7680891752243042, Number of mined P N = 202 624\n",
      "Validation loss:  1.5806983089447022\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 98 Iteration 0: Loss = 1.8191744089126587, Number of mined P N = 210 716\n",
      "Epoch 98 Iteration 100: Loss = 1.5865097045898438, Number of mined P N = 215 667\n",
      "Epoch 98 Iteration 200: Loss = 1.5794093608856201, Number of mined P N = 160 518\n",
      "Epoch 98 Iteration 300: Loss = 1.4038699865341187, Number of mined P N = 156 398\n",
      "Epoch 98 Iteration 400: Loss = 1.6445209980010986, Number of mined P N = 109 312\n",
      "Epoch 98 Iteration 500: Loss = 1.4448845386505127, Number of mined P N = 178 355\n",
      "Epoch 98 Iteration 600: Loss = 1.4865684509277344, Number of mined P N = 161 370\n",
      "Epoch 98 Iteration 700: Loss = 1.5647003650665283, Number of mined P N = 159 570\n",
      "Validation loss:  1.5627614569664001\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 99 Iteration 0: Loss = 1.6088759899139404, Number of mined P N = 187 600\n",
      "Epoch 99 Iteration 100: Loss = 1.3706536293029785, Number of mined P N = 153 323\n",
      "Epoch 99 Iteration 200: Loss = 1.641287922859192, Number of mined P N = 185 665\n",
      "Epoch 99 Iteration 300: Loss = 1.5785934925079346, Number of mined P N = 183 509\n",
      "Epoch 99 Iteration 400: Loss = 1.8143715858459473, Number of mined P N = 182 597\n",
      "Epoch 99 Iteration 500: Loss = 1.5361863374710083, Number of mined P N = 178 444\n",
      "Epoch 99 Iteration 600: Loss = 1.369470238685608, Number of mined P N = 157 366\n",
      "Epoch 99 Iteration 700: Loss = 1.6032179594039917, Number of mined P N = 200 548\n",
      "Validation loss:  1.569781138896942\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "feature= \"raw\"\n",
    "sample_len = 500\n",
    "num_epochs=99\n",
    "batch_s= 128\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "from pytorch_metric_learning.distances import LpDistance, CosineSimilarity,SNRDistance\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "\n",
    "        # Access the data and labels from the HDF5 file\n",
    "        self.x_data = self.h5_file['data']  # EEG data (use memory-mapped access)\n",
    "        self.y_data = self.h5_file['labels'][:]  # Labels (load fully into memory)\n",
    "        self.s_data = self.h5_file['sessions'][:]  # Sessions (load fully into memory)\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Convert to torch tensor\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "    def close(self):\n",
    "        self.h5_file.close()\n",
    "\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path, num_subjects=None):\n",
    "        # Open the HDF5 file and keep it open for on-the-fly access\n",
    "        self.h5_file_path = h5_file_path\n",
    "        with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "            self.y_data = np.array(h5_file['labels'])  # Load labels into memory\n",
    "            self.s_data = np.array(h5_file['sessions'])  # Load sessions into memory\n",
    "\n",
    "            # Get unique subjects\n",
    "            unique_subjects = np.unique(self.y_data)\n",
    "\n",
    "            # If a specific number of subjects is requested, select a random subset\n",
    "            if num_subjects is not None and num_subjects < len(unique_subjects):\n",
    "                selected_subjects = np.random.choice(unique_subjects, size=num_subjects, replace=False)\n",
    "                mask = np.isin(self.y_data, selected_subjects)  # Filter data by selected subjects\n",
    "                self.indices = np.where(mask)[0]\n",
    "                self.y_data = self.y_data[mask]\n",
    "                self.s_data = self.s_data[mask]\n",
    "                unique_subjects = selected_subjects  # Update unique subjects to the selected subset\n",
    "            else:\n",
    "                self.indices = np.arange(len(self.y_data))  # Keep all indices if no filtering\n",
    "\n",
    "            # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "            self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}\n",
    "\n",
    "            # Map the y_data labels using the subject_map\n",
    "            self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "            # Convert labels to torch tensors\n",
    "            self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "            # Print the number of unique subjects (labels)\n",
    "            print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the global index in the HDF5 file\n",
    "        global_idx = self.indices[idx]\n",
    "\n",
    "        # Open the HDF5 file and fetch data on-the-fly\n",
    "        with h5py.File(self.h5_file_path, 'r') as h5_file:\n",
    "            x_data = h5_file['data'][global_idx]\n",
    "\n",
    "        # Convert data and labels into torch tensors\n",
    "        x_tensor = torch.tensor(x_data, dtype=torch.float32)  # Fetch EEG data\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Fetch the session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "h5_file_path_t = f'./data/train_{feature}.h5'\n",
    "h5_file_path_v = f'./data/valid_{feature}.h5'\n",
    "train_dataset = EEGDataset(h5_file_path_t,128)\n",
    "valid_dataset = EEGDataset(h5_file_path_v)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "subject_ids = train_dataset.targets  # Replace with train_dataset.targets\n",
    "session_ids = train_dataset.s_data          # Replace with train_dataset.s_data\n",
    "\n",
    "# Combine subject and session IDs into unique pairs\n",
    "pairs = list(zip(subject_ids.tolist(), session_ids.tolist()))\n",
    "\n",
    "# Create a mapping from pairs to unique IDs\n",
    "unique_pairs = list(set(pairs))  # Get unique pairs\n",
    "pair_to_id = {pair: idx for idx, pair in enumerate(unique_pairs)}\n",
    "\n",
    "# Map each pair to its unique ID\n",
    "unique_ids = torch.tensor([pair_to_id[pair] for pair in pairs])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate(model, loader, loss_func, mining_func, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation loader (using the provided loader, not train_loader)\n",
    "        for batch_idx, (data, labels, sessions) in enumerate(loader):\n",
    "            # Move data and labels to the specified device\n",
    "            inputs = data.to(device)\n",
    "            targets = labels.to(device)\n",
    "\n",
    "            # Compute embeddings using the model\n",
    "            embeddings = model(inputs)\n",
    "            \n",
    "            # Get mining output for the embeddings\n",
    "            mined_indices = mining_func(embeddings, targets)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_func(embeddings, targets, mined_indices)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "    # Compute the average validation loss\n",
    "    average_loss = total_loss / total_batches if total_batches > 0 else 0\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet7, self).__init__()\n",
    "        # InstanceNorm1d normalizes each channel across its 500 values for each sample\n",
    "        self.norm = nn.InstanceNorm1d(93, affine=False)  # Normalizes across the 500 values in each of the 93 channels\n",
    "        self.act = nn.ReLU()  # or nn.SELU() , ReLU\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.conv1 = nn.Conv2d(1, 256, (1, 4), padding='same')\n",
    "        self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 192, (4, 1), padding='same')\n",
    "        self.pool2 = nn.MaxPool2d((2, 1))\n",
    "        self.conv3 = nn.Conv2d(192, 128, (1, 4), padding='same')\n",
    "        self.pool3 = nn.MaxPool2d((1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 96, (4, 1), padding='same')\n",
    "        self.pool4 = nn.MaxPool2d((2, 1))\n",
    "        self.conv5 = nn.Conv2d(96, 64, (1, 4), padding='same')\n",
    "        self.pool5 = nn.MaxPool2d((1, 2))\n",
    "        self.conv6 = nn.Conv2d(64, 32, (4, 1), padding='same')\n",
    "        self.pool6 = nn.MaxPool2d((2, 1))\n",
    "        self.conv7 = nn.Conv2d(32, 16, (1, 2), padding='same')\n",
    "        self.conv8 = nn.Conv2d(16, 2, (2, 1), padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.embedding = nn.Linear(1364, 128)  # Embedding layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #if x.dim() == 3:\n",
    "            #x = x.unsqueeze(1)  # Adding a channel dimension if input is 3D\n",
    "        x = self.norm(x)  # Apply InstanceNorm along the channel dimension (squeeze to 1D first)\n",
    "        x = x.unsqueeze(1)  # Reshape to 4D again for Conv2d\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.act(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        x = self.act(self.conv6(x))\n",
    "        x = self.pool6(x)\n",
    "        x = self.act(self.conv7(x))\n",
    "        x = self.act(self.conv8(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch, test_loader):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    print(f\"Total number of batches in train_loader: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use mixed precision training\n",
    "        with autocast():\n",
    "            embeddings = model(data)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        # Scales the loss, and backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales gradients and optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined P N = {} {}\".format(\n",
    "                    epoch, batch_idx, loss.item(), mining_func.num_pos_pairs, mining_func.num_neg_pairs  \n",
    "                )\n",
    "            )\n",
    "    val_loss = validate(model, test_loader, loss_func, mining_func, device)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"device\", device)\n",
    "trunk = EEGNet7().to(device)\n",
    "summary(trunk, (93, sample_len)) \n",
    "\n",
    "loss_func = losses.SupConLoss(temperature=0.1).to(device)\n",
    "#loss_func = losses.LiftedStructureLoss().to(device)\n",
    "\n",
    "#sampler = samplers.MPerClassSampler(unique_ids, m=1, batch_size=batch_s)\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, batch_size=batch_s)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_s, sampler=sampler)\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001)\n",
    "#mining_func = miners.PairMarginMiner(pos_margin=0.20, neg_margin=0.8)\n",
    "mining_func = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(trunk, loss_func, mining_func, device, train_loader, trunk_optimizer, epoch,valid_loader)\n",
    "    #test(trunk, loss_func, mining_func, device, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(trunk.state_dict(), './model/SupConLoss128_m4_e99_S128_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f8fc2-c562-4fcf-82b3-be130c01d33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
