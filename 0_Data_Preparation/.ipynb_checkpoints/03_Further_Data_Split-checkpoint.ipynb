{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140aed46-0643-4a97-9464-073ad97f585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for hardware BioSemi saved to ../Data/test_hardware_BioSemi.h5\n",
      "Data for hardware Geodisi saved to ../Data/test_hardware_Geodisi.h5\n",
      "Data for hardware HydroCe saved to ../Data/test_hardware_HydroCe.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load data function\n",
    "def load_data(file_path):\n",
    "    with h5py.File(file_path, \"r\") as file:\n",
    "        data = {\n",
    "            'X': file['data'][:],\n",
    "            'Y': file['labels'][:],\n",
    "            'S': file['sessions'][:],\n",
    "            'H': file['hardwares'][:]\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# Load and combine datasets\n",
    "data_test = load_data(\"../Data/test_raw.h5\")\n",
    "data_neg = load_data(\"../Data/neg_raw.h5\")\n",
    "\n",
    "# Combine test and negative datasets\n",
    "for key in data_test:\n",
    "    data_test[key] = np.concatenate((data_test[key], data_neg[key]), axis=0)\n",
    "\n",
    "# Shuffle the combined data\n",
    "indices = np.random.permutation(len(data_test['X']))\n",
    "for key in data_test:\n",
    "    data_test[key] = data_test[key][indices]\n",
    "\n",
    "# Split data based on hardware\n",
    "def split_and_save_data(data):\n",
    "    unique_hardware = np.unique(data['H'])\n",
    "    for hardware in unique_hardware:\n",
    "        # Filter data for each hardware\n",
    "        mask = data['H'] == hardware\n",
    "        filtered_data = {\n",
    "            'X': data['X'][mask],\n",
    "            'Y': data['Y'][mask],\n",
    "            'S': data['S'][mask],\n",
    "            'H': data['H'][mask]\n",
    "        }\n",
    "        \n",
    "        # Save filtered data to a new HDF5 file\n",
    "        file_name = f\"../Data/test_hardware_{hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware}.h5\"\n",
    "        with h5py.File(file_name, 'w') as f:\n",
    "            for key, value in filtered_data.items():\n",
    "                f.create_dataset(key, data=value)\n",
    "        print(f\"Data for hardware {hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware} saved to {file_name}\")\n",
    "\n",
    "split_and_save_data(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee869cc4-f194-4c2e-af5f-5d9048dfe773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7835f4bb-fe87-49c0-a610-552bb99c139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for hardware BioSemi saved to ../Data/train_hardware_BioSemi.h5\n",
      "Data for hardware Geodisi saved to ../Data/train_hardware_Geodisi.h5\n",
      "Data for hardware HydroCe saved to ../Data/train_hardware_HydroCe.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load data function\n",
    "def load_data(file_path):\n",
    "    with h5py.File(file_path, \"r\") as file:\n",
    "        data = {\n",
    "            'X': file['data'][:],\n",
    "            'Y': file['labels'][:],\n",
    "            'S': file['sessions'][:],\n",
    "            'H': file['hardwares'][:]\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# Load and combine datasets\n",
    "data_train = load_data(\"../Data/train_raw.h5\")\n",
    "\n",
    "\n",
    "# Shuffle the combined data\n",
    "indices = np.random.permutation(len(data_train['X']))\n",
    "for key in data_train:\n",
    "    data_train[key] = data_train[key][indices]\n",
    "\n",
    "# Split data based on hardware\n",
    "def split_and_save_data(data):\n",
    "    unique_hardware = np.unique(data['H'])\n",
    "    for hardware in unique_hardware:\n",
    "        # Filter data for each hardware\n",
    "        mask = data['H'] == hardware\n",
    "        filtered_data = {\n",
    "            'data': data['X'][mask],\n",
    "            'labels': data['Y'][mask],\n",
    "            'sessions': data['S'][mask],\n",
    "            'H': data['H'][mask]\n",
    "        }\n",
    "        \n",
    "        # Save filtered data to a new HDF5 file\n",
    "        file_name = f\"../Data/train_hardware_{hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware}.h5\"\n",
    "        with h5py.File(file_name, 'w') as f:\n",
    "            for key, value in filtered_data.items():\n",
    "                f.create_dataset(key, data=value)\n",
    "        print(f\"Data for hardware {hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware} saved to {file_name}\")\n",
    "\n",
    "split_and_save_data(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4598e2-5076-4772-8f16-5725aa40fb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a88fa-2683-4b14-8135-dd0350244377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3741015-69c4-4447-a743-a57cb4862969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved as train_raw_unconnected.h5.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "with h5py.File(\"../Data/train_raw.h5\", \"r\") as f:\n",
    "    X_test = f['data'][:]\n",
    "    Y_test = f['labels'][:]\n",
    "    S_test = f['sessions'][:]\n",
    "    H_test = f['hardwares'][:]\n",
    "\n",
    "# Initialize a new list to store indices to keep\n",
    "indices_to_keep = []\n",
    "\n",
    "# Find unique labels\n",
    "unique_labels = np.unique(Y_test)\n",
    "\n",
    "# Process each label\n",
    "for label in unique_labels:\n",
    "    # Get indices of the current label\n",
    "    label_indices = np.where(Y_test == label)[0]\n",
    "    # Extract hardware types for the current label\n",
    "    hardware_for_label = H_test[label_indices]\n",
    "    # Count occurrences of each hardware\n",
    "    hardware_counts = Counter(hardware_for_label)\n",
    "    # Find the hardware with the majority occurrences\n",
    "    majority_hardware = max(hardware_counts, key=hardware_counts.get)\n",
    "    # Keep indices for the majority hardware\n",
    "    majority_indices = label_indices[hardware_for_label == majority_hardware]\n",
    "    indices_to_keep.extend(majority_indices)\n",
    "\n",
    "# Filter the dataset\n",
    "indices_to_keep = np.array(indices_to_keep)\n",
    "X_filtered = X_test[indices_to_keep]\n",
    "Y_filtered = Y_test[indices_to_keep]\n",
    "S_filtered = S_test[indices_to_keep]\n",
    "H_filtered = H_test[indices_to_keep]\n",
    "\n",
    "# Save the filtered dataset\n",
    "with h5py.File(\"../Data/train_raw_unconnected.h5\", \"w\") as f_out:\n",
    "    f_out.create_dataset('data', data=X_filtered)\n",
    "    f_out.create_dataset('labels', data=Y_filtered)\n",
    "    f_out.create_dataset('sessions', data=S_filtered)\n",
    "    f_out.create_dataset('hardwares', data=H_filtered)\n",
    "\n",
    "print(\"Filtered dataset saved as train_raw_unconnected.h5.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4a24a4-54d9-4a06-bbed-9ff8c15d4adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for hardware BioSemi saved to ../Data/train_unconnected_hardware_BioSemi.h5\n",
      "Data for hardware Geodisi saved to ../Data/train_unconnected_hardware_Geodisi.h5\n",
      "Data for hardware HydroCe saved to ../Data/train_unconnected_hardware_HydroCe.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load data function\n",
    "def load_data(file_path):\n",
    "    with h5py.File(file_path, \"r\") as file:\n",
    "        data = {\n",
    "            'X': file['data'][:],\n",
    "            'Y': file['labels'][:],\n",
    "            'S': file['sessions'][:],\n",
    "            'H': file['hardwares'][:]\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# Load and combine datasets\n",
    "data_test = load_data(\"../Data/train_raw_unconnected.h5\")\n",
    "\n",
    "\n",
    "\n",
    "# Shuffle the combined data\n",
    "indices = np.random.permutation(len(data_test['X']))\n",
    "for key in data_test:\n",
    "    data_test[key] = data_test[key][indices]\n",
    "\n",
    "# Split data based on hardware\n",
    "def split_and_save_data(data):\n",
    "    unique_hardware = np.unique(data['H'])\n",
    "    for hardware in unique_hardware:\n",
    "        # Filter data for each hardware\n",
    "        mask = data['H'] == hardware\n",
    "        filtered_data = {\n",
    "            'data': data['X'][mask],\n",
    "            'labels': data['Y'][mask],\n",
    "            'sessions': data['S'][mask],\n",
    "            'hardwares': data['H'][mask]\n",
    "        }\n",
    "        \n",
    "        # Save filtered data to a new HDF5 file\n",
    "        file_name = f\"../Data/train_unconnected_hardware_{hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware}.h5\"\n",
    "        with h5py.File(file_name, 'w') as f:\n",
    "            for key, value in filtered_data.items():\n",
    "                f.create_dataset(key, data=value)\n",
    "        print(f\"Data for hardware {hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware} saved to {file_name}\")\n",
    "\n",
    "split_and_save_data(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd9261-6cf5-4b93-b06b-b5925206c40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "oml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
