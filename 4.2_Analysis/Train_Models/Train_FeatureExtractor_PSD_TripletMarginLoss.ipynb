{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9166b40a-7bbe-44b9-b318-75d390807900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 230\n",
      "Number of unique subjects: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    InstanceNorm1d-1              [-1, 93, 129]               0\n",
      "            Conv2d-2         [-1, 256, 93, 129]           1,280\n",
      "              ReLU-3         [-1, 256, 93, 129]               0\n",
      "         MaxPool2d-4          [-1, 256, 93, 64]               0\n",
      "            Conv2d-5          [-1, 192, 93, 64]         196,800\n",
      "              ReLU-6          [-1, 192, 93, 64]               0\n",
      "         MaxPool2d-7          [-1, 192, 46, 64]               0\n",
      "            Conv2d-8          [-1, 128, 46, 64]          98,432\n",
      "              ReLU-9          [-1, 128, 46, 64]               0\n",
      "        MaxPool2d-10          [-1, 128, 46, 32]               0\n",
      "           Conv2d-11           [-1, 96, 46, 32]          49,248\n",
      "             ReLU-12           [-1, 96, 46, 32]               0\n",
      "        MaxPool2d-13           [-1, 96, 23, 32]               0\n",
      "           Conv2d-14           [-1, 64, 23, 32]          24,640\n",
      "             ReLU-15           [-1, 64, 23, 32]               0\n",
      "        MaxPool2d-16           [-1, 64, 23, 16]               0\n",
      "           Conv2d-17           [-1, 32, 23, 16]           8,224\n",
      "             ReLU-18           [-1, 32, 23, 16]               0\n",
      "        MaxPool2d-19           [-1, 32, 11, 16]               0\n",
      "           Conv2d-20           [-1, 16, 11, 16]           1,040\n",
      "             ReLU-21           [-1, 16, 11, 16]               0\n",
      "           Conv2d-22            [-1, 2, 11, 16]              66\n",
      "             ReLU-23            [-1, 2, 11, 16]               0\n",
      "          Flatten-24                  [-1, 352]               0\n",
      "           Linear-25                  [-1, 128]          45,184\n",
      "================================================================\n",
      "Total params: 424,914\n",
      "Trainable params: 424,914\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 91.39\n",
      "Params size (MB): 1.62\n",
      "Estimated Total Size (MB): 93.05\n",
      "----------------------------------------------------------------\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 1 Iteration 0: Loss = 0.49945154786109924, Number of mined triplets = 47616 \n",
      "Epoch 1 Iteration 100: Loss = 0.42959028482437134, Number of mined triplets = 25782 \n",
      "Epoch 1 Iteration 200: Loss = 0.3957599103450775, Number of mined triplets = 23846 \n",
      "Epoch 1 Iteration 300: Loss = 0.40441039204597473, Number of mined triplets = 25545 \n",
      "Epoch 1 Iteration 400: Loss = 0.40454116463661194, Number of mined triplets = 21438 \n",
      "Epoch 1 Iteration 500: Loss = 0.38252541422843933, Number of mined triplets = 20616 \n",
      "Epoch 1 Iteration 600: Loss = 0.3719486892223358, Number of mined triplets = 19202 \n",
      "Epoch 1 Iteration 700: Loss = 0.40729227662086487, Number of mined triplets = 25322 \n",
      "Validation loss:  0.38813919365406035\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 2 Iteration 0: Loss = 0.373866468667984, Number of mined triplets = 19535 \n",
      "Epoch 2 Iteration 100: Loss = 0.3901020288467407, Number of mined triplets = 23137 \n",
      "Epoch 2 Iteration 200: Loss = 0.3613700270652771, Number of mined triplets = 20795 \n",
      "Epoch 2 Iteration 300: Loss = 0.37247875332832336, Number of mined triplets = 23167 \n",
      "Epoch 2 Iteration 400: Loss = 0.3495314419269562, Number of mined triplets = 20115 \n",
      "Epoch 2 Iteration 500: Loss = 0.3807046115398407, Number of mined triplets = 20672 \n",
      "Epoch 2 Iteration 600: Loss = 0.40111756324768066, Number of mined triplets = 27177 \n",
      "Epoch 2 Iteration 700: Loss = 0.388332724571228, Number of mined triplets = 21743 \n",
      "Validation loss:  0.3729827934503555\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 3 Iteration 0: Loss = 0.35953155159950256, Number of mined triplets = 18446 \n",
      "Epoch 3 Iteration 100: Loss = 0.39743050932884216, Number of mined triplets = 20553 \n",
      "Epoch 3 Iteration 200: Loss = 0.35668274760246277, Number of mined triplets = 16908 \n",
      "Epoch 3 Iteration 300: Loss = 0.3671329617500305, Number of mined triplets = 20144 \n",
      "Epoch 3 Iteration 400: Loss = 0.3634571135044098, Number of mined triplets = 20067 \n",
      "Epoch 3 Iteration 500: Loss = 0.3619787395000458, Number of mined triplets = 21058 \n",
      "Epoch 3 Iteration 600: Loss = 0.3760937750339508, Number of mined triplets = 21077 \n",
      "Epoch 3 Iteration 700: Loss = 0.36695924401283264, Number of mined triplets = 19290 \n",
      "Validation loss:  0.36851652920246125\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 4 Iteration 0: Loss = 0.3480852246284485, Number of mined triplets = 17856 \n",
      "Epoch 4 Iteration 100: Loss = 0.348704993724823, Number of mined triplets = 20383 \n",
      "Epoch 4 Iteration 200: Loss = 0.35231950879096985, Number of mined triplets = 25539 \n",
      "Epoch 4 Iteration 300: Loss = 0.35059988498687744, Number of mined triplets = 19692 \n",
      "Epoch 4 Iteration 400: Loss = 0.3479688763618469, Number of mined triplets = 21823 \n",
      "Epoch 4 Iteration 500: Loss = 0.3461949825286865, Number of mined triplets = 21163 \n",
      "Epoch 4 Iteration 600: Loss = 0.371425986289978, Number of mined triplets = 19065 \n",
      "Epoch 4 Iteration 700: Loss = 0.3239218294620514, Number of mined triplets = 21296 \n",
      "Validation loss:  0.3525944364070892\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 5 Iteration 0: Loss = 0.34960541129112244, Number of mined triplets = 18261 \n",
      "Epoch 5 Iteration 100: Loss = 0.3769444525241852, Number of mined triplets = 19815 \n",
      "Epoch 5 Iteration 200: Loss = 0.3643680512905121, Number of mined triplets = 18284 \n",
      "Epoch 5 Iteration 300: Loss = 0.3393172025680542, Number of mined triplets = 19601 \n",
      "Epoch 5 Iteration 400: Loss = 0.3519107699394226, Number of mined triplets = 18066 \n",
      "Epoch 5 Iteration 500: Loss = 0.34307533502578735, Number of mined triplets = 17920 \n",
      "Epoch 5 Iteration 600: Loss = 0.3620755672454834, Number of mined triplets = 18409 \n",
      "Epoch 5 Iteration 700: Loss = 0.32931867241859436, Number of mined triplets = 19027 \n",
      "Validation loss:  0.35413079619407656\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 6 Iteration 0: Loss = 0.3601977527141571, Number of mined triplets = 19602 \n",
      "Epoch 6 Iteration 100: Loss = 0.33578965067863464, Number of mined triplets = 19869 \n",
      "Epoch 6 Iteration 200: Loss = 0.32657039165496826, Number of mined triplets = 16413 \n",
      "Epoch 6 Iteration 300: Loss = 0.3331475257873535, Number of mined triplets = 17720 \n",
      "Epoch 6 Iteration 400: Loss = 0.3307240307331085, Number of mined triplets = 17873 \n",
      "Epoch 6 Iteration 500: Loss = 0.3848360776901245, Number of mined triplets = 21668 \n",
      "Epoch 6 Iteration 600: Loss = 0.35965749621391296, Number of mined triplets = 17763 \n",
      "Epoch 6 Iteration 700: Loss = 0.29117414355278015, Number of mined triplets = 16248 \n",
      "Validation loss:  0.3427735096216202\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 7 Iteration 0: Loss = 0.3448122441768646, Number of mined triplets = 18520 \n",
      "Epoch 7 Iteration 100: Loss = 0.35969650745391846, Number of mined triplets = 21586 \n",
      "Epoch 7 Iteration 200: Loss = 0.3764077425003052, Number of mined triplets = 16797 \n",
      "Epoch 7 Iteration 300: Loss = 0.33941757678985596, Number of mined triplets = 19613 \n",
      "Epoch 7 Iteration 400: Loss = 0.34106016159057617, Number of mined triplets = 20082 \n",
      "Epoch 7 Iteration 500: Loss = 0.3559172749519348, Number of mined triplets = 16828 \n",
      "Epoch 7 Iteration 600: Loss = 0.3462586998939514, Number of mined triplets = 18625 \n",
      "Epoch 7 Iteration 700: Loss = 0.3346823453903198, Number of mined triplets = 19012 \n",
      "Validation loss:  0.3454314476251602\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 8 Iteration 0: Loss = 0.3475716710090637, Number of mined triplets = 15997 \n",
      "Epoch 8 Iteration 100: Loss = 0.3243115246295929, Number of mined triplets = 19046 \n",
      "Epoch 8 Iteration 200: Loss = 0.3590161204338074, Number of mined triplets = 19051 \n",
      "Epoch 8 Iteration 300: Loss = 0.3469933867454529, Number of mined triplets = 20314 \n",
      "Epoch 8 Iteration 400: Loss = 0.33820271492004395, Number of mined triplets = 17908 \n",
      "Epoch 8 Iteration 500: Loss = 0.3271554708480835, Number of mined triplets = 15403 \n",
      "Epoch 8 Iteration 600: Loss = 0.35422253608703613, Number of mined triplets = 19232 \n",
      "Epoch 8 Iteration 700: Loss = 0.39366427063941956, Number of mined triplets = 17669 \n",
      "Validation loss:  0.3425700122117996\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 9 Iteration 0: Loss = 0.34796077013015747, Number of mined triplets = 18519 \n",
      "Epoch 9 Iteration 100: Loss = 0.34198305010795593, Number of mined triplets = 19640 \n",
      "Epoch 9 Iteration 200: Loss = 0.34161123633384705, Number of mined triplets = 16929 \n",
      "Epoch 9 Iteration 300: Loss = 0.35143157839775085, Number of mined triplets = 18656 \n",
      "Epoch 9 Iteration 400: Loss = 0.31463006138801575, Number of mined triplets = 16172 \n",
      "Epoch 9 Iteration 500: Loss = 0.31927308440208435, Number of mined triplets = 16862 \n",
      "Epoch 9 Iteration 600: Loss = 0.325073778629303, Number of mined triplets = 16387 \n",
      "Epoch 9 Iteration 700: Loss = 0.33136069774627686, Number of mined triplets = 16977 \n",
      "Validation loss:  0.3404524314403534\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 10 Iteration 0: Loss = 0.3119290769100189, Number of mined triplets = 14694 \n",
      "Epoch 10 Iteration 100: Loss = 0.3342111110687256, Number of mined triplets = 18078 \n",
      "Epoch 10 Iteration 200: Loss = 0.31350046396255493, Number of mined triplets = 16271 \n",
      "Epoch 10 Iteration 300: Loss = 0.35369420051574707, Number of mined triplets = 20132 \n",
      "Epoch 10 Iteration 400: Loss = 0.3409482538700104, Number of mined triplets = 15687 \n",
      "Epoch 10 Iteration 500: Loss = 0.3269301950931549, Number of mined triplets = 19951 \n",
      "Epoch 10 Iteration 600: Loss = 0.363463819026947, Number of mined triplets = 17995 \n",
      "Epoch 10 Iteration 700: Loss = 0.31077778339385986, Number of mined triplets = 15458 \n",
      "Validation loss:  0.3380947577953339\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 11 Iteration 0: Loss = 0.3605272173881531, Number of mined triplets = 15960 \n",
      "Epoch 11 Iteration 100: Loss = 0.3426303565502167, Number of mined triplets = 15568 \n",
      "Epoch 11 Iteration 200: Loss = 0.3657940626144409, Number of mined triplets = 19049 \n",
      "Epoch 11 Iteration 300: Loss = 0.3428097367286682, Number of mined triplets = 21596 \n",
      "Epoch 11 Iteration 400: Loss = 0.3431466519832611, Number of mined triplets = 18127 \n",
      "Epoch 11 Iteration 500: Loss = 0.29251426458358765, Number of mined triplets = 15408 \n",
      "Epoch 11 Iteration 600: Loss = 0.31247979402542114, Number of mined triplets = 15509 \n",
      "Epoch 11 Iteration 700: Loss = 0.33496996760368347, Number of mined triplets = 15942 \n",
      "Validation loss:  0.3400492507219315\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 12 Iteration 0: Loss = 0.34171828627586365, Number of mined triplets = 15960 \n",
      "Epoch 12 Iteration 100: Loss = 0.334364652633667, Number of mined triplets = 15322 \n",
      "Epoch 12 Iteration 200: Loss = 0.34729093313217163, Number of mined triplets = 18702 \n",
      "Epoch 12 Iteration 300: Loss = 0.3183389902114868, Number of mined triplets = 17261 \n",
      "Epoch 12 Iteration 400: Loss = 0.30526071786880493, Number of mined triplets = 14606 \n",
      "Epoch 12 Iteration 500: Loss = 0.342877596616745, Number of mined triplets = 17662 \n",
      "Epoch 12 Iteration 600: Loss = 0.32960012555122375, Number of mined triplets = 16376 \n",
      "Epoch 12 Iteration 700: Loss = 0.3527708351612091, Number of mined triplets = 17205 \n",
      "Validation loss:  0.34160563588142395\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 13 Iteration 0: Loss = 0.3347938060760498, Number of mined triplets = 17950 \n",
      "Epoch 13 Iteration 100: Loss = 0.3321737051010132, Number of mined triplets = 16417 \n",
      "Epoch 13 Iteration 200: Loss = 0.31430745124816895, Number of mined triplets = 15074 \n",
      "Epoch 13 Iteration 300: Loss = 0.30641889572143555, Number of mined triplets = 15519 \n",
      "Epoch 13 Iteration 400: Loss = 0.39146891236305237, Number of mined triplets = 16244 \n",
      "Epoch 13 Iteration 500: Loss = 0.3455643057823181, Number of mined triplets = 17378 \n",
      "Epoch 13 Iteration 600: Loss = 0.312689870595932, Number of mined triplets = 14977 \n",
      "Epoch 13 Iteration 700: Loss = 0.33475175499916077, Number of mined triplets = 17797 \n",
      "Validation loss:  0.33694833040237426\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 14 Iteration 0: Loss = 0.32161635160446167, Number of mined triplets = 19201 \n",
      "Epoch 14 Iteration 100: Loss = 0.3349858522415161, Number of mined triplets = 16319 \n",
      "Epoch 14 Iteration 200: Loss = 0.3217237591743469, Number of mined triplets = 18147 \n",
      "Epoch 14 Iteration 300: Loss = 0.31607988476753235, Number of mined triplets = 15204 \n",
      "Epoch 14 Iteration 400: Loss = 0.2874358296394348, Number of mined triplets = 14182 \n",
      "Epoch 14 Iteration 500: Loss = 0.3596402406692505, Number of mined triplets = 20346 \n",
      "Epoch 14 Iteration 600: Loss = 0.32701045274734497, Number of mined triplets = 15576 \n",
      "Epoch 14 Iteration 700: Loss = 0.34611865878105164, Number of mined triplets = 17863 \n",
      "Validation loss:  0.3419033402204514\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 15 Iteration 0: Loss = 0.3233593702316284, Number of mined triplets = 14735 \n",
      "Epoch 15 Iteration 100: Loss = 0.3627999722957611, Number of mined triplets = 14914 \n",
      "Epoch 15 Iteration 200: Loss = 0.31505852937698364, Number of mined triplets = 16147 \n",
      "Epoch 15 Iteration 300: Loss = 0.327367901802063, Number of mined triplets = 15554 \n",
      "Epoch 15 Iteration 400: Loss = 0.32181334495544434, Number of mined triplets = 17709 \n",
      "Epoch 15 Iteration 500: Loss = 0.349767804145813, Number of mined triplets = 17522 \n",
      "Epoch 15 Iteration 600: Loss = 0.3185095489025116, Number of mined triplets = 13160 \n",
      "Epoch 15 Iteration 700: Loss = 0.2937457263469696, Number of mined triplets = 16111 \n",
      "Validation loss:  0.3359616619348526\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 16 Iteration 0: Loss = 0.33261364698410034, Number of mined triplets = 17909 \n",
      "Epoch 16 Iteration 100: Loss = 0.3293347954750061, Number of mined triplets = 15016 \n",
      "Epoch 16 Iteration 200: Loss = 0.3316011428833008, Number of mined triplets = 15180 \n",
      "Epoch 16 Iteration 300: Loss = 0.34309059381484985, Number of mined triplets = 14915 \n",
      "Epoch 16 Iteration 400: Loss = 0.3510652780532837, Number of mined triplets = 17403 \n",
      "Epoch 16 Iteration 500: Loss = 0.3008321523666382, Number of mined triplets = 14740 \n",
      "Epoch 16 Iteration 600: Loss = 0.31142857670783997, Number of mined triplets = 13459 \n",
      "Epoch 16 Iteration 700: Loss = 0.34948447346687317, Number of mined triplets = 16332 \n",
      "Validation loss:  0.3288501673936844\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 17 Iteration 0: Loss = 0.3513379991054535, Number of mined triplets = 16160 \n",
      "Epoch 17 Iteration 100: Loss = 0.3212551772594452, Number of mined triplets = 17578 \n",
      "Epoch 17 Iteration 200: Loss = 0.3026483356952667, Number of mined triplets = 15793 \n",
      "Epoch 17 Iteration 300: Loss = 0.3212633728981018, Number of mined triplets = 17835 \n",
      "Epoch 17 Iteration 400: Loss = 0.35010942816734314, Number of mined triplets = 16961 \n",
      "Epoch 17 Iteration 500: Loss = 0.32275137305259705, Number of mined triplets = 14935 \n",
      "Epoch 17 Iteration 600: Loss = 0.3068472146987915, Number of mined triplets = 14587 \n",
      "Epoch 17 Iteration 700: Loss = 0.3361108899116516, Number of mined triplets = 15113 \n",
      "Validation loss:  0.32938954830169676\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 18 Iteration 0: Loss = 0.2973020672798157, Number of mined triplets = 14109 \n",
      "Epoch 18 Iteration 100: Loss = 0.3295610547065735, Number of mined triplets = 15881 \n",
      "Epoch 18 Iteration 200: Loss = 0.33420854806900024, Number of mined triplets = 14072 \n",
      "Epoch 18 Iteration 300: Loss = 0.3640854060649872, Number of mined triplets = 14983 \n",
      "Epoch 18 Iteration 400: Loss = 0.33991438150405884, Number of mined triplets = 14326 \n",
      "Epoch 18 Iteration 500: Loss = 0.31307655572891235, Number of mined triplets = 16355 \n",
      "Epoch 18 Iteration 600: Loss = 0.3100055754184723, Number of mined triplets = 14742 \n",
      "Epoch 18 Iteration 700: Loss = 0.36802026629447937, Number of mined triplets = 16508 \n",
      "Validation loss:  0.3257820391654968\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 19 Iteration 0: Loss = 0.34218311309814453, Number of mined triplets = 14318 \n",
      "Epoch 19 Iteration 100: Loss = 0.31772470474243164, Number of mined triplets = 17866 \n",
      "Epoch 19 Iteration 200: Loss = 0.34335681796073914, Number of mined triplets = 16780 \n",
      "Epoch 19 Iteration 300: Loss = 0.3302699029445648, Number of mined triplets = 15686 \n",
      "Epoch 19 Iteration 400: Loss = 0.35475704073905945, Number of mined triplets = 15003 \n",
      "Epoch 19 Iteration 500: Loss = 0.3090883791446686, Number of mined triplets = 15931 \n",
      "Epoch 19 Iteration 600: Loss = 0.30674344301223755, Number of mined triplets = 11245 \n",
      "Epoch 19 Iteration 700: Loss = 0.31638050079345703, Number of mined triplets = 15050 \n",
      "Validation loss:  0.32949399173259736\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 20 Iteration 0: Loss = 0.29487717151641846, Number of mined triplets = 14423 \n",
      "Epoch 20 Iteration 100: Loss = 0.32930609583854675, Number of mined triplets = 15732 \n",
      "Epoch 20 Iteration 200: Loss = 0.3358617424964905, Number of mined triplets = 14660 \n",
      "Epoch 20 Iteration 300: Loss = 0.3596991002559662, Number of mined triplets = 14944 \n",
      "Epoch 20 Iteration 400: Loss = 0.3183019757270813, Number of mined triplets = 14594 \n",
      "Epoch 20 Iteration 500: Loss = 0.3119919002056122, Number of mined triplets = 15295 \n",
      "Epoch 20 Iteration 600: Loss = 0.3402325510978699, Number of mined triplets = 15745 \n",
      "Epoch 20 Iteration 700: Loss = 0.3469521105289459, Number of mined triplets = 15839 \n",
      "Validation loss:  0.32388601541519163\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 21 Iteration 0: Loss = 0.3302810490131378, Number of mined triplets = 13109 \n",
      "Epoch 21 Iteration 100: Loss = 0.30652689933776855, Number of mined triplets = 12995 \n",
      "Epoch 21 Iteration 200: Loss = 0.33267447352409363, Number of mined triplets = 17375 \n",
      "Epoch 21 Iteration 300: Loss = 0.2986893653869629, Number of mined triplets = 15009 \n",
      "Epoch 21 Iteration 400: Loss = 0.32099029421806335, Number of mined triplets = 14378 \n",
      "Epoch 21 Iteration 500: Loss = 0.3077465891838074, Number of mined triplets = 14195 \n",
      "Epoch 21 Iteration 600: Loss = 0.3699088394641876, Number of mined triplets = 15552 \n",
      "Epoch 21 Iteration 700: Loss = 0.31428036093711853, Number of mined triplets = 15364 \n",
      "Validation loss:  0.31853216648101806\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 22 Iteration 0: Loss = 0.3245788514614105, Number of mined triplets = 15727 \n",
      "Epoch 22 Iteration 100: Loss = 0.32909902930259705, Number of mined triplets = 16566 \n",
      "Epoch 22 Iteration 200: Loss = 0.302856981754303, Number of mined triplets = 15857 \n",
      "Epoch 22 Iteration 300: Loss = 0.3347431421279907, Number of mined triplets = 14192 \n",
      "Epoch 22 Iteration 400: Loss = 0.2979888916015625, Number of mined triplets = 15359 \n",
      "Epoch 22 Iteration 500: Loss = 0.3476753532886505, Number of mined triplets = 15903 \n",
      "Epoch 22 Iteration 600: Loss = 0.3309646546840668, Number of mined triplets = 13849 \n",
      "Epoch 22 Iteration 700: Loss = 0.34765204787254333, Number of mined triplets = 14417 \n",
      "Validation loss:  0.32617643296718596\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 23 Iteration 0: Loss = 0.3383718729019165, Number of mined triplets = 14829 \n",
      "Epoch 23 Iteration 100: Loss = 0.32215172052383423, Number of mined triplets = 15650 \n",
      "Epoch 23 Iteration 200: Loss = 0.3253767490386963, Number of mined triplets = 14392 \n",
      "Epoch 23 Iteration 300: Loss = 0.3434467613697052, Number of mined triplets = 16750 \n",
      "Epoch 23 Iteration 400: Loss = 0.29196634888648987, Number of mined triplets = 13456 \n",
      "Epoch 23 Iteration 500: Loss = 0.3170219957828522, Number of mined triplets = 13122 \n",
      "Epoch 23 Iteration 600: Loss = 0.34510910511016846, Number of mined triplets = 14953 \n",
      "Epoch 23 Iteration 700: Loss = 0.34222784638404846, Number of mined triplets = 14582 \n",
      "Validation loss:  0.3312783932685852\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 24 Iteration 0: Loss = 0.3295039236545563, Number of mined triplets = 14380 \n",
      "Epoch 24 Iteration 100: Loss = 0.32364898920059204, Number of mined triplets = 15196 \n",
      "Epoch 24 Iteration 200: Loss = 0.2954748868942261, Number of mined triplets = 12413 \n",
      "Epoch 24 Iteration 300: Loss = 0.32031333446502686, Number of mined triplets = 13961 \n",
      "Epoch 24 Iteration 400: Loss = 0.3407575190067291, Number of mined triplets = 11754 \n",
      "Epoch 24 Iteration 500: Loss = 0.3460061848163605, Number of mined triplets = 13630 \n",
      "Epoch 24 Iteration 600: Loss = 0.35052046179771423, Number of mined triplets = 14842 \n",
      "Epoch 24 Iteration 700: Loss = 0.3252866268157959, Number of mined triplets = 14469 \n",
      "Validation loss:  0.3188080072402954\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 25 Iteration 0: Loss = 0.3257887065410614, Number of mined triplets = 14162 \n",
      "Epoch 25 Iteration 100: Loss = 0.31588539481163025, Number of mined triplets = 13853 \n",
      "Epoch 25 Iteration 200: Loss = 0.32509899139404297, Number of mined triplets = 13799 \n",
      "Epoch 25 Iteration 300: Loss = 0.3115127980709076, Number of mined triplets = 12788 \n",
      "Epoch 25 Iteration 400: Loss = 0.32630112767219543, Number of mined triplets = 19142 \n",
      "Epoch 25 Iteration 500: Loss = 0.3468438982963562, Number of mined triplets = 16640 \n",
      "Epoch 25 Iteration 600: Loss = 0.3526407480239868, Number of mined triplets = 16497 \n",
      "Epoch 25 Iteration 700: Loss = 0.33060237765312195, Number of mined triplets = 15215 \n",
      "Validation loss:  0.3139959317445755\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 26 Iteration 0: Loss = 0.2963113486766815, Number of mined triplets = 13983 \n",
      "Epoch 26 Iteration 100: Loss = 0.33712127804756165, Number of mined triplets = 14307 \n",
      "Epoch 26 Iteration 200: Loss = 0.3419606685638428, Number of mined triplets = 14519 \n",
      "Epoch 26 Iteration 300: Loss = 0.324582576751709, Number of mined triplets = 18119 \n",
      "Epoch 26 Iteration 400: Loss = 0.2866876423358917, Number of mined triplets = 11525 \n",
      "Epoch 26 Iteration 500: Loss = 0.3225726783275604, Number of mined triplets = 13961 \n",
      "Epoch 26 Iteration 600: Loss = 0.31346121430397034, Number of mined triplets = 13527 \n",
      "Epoch 26 Iteration 700: Loss = 0.30875521898269653, Number of mined triplets = 12542 \n",
      "Validation loss:  0.3193747305870056\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 27 Iteration 0: Loss = 0.3369361460208893, Number of mined triplets = 14523 \n",
      "Epoch 27 Iteration 100: Loss = 0.3318755626678467, Number of mined triplets = 15366 \n",
      "Epoch 27 Iteration 200: Loss = 0.35318535566329956, Number of mined triplets = 20473 \n",
      "Epoch 27 Iteration 300: Loss = 0.3067275583744049, Number of mined triplets = 12338 \n",
      "Epoch 27 Iteration 400: Loss = 0.2915818393230438, Number of mined triplets = 14379 \n",
      "Epoch 27 Iteration 500: Loss = 0.3156692087650299, Number of mined triplets = 16459 \n",
      "Epoch 27 Iteration 600: Loss = 0.28017351031303406, Number of mined triplets = 12458 \n",
      "Epoch 27 Iteration 700: Loss = 0.32229888439178467, Number of mined triplets = 14647 \n",
      "Validation loss:  0.3207820987701416\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 28 Iteration 0: Loss = 0.35231244564056396, Number of mined triplets = 17766 \n",
      "Epoch 28 Iteration 100: Loss = 0.33098500967025757, Number of mined triplets = 15838 \n",
      "Epoch 28 Iteration 200: Loss = 0.2962713837623596, Number of mined triplets = 14084 \n",
      "Epoch 28 Iteration 300: Loss = 0.3652454614639282, Number of mined triplets = 14847 \n",
      "Epoch 28 Iteration 400: Loss = 0.32027667760849, Number of mined triplets = 14964 \n",
      "Epoch 28 Iteration 500: Loss = 0.316795289516449, Number of mined triplets = 14825 \n",
      "Epoch 28 Iteration 600: Loss = 0.3005523383617401, Number of mined triplets = 16017 \n",
      "Epoch 28 Iteration 700: Loss = 0.3427775800228119, Number of mined triplets = 15323 \n",
      "Validation loss:  0.3158895421028137\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 29 Iteration 0: Loss = 0.29697558283805847, Number of mined triplets = 11841 \n",
      "Epoch 29 Iteration 100: Loss = 0.3217279016971588, Number of mined triplets = 13784 \n",
      "Epoch 29 Iteration 200: Loss = 0.345129132270813, Number of mined triplets = 12966 \n",
      "Epoch 29 Iteration 300: Loss = 0.35573381185531616, Number of mined triplets = 14413 \n",
      "Epoch 29 Iteration 400: Loss = 0.32045161724090576, Number of mined triplets = 15103 \n",
      "Epoch 29 Iteration 500: Loss = 0.3328312337398529, Number of mined triplets = 16092 \n",
      "Epoch 29 Iteration 600: Loss = 0.32206428050994873, Number of mined triplets = 14950 \n",
      "Epoch 29 Iteration 700: Loss = 0.29071906208992004, Number of mined triplets = 12074 \n",
      "Validation loss:  0.3167476361989975\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 30 Iteration 0: Loss = 0.2714524567127228, Number of mined triplets = 12433 \n",
      "Epoch 30 Iteration 100: Loss = 0.28507062792778015, Number of mined triplets = 12192 \n",
      "Epoch 30 Iteration 200: Loss = 0.3058372735977173, Number of mined triplets = 12989 \n",
      "Epoch 30 Iteration 300: Loss = 0.3620905876159668, Number of mined triplets = 18254 \n",
      "Epoch 30 Iteration 400: Loss = 0.30031105875968933, Number of mined triplets = 13704 \n",
      "Epoch 30 Iteration 500: Loss = 0.30139532685279846, Number of mined triplets = 13914 \n",
      "Epoch 30 Iteration 600: Loss = 0.29362502694129944, Number of mined triplets = 12764 \n",
      "Epoch 30 Iteration 700: Loss = 0.31822800636291504, Number of mined triplets = 18085 \n",
      "Validation loss:  0.31500635623931883\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 31 Iteration 0: Loss = 0.31816405057907104, Number of mined triplets = 16544 \n",
      "Epoch 31 Iteration 100: Loss = 0.2942361831665039, Number of mined triplets = 13892 \n",
      "Epoch 31 Iteration 200: Loss = 0.30534499883651733, Number of mined triplets = 13517 \n",
      "Epoch 31 Iteration 300: Loss = 0.3247937858104706, Number of mined triplets = 14720 \n",
      "Epoch 31 Iteration 400: Loss = 0.29828622937202454, Number of mined triplets = 15656 \n",
      "Epoch 31 Iteration 500: Loss = 0.2985551953315735, Number of mined triplets = 14719 \n",
      "Epoch 31 Iteration 600: Loss = 0.3117541968822479, Number of mined triplets = 13246 \n",
      "Epoch 31 Iteration 700: Loss = 0.2994473874568939, Number of mined triplets = 12556 \n",
      "Validation loss:  0.32041418612003325\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 32 Iteration 0: Loss = 0.2779366374015808, Number of mined triplets = 15658 \n",
      "Epoch 32 Iteration 100: Loss = 0.3135741055011749, Number of mined triplets = 12707 \n",
      "Epoch 32 Iteration 200: Loss = 0.3193082809448242, Number of mined triplets = 14314 \n",
      "Epoch 32 Iteration 300: Loss = 0.31391027569770813, Number of mined triplets = 15849 \n",
      "Epoch 32 Iteration 400: Loss = 0.31782424449920654, Number of mined triplets = 13726 \n",
      "Epoch 32 Iteration 500: Loss = 0.30926838517189026, Number of mined triplets = 11872 \n",
      "Epoch 32 Iteration 600: Loss = 0.2997303009033203, Number of mined triplets = 12819 \n",
      "Epoch 32 Iteration 700: Loss = 0.29658597707748413, Number of mined triplets = 12342 \n",
      "Validation loss:  0.32116627871990205\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 33 Iteration 0: Loss = 0.3648820221424103, Number of mined triplets = 13493 \n",
      "Epoch 33 Iteration 100: Loss = 0.35419660806655884, Number of mined triplets = 14293 \n",
      "Epoch 33 Iteration 200: Loss = 0.312924325466156, Number of mined triplets = 14580 \n",
      "Epoch 33 Iteration 300: Loss = 0.31331875920295715, Number of mined triplets = 14547 \n",
      "Epoch 33 Iteration 400: Loss = 0.33091965317726135, Number of mined triplets = 13788 \n",
      "Epoch 33 Iteration 500: Loss = 0.31956785917282104, Number of mined triplets = 15522 \n",
      "Epoch 33 Iteration 600: Loss = 0.2902344763278961, Number of mined triplets = 12938 \n",
      "Epoch 33 Iteration 700: Loss = 0.30133309960365295, Number of mined triplets = 12499 \n",
      "Validation loss:  0.3081682473421097\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 34 Iteration 0: Loss = 0.33027419447898865, Number of mined triplets = 13354 \n",
      "Epoch 34 Iteration 100: Loss = 0.306698739528656, Number of mined triplets = 14037 \n",
      "Epoch 34 Iteration 200: Loss = 0.3133029043674469, Number of mined triplets = 15493 \n",
      "Epoch 34 Iteration 300: Loss = 0.3333248496055603, Number of mined triplets = 14995 \n",
      "Epoch 34 Iteration 400: Loss = 0.321296751499176, Number of mined triplets = 15050 \n",
      "Epoch 34 Iteration 500: Loss = 0.3041878342628479, Number of mined triplets = 14016 \n",
      "Epoch 34 Iteration 600: Loss = 0.31605806946754456, Number of mined triplets = 13467 \n",
      "Epoch 34 Iteration 700: Loss = 0.3205130994319916, Number of mined triplets = 15345 \n",
      "Validation loss:  0.3144082444906235\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 35 Iteration 0: Loss = 0.31583288311958313, Number of mined triplets = 16206 \n",
      "Epoch 35 Iteration 100: Loss = 0.3094554543495178, Number of mined triplets = 14839 \n",
      "Epoch 35 Iteration 200: Loss = 0.30157989263534546, Number of mined triplets = 13207 \n",
      "Epoch 35 Iteration 300: Loss = 0.32021564245224, Number of mined triplets = 12620 \n",
      "Epoch 35 Iteration 400: Loss = 0.2797887921333313, Number of mined triplets = 11561 \n",
      "Epoch 35 Iteration 500: Loss = 0.33438342809677124, Number of mined triplets = 12738 \n",
      "Epoch 35 Iteration 600: Loss = 0.31622740626335144, Number of mined triplets = 12662 \n",
      "Epoch 35 Iteration 700: Loss = 0.34043532609939575, Number of mined triplets = 12262 \n",
      "Validation loss:  0.3147460407018661\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 36 Iteration 0: Loss = 0.3122357726097107, Number of mined triplets = 13326 \n",
      "Epoch 36 Iteration 100: Loss = 0.292763888835907, Number of mined triplets = 11854 \n",
      "Epoch 36 Iteration 200: Loss = 0.31088200211524963, Number of mined triplets = 12888 \n",
      "Epoch 36 Iteration 300: Loss = 0.3051931858062744, Number of mined triplets = 12303 \n",
      "Epoch 36 Iteration 400: Loss = 0.2928079068660736, Number of mined triplets = 10965 \n",
      "Epoch 36 Iteration 500: Loss = 0.3043077886104584, Number of mined triplets = 10718 \n",
      "Epoch 36 Iteration 600: Loss = 0.3056930601596832, Number of mined triplets = 15320 \n",
      "Epoch 36 Iteration 700: Loss = 0.30387234687805176, Number of mined triplets = 12496 \n",
      "Validation loss:  0.3072650009393692\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 37 Iteration 0: Loss = 0.3024551272392273, Number of mined triplets = 11725 \n",
      "Epoch 37 Iteration 100: Loss = 0.3207989037036896, Number of mined triplets = 11975 \n",
      "Epoch 37 Iteration 200: Loss = 0.3051157593727112, Number of mined triplets = 15650 \n",
      "Epoch 37 Iteration 300: Loss = 0.30694204568862915, Number of mined triplets = 12578 \n",
      "Epoch 37 Iteration 400: Loss = 0.350890189409256, Number of mined triplets = 14233 \n",
      "Epoch 37 Iteration 500: Loss = 0.304584801197052, Number of mined triplets = 14749 \n",
      "Epoch 37 Iteration 600: Loss = 0.30487367510795593, Number of mined triplets = 12637 \n",
      "Epoch 37 Iteration 700: Loss = 0.31297412514686584, Number of mined triplets = 14071 \n",
      "Validation loss:  0.31931250989437104\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 38 Iteration 0: Loss = 0.32529014348983765, Number of mined triplets = 13592 \n",
      "Epoch 38 Iteration 100: Loss = 0.3066493570804596, Number of mined triplets = 13564 \n",
      "Epoch 38 Iteration 200: Loss = 0.31963759660720825, Number of mined triplets = 11999 \n",
      "Epoch 38 Iteration 300: Loss = 0.334449827671051, Number of mined triplets = 14423 \n",
      "Epoch 38 Iteration 400: Loss = 0.29901188611984253, Number of mined triplets = 14954 \n",
      "Epoch 38 Iteration 500: Loss = 0.33589956164360046, Number of mined triplets = 14853 \n",
      "Epoch 38 Iteration 600: Loss = 0.27180561423301697, Number of mined triplets = 11671 \n",
      "Epoch 38 Iteration 700: Loss = 0.3112335205078125, Number of mined triplets = 16322 \n",
      "Validation loss:  0.3148623776435852\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 39 Iteration 0: Loss = 0.30104705691337585, Number of mined triplets = 15010 \n",
      "Epoch 39 Iteration 100: Loss = 0.29453104734420776, Number of mined triplets = 12467 \n",
      "Epoch 39 Iteration 200: Loss = 0.29991668462753296, Number of mined triplets = 11108 \n",
      "Epoch 39 Iteration 300: Loss = 0.3096367120742798, Number of mined triplets = 13461 \n",
      "Epoch 39 Iteration 400: Loss = 0.34239107370376587, Number of mined triplets = 13714 \n",
      "Epoch 39 Iteration 500: Loss = 0.3452512323856354, Number of mined triplets = 14499 \n",
      "Epoch 39 Iteration 600: Loss = 0.2855355143547058, Number of mined triplets = 11599 \n",
      "Epoch 39 Iteration 700: Loss = 0.348458856344223, Number of mined triplets = 13722 \n",
      "Validation loss:  0.3157135093212128\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 40 Iteration 0: Loss = 0.306977778673172, Number of mined triplets = 12043 \n",
      "Epoch 40 Iteration 100: Loss = 0.30645039677619934, Number of mined triplets = 13528 \n",
      "Epoch 40 Iteration 200: Loss = 0.3115788996219635, Number of mined triplets = 14910 \n",
      "Epoch 40 Iteration 300: Loss = 0.3023413419723511, Number of mined triplets = 11598 \n",
      "Epoch 40 Iteration 400: Loss = 0.3157738745212555, Number of mined triplets = 15295 \n",
      "Epoch 40 Iteration 500: Loss = 0.32767388224601746, Number of mined triplets = 13885 \n",
      "Epoch 40 Iteration 600: Loss = 0.27580416202545166, Number of mined triplets = 12968 \n",
      "Epoch 40 Iteration 700: Loss = 0.325054794549942, Number of mined triplets = 13348 \n",
      "Validation loss:  0.31008599400520326\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 41 Iteration 0: Loss = 0.2733803391456604, Number of mined triplets = 12606 \n",
      "Epoch 41 Iteration 100: Loss = 0.3136022686958313, Number of mined triplets = 14203 \n",
      "Epoch 41 Iteration 200: Loss = 0.31085485219955444, Number of mined triplets = 14964 \n",
      "Epoch 41 Iteration 300: Loss = 0.303904265165329, Number of mined triplets = 10715 \n",
      "Epoch 41 Iteration 400: Loss = 0.30366095900535583, Number of mined triplets = 11448 \n",
      "Epoch 41 Iteration 500: Loss = 0.3317204415798187, Number of mined triplets = 13323 \n",
      "Epoch 41 Iteration 600: Loss = 0.29457008838653564, Number of mined triplets = 12123 \n",
      "Epoch 41 Iteration 700: Loss = 0.26702913641929626, Number of mined triplets = 11214 \n",
      "Validation loss:  0.3050295102596283\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 42 Iteration 0: Loss = 0.3115045726299286, Number of mined triplets = 11582 \n",
      "Epoch 42 Iteration 100: Loss = 0.283530592918396, Number of mined triplets = 11731 \n",
      "Epoch 42 Iteration 200: Loss = 0.305490642786026, Number of mined triplets = 14731 \n",
      "Epoch 42 Iteration 300: Loss = 0.3018330931663513, Number of mined triplets = 13698 \n",
      "Epoch 42 Iteration 400: Loss = 0.29796355962753296, Number of mined triplets = 12115 \n",
      "Epoch 42 Iteration 500: Loss = 0.3080187439918518, Number of mined triplets = 12232 \n",
      "Epoch 42 Iteration 600: Loss = 0.282522588968277, Number of mined triplets = 12905 \n",
      "Epoch 42 Iteration 700: Loss = 0.3172460198402405, Number of mined triplets = 12268 \n",
      "Validation loss:  0.30906633913517\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 43 Iteration 0: Loss = 0.35364842414855957, Number of mined triplets = 14154 \n",
      "Epoch 43 Iteration 100: Loss = 0.30404195189476013, Number of mined triplets = 12142 \n",
      "Epoch 43 Iteration 200: Loss = 0.2890748679637909, Number of mined triplets = 11028 \n",
      "Epoch 43 Iteration 300: Loss = 0.2968748211860657, Number of mined triplets = 11590 \n",
      "Epoch 43 Iteration 400: Loss = 0.3132600486278534, Number of mined triplets = 13880 \n",
      "Epoch 43 Iteration 500: Loss = 0.29694074392318726, Number of mined triplets = 12063 \n",
      "Epoch 43 Iteration 600: Loss = 0.3489128351211548, Number of mined triplets = 15128 \n",
      "Epoch 43 Iteration 700: Loss = 0.3157632350921631, Number of mined triplets = 14205 \n",
      "Validation loss:  0.31236122608184813\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 44 Iteration 0: Loss = 0.306551069021225, Number of mined triplets = 12453 \n",
      "Epoch 44 Iteration 100: Loss = 0.28329533338546753, Number of mined triplets = 10542 \n",
      "Epoch 44 Iteration 200: Loss = 0.2867911756038666, Number of mined triplets = 11764 \n",
      "Epoch 44 Iteration 300: Loss = 0.310828298330307, Number of mined triplets = 12457 \n",
      "Epoch 44 Iteration 400: Loss = 0.32692644000053406, Number of mined triplets = 13532 \n",
      "Epoch 44 Iteration 500: Loss = 0.2851347327232361, Number of mined triplets = 10972 \n",
      "Epoch 44 Iteration 600: Loss = 0.29499009251594543, Number of mined triplets = 11490 \n",
      "Epoch 44 Iteration 700: Loss = 0.28051215410232544, Number of mined triplets = 11236 \n",
      "Validation loss:  0.3188982427120209\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 45 Iteration 0: Loss = 0.3065442740917206, Number of mined triplets = 11761 \n",
      "Epoch 45 Iteration 100: Loss = 0.33500680327415466, Number of mined triplets = 13652 \n",
      "Epoch 45 Iteration 200: Loss = 0.3737579882144928, Number of mined triplets = 15672 \n",
      "Epoch 45 Iteration 300: Loss = 0.3207305073738098, Number of mined triplets = 11296 \n",
      "Epoch 45 Iteration 400: Loss = 0.3214114308357239, Number of mined triplets = 12747 \n",
      "Epoch 45 Iteration 500: Loss = 0.32371824979782104, Number of mined triplets = 13229 \n",
      "Epoch 45 Iteration 600: Loss = 0.295447438955307, Number of mined triplets = 12067 \n",
      "Epoch 45 Iteration 700: Loss = 0.31883713603019714, Number of mined triplets = 11013 \n",
      "Validation loss:  0.3094822978973389\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 46 Iteration 0: Loss = 0.2681247889995575, Number of mined triplets = 11303 \n",
      "Epoch 46 Iteration 100: Loss = 0.31253376603126526, Number of mined triplets = 13940 \n",
      "Epoch 46 Iteration 200: Loss = 0.34069815278053284, Number of mined triplets = 13605 \n",
      "Epoch 46 Iteration 300: Loss = 0.29039818048477173, Number of mined triplets = 10871 \n",
      "Epoch 46 Iteration 400: Loss = 0.3015269935131073, Number of mined triplets = 12300 \n",
      "Epoch 46 Iteration 500: Loss = 0.3162148892879486, Number of mined triplets = 15079 \n",
      "Epoch 46 Iteration 600: Loss = 0.2959805428981781, Number of mined triplets = 13196 \n",
      "Epoch 46 Iteration 700: Loss = 0.29563242197036743, Number of mined triplets = 12231 \n",
      "Validation loss:  0.3126454615592957\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 47 Iteration 0: Loss = 0.3304567039012909, Number of mined triplets = 14722 \n",
      "Epoch 47 Iteration 100: Loss = 0.3238891363143921, Number of mined triplets = 12807 \n",
      "Epoch 47 Iteration 200: Loss = 0.33439919352531433, Number of mined triplets = 12908 \n",
      "Epoch 47 Iteration 300: Loss = 0.3006443977355957, Number of mined triplets = 12740 \n",
      "Epoch 47 Iteration 400: Loss = 0.34711456298828125, Number of mined triplets = 13075 \n",
      "Epoch 47 Iteration 500: Loss = 0.31849929690361023, Number of mined triplets = 11799 \n",
      "Epoch 47 Iteration 600: Loss = 0.2871564030647278, Number of mined triplets = 11325 \n",
      "Epoch 47 Iteration 700: Loss = 0.3165968358516693, Number of mined triplets = 13914 \n",
      "Validation loss:  0.3161862003803253\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 48 Iteration 0: Loss = 0.30834200978279114, Number of mined triplets = 14532 \n",
      "Epoch 48 Iteration 100: Loss = 0.3344145119190216, Number of mined triplets = 14928 \n",
      "Epoch 48 Iteration 200: Loss = 0.31018874049186707, Number of mined triplets = 11837 \n",
      "Epoch 48 Iteration 300: Loss = 0.2983038127422333, Number of mined triplets = 14742 \n",
      "Epoch 48 Iteration 400: Loss = 0.30080661177635193, Number of mined triplets = 12614 \n",
      "Epoch 48 Iteration 500: Loss = 0.3138655126094818, Number of mined triplets = 12434 \n",
      "Epoch 48 Iteration 600: Loss = 0.30490291118621826, Number of mined triplets = 11741 \n",
      "Epoch 48 Iteration 700: Loss = 0.3312782943248749, Number of mined triplets = 11800 \n",
      "Validation loss:  0.30727373957633974\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 49 Iteration 0: Loss = 0.3533911406993866, Number of mined triplets = 14606 \n",
      "Epoch 49 Iteration 100: Loss = 0.292656272649765, Number of mined triplets = 12099 \n",
      "Epoch 49 Iteration 200: Loss = 0.3061213493347168, Number of mined triplets = 13363 \n",
      "Epoch 49 Iteration 300: Loss = 0.31458601355552673, Number of mined triplets = 15020 \n",
      "Epoch 49 Iteration 400: Loss = 0.3351899981498718, Number of mined triplets = 12185 \n",
      "Epoch 49 Iteration 500: Loss = 0.2943729758262634, Number of mined triplets = 12511 \n",
      "Epoch 49 Iteration 600: Loss = 0.3123149275779724, Number of mined triplets = 11802 \n",
      "Epoch 49 Iteration 700: Loss = 0.3370993137359619, Number of mined triplets = 14681 \n",
      "Validation loss:  0.306972416639328\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 50 Iteration 0: Loss = 0.3339761793613434, Number of mined triplets = 12980 \n",
      "Epoch 50 Iteration 100: Loss = 0.28630688786506653, Number of mined triplets = 11420 \n",
      "Epoch 50 Iteration 200: Loss = 0.29808029532432556, Number of mined triplets = 11653 \n",
      "Epoch 50 Iteration 300: Loss = 0.30616575479507446, Number of mined triplets = 11821 \n",
      "Epoch 50 Iteration 400: Loss = 0.2964912950992584, Number of mined triplets = 12728 \n",
      "Epoch 50 Iteration 500: Loss = 0.31795763969421387, Number of mined triplets = 14273 \n",
      "Epoch 50 Iteration 600: Loss = 0.3018081486225128, Number of mined triplets = 12187 \n",
      "Epoch 50 Iteration 700: Loss = 0.358659029006958, Number of mined triplets = 14251 \n",
      "Validation loss:  0.3062440997362137\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 51 Iteration 0: Loss = 0.32003065943717957, Number of mined triplets = 12538 \n",
      "Epoch 51 Iteration 100: Loss = 0.32867830991744995, Number of mined triplets = 12738 \n",
      "Epoch 51 Iteration 200: Loss = 0.29726287722587585, Number of mined triplets = 14621 \n",
      "Epoch 51 Iteration 300: Loss = 0.27028536796569824, Number of mined triplets = 12139 \n",
      "Epoch 51 Iteration 400: Loss = 0.3240865170955658, Number of mined triplets = 13222 \n",
      "Epoch 51 Iteration 500: Loss = 0.30214256048202515, Number of mined triplets = 13904 \n",
      "Epoch 51 Iteration 600: Loss = 0.28605949878692627, Number of mined triplets = 12730 \n",
      "Epoch 51 Iteration 700: Loss = 0.29916155338287354, Number of mined triplets = 11158 \n",
      "Validation loss:  0.29967977702617643\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 52 Iteration 0: Loss = 0.27996349334716797, Number of mined triplets = 10901 \n",
      "Epoch 52 Iteration 100: Loss = 0.3159511387348175, Number of mined triplets = 14840 \n",
      "Epoch 52 Iteration 200: Loss = 0.3425349295139313, Number of mined triplets = 13348 \n",
      "Epoch 52 Iteration 300: Loss = 0.3234412968158722, Number of mined triplets = 12563 \n",
      "Epoch 52 Iteration 400: Loss = 0.30228105187416077, Number of mined triplets = 12231 \n",
      "Epoch 52 Iteration 500: Loss = 0.2787116467952728, Number of mined triplets = 12694 \n",
      "Epoch 52 Iteration 600: Loss = 0.3289882242679596, Number of mined triplets = 14121 \n",
      "Epoch 52 Iteration 700: Loss = 0.2918950319290161, Number of mined triplets = 11788 \n",
      "Validation loss:  0.30796335995197294\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 53 Iteration 0: Loss = 0.26808369159698486, Number of mined triplets = 10873 \n",
      "Epoch 53 Iteration 100: Loss = 0.2937106490135193, Number of mined triplets = 12001 \n",
      "Epoch 53 Iteration 200: Loss = 0.2975648045539856, Number of mined triplets = 12579 \n",
      "Epoch 53 Iteration 300: Loss = 0.28658315539360046, Number of mined triplets = 11487 \n",
      "Epoch 53 Iteration 400: Loss = 0.2894035577774048, Number of mined triplets = 11549 \n",
      "Epoch 53 Iteration 500: Loss = 0.26860520243644714, Number of mined triplets = 11140 \n",
      "Epoch 53 Iteration 600: Loss = 0.3274524509906769, Number of mined triplets = 12396 \n",
      "Epoch 53 Iteration 700: Loss = 0.3454635441303253, Number of mined triplets = 13826 \n",
      "Validation loss:  0.307535218000412\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 54 Iteration 0: Loss = 0.2889401614665985, Number of mined triplets = 12112 \n",
      "Epoch 54 Iteration 100: Loss = 0.3122056722640991, Number of mined triplets = 12091 \n",
      "Epoch 54 Iteration 200: Loss = 0.33853939175605774, Number of mined triplets = 12235 \n",
      "Epoch 54 Iteration 300: Loss = 0.29487648606300354, Number of mined triplets = 11825 \n",
      "Epoch 54 Iteration 400: Loss = 0.3491027355194092, Number of mined triplets = 14898 \n",
      "Epoch 54 Iteration 500: Loss = 0.29840222001075745, Number of mined triplets = 11456 \n",
      "Epoch 54 Iteration 600: Loss = 0.35202354192733765, Number of mined triplets = 13990 \n",
      "Epoch 54 Iteration 700: Loss = 0.27656611800193787, Number of mined triplets = 11863 \n",
      "Validation loss:  0.3013697934150696\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 55 Iteration 0: Loss = 0.29998019337654114, Number of mined triplets = 12519 \n",
      "Epoch 55 Iteration 100: Loss = 0.29167118668556213, Number of mined triplets = 11034 \n",
      "Epoch 55 Iteration 200: Loss = 0.32808905839920044, Number of mined triplets = 13638 \n",
      "Epoch 55 Iteration 300: Loss = 0.34951701760292053, Number of mined triplets = 15694 \n",
      "Epoch 55 Iteration 400: Loss = 0.29036927223205566, Number of mined triplets = 12499 \n",
      "Epoch 55 Iteration 500: Loss = 0.2909744083881378, Number of mined triplets = 11989 \n",
      "Epoch 55 Iteration 600: Loss = 0.30789563059806824, Number of mined triplets = 13006 \n",
      "Epoch 55 Iteration 700: Loss = 0.2914716899394989, Number of mined triplets = 12029 \n",
      "Validation loss:  0.31074762940406797\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 56 Iteration 0: Loss = 0.26868847012519836, Number of mined triplets = 10914 \n",
      "Epoch 56 Iteration 100: Loss = 0.3347988426685333, Number of mined triplets = 12654 \n",
      "Epoch 56 Iteration 200: Loss = 0.30507761240005493, Number of mined triplets = 13030 \n",
      "Epoch 56 Iteration 300: Loss = 0.3225253224372864, Number of mined triplets = 12484 \n",
      "Epoch 56 Iteration 400: Loss = 0.30308112502098083, Number of mined triplets = 12672 \n",
      "Epoch 56 Iteration 500: Loss = 0.31510257720947266, Number of mined triplets = 13395 \n",
      "Epoch 56 Iteration 600: Loss = 0.314566433429718, Number of mined triplets = 10342 \n",
      "Epoch 56 Iteration 700: Loss = 0.3350585699081421, Number of mined triplets = 12054 \n",
      "Validation loss:  0.308540917634964\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 57 Iteration 0: Loss = 0.3106324374675751, Number of mined triplets = 12526 \n",
      "Epoch 57 Iteration 100: Loss = 0.302127480506897, Number of mined triplets = 11901 \n",
      "Epoch 57 Iteration 200: Loss = 0.3317606747150421, Number of mined triplets = 11778 \n",
      "Epoch 57 Iteration 300: Loss = 0.316857248544693, Number of mined triplets = 14878 \n",
      "Epoch 57 Iteration 400: Loss = 0.32191839814186096, Number of mined triplets = 12575 \n",
      "Epoch 57 Iteration 500: Loss = 0.2885901927947998, Number of mined triplets = 11391 \n",
      "Epoch 57 Iteration 600: Loss = 0.31613099575042725, Number of mined triplets = 12990 \n",
      "Epoch 57 Iteration 700: Loss = 0.3087281286716461, Number of mined triplets = 12935 \n",
      "Validation loss:  0.3012078368663788\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 58 Iteration 0: Loss = 0.31261521577835083, Number of mined triplets = 11158 \n",
      "Epoch 58 Iteration 100: Loss = 0.2973366677761078, Number of mined triplets = 10925 \n",
      "Epoch 58 Iteration 200: Loss = 0.273637592792511, Number of mined triplets = 12389 \n",
      "Epoch 58 Iteration 300: Loss = 0.29388853907585144, Number of mined triplets = 10991 \n",
      "Epoch 58 Iteration 400: Loss = 0.28384819626808167, Number of mined triplets = 11985 \n",
      "Epoch 58 Iteration 500: Loss = 0.3015420734882355, Number of mined triplets = 10348 \n",
      "Epoch 58 Iteration 600: Loss = 0.29376617074012756, Number of mined triplets = 11668 \n",
      "Epoch 58 Iteration 700: Loss = 0.3227076828479767, Number of mined triplets = 15274 \n",
      "Validation loss:  0.31136818110942843\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 59 Iteration 0: Loss = 0.29357779026031494, Number of mined triplets = 12425 \n",
      "Epoch 59 Iteration 100: Loss = 0.3399217128753662, Number of mined triplets = 13475 \n",
      "Epoch 59 Iteration 200: Loss = 0.315439909696579, Number of mined triplets = 11750 \n",
      "Epoch 59 Iteration 300: Loss = 0.29684358835220337, Number of mined triplets = 12377 \n",
      "Epoch 59 Iteration 400: Loss = 0.3094521164894104, Number of mined triplets = 11729 \n",
      "Epoch 59 Iteration 500: Loss = 0.3132246434688568, Number of mined triplets = 12745 \n",
      "Epoch 59 Iteration 600: Loss = 0.2959701120853424, Number of mined triplets = 11697 \n",
      "Epoch 59 Iteration 700: Loss = 0.28660067915916443, Number of mined triplets = 12306 \n",
      "Validation loss:  0.3072385150194168\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 60 Iteration 0: Loss = 0.3079517185688019, Number of mined triplets = 13872 \n",
      "Epoch 60 Iteration 100: Loss = 0.30381497740745544, Number of mined triplets = 11500 \n",
      "Epoch 60 Iteration 200: Loss = 0.3060542345046997, Number of mined triplets = 12080 \n",
      "Epoch 60 Iteration 300: Loss = 0.27774283289909363, Number of mined triplets = 12147 \n",
      "Epoch 60 Iteration 400: Loss = 0.3073684573173523, Number of mined triplets = 10882 \n",
      "Epoch 60 Iteration 500: Loss = 0.2821912169456482, Number of mined triplets = 8912 \n",
      "Epoch 60 Iteration 600: Loss = 0.2875690758228302, Number of mined triplets = 10569 \n",
      "Epoch 60 Iteration 700: Loss = 0.28609779477119446, Number of mined triplets = 11598 \n",
      "Validation loss:  0.304896679520607\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 61 Iteration 0: Loss = 0.30667242407798767, Number of mined triplets = 13602 \n",
      "Epoch 61 Iteration 100: Loss = 0.28705480694770813, Number of mined triplets = 9761 \n",
      "Epoch 61 Iteration 200: Loss = 0.3253398835659027, Number of mined triplets = 13763 \n",
      "Epoch 61 Iteration 300: Loss = 0.3281680643558502, Number of mined triplets = 13082 \n",
      "Epoch 61 Iteration 400: Loss = 0.32311299443244934, Number of mined triplets = 12879 \n",
      "Epoch 61 Iteration 500: Loss = 0.29624083638191223, Number of mined triplets = 11257 \n",
      "Epoch 61 Iteration 600: Loss = 0.2873416244983673, Number of mined triplets = 10981 \n",
      "Epoch 61 Iteration 700: Loss = 0.3070112466812134, Number of mined triplets = 11333 \n",
      "Validation loss:  0.30498326897621153\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 62 Iteration 0: Loss = 0.33908119797706604, Number of mined triplets = 13630 \n",
      "Epoch 62 Iteration 100: Loss = 0.3071966767311096, Number of mined triplets = 13204 \n",
      "Epoch 62 Iteration 200: Loss = 0.3205089271068573, Number of mined triplets = 10840 \n",
      "Epoch 62 Iteration 300: Loss = 0.28700923919677734, Number of mined triplets = 10646 \n",
      "Epoch 62 Iteration 400: Loss = 0.2774023115634918, Number of mined triplets = 10272 \n",
      "Epoch 62 Iteration 500: Loss = 0.26323267817497253, Number of mined triplets = 9550 \n",
      "Epoch 62 Iteration 600: Loss = 0.31046104431152344, Number of mined triplets = 12113 \n",
      "Epoch 62 Iteration 700: Loss = 0.3104155361652374, Number of mined triplets = 10846 \n",
      "Validation loss:  0.2974529790878296\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 63 Iteration 0: Loss = 0.3907317817211151, Number of mined triplets = 14429 \n",
      "Epoch 63 Iteration 100: Loss = 0.2835746109485626, Number of mined triplets = 10790 \n",
      "Epoch 63 Iteration 200: Loss = 0.28429272770881653, Number of mined triplets = 10628 \n",
      "Epoch 63 Iteration 300: Loss = 0.2981087267398834, Number of mined triplets = 12981 \n",
      "Epoch 63 Iteration 400: Loss = 0.33607539534568787, Number of mined triplets = 13350 \n",
      "Epoch 63 Iteration 500: Loss = 0.3676808178424835, Number of mined triplets = 14319 \n",
      "Epoch 63 Iteration 600: Loss = 0.33915090560913086, Number of mined triplets = 12381 \n",
      "Epoch 63 Iteration 700: Loss = 0.2953111231327057, Number of mined triplets = 10933 \n",
      "Validation loss:  0.30304798364639285\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 64 Iteration 0: Loss = 0.2862352728843689, Number of mined triplets = 10808 \n",
      "Epoch 64 Iteration 100: Loss = 0.3198905885219574, Number of mined triplets = 13077 \n",
      "Epoch 64 Iteration 200: Loss = 0.3234032988548279, Number of mined triplets = 12461 \n",
      "Epoch 64 Iteration 300: Loss = 0.32963624596595764, Number of mined triplets = 12460 \n",
      "Epoch 64 Iteration 400: Loss = 0.354326069355011, Number of mined triplets = 14764 \n",
      "Epoch 64 Iteration 500: Loss = 0.31975510716438293, Number of mined triplets = 10579 \n",
      "Epoch 64 Iteration 600: Loss = 0.303798645734787, Number of mined triplets = 12285 \n",
      "Epoch 64 Iteration 700: Loss = 0.3215564489364624, Number of mined triplets = 13464 \n",
      "Validation loss:  0.30960744619369507\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 65 Iteration 0: Loss = 0.33856555819511414, Number of mined triplets = 13016 \n",
      "Epoch 65 Iteration 100: Loss = 0.3062608540058136, Number of mined triplets = 12095 \n",
      "Epoch 65 Iteration 200: Loss = 0.3164902329444885, Number of mined triplets = 14137 \n",
      "Epoch 65 Iteration 300: Loss = 0.29666808247566223, Number of mined triplets = 11326 \n",
      "Epoch 65 Iteration 400: Loss = 0.2910454571247101, Number of mined triplets = 11232 \n",
      "Epoch 65 Iteration 500: Loss = 0.29118573665618896, Number of mined triplets = 12454 \n",
      "Epoch 65 Iteration 600: Loss = 0.2862470746040344, Number of mined triplets = 10828 \n",
      "Epoch 65 Iteration 700: Loss = 0.293159544467926, Number of mined triplets = 11247 \n",
      "Validation loss:  0.3034528559446335\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 66 Iteration 0: Loss = 0.3292052745819092, Number of mined triplets = 14565 \n",
      "Epoch 66 Iteration 100: Loss = 0.29491445422172546, Number of mined triplets = 11137 \n",
      "Epoch 66 Iteration 200: Loss = 0.29892435669898987, Number of mined triplets = 11724 \n",
      "Epoch 66 Iteration 300: Loss = 0.3631584644317627, Number of mined triplets = 11402 \n",
      "Epoch 66 Iteration 400: Loss = 0.2914994955062866, Number of mined triplets = 9967 \n",
      "Epoch 66 Iteration 500: Loss = 0.2636011838912964, Number of mined triplets = 10860 \n",
      "Epoch 66 Iteration 600: Loss = 0.3096979260444641, Number of mined triplets = 12677 \n",
      "Epoch 66 Iteration 700: Loss = 0.3033801317214966, Number of mined triplets = 13113 \n",
      "Validation loss:  0.30173528313636777\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 67 Iteration 0: Loss = 0.3424619436264038, Number of mined triplets = 10489 \n",
      "Epoch 67 Iteration 100: Loss = 0.2901110351085663, Number of mined triplets = 11615 \n",
      "Epoch 67 Iteration 200: Loss = 0.32916417717933655, Number of mined triplets = 12344 \n",
      "Epoch 67 Iteration 300: Loss = 0.31684547662734985, Number of mined triplets = 13266 \n",
      "Epoch 67 Iteration 400: Loss = 0.2800026535987854, Number of mined triplets = 11010 \n",
      "Epoch 67 Iteration 500: Loss = 0.33181172609329224, Number of mined triplets = 14727 \n",
      "Epoch 67 Iteration 600: Loss = 0.2919609248638153, Number of mined triplets = 11106 \n",
      "Epoch 67 Iteration 700: Loss = 0.31253597140312195, Number of mined triplets = 11024 \n",
      "Validation loss:  0.3015342754125595\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 68 Iteration 0: Loss = 0.33902665972709656, Number of mined triplets = 13135 \n",
      "Epoch 68 Iteration 100: Loss = 0.2632150650024414, Number of mined triplets = 9770 \n",
      "Epoch 68 Iteration 200: Loss = 0.28498297929763794, Number of mined triplets = 10188 \n",
      "Epoch 68 Iteration 300: Loss = 0.31281012296676636, Number of mined triplets = 11189 \n",
      "Epoch 68 Iteration 400: Loss = 0.3174731135368347, Number of mined triplets = 13134 \n",
      "Epoch 68 Iteration 500: Loss = 0.28273847699165344, Number of mined triplets = 11008 \n",
      "Epoch 68 Iteration 600: Loss = 0.2911020815372467, Number of mined triplets = 12647 \n",
      "Epoch 68 Iteration 700: Loss = 0.2842559218406677, Number of mined triplets = 10612 \n",
      "Validation loss:  0.30122017025947573\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 69 Iteration 0: Loss = 0.29679208993911743, Number of mined triplets = 10679 \n",
      "Epoch 69 Iteration 100: Loss = 0.29786571860313416, Number of mined triplets = 11589 \n",
      "Epoch 69 Iteration 200: Loss = 0.29877591133117676, Number of mined triplets = 11276 \n",
      "Epoch 69 Iteration 300: Loss = 0.33273401856422424, Number of mined triplets = 13398 \n",
      "Epoch 69 Iteration 400: Loss = 0.3205558657646179, Number of mined triplets = 12089 \n",
      "Epoch 69 Iteration 500: Loss = 0.3073170781135559, Number of mined triplets = 12197 \n",
      "Epoch 69 Iteration 600: Loss = 0.2789324223995209, Number of mined triplets = 10686 \n",
      "Epoch 69 Iteration 700: Loss = 0.28871622681617737, Number of mined triplets = 11232 \n",
      "Validation loss:  0.30314296543598174\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 70 Iteration 0: Loss = 0.2931582033634186, Number of mined triplets = 11067 \n",
      "Epoch 70 Iteration 100: Loss = 0.34710702300071716, Number of mined triplets = 11799 \n",
      "Epoch 70 Iteration 200: Loss = 0.32162410020828247, Number of mined triplets = 12343 \n",
      "Epoch 70 Iteration 300: Loss = 0.303962379693985, Number of mined triplets = 13080 \n",
      "Epoch 70 Iteration 400: Loss = 0.2933202087879181, Number of mined triplets = 11085 \n",
      "Epoch 70 Iteration 500: Loss = 0.3077583909034729, Number of mined triplets = 11051 \n",
      "Epoch 70 Iteration 600: Loss = 0.3213433027267456, Number of mined triplets = 11761 \n",
      "Epoch 70 Iteration 700: Loss = 0.28786808252334595, Number of mined triplets = 10850 \n",
      "Validation loss:  0.2996127611398697\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 71 Iteration 0: Loss = 0.3241041898727417, Number of mined triplets = 12360 \n",
      "Epoch 71 Iteration 100: Loss = 0.2825373113155365, Number of mined triplets = 9904 \n",
      "Epoch 71 Iteration 200: Loss = 0.2866530418395996, Number of mined triplets = 11970 \n",
      "Epoch 71 Iteration 300: Loss = 0.3270895779132843, Number of mined triplets = 11916 \n",
      "Epoch 71 Iteration 400: Loss = 0.3098239302635193, Number of mined triplets = 11601 \n",
      "Epoch 71 Iteration 500: Loss = 0.26270413398742676, Number of mined triplets = 8331 \n",
      "Epoch 71 Iteration 600: Loss = 0.2815859615802765, Number of mined triplets = 10942 \n",
      "Epoch 71 Iteration 700: Loss = 0.2941356599330902, Number of mined triplets = 10873 \n",
      "Validation loss:  0.3002357444167137\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 72 Iteration 0: Loss = 0.30924192070961, Number of mined triplets = 12854 \n",
      "Epoch 72 Iteration 100: Loss = 0.33111271262168884, Number of mined triplets = 12470 \n",
      "Epoch 72 Iteration 200: Loss = 0.32022568583488464, Number of mined triplets = 11712 \n",
      "Epoch 72 Iteration 300: Loss = 0.32478347420692444, Number of mined triplets = 12249 \n",
      "Epoch 72 Iteration 400: Loss = 0.31807759404182434, Number of mined triplets = 10140 \n",
      "Epoch 72 Iteration 500: Loss = 0.30949145555496216, Number of mined triplets = 11151 \n",
      "Epoch 72 Iteration 600: Loss = 0.26608121395111084, Number of mined triplets = 11597 \n",
      "Epoch 72 Iteration 700: Loss = 0.316385418176651, Number of mined triplets = 10588 \n",
      "Validation loss:  0.31018395245075225\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 73 Iteration 0: Loss = 0.31787532567977905, Number of mined triplets = 13155 \n",
      "Epoch 73 Iteration 100: Loss = 0.3026103973388672, Number of mined triplets = 11872 \n",
      "Epoch 73 Iteration 200: Loss = 0.3470100462436676, Number of mined triplets = 13421 \n",
      "Epoch 73 Iteration 300: Loss = 0.26976829767227173, Number of mined triplets = 10654 \n",
      "Epoch 73 Iteration 400: Loss = 0.32250598073005676, Number of mined triplets = 15067 \n",
      "Epoch 73 Iteration 500: Loss = 0.28481897711753845, Number of mined triplets = 10561 \n",
      "Epoch 73 Iteration 600: Loss = 0.2911302149295807, Number of mined triplets = 11554 \n",
      "Epoch 73 Iteration 700: Loss = 0.28038841485977173, Number of mined triplets = 10645 \n",
      "Validation loss:  0.3089954370260239\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 74 Iteration 0: Loss = 0.2601259648799896, Number of mined triplets = 11304 \n",
      "Epoch 74 Iteration 100: Loss = 0.3133790194988251, Number of mined triplets = 12440 \n",
      "Epoch 74 Iteration 200: Loss = 0.2766161561012268, Number of mined triplets = 9883 \n",
      "Epoch 74 Iteration 300: Loss = 0.3083897829055786, Number of mined triplets = 12489 \n",
      "Epoch 74 Iteration 400: Loss = 0.318462997674942, Number of mined triplets = 13129 \n",
      "Epoch 74 Iteration 500: Loss = 0.33029288053512573, Number of mined triplets = 12307 \n",
      "Epoch 74 Iteration 600: Loss = 0.2941424548625946, Number of mined triplets = 10428 \n",
      "Epoch 74 Iteration 700: Loss = 0.36040058732032776, Number of mined triplets = 13694 \n",
      "Validation loss:  0.30131449103355407\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 75 Iteration 0: Loss = 0.3108590543270111, Number of mined triplets = 12089 \n",
      "Epoch 75 Iteration 100: Loss = 0.3446040153503418, Number of mined triplets = 12220 \n",
      "Epoch 75 Iteration 200: Loss = 0.2603641748428345, Number of mined triplets = 10513 \n",
      "Epoch 75 Iteration 300: Loss = 0.2920979857444763, Number of mined triplets = 9974 \n",
      "Epoch 75 Iteration 400: Loss = 0.2934403121471405, Number of mined triplets = 13070 \n",
      "Epoch 75 Iteration 500: Loss = 0.28013214468955994, Number of mined triplets = 10845 \n",
      "Epoch 75 Iteration 600: Loss = 0.35141947865486145, Number of mined triplets = 12407 \n",
      "Epoch 75 Iteration 700: Loss = 0.32380029559135437, Number of mined triplets = 10651 \n",
      "Validation loss:  0.29916599512100217\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 76 Iteration 0: Loss = 0.29447996616363525, Number of mined triplets = 11268 \n",
      "Epoch 76 Iteration 100: Loss = 0.3045732080936432, Number of mined triplets = 11998 \n",
      "Epoch 76 Iteration 200: Loss = 0.28180280327796936, Number of mined triplets = 10688 \n",
      "Epoch 76 Iteration 300: Loss = 0.3154105842113495, Number of mined triplets = 13289 \n",
      "Epoch 76 Iteration 400: Loss = 0.3092847466468811, Number of mined triplets = 13268 \n",
      "Epoch 76 Iteration 500: Loss = 0.31784284114837646, Number of mined triplets = 11204 \n",
      "Epoch 76 Iteration 600: Loss = 0.3024882376194, Number of mined triplets = 12055 \n",
      "Epoch 76 Iteration 700: Loss = 0.29505375027656555, Number of mined triplets = 11131 \n",
      "Validation loss:  0.2993548423051834\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 77 Iteration 0: Loss = 0.32938021421432495, Number of mined triplets = 12964 \n",
      "Epoch 77 Iteration 100: Loss = 0.28446105122566223, Number of mined triplets = 9842 \n",
      "Epoch 77 Iteration 200: Loss = 0.2477089911699295, Number of mined triplets = 9402 \n",
      "Epoch 77 Iteration 300: Loss = 0.3008755147457123, Number of mined triplets = 11023 \n",
      "Epoch 77 Iteration 400: Loss = 0.28633561730384827, Number of mined triplets = 10673 \n",
      "Epoch 77 Iteration 500: Loss = 0.28222861886024475, Number of mined triplets = 10747 \n",
      "Epoch 77 Iteration 600: Loss = 0.2795581519603729, Number of mined triplets = 10805 \n",
      "Epoch 77 Iteration 700: Loss = 0.29953381419181824, Number of mined triplets = 12521 \n",
      "Validation loss:  0.29198740363121034\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 78 Iteration 0: Loss = 0.2914081811904907, Number of mined triplets = 8686 \n",
      "Epoch 78 Iteration 100: Loss = 0.2718367278575897, Number of mined triplets = 10206 \n",
      "Epoch 78 Iteration 200: Loss = 0.2926596403121948, Number of mined triplets = 11785 \n",
      "Epoch 78 Iteration 300: Loss = 0.28526049852371216, Number of mined triplets = 10368 \n",
      "Epoch 78 Iteration 400: Loss = 0.30841538310050964, Number of mined triplets = 12810 \n",
      "Epoch 78 Iteration 500: Loss = 0.28661689162254333, Number of mined triplets = 12103 \n",
      "Epoch 78 Iteration 600: Loss = 0.2900708019733429, Number of mined triplets = 10791 \n",
      "Epoch 78 Iteration 700: Loss = 0.3227098882198334, Number of mined triplets = 12143 \n",
      "Validation loss:  0.2965066158771515\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 79 Iteration 0: Loss = 0.27953946590423584, Number of mined triplets = 11093 \n",
      "Epoch 79 Iteration 100: Loss = 0.30117544531822205, Number of mined triplets = 11953 \n",
      "Epoch 79 Iteration 200: Loss = 0.28745970129966736, Number of mined triplets = 11634 \n",
      "Epoch 79 Iteration 300: Loss = 0.2799491882324219, Number of mined triplets = 10847 \n",
      "Epoch 79 Iteration 400: Loss = 0.2996408939361572, Number of mined triplets = 13129 \n",
      "Epoch 79 Iteration 500: Loss = 0.3224041163921356, Number of mined triplets = 12045 \n",
      "Epoch 79 Iteration 600: Loss = 0.2988799810409546, Number of mined triplets = 9927 \n",
      "Epoch 79 Iteration 700: Loss = 0.2983233630657196, Number of mined triplets = 12591 \n",
      "Validation loss:  0.29540075719356534\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 80 Iteration 0: Loss = 0.3048696219921112, Number of mined triplets = 11270 \n",
      "Epoch 80 Iteration 100: Loss = 0.2739464044570923, Number of mined triplets = 9387 \n",
      "Epoch 80 Iteration 200: Loss = 0.3004634380340576, Number of mined triplets = 10517 \n",
      "Epoch 80 Iteration 300: Loss = 0.28405502438545227, Number of mined triplets = 11150 \n",
      "Epoch 80 Iteration 400: Loss = 0.2733689546585083, Number of mined triplets = 9832 \n",
      "Epoch 80 Iteration 500: Loss = 0.30044710636138916, Number of mined triplets = 11152 \n",
      "Epoch 80 Iteration 600: Loss = 0.28733283281326294, Number of mined triplets = 9255 \n",
      "Epoch 80 Iteration 700: Loss = 0.32475677132606506, Number of mined triplets = 12462 \n",
      "Validation loss:  0.30477454960346223\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 81 Iteration 0: Loss = 0.3404889702796936, Number of mined triplets = 12676 \n",
      "Epoch 81 Iteration 100: Loss = 0.34172892570495605, Number of mined triplets = 13870 \n",
      "Epoch 81 Iteration 200: Loss = 0.32930421829223633, Number of mined triplets = 12490 \n",
      "Epoch 81 Iteration 300: Loss = 0.3124735355377197, Number of mined triplets = 11403 \n",
      "Epoch 81 Iteration 400: Loss = 0.28090551495552063, Number of mined triplets = 12055 \n",
      "Epoch 81 Iteration 500: Loss = 0.2710144519805908, Number of mined triplets = 10809 \n",
      "Epoch 81 Iteration 600: Loss = 0.3049432933330536, Number of mined triplets = 11173 \n",
      "Epoch 81 Iteration 700: Loss = 0.29123273491859436, Number of mined triplets = 12489 \n",
      "Validation loss:  0.29542696177959443\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 82 Iteration 0: Loss = 0.31569650769233704, Number of mined triplets = 12321 \n",
      "Epoch 82 Iteration 100: Loss = 0.26715466380119324, Number of mined triplets = 10908 \n",
      "Epoch 82 Iteration 200: Loss = 0.31235653162002563, Number of mined triplets = 12089 \n",
      "Epoch 82 Iteration 300: Loss = 0.3084605634212494, Number of mined triplets = 12675 \n",
      "Epoch 82 Iteration 400: Loss = 0.2684513032436371, Number of mined triplets = 10133 \n",
      "Epoch 82 Iteration 500: Loss = 0.3094349205493927, Number of mined triplets = 11849 \n",
      "Epoch 82 Iteration 600: Loss = 0.3004085421562195, Number of mined triplets = 11509 \n",
      "Epoch 82 Iteration 700: Loss = 0.30175620317459106, Number of mined triplets = 12075 \n",
      "Validation loss:  0.2958632618188858\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 83 Iteration 0: Loss = 0.2893272638320923, Number of mined triplets = 10678 \n",
      "Epoch 83 Iteration 100: Loss = 0.3069998621940613, Number of mined triplets = 11261 \n",
      "Epoch 83 Iteration 200: Loss = 0.29081252217292786, Number of mined triplets = 10445 \n",
      "Epoch 83 Iteration 300: Loss = 0.2788909673690796, Number of mined triplets = 10336 \n",
      "Epoch 83 Iteration 400: Loss = 0.2699466049671173, Number of mined triplets = 9584 \n",
      "Epoch 83 Iteration 500: Loss = 0.306196004152298, Number of mined triplets = 12135 \n",
      "Epoch 83 Iteration 600: Loss = 0.26639530062675476, Number of mined triplets = 11146 \n",
      "Epoch 83 Iteration 700: Loss = 0.28992176055908203, Number of mined triplets = 10149 \n",
      "Validation loss:  0.29892040371894835\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 84 Iteration 0: Loss = 0.3039541244506836, Number of mined triplets = 11907 \n",
      "Epoch 84 Iteration 100: Loss = 0.2581167221069336, Number of mined triplets = 10889 \n",
      "Epoch 84 Iteration 200: Loss = 0.28902918100357056, Number of mined triplets = 11047 \n",
      "Epoch 84 Iteration 300: Loss = 0.30356818437576294, Number of mined triplets = 12246 \n",
      "Epoch 84 Iteration 400: Loss = 0.27314820885658264, Number of mined triplets = 10298 \n",
      "Epoch 84 Iteration 500: Loss = 0.2951972782611847, Number of mined triplets = 11079 \n",
      "Epoch 84 Iteration 600: Loss = 0.29722467064857483, Number of mined triplets = 10758 \n",
      "Epoch 84 Iteration 700: Loss = 0.3025575876235962, Number of mined triplets = 11017 \n",
      "Validation loss:  0.29643374860286714\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 85 Iteration 0: Loss = 0.3191801607608795, Number of mined triplets = 11095 \n",
      "Epoch 85 Iteration 100: Loss = 0.31261974573135376, Number of mined triplets = 10913 \n",
      "Epoch 85 Iteration 200: Loss = 0.2820303440093994, Number of mined triplets = 11038 \n",
      "Epoch 85 Iteration 300: Loss = 0.3395863175392151, Number of mined triplets = 11446 \n",
      "Epoch 85 Iteration 400: Loss = 0.30897775292396545, Number of mined triplets = 12956 \n",
      "Epoch 85 Iteration 500: Loss = 0.3265150487422943, Number of mined triplets = 12604 \n",
      "Epoch 85 Iteration 600: Loss = 0.31652623414993286, Number of mined triplets = 10984 \n",
      "Epoch 85 Iteration 700: Loss = 0.28877687454223633, Number of mined triplets = 10691 \n",
      "Validation loss:  0.29792756229639056\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 86 Iteration 0: Loss = 0.3130096197128296, Number of mined triplets = 10443 \n",
      "Epoch 86 Iteration 100: Loss = 0.2922016382217407, Number of mined triplets = 14860 \n",
      "Epoch 86 Iteration 200: Loss = 0.28841179609298706, Number of mined triplets = 10441 \n",
      "Epoch 86 Iteration 300: Loss = 0.31692230701446533, Number of mined triplets = 9691 \n",
      "Epoch 86 Iteration 400: Loss = 0.26748019456863403, Number of mined triplets = 11785 \n",
      "Epoch 86 Iteration 500: Loss = 0.3186653256416321, Number of mined triplets = 12119 \n",
      "Epoch 86 Iteration 600: Loss = 0.27379029989242554, Number of mined triplets = 9424 \n",
      "Epoch 86 Iteration 700: Loss = 0.29201385378837585, Number of mined triplets = 11558 \n",
      "Validation loss:  0.3037553659081459\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 87 Iteration 0: Loss = 0.282291978597641, Number of mined triplets = 10662 \n",
      "Epoch 87 Iteration 100: Loss = 0.2890232801437378, Number of mined triplets = 9795 \n",
      "Epoch 87 Iteration 200: Loss = 0.2627198398113251, Number of mined triplets = 10674 \n",
      "Epoch 87 Iteration 300: Loss = 0.2734900712966919, Number of mined triplets = 12360 \n",
      "Epoch 87 Iteration 400: Loss = 0.30254673957824707, Number of mined triplets = 11270 \n",
      "Epoch 87 Iteration 500: Loss = 0.27621933817863464, Number of mined triplets = 9816 \n",
      "Epoch 87 Iteration 600: Loss = 0.32426419854164124, Number of mined triplets = 11872 \n",
      "Epoch 87 Iteration 700: Loss = 0.3139520287513733, Number of mined triplets = 11916 \n",
      "Validation loss:  0.3005042636394501\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 88 Iteration 0: Loss = 0.35491445660591125, Number of mined triplets = 11564 \n",
      "Epoch 88 Iteration 100: Loss = 0.31181302666664124, Number of mined triplets = 10930 \n",
      "Epoch 88 Iteration 200: Loss = 0.32073888182640076, Number of mined triplets = 12177 \n",
      "Epoch 88 Iteration 300: Loss = 0.2744344472885132, Number of mined triplets = 9075 \n",
      "Epoch 88 Iteration 400: Loss = 0.3288077414035797, Number of mined triplets = 13723 \n",
      "Epoch 88 Iteration 500: Loss = 0.32686522603034973, Number of mined triplets = 13088 \n",
      "Epoch 88 Iteration 600: Loss = 0.3221757411956787, Number of mined triplets = 11994 \n",
      "Epoch 88 Iteration 700: Loss = 0.28686344623565674, Number of mined triplets = 11242 \n",
      "Validation loss:  0.2996933817863464\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 89 Iteration 0: Loss = 0.30686381459236145, Number of mined triplets = 10608 \n",
      "Epoch 89 Iteration 100: Loss = 0.25879815220832825, Number of mined triplets = 8635 \n",
      "Epoch 89 Iteration 200: Loss = 0.2829741835594177, Number of mined triplets = 11317 \n",
      "Epoch 89 Iteration 300: Loss = 0.32092857360839844, Number of mined triplets = 12689 \n",
      "Epoch 89 Iteration 400: Loss = 0.27490970492362976, Number of mined triplets = 10505 \n",
      "Epoch 89 Iteration 500: Loss = 0.3024252951145172, Number of mined triplets = 10346 \n",
      "Epoch 89 Iteration 600: Loss = 0.33519604802131653, Number of mined triplets = 11385 \n",
      "Epoch 89 Iteration 700: Loss = 0.2698167860507965, Number of mined triplets = 10281 \n",
      "Validation loss:  0.29089329242706297\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 90 Iteration 0: Loss = 0.3370460867881775, Number of mined triplets = 12614 \n",
      "Epoch 90 Iteration 100: Loss = 0.2996298372745514, Number of mined triplets = 11480 \n",
      "Epoch 90 Iteration 200: Loss = 0.2875051498413086, Number of mined triplets = 11305 \n",
      "Epoch 90 Iteration 300: Loss = 0.35775282979011536, Number of mined triplets = 10776 \n",
      "Epoch 90 Iteration 400: Loss = 0.27435043454170227, Number of mined triplets = 10720 \n",
      "Epoch 90 Iteration 500: Loss = 0.29115042090415955, Number of mined triplets = 10015 \n",
      "Epoch 90 Iteration 600: Loss = 0.312775582075119, Number of mined triplets = 11501 \n",
      "Epoch 90 Iteration 700: Loss = 0.28725528717041016, Number of mined triplets = 10150 \n",
      "Validation loss:  0.2912490808963776\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 91 Iteration 0: Loss = 0.30470794439315796, Number of mined triplets = 11889 \n",
      "Epoch 91 Iteration 100: Loss = 0.29158249497413635, Number of mined triplets = 9790 \n",
      "Epoch 91 Iteration 200: Loss = 0.3147394061088562, Number of mined triplets = 12478 \n",
      "Epoch 91 Iteration 300: Loss = 0.3783748745918274, Number of mined triplets = 14107 \n",
      "Epoch 91 Iteration 400: Loss = 0.3028285801410675, Number of mined triplets = 11400 \n",
      "Epoch 91 Iteration 500: Loss = 0.286293625831604, Number of mined triplets = 13646 \n",
      "Epoch 91 Iteration 600: Loss = 0.3054596483707428, Number of mined triplets = 10318 \n",
      "Epoch 91 Iteration 700: Loss = 0.3113420903682709, Number of mined triplets = 11096 \n",
      "Validation loss:  0.30118059188127516\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 92 Iteration 0: Loss = 0.28449422121047974, Number of mined triplets = 12310 \n",
      "Epoch 92 Iteration 100: Loss = 0.3126774728298187, Number of mined triplets = 12254 \n",
      "Epoch 92 Iteration 200: Loss = 0.31816336512565613, Number of mined triplets = 11915 \n",
      "Epoch 92 Iteration 300: Loss = 0.30596089363098145, Number of mined triplets = 11590 \n",
      "Epoch 92 Iteration 400: Loss = 0.2901434600353241, Number of mined triplets = 10600 \n",
      "Epoch 92 Iteration 500: Loss = 0.2662999629974365, Number of mined triplets = 11884 \n",
      "Epoch 92 Iteration 600: Loss = 0.2986597716808319, Number of mined triplets = 11626 \n",
      "Epoch 92 Iteration 700: Loss = 0.29852309823036194, Number of mined triplets = 12087 \n",
      "Validation loss:  0.2995913833379745\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 93 Iteration 0: Loss = 0.29437997937202454, Number of mined triplets = 11138 \n",
      "Epoch 93 Iteration 100: Loss = 0.270045667886734, Number of mined triplets = 8783 \n",
      "Epoch 93 Iteration 200: Loss = 0.28460782766342163, Number of mined triplets = 10739 \n",
      "Epoch 93 Iteration 300: Loss = 0.31611353158950806, Number of mined triplets = 10464 \n",
      "Epoch 93 Iteration 400: Loss = 0.2946895956993103, Number of mined triplets = 10859 \n",
      "Epoch 93 Iteration 500: Loss = 0.28795358538627625, Number of mined triplets = 9997 \n",
      "Epoch 93 Iteration 600: Loss = 0.2833443582057953, Number of mined triplets = 11032 \n",
      "Epoch 93 Iteration 700: Loss = 0.28228986263275146, Number of mined triplets = 10053 \n",
      "Validation loss:  0.29229735434055326\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 94 Iteration 0: Loss = 0.2798481285572052, Number of mined triplets = 9821 \n",
      "Epoch 94 Iteration 100: Loss = 0.29665839672088623, Number of mined triplets = 9208 \n",
      "Epoch 94 Iteration 200: Loss = 0.30016541481018066, Number of mined triplets = 10272 \n",
      "Epoch 94 Iteration 300: Loss = 0.29646414518356323, Number of mined triplets = 10095 \n",
      "Epoch 94 Iteration 400: Loss = 0.33394503593444824, Number of mined triplets = 12112 \n",
      "Epoch 94 Iteration 500: Loss = 0.2582760453224182, Number of mined triplets = 8150 \n",
      "Epoch 94 Iteration 600: Loss = 0.28998324275016785, Number of mined triplets = 9891 \n",
      "Epoch 94 Iteration 700: Loss = 0.2786771357059479, Number of mined triplets = 9999 \n",
      "Validation loss:  0.2949099010229111\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 95 Iteration 0: Loss = 0.263497918844223, Number of mined triplets = 8590 \n",
      "Epoch 95 Iteration 100: Loss = 0.3378947079181671, Number of mined triplets = 14587 \n",
      "Epoch 95 Iteration 200: Loss = 0.2919541597366333, Number of mined triplets = 11260 \n",
      "Epoch 95 Iteration 300: Loss = 0.27844521403312683, Number of mined triplets = 10149 \n",
      "Epoch 95 Iteration 400: Loss = 0.2757481038570404, Number of mined triplets = 10944 \n",
      "Epoch 95 Iteration 500: Loss = 0.2957388758659363, Number of mined triplets = 11280 \n",
      "Epoch 95 Iteration 600: Loss = 0.29914405941963196, Number of mined triplets = 12693 \n",
      "Epoch 95 Iteration 700: Loss = 0.2991277575492859, Number of mined triplets = 9671 \n",
      "Validation loss:  0.2860798928141594\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 96 Iteration 0: Loss = 0.2784750163555145, Number of mined triplets = 11687 \n",
      "Epoch 96 Iteration 100: Loss = 0.279409795999527, Number of mined triplets = 9656 \n",
      "Epoch 96 Iteration 200: Loss = 0.36765870451927185, Number of mined triplets = 12763 \n",
      "Epoch 96 Iteration 300: Loss = 0.33985650539398193, Number of mined triplets = 13578 \n",
      "Epoch 96 Iteration 400: Loss = 0.2966858744621277, Number of mined triplets = 11216 \n",
      "Epoch 96 Iteration 500: Loss = 0.2927083671092987, Number of mined triplets = 10967 \n",
      "Epoch 96 Iteration 600: Loss = 0.29126763343811035, Number of mined triplets = 9461 \n",
      "Epoch 96 Iteration 700: Loss = 0.3064981997013092, Number of mined triplets = 11601 \n",
      "Validation loss:  0.29305275619029997\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 97 Iteration 0: Loss = 0.27768030762672424, Number of mined triplets = 10334 \n",
      "Epoch 97 Iteration 100: Loss = 0.27431419491767883, Number of mined triplets = 11022 \n",
      "Epoch 97 Iteration 200: Loss = 0.31404203176498413, Number of mined triplets = 11324 \n",
      "Epoch 97 Iteration 300: Loss = 0.2779224216938019, Number of mined triplets = 9090 \n",
      "Epoch 97 Iteration 400: Loss = 0.3048379421234131, Number of mined triplets = 12662 \n",
      "Epoch 97 Iteration 500: Loss = 0.28116023540496826, Number of mined triplets = 9846 \n",
      "Epoch 97 Iteration 600: Loss = 0.30901265144348145, Number of mined triplets = 13346 \n",
      "Epoch 97 Iteration 700: Loss = 0.2641950249671936, Number of mined triplets = 10667 \n",
      "Validation loss:  0.29370444297790527\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 98 Iteration 0: Loss = 0.2813107669353485, Number of mined triplets = 10172 \n",
      "Epoch 98 Iteration 100: Loss = 0.2993716597557068, Number of mined triplets = 10581 \n",
      "Epoch 98 Iteration 200: Loss = 0.3032344579696655, Number of mined triplets = 9958 \n",
      "Epoch 98 Iteration 300: Loss = 0.29189857840538025, Number of mined triplets = 11156 \n",
      "Epoch 98 Iteration 400: Loss = 0.32274502515792847, Number of mined triplets = 11456 \n",
      "Epoch 98 Iteration 500: Loss = 0.27813521027565, Number of mined triplets = 10000 \n",
      "Epoch 98 Iteration 600: Loss = 0.30102619528770447, Number of mined triplets = 11425 \n",
      "Epoch 98 Iteration 700: Loss = 0.3102478086948395, Number of mined triplets = 10410 \n",
      "Validation loss:  0.29258628606796266\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 99 Iteration 0: Loss = 0.2836586833000183, Number of mined triplets = 11621 \n",
      "Epoch 99 Iteration 100: Loss = 0.3381207287311554, Number of mined triplets = 10396 \n",
      "Epoch 99 Iteration 200: Loss = 0.2921901047229767, Number of mined triplets = 11006 \n",
      "Epoch 99 Iteration 300: Loss = 0.2946757972240448, Number of mined triplets = 10592 \n",
      "Epoch 99 Iteration 400: Loss = 0.30008813738822937, Number of mined triplets = 10619 \n",
      "Epoch 99 Iteration 500: Loss = 0.2797295153141022, Number of mined triplets = 12802 \n",
      "Epoch 99 Iteration 600: Loss = 0.27619513869285583, Number of mined triplets = 10194 \n",
      "Epoch 99 Iteration 700: Loss = 0.26885610818862915, Number of mined triplets = 8619 \n",
      "Validation loss:  0.2943292662501335\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "feature= \"psd\"\n",
    "sample_len = 129\n",
    "num_epochs=99\n",
    "batch_s= 128\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "from pytorch_metric_learning.distances import LpDistance, CosineSimilarity,SNRDistance\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "\n",
    "        # Access the data and labels from the HDF5 file\n",
    "        self.x_data = self.h5_file['data']  # EEG data (use memory-mapped access)\n",
    "        self.y_data = self.h5_file['labels'][:]  # Labels (load fully into memory)\n",
    "        self.s_data = self.h5_file['sessions'][:]  # Sessions (load fully into memory)\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Convert to torch tensor\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "    def close(self):\n",
    "        self.h5_file.close()\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "            # Load the data, labels, and sessions fully into memory\n",
    "            self.x_data = np.array(h5_file['data'])  # Load EEG data into memory\n",
    "            self.y_data = np.array(h5_file['labels'])  # Load labels into memory\n",
    "            self.s_data = np.array(h5_file['sessions'])  # Load sessions into memory\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert data and labels into torch tensors\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Fetch EEG data\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Fetch the session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "\n",
    "# Usage example\n",
    "h5_file_path_t = f'../Data/train_{feature}.h5'\n",
    "h5_file_path_v = f'../Data/valid_{feature}.h5'\n",
    "train_dataset = EEGDataset(h5_file_path_t)\n",
    "valid_dataset = EEGDataset(h5_file_path_v)\n",
    "#valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "subject_ids = train_dataset.targets  # Replace with train_dataset.targets\n",
    "session_ids = train_dataset.s_data          # Replace with train_dataset.s_data\n",
    "\n",
    "# Combine subject and session IDs into unique pairs\n",
    "pairs = list(zip(subject_ids.tolist(), session_ids.tolist()))\n",
    "\n",
    "# Create a mapping from pairs to unique IDs\n",
    "unique_pairs = list(set(pairs))  # Get unique pairs\n",
    "pair_to_id = {pair: idx for idx, pair in enumerate(unique_pairs)}\n",
    "\n",
    "# Map each pair to its unique ID\n",
    "unique_ids = torch.tensor([pair_to_id[pair] for pair in pairs])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate(model, loader, loss_func, mining_func, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation loader (using the provided loader, not train_loader)\n",
    "        for batch_idx, (data, labels, sessions) in enumerate(loader):\n",
    "            # Move data and labels to the specified device\n",
    "            inputs = data.to(device)\n",
    "            targets = labels.to(device)\n",
    "\n",
    "            # Compute embeddings using the model\n",
    "            embeddings = model(inputs)\n",
    "            \n",
    "            # Get mining output for the embeddings\n",
    "            mined_indices = mining_func(embeddings, targets)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_func(embeddings, targets, mined_indices)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "    # Compute the average validation loss\n",
    "    average_loss = total_loss / total_batches if total_batches > 0 else 0\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet7, self).__init__()\n",
    "        # InstanceNorm1d normalizes each channel across its 500 values for each sample\n",
    "        self.norm = nn.InstanceNorm1d(93, affine=False)  # Normalizes across the 500 values in each of the 93 channels\n",
    "        self.act = nn.ReLU()  # or nn.SELU() , ReLU\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.conv1 = nn.Conv2d(1, 256, (1, 4), padding='same')\n",
    "        self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 192, (4, 1), padding='same')\n",
    "        self.pool2 = nn.MaxPool2d((2, 1))\n",
    "        self.conv3 = nn.Conv2d(192, 128, (1, 4), padding='same')\n",
    "        self.pool3 = nn.MaxPool2d((1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 96, (4, 1), padding='same')\n",
    "        self.pool4 = nn.MaxPool2d((2, 1))\n",
    "        self.conv5 = nn.Conv2d(96, 64, (1, 4), padding='same')\n",
    "        self.pool5 = nn.MaxPool2d((1, 2))\n",
    "        self.conv6 = nn.Conv2d(64, 32, (4, 1), padding='same')\n",
    "        self.pool6 = nn.MaxPool2d((2, 1))\n",
    "        self.conv7 = nn.Conv2d(32, 16, (1, 2), padding='same')\n",
    "        self.conv8 = nn.Conv2d(16, 2, (2, 1), padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.embedding = nn.Linear(352, 128)  # Embedding layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #if x.dim() == 3:\n",
    "            #x = x.unsqueeze(1)  # Adding a channel dimension if input is 3D\n",
    "        x = self.norm(x)  # Apply InstanceNorm along the channel dimension (squeeze to 1D first)\n",
    "        x = x.unsqueeze(1)  # Reshape to 4D again for Conv2d\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.act(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        x = self.act(self.conv6(x))\n",
    "        x = self.pool6(x)\n",
    "        x = self.act(self.conv7(x))\n",
    "        x = self.act(self.conv8(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch, test_loader):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    print(f\"Total number of batches in train_loader: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use mixed precision training\n",
    "        with autocast():\n",
    "            embeddings = model(data)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        # Scales the loss, and backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales gradients and optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {} \".format(\n",
    "                    epoch, batch_idx, loss.item(), mining_func.num_triplets\n",
    "                )\n",
    "            )\n",
    "    val_loss = validate(model, test_loader, loss_func, mining_func, device)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trunk = EEGNet7().to(device)\n",
    "summary(trunk, (93, sample_len)) \n",
    "\n",
    "loss_func = losses.TripletMarginLoss(margin=0.5).to(device)\n",
    "mining_func = miners.TripletMarginMiner(margin=0.5)\n",
    "\n",
    "#sampler = samplers.MPerClassSampler(unique_ids, m=1, batch_size=batch_s)\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, batch_size=batch_s)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_s, sampler=sampler)\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001)\n",
    "#mining_func = miners.PairMarginMiner(pos_margin=0.20, neg_margin=0.8)\n",
    "#mining_func = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "sampler2 = samplers.MPerClassSampler(valid_dataset.targets, m=4, batch_size=32)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_s, sampler=sampler2)\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(trunk, loss_func, mining_func, device, train_loader, trunk_optimizer, epoch,valid_loader)\n",
    "    #test(trunk, loss_func, mining_func, device, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(trunk.state_dict(), './model/TripletMarginLoss128_m4_e99_psd.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29a89d-f3c4-4573-84df-71c4215daa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13101496-c347-4c6f-ad48-aa2b6f13a370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
