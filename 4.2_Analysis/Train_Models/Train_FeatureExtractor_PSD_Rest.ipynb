{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9166b40a-7bbe-44b9-b318-75d390807900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "Number of unique subjects: 230\n",
      "15\n",
      "Number of unique subjects: 15\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    InstanceNorm1d-1              [-1, 93, 129]               0\n",
      "            Conv2d-2         [-1, 256, 93, 129]           1,280\n",
      "              ReLU-3         [-1, 256, 93, 129]               0\n",
      "         MaxPool2d-4          [-1, 256, 93, 64]               0\n",
      "            Conv2d-5          [-1, 192, 93, 64]         196,800\n",
      "              ReLU-6          [-1, 192, 93, 64]               0\n",
      "         MaxPool2d-7          [-1, 192, 46, 64]               0\n",
      "            Conv2d-8          [-1, 128, 46, 64]          98,432\n",
      "              ReLU-9          [-1, 128, 46, 64]               0\n",
      "        MaxPool2d-10          [-1, 128, 46, 32]               0\n",
      "           Conv2d-11           [-1, 96, 46, 32]          49,248\n",
      "             ReLU-12           [-1, 96, 46, 32]               0\n",
      "        MaxPool2d-13           [-1, 96, 23, 32]               0\n",
      "           Conv2d-14           [-1, 64, 23, 32]          24,640\n",
      "             ReLU-15           [-1, 64, 23, 32]               0\n",
      "        MaxPool2d-16           [-1, 64, 23, 16]               0\n",
      "           Conv2d-17           [-1, 32, 23, 16]           8,224\n",
      "             ReLU-18           [-1, 32, 23, 16]               0\n",
      "        MaxPool2d-19           [-1, 32, 11, 16]               0\n",
      "           Conv2d-20           [-1, 16, 11, 16]           1,040\n",
      "             ReLU-21           [-1, 16, 11, 16]               0\n",
      "           Conv2d-22            [-1, 2, 11, 16]              66\n",
      "             ReLU-23            [-1, 2, 11, 16]               0\n",
      "          Flatten-24                  [-1, 352]               0\n",
      "           Linear-25                  [-1, 128]          45,184\n",
      "================================================================\n",
      "Total params: 424,914\n",
      "Trainable params: 424,914\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 91.39\n",
      "Params size (MB): 1.62\n",
      "Estimated Total Size (MB): 93.05\n",
      "----------------------------------------------------------------\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 1 Iteration 0: Loss = 45.7950439453125, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 100: Loss = 37.82536315917969, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 200: Loss = 37.442718505859375, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 300: Loss = 37.879493713378906, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 400: Loss = 37.68608856201172, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 500: Loss = 36.98387145996094, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 600: Loss = 37.46501922607422, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 700: Loss = 36.94927978515625, Number of mined P N = 384 15872\n",
      "Validation loss:  37.035908432006835\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 2 Iteration 0: Loss = 36.9431037902832, Number of mined P N = 384 15872\n",
      "Epoch 2 Iteration 100: Loss = 36.4300422668457, Number of mined P N = 384 15872\n",
      "Epoch 2 Iteration 200: Loss = 36.912010192871094, Number of mined P N = 384 15872\n",
      "Epoch 2 Iteration 300: Loss = 36.81467056274414, Number of mined P N = 384 15872\n",
      "Epoch 2 Iteration 400: Loss = 37.20525360107422, Number of mined P N = 384 15872\n",
      "Epoch 2 Iteration 500: Loss = 36.611000061035156, Number of mined P N = 384 15872\n",
      "Epoch 2 Iteration 600: Loss = 36.969276428222656, Number of mined P N = 384 15849\n",
      "Epoch 2 Iteration 700: Loss = 36.57028579711914, Number of mined P N = 384 15872\n",
      "Validation loss:  36.32150505065918\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 3 Iteration 0: Loss = 36.722713470458984, Number of mined P N = 384 15815\n",
      "Epoch 3 Iteration 100: Loss = 36.849090576171875, Number of mined P N = 384 15603\n",
      "Epoch 3 Iteration 200: Loss = 36.63965606689453, Number of mined P N = 384 14513\n",
      "Epoch 3 Iteration 300: Loss = 35.982730865478516, Number of mined P N = 384 14758\n",
      "Epoch 3 Iteration 400: Loss = 36.25200653076172, Number of mined P N = 384 13783\n",
      "Epoch 3 Iteration 500: Loss = 35.72099304199219, Number of mined P N = 384 13540\n",
      "Epoch 3 Iteration 600: Loss = 35.812660217285156, Number of mined P N = 384 10853\n",
      "Epoch 3 Iteration 700: Loss = 35.91143035888672, Number of mined P N = 384 12015\n",
      "Validation loss:  24.38762680053711\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 4 Iteration 0: Loss = 35.50580596923828, Number of mined P N = 384 10479\n",
      "Epoch 4 Iteration 100: Loss = 35.83074951171875, Number of mined P N = 384 10636\n",
      "Epoch 4 Iteration 200: Loss = 35.32258987426758, Number of mined P N = 384 9415\n",
      "Epoch 4 Iteration 300: Loss = 36.16257858276367, Number of mined P N = 384 9518\n",
      "Epoch 4 Iteration 400: Loss = 35.73687744140625, Number of mined P N = 384 9629\n",
      "Epoch 4 Iteration 500: Loss = 35.4774055480957, Number of mined P N = 384 8644\n",
      "Epoch 4 Iteration 600: Loss = 35.40233612060547, Number of mined P N = 384 8082\n",
      "Epoch 4 Iteration 700: Loss = 35.30333709716797, Number of mined P N = 384 7829\n",
      "Validation loss:  22.525731735229492\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 5 Iteration 0: Loss = 35.42576599121094, Number of mined P N = 384 8083\n",
      "Epoch 5 Iteration 100: Loss = 35.30809783935547, Number of mined P N = 384 7689\n",
      "Epoch 5 Iteration 200: Loss = 34.67411804199219, Number of mined P N = 384 8577\n",
      "Epoch 5 Iteration 300: Loss = 35.437644958496094, Number of mined P N = 384 8267\n",
      "Epoch 5 Iteration 400: Loss = 35.256317138671875, Number of mined P N = 384 8741\n",
      "Epoch 5 Iteration 500: Loss = 34.968719482421875, Number of mined P N = 384 7925\n",
      "Epoch 5 Iteration 600: Loss = 34.6390380859375, Number of mined P N = 384 9122\n",
      "Epoch 5 Iteration 700: Loss = 35.202850341796875, Number of mined P N = 384 8194\n",
      "Validation loss:  20.750973625183107\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 6 Iteration 0: Loss = 34.93092346191406, Number of mined P N = 384 7141\n",
      "Epoch 6 Iteration 100: Loss = 34.951107025146484, Number of mined P N = 384 7164\n",
      "Epoch 6 Iteration 200: Loss = 34.51143264770508, Number of mined P N = 382 6053\n",
      "Epoch 6 Iteration 300: Loss = 34.13087844848633, Number of mined P N = 382 6826\n",
      "Epoch 6 Iteration 400: Loss = 34.52789306640625, Number of mined P N = 375 8726\n",
      "Epoch 6 Iteration 500: Loss = 34.71297073364258, Number of mined P N = 384 7447\n",
      "Epoch 6 Iteration 600: Loss = 34.87120056152344, Number of mined P N = 384 7987\n",
      "Epoch 6 Iteration 700: Loss = 34.258785247802734, Number of mined P N = 384 8173\n",
      "Validation loss:  20.321357192993165\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 7 Iteration 0: Loss = 34.799259185791016, Number of mined P N = 382 7634\n",
      "Epoch 7 Iteration 100: Loss = 34.55406951904297, Number of mined P N = 384 6894\n",
      "Epoch 7 Iteration 200: Loss = 33.88612365722656, Number of mined P N = 383 6771\n",
      "Epoch 7 Iteration 300: Loss = 34.58052062988281, Number of mined P N = 382 7441\n",
      "Epoch 7 Iteration 400: Loss = 34.42868423461914, Number of mined P N = 383 7001\n",
      "Epoch 7 Iteration 500: Loss = 34.56360626220703, Number of mined P N = 383 7611\n",
      "Epoch 7 Iteration 600: Loss = 34.30223846435547, Number of mined P N = 377 6555\n",
      "Epoch 7 Iteration 700: Loss = 34.53350067138672, Number of mined P N = 383 7516\n",
      "Validation loss:  19.817934761047365\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 8 Iteration 0: Loss = 34.06452178955078, Number of mined P N = 376 5820\n",
      "Epoch 8 Iteration 100: Loss = 33.267173767089844, Number of mined P N = 373 6426\n",
      "Epoch 8 Iteration 200: Loss = 34.65107345581055, Number of mined P N = 384 5633\n",
      "Epoch 8 Iteration 300: Loss = 34.830963134765625, Number of mined P N = 381 6416\n",
      "Epoch 8 Iteration 400: Loss = 34.55296325683594, Number of mined P N = 384 6679\n",
      "Epoch 8 Iteration 500: Loss = 34.45872497558594, Number of mined P N = 383 7331\n",
      "Epoch 8 Iteration 600: Loss = 33.57046890258789, Number of mined P N = 381 6118\n",
      "Epoch 8 Iteration 700: Loss = 34.5025520324707, Number of mined P N = 381 6766\n",
      "Validation loss:  19.356766471862795\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 9 Iteration 0: Loss = 34.25217819213867, Number of mined P N = 377 7195\n",
      "Epoch 9 Iteration 100: Loss = 34.51799011230469, Number of mined P N = 380 5713\n",
      "Epoch 9 Iteration 200: Loss = 34.504600524902344, Number of mined P N = 379 7920\n",
      "Epoch 9 Iteration 300: Loss = 34.17194366455078, Number of mined P N = 383 7478\n",
      "Epoch 9 Iteration 400: Loss = 33.655967712402344, Number of mined P N = 374 7397\n",
      "Epoch 9 Iteration 500: Loss = 33.1875, Number of mined P N = 381 6403\n",
      "Epoch 9 Iteration 600: Loss = 33.710601806640625, Number of mined P N = 377 7612\n",
      "Epoch 9 Iteration 700: Loss = 32.30095672607422, Number of mined P N = 359 6951\n",
      "Validation loss:  18.60744888305664\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 10 Iteration 0: Loss = 34.10165023803711, Number of mined P N = 381 5877\n",
      "Epoch 10 Iteration 100: Loss = 33.14922332763672, Number of mined P N = 369 7304\n",
      "Epoch 10 Iteration 200: Loss = 33.378196716308594, Number of mined P N = 376 6634\n",
      "Epoch 10 Iteration 300: Loss = 33.437225341796875, Number of mined P N = 368 6021\n",
      "Epoch 10 Iteration 400: Loss = 34.063079833984375, Number of mined P N = 383 6479\n",
      "Epoch 10 Iteration 500: Loss = 33.71989059448242, Number of mined P N = 375 7022\n",
      "Epoch 10 Iteration 600: Loss = 33.880897521972656, Number of mined P N = 381 6460\n",
      "Epoch 10 Iteration 700: Loss = 33.86955261230469, Number of mined P N = 375 6751\n",
      "Validation loss:  18.385863647460937\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 11 Iteration 0: Loss = 33.505226135253906, Number of mined P N = 377 6728\n",
      "Epoch 11 Iteration 100: Loss = 32.5281982421875, Number of mined P N = 372 6705\n",
      "Epoch 11 Iteration 200: Loss = 31.907949447631836, Number of mined P N = 372 5759\n",
      "Epoch 11 Iteration 300: Loss = 32.517295837402344, Number of mined P N = 358 5497\n",
      "Epoch 11 Iteration 400: Loss = 34.09873580932617, Number of mined P N = 376 6089\n",
      "Epoch 11 Iteration 500: Loss = 34.16057586669922, Number of mined P N = 380 6882\n",
      "Epoch 11 Iteration 600: Loss = 33.398277282714844, Number of mined P N = 378 6116\n",
      "Epoch 11 Iteration 700: Loss = 32.42184066772461, Number of mined P N = 365 5931\n",
      "Validation loss:  17.869288635253906\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 12 Iteration 0: Loss = 33.479068756103516, Number of mined P N = 370 6727\n",
      "Epoch 12 Iteration 100: Loss = 32.738983154296875, Number of mined P N = 365 6694\n",
      "Epoch 12 Iteration 200: Loss = 33.68782424926758, Number of mined P N = 377 6365\n",
      "Epoch 12 Iteration 300: Loss = 33.299774169921875, Number of mined P N = 376 7428\n",
      "Epoch 12 Iteration 400: Loss = 32.02302551269531, Number of mined P N = 357 6110\n",
      "Epoch 12 Iteration 500: Loss = 33.082889556884766, Number of mined P N = 371 5545\n",
      "Epoch 12 Iteration 600: Loss = 32.610687255859375, Number of mined P N = 368 5939\n",
      "Epoch 12 Iteration 700: Loss = 31.778146743774414, Number of mined P N = 358 5767\n",
      "Validation loss:  18.09269771575928\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 13 Iteration 0: Loss = 32.98250961303711, Number of mined P N = 373 7925\n",
      "Epoch 13 Iteration 100: Loss = 33.02040100097656, Number of mined P N = 368 6432\n",
      "Epoch 13 Iteration 200: Loss = 33.22547912597656, Number of mined P N = 380 6489\n",
      "Epoch 13 Iteration 300: Loss = 32.714454650878906, Number of mined P N = 368 5808\n",
      "Epoch 13 Iteration 400: Loss = 33.545196533203125, Number of mined P N = 375 6117\n",
      "Epoch 13 Iteration 500: Loss = 32.15094757080078, Number of mined P N = 370 6696\n",
      "Epoch 13 Iteration 600: Loss = 30.91809844970703, Number of mined P N = 359 6129\n",
      "Epoch 13 Iteration 700: Loss = 31.074642181396484, Number of mined P N = 357 5650\n",
      "Validation loss:  17.944283542633055\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 14 Iteration 0: Loss = 31.731853485107422, Number of mined P N = 368 6552\n",
      "Epoch 14 Iteration 100: Loss = 31.507877349853516, Number of mined P N = 360 5608\n",
      "Epoch 14 Iteration 200: Loss = 33.06841278076172, Number of mined P N = 373 6435\n",
      "Epoch 14 Iteration 300: Loss = 31.00979995727539, Number of mined P N = 361 5988\n",
      "Epoch 14 Iteration 400: Loss = 33.290138244628906, Number of mined P N = 364 5040\n",
      "Epoch 14 Iteration 500: Loss = 30.70721435546875, Number of mined P N = 344 5736\n",
      "Epoch 14 Iteration 600: Loss = 32.719886779785156, Number of mined P N = 359 5776\n",
      "Epoch 14 Iteration 700: Loss = 33.743247985839844, Number of mined P N = 375 6378\n",
      "Validation loss:  17.778764667510988\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 15 Iteration 0: Loss = 32.94355773925781, Number of mined P N = 364 5501\n",
      "Epoch 15 Iteration 100: Loss = 32.22107696533203, Number of mined P N = 367 5907\n",
      "Epoch 15 Iteration 200: Loss = 32.01392364501953, Number of mined P N = 357 5891\n",
      "Epoch 15 Iteration 300: Loss = 32.789249420166016, Number of mined P N = 360 7216\n",
      "Epoch 15 Iteration 400: Loss = 33.316986083984375, Number of mined P N = 369 6008\n",
      "Epoch 15 Iteration 500: Loss = 31.996963500976562, Number of mined P N = 362 5603\n",
      "Epoch 15 Iteration 600: Loss = 31.88827896118164, Number of mined P N = 372 6775\n",
      "Epoch 15 Iteration 700: Loss = 33.217079162597656, Number of mined P N = 363 6031\n",
      "Validation loss:  17.641946449279786\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 16 Iteration 0: Loss = 32.16437530517578, Number of mined P N = 377 7287\n",
      "Epoch 16 Iteration 100: Loss = 32.71269226074219, Number of mined P N = 378 6955\n",
      "Epoch 16 Iteration 200: Loss = 31.36700439453125, Number of mined P N = 356 7210\n",
      "Epoch 16 Iteration 300: Loss = 32.54558181762695, Number of mined P N = 367 6339\n",
      "Epoch 16 Iteration 400: Loss = 31.489635467529297, Number of mined P N = 364 5537\n",
      "Epoch 16 Iteration 500: Loss = 31.889842987060547, Number of mined P N = 360 5852\n",
      "Epoch 16 Iteration 600: Loss = 30.832073211669922, Number of mined P N = 349 6044\n",
      "Epoch 16 Iteration 700: Loss = 32.433631896972656, Number of mined P N = 365 6656\n",
      "Validation loss:  17.385966510772704\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 17 Iteration 0: Loss = 32.40229797363281, Number of mined P N = 357 6401\n",
      "Epoch 17 Iteration 100: Loss = 30.785186767578125, Number of mined P N = 347 6667\n",
      "Epoch 17 Iteration 200: Loss = 31.59726333618164, Number of mined P N = 363 5314\n",
      "Epoch 17 Iteration 300: Loss = 30.262277603149414, Number of mined P N = 346 6087\n",
      "Epoch 17 Iteration 400: Loss = 31.974170684814453, Number of mined P N = 358 6116\n",
      "Epoch 17 Iteration 500: Loss = 32.66752243041992, Number of mined P N = 377 6401\n",
      "Epoch 17 Iteration 600: Loss = 32.714927673339844, Number of mined P N = 371 6294\n",
      "Epoch 17 Iteration 700: Loss = 32.76245880126953, Number of mined P N = 361 6504\n",
      "Validation loss:  17.910086917877198\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 18 Iteration 0: Loss = 32.57613754272461, Number of mined P N = 365 5983\n",
      "Epoch 18 Iteration 100: Loss = 31.739831924438477, Number of mined P N = 364 6374\n",
      "Epoch 18 Iteration 200: Loss = 31.182008743286133, Number of mined P N = 364 6090\n",
      "Epoch 18 Iteration 300: Loss = 31.080120086669922, Number of mined P N = 356 5818\n",
      "Epoch 18 Iteration 400: Loss = 32.55561447143555, Number of mined P N = 371 5851\n",
      "Epoch 18 Iteration 500: Loss = 31.050445556640625, Number of mined P N = 358 5759\n",
      "Epoch 18 Iteration 600: Loss = 31.238550186157227, Number of mined P N = 362 6362\n",
      "Epoch 18 Iteration 700: Loss = 31.08525848388672, Number of mined P N = 354 6082\n",
      "Validation loss:  16.65701843261719\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 19 Iteration 0: Loss = 32.25810241699219, Number of mined P N = 360 7335\n",
      "Epoch 19 Iteration 100: Loss = 31.705005645751953, Number of mined P N = 355 5852\n",
      "Epoch 19 Iteration 200: Loss = 33.839412689208984, Number of mined P N = 376 6585\n",
      "Epoch 19 Iteration 300: Loss = 31.488319396972656, Number of mined P N = 349 5023\n",
      "Epoch 19 Iteration 400: Loss = 30.296424865722656, Number of mined P N = 348 5849\n",
      "Epoch 19 Iteration 500: Loss = 30.127946853637695, Number of mined P N = 341 4239\n",
      "Epoch 19 Iteration 600: Loss = 31.82598114013672, Number of mined P N = 363 5834\n",
      "Epoch 19 Iteration 700: Loss = 31.323680877685547, Number of mined P N = 371 6567\n",
      "Validation loss:  16.88389139175415\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 20 Iteration 0: Loss = 31.818836212158203, Number of mined P N = 365 5682\n",
      "Epoch 20 Iteration 100: Loss = 30.206958770751953, Number of mined P N = 353 5516\n",
      "Epoch 20 Iteration 200: Loss = 31.046161651611328, Number of mined P N = 363 6348\n",
      "Epoch 20 Iteration 300: Loss = 32.74119567871094, Number of mined P N = 365 6522\n",
      "Epoch 20 Iteration 400: Loss = 30.282188415527344, Number of mined P N = 351 6387\n",
      "Epoch 20 Iteration 500: Loss = 29.854450225830078, Number of mined P N = 351 6839\n",
      "Epoch 20 Iteration 600: Loss = 31.046276092529297, Number of mined P N = 353 5033\n",
      "Epoch 20 Iteration 700: Loss = 31.915510177612305, Number of mined P N = 363 5855\n",
      "Validation loss:  17.04158250808716\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 21 Iteration 0: Loss = 31.654544830322266, Number of mined P N = 365 6022\n",
      "Epoch 21 Iteration 100: Loss = 31.239835739135742, Number of mined P N = 360 5698\n",
      "Epoch 21 Iteration 200: Loss = 32.033851623535156, Number of mined P N = 364 5915\n",
      "Epoch 21 Iteration 300: Loss = 30.474422454833984, Number of mined P N = 352 5421\n",
      "Epoch 21 Iteration 400: Loss = 31.360254287719727, Number of mined P N = 356 6179\n",
      "Epoch 21 Iteration 500: Loss = 30.238929748535156, Number of mined P N = 346 5162\n",
      "Epoch 21 Iteration 600: Loss = 31.47780990600586, Number of mined P N = 357 6286\n",
      "Epoch 21 Iteration 700: Loss = 31.428035736083984, Number of mined P N = 373 7230\n",
      "Validation loss:  16.305200595855712\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 22 Iteration 0: Loss = 31.86119842529297, Number of mined P N = 365 6660\n",
      "Epoch 22 Iteration 100: Loss = 30.91252899169922, Number of mined P N = 354 5490\n",
      "Epoch 22 Iteration 200: Loss = 31.53173828125, Number of mined P N = 361 5420\n",
      "Epoch 22 Iteration 300: Loss = 32.80052185058594, Number of mined P N = 371 5522\n",
      "Epoch 22 Iteration 400: Loss = 28.845584869384766, Number of mined P N = 337 6235\n",
      "Epoch 22 Iteration 500: Loss = 32.44167709350586, Number of mined P N = 370 7149\n",
      "Epoch 22 Iteration 600: Loss = 29.85618782043457, Number of mined P N = 339 5142\n",
      "Epoch 22 Iteration 700: Loss = 31.06337547302246, Number of mined P N = 344 5115\n",
      "Validation loss:  16.26593267440796\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 23 Iteration 0: Loss = 30.968666076660156, Number of mined P N = 360 5724\n",
      "Epoch 23 Iteration 100: Loss = 31.521495819091797, Number of mined P N = 350 6231\n",
      "Epoch 23 Iteration 200: Loss = 31.727771759033203, Number of mined P N = 343 6414\n",
      "Epoch 23 Iteration 300: Loss = 31.171649932861328, Number of mined P N = 366 5032\n",
      "Epoch 23 Iteration 400: Loss = 30.73478126525879, Number of mined P N = 361 5587\n",
      "Epoch 23 Iteration 500: Loss = 27.587936401367188, Number of mined P N = 342 5123\n",
      "Epoch 23 Iteration 600: Loss = 30.965747833251953, Number of mined P N = 346 5300\n",
      "Epoch 23 Iteration 700: Loss = 32.15089416503906, Number of mined P N = 370 6199\n",
      "Validation loss:  16.501083488464356\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 24 Iteration 0: Loss = 31.350322723388672, Number of mined P N = 354 6529\n",
      "Epoch 24 Iteration 100: Loss = 30.541860580444336, Number of mined P N = 360 5725\n",
      "Epoch 24 Iteration 200: Loss = 29.765222549438477, Number of mined P N = 332 5597\n",
      "Epoch 24 Iteration 300: Loss = 31.463640213012695, Number of mined P N = 372 7645\n",
      "Epoch 24 Iteration 400: Loss = 30.001922607421875, Number of mined P N = 351 4877\n",
      "Epoch 24 Iteration 500: Loss = 30.434850692749023, Number of mined P N = 351 5512\n",
      "Epoch 24 Iteration 600: Loss = 28.992408752441406, Number of mined P N = 343 6078\n",
      "Epoch 24 Iteration 700: Loss = 30.53481101989746, Number of mined P N = 353 6103\n",
      "Validation loss:  16.328057231903077\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 25 Iteration 0: Loss = 30.177501678466797, Number of mined P N = 351 5118\n",
      "Epoch 25 Iteration 100: Loss = 31.203784942626953, Number of mined P N = 368 6206\n",
      "Epoch 25 Iteration 200: Loss = 29.653709411621094, Number of mined P N = 348 4474\n",
      "Epoch 25 Iteration 300: Loss = 30.417072296142578, Number of mined P N = 351 5808\n",
      "Epoch 25 Iteration 400: Loss = 29.588090896606445, Number of mined P N = 361 5954\n",
      "Epoch 25 Iteration 500: Loss = 27.845853805541992, Number of mined P N = 334 4757\n",
      "Epoch 25 Iteration 600: Loss = 30.53563690185547, Number of mined P N = 350 5108\n",
      "Epoch 25 Iteration 700: Loss = 30.278118133544922, Number of mined P N = 351 6301\n",
      "Validation loss:  15.718802661895753\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 26 Iteration 0: Loss = 30.53774070739746, Number of mined P N = 343 5604\n",
      "Epoch 26 Iteration 100: Loss = 31.238460540771484, Number of mined P N = 365 5795\n",
      "Epoch 26 Iteration 200: Loss = 29.987348556518555, Number of mined P N = 349 6120\n",
      "Epoch 26 Iteration 300: Loss = 30.73550033569336, Number of mined P N = 362 5745\n",
      "Epoch 26 Iteration 400: Loss = 31.043109893798828, Number of mined P N = 357 7170\n",
      "Epoch 26 Iteration 500: Loss = 32.630836486816406, Number of mined P N = 362 6415\n",
      "Epoch 26 Iteration 600: Loss = 31.415861129760742, Number of mined P N = 356 5899\n",
      "Epoch 26 Iteration 700: Loss = 32.032676696777344, Number of mined P N = 357 5561\n",
      "Validation loss:  16.595807399749756\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 27 Iteration 0: Loss = 30.627647399902344, Number of mined P N = 343 6367\n",
      "Epoch 27 Iteration 100: Loss = 30.301895141601562, Number of mined P N = 343 5904\n",
      "Epoch 27 Iteration 200: Loss = 31.348567962646484, Number of mined P N = 342 5915\n",
      "Epoch 27 Iteration 300: Loss = 30.422393798828125, Number of mined P N = 347 6707\n",
      "Epoch 27 Iteration 400: Loss = 28.126373291015625, Number of mined P N = 340 5481\n",
      "Epoch 27 Iteration 500: Loss = 29.599689483642578, Number of mined P N = 343 5726\n",
      "Epoch 27 Iteration 600: Loss = 29.02545166015625, Number of mined P N = 337 6005\n",
      "Epoch 27 Iteration 700: Loss = 30.162912368774414, Number of mined P N = 354 5909\n",
      "Validation loss:  16.288604011535643\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 28 Iteration 0: Loss = 30.094579696655273, Number of mined P N = 347 5893\n",
      "Epoch 28 Iteration 100: Loss = 29.705734252929688, Number of mined P N = 338 5919\n",
      "Epoch 28 Iteration 200: Loss = 31.162879943847656, Number of mined P N = 362 5743\n",
      "Epoch 28 Iteration 300: Loss = 29.88851547241211, Number of mined P N = 340 5224\n",
      "Epoch 28 Iteration 400: Loss = 30.615755081176758, Number of mined P N = 356 6140\n",
      "Epoch 28 Iteration 500: Loss = 29.599496841430664, Number of mined P N = 340 5156\n",
      "Epoch 28 Iteration 600: Loss = 30.711240768432617, Number of mined P N = 353 5349\n",
      "Epoch 28 Iteration 700: Loss = 29.766218185424805, Number of mined P N = 342 5913\n",
      "Validation loss:  15.856042022705077\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 29 Iteration 0: Loss = 29.656234741210938, Number of mined P N = 340 5388\n",
      "Epoch 29 Iteration 100: Loss = 31.855255126953125, Number of mined P N = 358 5550\n",
      "Epoch 29 Iteration 200: Loss = 29.813661575317383, Number of mined P N = 351 7309\n",
      "Epoch 29 Iteration 300: Loss = 28.520004272460938, Number of mined P N = 331 5344\n",
      "Epoch 29 Iteration 400: Loss = 28.099109649658203, Number of mined P N = 323 4766\n",
      "Epoch 29 Iteration 500: Loss = 28.69969367980957, Number of mined P N = 335 5007\n",
      "Epoch 29 Iteration 600: Loss = 29.611696243286133, Number of mined P N = 345 4866\n",
      "Epoch 29 Iteration 700: Loss = 31.162002563476562, Number of mined P N = 351 6010\n",
      "Validation loss:  16.260635662078858\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 30 Iteration 0: Loss = 31.054798126220703, Number of mined P N = 358 7080\n",
      "Epoch 30 Iteration 100: Loss = 31.984832763671875, Number of mined P N = 371 5802\n",
      "Epoch 30 Iteration 200: Loss = 30.318756103515625, Number of mined P N = 358 5399\n",
      "Epoch 30 Iteration 300: Loss = 31.152385711669922, Number of mined P N = 353 4997\n",
      "Epoch 30 Iteration 400: Loss = 31.4622859954834, Number of mined P N = 352 6315\n",
      "Epoch 30 Iteration 500: Loss = 30.28814125061035, Number of mined P N = 333 6350\n",
      "Epoch 30 Iteration 600: Loss = 29.01628875732422, Number of mined P N = 350 5652\n",
      "Epoch 30 Iteration 700: Loss = 32.3656005859375, Number of mined P N = 363 6362\n",
      "Validation loss:  16.480424613952636\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 31 Iteration 0: Loss = 29.17230987548828, Number of mined P N = 349 6294\n",
      "Epoch 31 Iteration 100: Loss = 29.594192504882812, Number of mined P N = 343 5844\n",
      "Epoch 31 Iteration 200: Loss = 30.059162139892578, Number of mined P N = 336 5530\n",
      "Epoch 31 Iteration 300: Loss = 29.96554946899414, Number of mined P N = 334 6004\n",
      "Epoch 31 Iteration 400: Loss = 29.16103172302246, Number of mined P N = 336 5987\n",
      "Epoch 31 Iteration 500: Loss = 29.601533889770508, Number of mined P N = 334 5119\n",
      "Epoch 31 Iteration 600: Loss = 29.82386589050293, Number of mined P N = 349 6127\n",
      "Epoch 31 Iteration 700: Loss = 27.76494026184082, Number of mined P N = 310 5116\n",
      "Validation loss:  16.385244331359864\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 32 Iteration 0: Loss = 29.61029052734375, Number of mined P N = 342 6291\n",
      "Epoch 32 Iteration 100: Loss = 29.378620147705078, Number of mined P N = 352 5690\n",
      "Epoch 32 Iteration 200: Loss = 29.04807472229004, Number of mined P N = 340 5706\n",
      "Epoch 32 Iteration 300: Loss = 29.472227096557617, Number of mined P N = 352 5328\n",
      "Epoch 32 Iteration 400: Loss = 28.822351455688477, Number of mined P N = 332 4777\n",
      "Epoch 32 Iteration 500: Loss = 29.666542053222656, Number of mined P N = 341 5702\n",
      "Epoch 32 Iteration 600: Loss = 26.776119232177734, Number of mined P N = 330 4431\n",
      "Epoch 32 Iteration 700: Loss = 31.26071548461914, Number of mined P N = 361 5986\n",
      "Validation loss:  15.77638334274292\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 33 Iteration 0: Loss = 28.96029281616211, Number of mined P N = 343 5890\n",
      "Epoch 33 Iteration 100: Loss = 31.2366886138916, Number of mined P N = 356 6905\n",
      "Epoch 33 Iteration 200: Loss = 29.560976028442383, Number of mined P N = 345 6013\n",
      "Epoch 33 Iteration 300: Loss = 31.103809356689453, Number of mined P N = 362 5387\n",
      "Epoch 33 Iteration 400: Loss = 30.088085174560547, Number of mined P N = 336 5173\n",
      "Epoch 33 Iteration 500: Loss = 29.784252166748047, Number of mined P N = 331 5005\n",
      "Epoch 33 Iteration 600: Loss = 29.781883239746094, Number of mined P N = 339 5457\n",
      "Epoch 33 Iteration 700: Loss = 32.582847595214844, Number of mined P N = 357 5816\n",
      "Validation loss:  16.194964828491212\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 34 Iteration 0: Loss = 32.483821868896484, Number of mined P N = 365 6675\n",
      "Epoch 34 Iteration 100: Loss = 29.3175106048584, Number of mined P N = 346 5148\n",
      "Epoch 34 Iteration 200: Loss = 27.723112106323242, Number of mined P N = 324 4697\n",
      "Epoch 34 Iteration 300: Loss = 29.957408905029297, Number of mined P N = 351 5285\n",
      "Epoch 34 Iteration 400: Loss = 27.343608856201172, Number of mined P N = 337 5682\n",
      "Epoch 34 Iteration 500: Loss = 30.371007919311523, Number of mined P N = 349 5584\n",
      "Epoch 34 Iteration 600: Loss = 30.234500885009766, Number of mined P N = 354 5870\n",
      "Epoch 34 Iteration 700: Loss = 29.9466552734375, Number of mined P N = 354 5886\n",
      "Validation loss:  16.17651725769043\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 35 Iteration 0: Loss = 30.08633041381836, Number of mined P N = 353 6249\n",
      "Epoch 35 Iteration 100: Loss = 29.646482467651367, Number of mined P N = 349 4974\n",
      "Epoch 35 Iteration 200: Loss = 28.602657318115234, Number of mined P N = 340 5260\n",
      "Epoch 35 Iteration 300: Loss = 28.688831329345703, Number of mined P N = 328 6589\n",
      "Epoch 35 Iteration 400: Loss = 30.155044555664062, Number of mined P N = 350 4904\n",
      "Epoch 35 Iteration 500: Loss = 29.53144645690918, Number of mined P N = 350 5200\n",
      "Epoch 35 Iteration 600: Loss = 27.930570602416992, Number of mined P N = 334 5571\n",
      "Epoch 35 Iteration 700: Loss = 28.127206802368164, Number of mined P N = 344 5352\n",
      "Validation loss:  15.737206726074218\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 36 Iteration 0: Loss = 28.883747100830078, Number of mined P N = 345 6052\n",
      "Epoch 36 Iteration 100: Loss = 30.1507625579834, Number of mined P N = 354 5805\n",
      "Epoch 36 Iteration 200: Loss = 30.310256958007812, Number of mined P N = 357 5269\n",
      "Epoch 36 Iteration 300: Loss = 30.907337188720703, Number of mined P N = 356 7664\n",
      "Epoch 36 Iteration 400: Loss = 29.775819778442383, Number of mined P N = 346 5375\n",
      "Epoch 36 Iteration 500: Loss = 29.186779022216797, Number of mined P N = 335 5598\n",
      "Epoch 36 Iteration 600: Loss = 27.536205291748047, Number of mined P N = 320 4337\n",
      "Epoch 36 Iteration 700: Loss = 29.22593116760254, Number of mined P N = 347 4121\n",
      "Validation loss:  15.501854667663574\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 37 Iteration 0: Loss = 29.13533592224121, Number of mined P N = 346 5726\n",
      "Epoch 37 Iteration 100: Loss = 29.125991821289062, Number of mined P N = 331 5004\n",
      "Epoch 37 Iteration 200: Loss = 28.113767623901367, Number of mined P N = 338 5149\n",
      "Epoch 37 Iteration 300: Loss = 28.72754669189453, Number of mined P N = 329 5826\n",
      "Epoch 37 Iteration 400: Loss = 28.863378524780273, Number of mined P N = 333 5090\n",
      "Epoch 37 Iteration 500: Loss = 30.645458221435547, Number of mined P N = 353 6324\n",
      "Epoch 37 Iteration 600: Loss = 29.333484649658203, Number of mined P N = 335 5376\n",
      "Epoch 37 Iteration 700: Loss = 29.739850997924805, Number of mined P N = 346 6714\n",
      "Validation loss:  15.609207935333252\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 38 Iteration 0: Loss = 28.950653076171875, Number of mined P N = 335 4751\n",
      "Epoch 38 Iteration 100: Loss = 29.706769943237305, Number of mined P N = 342 5577\n",
      "Epoch 38 Iteration 200: Loss = 30.401084899902344, Number of mined P N = 346 5656\n",
      "Epoch 38 Iteration 300: Loss = 28.01909637451172, Number of mined P N = 321 5240\n",
      "Epoch 38 Iteration 400: Loss = 28.38576889038086, Number of mined P N = 327 4990\n",
      "Epoch 38 Iteration 500: Loss = 26.830585479736328, Number of mined P N = 324 5061\n",
      "Epoch 38 Iteration 600: Loss = 27.072784423828125, Number of mined P N = 312 4377\n",
      "Epoch 38 Iteration 700: Loss = 28.578907012939453, Number of mined P N = 335 5247\n",
      "Validation loss:  15.57309061050415\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 39 Iteration 0: Loss = 28.180316925048828, Number of mined P N = 324 5021\n",
      "Epoch 39 Iteration 100: Loss = 29.361791610717773, Number of mined P N = 358 6552\n",
      "Epoch 39 Iteration 200: Loss = 28.60143280029297, Number of mined P N = 329 5601\n",
      "Epoch 39 Iteration 300: Loss = 29.552610397338867, Number of mined P N = 347 5439\n",
      "Epoch 39 Iteration 400: Loss = 30.727998733520508, Number of mined P N = 355 5459\n",
      "Epoch 39 Iteration 500: Loss = 28.026065826416016, Number of mined P N = 311 4245\n",
      "Epoch 39 Iteration 600: Loss = 30.343217849731445, Number of mined P N = 336 5883\n",
      "Epoch 39 Iteration 700: Loss = 30.128704071044922, Number of mined P N = 349 6517\n",
      "Validation loss:  14.781049156188965\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 40 Iteration 0: Loss = 27.060848236083984, Number of mined P N = 330 4722\n",
      "Epoch 40 Iteration 100: Loss = 29.300552368164062, Number of mined P N = 342 4868\n",
      "Epoch 40 Iteration 200: Loss = 31.132335662841797, Number of mined P N = 354 6872\n",
      "Epoch 40 Iteration 300: Loss = 28.280616760253906, Number of mined P N = 340 6137\n",
      "Epoch 40 Iteration 400: Loss = 30.36760902404785, Number of mined P N = 356 6898\n",
      "Epoch 40 Iteration 500: Loss = 26.72258186340332, Number of mined P N = 307 4673\n",
      "Epoch 40 Iteration 600: Loss = 26.64214324951172, Number of mined P N = 314 5040\n",
      "Epoch 40 Iteration 700: Loss = 29.387691497802734, Number of mined P N = 334 6934\n",
      "Validation loss:  14.937702808380127\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 41 Iteration 0: Loss = 29.16475486755371, Number of mined P N = 333 5827\n",
      "Epoch 41 Iteration 100: Loss = 31.126541137695312, Number of mined P N = 356 7134\n",
      "Epoch 41 Iteration 200: Loss = 28.120342254638672, Number of mined P N = 324 5406\n",
      "Epoch 41 Iteration 300: Loss = 29.669870376586914, Number of mined P N = 358 5579\n",
      "Epoch 41 Iteration 400: Loss = 29.309646606445312, Number of mined P N = 352 5036\n",
      "Epoch 41 Iteration 500: Loss = 28.023019790649414, Number of mined P N = 331 5410\n",
      "Epoch 41 Iteration 600: Loss = 30.839324951171875, Number of mined P N = 356 6396\n",
      "Epoch 41 Iteration 700: Loss = 28.822608947753906, Number of mined P N = 333 5679\n",
      "Validation loss:  15.495750904083252\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 42 Iteration 0: Loss = 30.875959396362305, Number of mined P N = 358 6524\n",
      "Epoch 42 Iteration 100: Loss = 27.795751571655273, Number of mined P N = 319 3833\n",
      "Epoch 42 Iteration 200: Loss = 28.04497718811035, Number of mined P N = 320 5274\n",
      "Epoch 42 Iteration 300: Loss = 30.213970184326172, Number of mined P N = 350 6488\n",
      "Epoch 42 Iteration 400: Loss = 29.491926193237305, Number of mined P N = 361 5550\n",
      "Epoch 42 Iteration 500: Loss = 27.954360961914062, Number of mined P N = 338 5477\n",
      "Epoch 42 Iteration 600: Loss = 29.892444610595703, Number of mined P N = 341 6721\n",
      "Epoch 42 Iteration 700: Loss = 30.74083709716797, Number of mined P N = 345 5084\n",
      "Validation loss:  15.275944232940674\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 43 Iteration 0: Loss = 30.032657623291016, Number of mined P N = 342 5655\n",
      "Epoch 43 Iteration 100: Loss = 26.652114868164062, Number of mined P N = 307 4207\n",
      "Epoch 43 Iteration 200: Loss = 29.296192169189453, Number of mined P N = 334 5415\n",
      "Epoch 43 Iteration 300: Loss = 28.662553787231445, Number of mined P N = 350 5111\n",
      "Epoch 43 Iteration 400: Loss = 28.589290618896484, Number of mined P N = 319 5015\n",
      "Epoch 43 Iteration 500: Loss = 30.16787338256836, Number of mined P N = 344 5800\n",
      "Epoch 43 Iteration 600: Loss = 27.689231872558594, Number of mined P N = 315 5046\n",
      "Epoch 43 Iteration 700: Loss = 28.053300857543945, Number of mined P N = 331 7504\n",
      "Validation loss:  15.164494647979737\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 44 Iteration 0: Loss = 27.734052658081055, Number of mined P N = 318 5375\n",
      "Epoch 44 Iteration 100: Loss = 26.962635040283203, Number of mined P N = 334 4602\n",
      "Epoch 44 Iteration 200: Loss = 29.399494171142578, Number of mined P N = 341 6187\n",
      "Epoch 44 Iteration 300: Loss = 29.689579010009766, Number of mined P N = 350 5638\n",
      "Epoch 44 Iteration 400: Loss = 27.567913055419922, Number of mined P N = 309 4241\n",
      "Epoch 44 Iteration 500: Loss = 26.639892578125, Number of mined P N = 313 3928\n",
      "Epoch 44 Iteration 600: Loss = 29.363788604736328, Number of mined P N = 351 6144\n",
      "Epoch 44 Iteration 700: Loss = 27.427841186523438, Number of mined P N = 311 5857\n",
      "Validation loss:  14.956939678192139\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 45 Iteration 0: Loss = 28.361352920532227, Number of mined P N = 328 5302\n",
      "Epoch 45 Iteration 100: Loss = 28.99985122680664, Number of mined P N = 339 6593\n",
      "Epoch 45 Iteration 200: Loss = 27.573009490966797, Number of mined P N = 319 5275\n",
      "Epoch 45 Iteration 300: Loss = 29.280193328857422, Number of mined P N = 331 5168\n",
      "Epoch 45 Iteration 400: Loss = 30.033069610595703, Number of mined P N = 345 5925\n",
      "Epoch 45 Iteration 500: Loss = 28.1844482421875, Number of mined P N = 341 5989\n",
      "Epoch 45 Iteration 600: Loss = 28.602161407470703, Number of mined P N = 329 5776\n",
      "Epoch 45 Iteration 700: Loss = 30.710643768310547, Number of mined P N = 340 5595\n",
      "Validation loss:  15.256868171691895\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 46 Iteration 0: Loss = 27.364707946777344, Number of mined P N = 332 6147\n",
      "Epoch 46 Iteration 100: Loss = 26.76837921142578, Number of mined P N = 312 4893\n",
      "Epoch 46 Iteration 200: Loss = 29.45071792602539, Number of mined P N = 332 5493\n",
      "Epoch 46 Iteration 300: Loss = 26.176651000976562, Number of mined P N = 315 4308\n",
      "Epoch 46 Iteration 400: Loss = 28.072629928588867, Number of mined P N = 339 6643\n",
      "Epoch 46 Iteration 500: Loss = 29.278451919555664, Number of mined P N = 328 6396\n",
      "Epoch 46 Iteration 600: Loss = 27.115116119384766, Number of mined P N = 317 5843\n",
      "Epoch 46 Iteration 700: Loss = 28.965496063232422, Number of mined P N = 340 4913\n",
      "Validation loss:  14.931946887969971\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 47 Iteration 0: Loss = 29.039409637451172, Number of mined P N = 346 5285\n",
      "Epoch 47 Iteration 100: Loss = 29.204940795898438, Number of mined P N = 343 5345\n",
      "Epoch 47 Iteration 200: Loss = 28.999286651611328, Number of mined P N = 333 5393\n",
      "Epoch 47 Iteration 300: Loss = 27.026447296142578, Number of mined P N = 320 4969\n",
      "Epoch 47 Iteration 400: Loss = 27.220260620117188, Number of mined P N = 324 4561\n",
      "Epoch 47 Iteration 500: Loss = 29.697032928466797, Number of mined P N = 349 4768\n",
      "Epoch 47 Iteration 600: Loss = 24.70295524597168, Number of mined P N = 291 3956\n",
      "Epoch 47 Iteration 700: Loss = 28.188289642333984, Number of mined P N = 325 4588\n",
      "Validation loss:  14.704363288879394\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 48 Iteration 0: Loss = 29.549455642700195, Number of mined P N = 340 5231\n",
      "Epoch 48 Iteration 100: Loss = 29.9973087310791, Number of mined P N = 352 5815\n",
      "Epoch 48 Iteration 200: Loss = 25.301162719726562, Number of mined P N = 303 3937\n",
      "Epoch 48 Iteration 300: Loss = 30.919063568115234, Number of mined P N = 365 7052\n",
      "Epoch 48 Iteration 400: Loss = 29.427356719970703, Number of mined P N = 345 6036\n",
      "Epoch 48 Iteration 500: Loss = 29.758403778076172, Number of mined P N = 342 4862\n",
      "Epoch 48 Iteration 600: Loss = 29.073623657226562, Number of mined P N = 334 5735\n",
      "Epoch 48 Iteration 700: Loss = 30.06739616394043, Number of mined P N = 335 5519\n",
      "Validation loss:  14.736350231170654\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 49 Iteration 0: Loss = 29.621492385864258, Number of mined P N = 345 6526\n",
      "Epoch 49 Iteration 100: Loss = 28.544166564941406, Number of mined P N = 332 6600\n",
      "Epoch 49 Iteration 200: Loss = 27.432968139648438, Number of mined P N = 319 5099\n",
      "Epoch 49 Iteration 300: Loss = 28.131166458129883, Number of mined P N = 326 5494\n",
      "Epoch 49 Iteration 400: Loss = 28.95501708984375, Number of mined P N = 336 5161\n",
      "Epoch 49 Iteration 500: Loss = 29.007308959960938, Number of mined P N = 355 6757\n",
      "Epoch 49 Iteration 600: Loss = 28.817096710205078, Number of mined P N = 352 5217\n",
      "Epoch 49 Iteration 700: Loss = 25.887542724609375, Number of mined P N = 323 5053\n",
      "Validation loss:  14.836975650787354\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 50 Iteration 0: Loss = 27.22314453125, Number of mined P N = 327 4716\n",
      "Epoch 50 Iteration 100: Loss = 30.555856704711914, Number of mined P N = 354 6291\n",
      "Epoch 50 Iteration 200: Loss = 29.884925842285156, Number of mined P N = 340 5124\n",
      "Epoch 50 Iteration 300: Loss = 26.47650909423828, Number of mined P N = 318 4788\n",
      "Epoch 50 Iteration 400: Loss = 30.37541961669922, Number of mined P N = 348 5646\n",
      "Epoch 50 Iteration 500: Loss = 25.93376922607422, Number of mined P N = 319 5756\n",
      "Epoch 50 Iteration 600: Loss = 26.011554718017578, Number of mined P N = 305 5238\n",
      "Epoch 50 Iteration 700: Loss = 26.343490600585938, Number of mined P N = 317 4954\n",
      "Validation loss:  14.795986080169678\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 51 Iteration 0: Loss = 27.124391555786133, Number of mined P N = 323 5424\n",
      "Epoch 51 Iteration 100: Loss = 26.406442642211914, Number of mined P N = 325 4572\n",
      "Epoch 51 Iteration 200: Loss = 28.724781036376953, Number of mined P N = 307 4925\n",
      "Epoch 51 Iteration 300: Loss = 31.7899169921875, Number of mined P N = 363 6067\n",
      "Epoch 51 Iteration 400: Loss = 30.033981323242188, Number of mined P N = 357 5811\n",
      "Epoch 51 Iteration 500: Loss = 27.247304916381836, Number of mined P N = 323 5163\n",
      "Epoch 51 Iteration 600: Loss = 25.212417602539062, Number of mined P N = 307 4167\n",
      "Epoch 51 Iteration 700: Loss = 28.234073638916016, Number of mined P N = 347 5797\n",
      "Validation loss:  14.77185380935669\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 52 Iteration 0: Loss = 26.944683074951172, Number of mined P N = 333 5055\n",
      "Epoch 52 Iteration 100: Loss = 28.994094848632812, Number of mined P N = 348 6183\n",
      "Epoch 52 Iteration 200: Loss = 28.797161102294922, Number of mined P N = 341 6313\n",
      "Epoch 52 Iteration 300: Loss = 29.350067138671875, Number of mined P N = 340 5649\n",
      "Epoch 52 Iteration 400: Loss = 27.193635940551758, Number of mined P N = 324 5877\n",
      "Epoch 52 Iteration 500: Loss = 27.417686462402344, Number of mined P N = 330 5367\n",
      "Epoch 52 Iteration 600: Loss = 29.533288955688477, Number of mined P N = 327 5750\n",
      "Epoch 52 Iteration 700: Loss = 27.82656478881836, Number of mined P N = 325 5138\n",
      "Validation loss:  14.932823104858398\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 53 Iteration 0: Loss = 29.391056060791016, Number of mined P N = 335 6451\n",
      "Epoch 53 Iteration 100: Loss = 28.836381912231445, Number of mined P N = 322 5059\n",
      "Epoch 53 Iteration 200: Loss = 29.364768981933594, Number of mined P N = 342 6185\n",
      "Epoch 53 Iteration 300: Loss = 27.42230987548828, Number of mined P N = 344 5581\n",
      "Epoch 53 Iteration 400: Loss = 27.80411148071289, Number of mined P N = 318 4281\n",
      "Epoch 53 Iteration 500: Loss = 26.90226173400879, Number of mined P N = 325 4795\n",
      "Epoch 53 Iteration 600: Loss = 29.18813705444336, Number of mined P N = 332 5216\n",
      "Epoch 53 Iteration 700: Loss = 29.75525665283203, Number of mined P N = 356 7179\n",
      "Validation loss:  14.538455429077148\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 54 Iteration 0: Loss = 29.414228439331055, Number of mined P N = 341 4622\n",
      "Epoch 54 Iteration 100: Loss = 27.60362434387207, Number of mined P N = 317 5061\n",
      "Epoch 54 Iteration 200: Loss = 27.846637725830078, Number of mined P N = 338 4680\n",
      "Epoch 54 Iteration 300: Loss = 26.998319625854492, Number of mined P N = 336 5149\n",
      "Epoch 54 Iteration 400: Loss = 27.194395065307617, Number of mined P N = 333 4744\n",
      "Epoch 54 Iteration 500: Loss = 28.445518493652344, Number of mined P N = 343 4776\n",
      "Epoch 54 Iteration 600: Loss = 27.077316284179688, Number of mined P N = 319 5468\n",
      "Epoch 54 Iteration 700: Loss = 26.956249237060547, Number of mined P N = 329 4421\n",
      "Validation loss:  14.975085887908936\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 55 Iteration 0: Loss = 26.697185516357422, Number of mined P N = 310 4781\n",
      "Epoch 55 Iteration 100: Loss = 28.91170883178711, Number of mined P N = 347 5503\n",
      "Epoch 55 Iteration 200: Loss = 30.210308074951172, Number of mined P N = 353 6327\n",
      "Epoch 55 Iteration 300: Loss = 26.995952606201172, Number of mined P N = 334 5683\n",
      "Epoch 55 Iteration 400: Loss = 29.089908599853516, Number of mined P N = 338 5746\n",
      "Epoch 55 Iteration 500: Loss = 28.419578552246094, Number of mined P N = 326 6286\n",
      "Epoch 55 Iteration 600: Loss = 27.187604904174805, Number of mined P N = 312 4683\n",
      "Epoch 55 Iteration 700: Loss = 28.862106323242188, Number of mined P N = 333 4593\n",
      "Validation loss:  14.370681476593017\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 56 Iteration 0: Loss = 30.060672760009766, Number of mined P N = 346 4654\n",
      "Epoch 56 Iteration 100: Loss = 26.025070190429688, Number of mined P N = 327 4708\n",
      "Epoch 56 Iteration 200: Loss = 24.55266571044922, Number of mined P N = 300 3848\n",
      "Epoch 56 Iteration 300: Loss = 28.712779998779297, Number of mined P N = 343 6069\n",
      "Epoch 56 Iteration 400: Loss = 25.37026596069336, Number of mined P N = 314 4166\n",
      "Epoch 56 Iteration 500: Loss = 27.7340087890625, Number of mined P N = 327 5947\n",
      "Epoch 56 Iteration 600: Loss = 26.783353805541992, Number of mined P N = 329 4667\n",
      "Epoch 56 Iteration 700: Loss = 27.483884811401367, Number of mined P N = 319 4115\n",
      "Validation loss:  14.364665393829346\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 57 Iteration 0: Loss = 29.391529083251953, Number of mined P N = 334 5718\n",
      "Epoch 57 Iteration 100: Loss = 27.07183265686035, Number of mined P N = 325 5096\n",
      "Epoch 57 Iteration 200: Loss = 24.806154251098633, Number of mined P N = 295 3774\n",
      "Epoch 57 Iteration 300: Loss = 26.28104019165039, Number of mined P N = 323 4424\n",
      "Epoch 57 Iteration 400: Loss = 26.768436431884766, Number of mined P N = 301 4797\n",
      "Epoch 57 Iteration 500: Loss = 28.871788024902344, Number of mined P N = 331 5786\n",
      "Epoch 57 Iteration 600: Loss = 27.641138076782227, Number of mined P N = 328 5750\n",
      "Epoch 57 Iteration 700: Loss = 27.142955780029297, Number of mined P N = 322 4351\n",
      "Validation loss:  14.360055179595948\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 58 Iteration 0: Loss = 25.470754623413086, Number of mined P N = 303 4550\n",
      "Epoch 58 Iteration 100: Loss = 28.099567413330078, Number of mined P N = 326 4333\n",
      "Epoch 58 Iteration 200: Loss = 23.528732299804688, Number of mined P N = 293 4758\n",
      "Epoch 58 Iteration 300: Loss = 29.417266845703125, Number of mined P N = 343 5930\n",
      "Epoch 58 Iteration 400: Loss = 28.7755184173584, Number of mined P N = 350 7652\n",
      "Epoch 58 Iteration 500: Loss = 28.677705764770508, Number of mined P N = 326 6407\n",
      "Epoch 58 Iteration 600: Loss = 26.214683532714844, Number of mined P N = 315 4662\n",
      "Epoch 58 Iteration 700: Loss = 26.06983184814453, Number of mined P N = 306 5797\n",
      "Validation loss:  14.406656646728516\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 59 Iteration 0: Loss = 25.971176147460938, Number of mined P N = 313 4388\n",
      "Epoch 59 Iteration 100: Loss = 28.217144012451172, Number of mined P N = 333 5067\n",
      "Epoch 59 Iteration 200: Loss = 26.722610473632812, Number of mined P N = 317 4965\n",
      "Epoch 59 Iteration 300: Loss = 28.25908660888672, Number of mined P N = 338 5160\n",
      "Epoch 59 Iteration 400: Loss = 28.03914451599121, Number of mined P N = 340 5922\n",
      "Epoch 59 Iteration 500: Loss = 27.437225341796875, Number of mined P N = 308 5025\n",
      "Epoch 59 Iteration 600: Loss = 27.52088165283203, Number of mined P N = 336 5283\n",
      "Epoch 59 Iteration 700: Loss = 27.24510955810547, Number of mined P N = 327 5447\n",
      "Validation loss:  14.967286128997802\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 60 Iteration 0: Loss = 26.517547607421875, Number of mined P N = 308 5528\n",
      "Epoch 60 Iteration 100: Loss = 30.391590118408203, Number of mined P N = 348 5160\n",
      "Epoch 60 Iteration 200: Loss = 28.358760833740234, Number of mined P N = 339 5451\n",
      "Epoch 60 Iteration 300: Loss = 30.26444435119629, Number of mined P N = 352 6007\n",
      "Epoch 60 Iteration 400: Loss = 28.559953689575195, Number of mined P N = 320 4861\n",
      "Epoch 60 Iteration 500: Loss = 27.914701461791992, Number of mined P N = 342 5556\n",
      "Epoch 60 Iteration 600: Loss = 26.271352767944336, Number of mined P N = 324 4641\n",
      "Epoch 60 Iteration 700: Loss = 29.608911514282227, Number of mined P N = 349 6210\n",
      "Validation loss:  14.928981075286865\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 61 Iteration 0: Loss = 27.788101196289062, Number of mined P N = 325 4912\n",
      "Epoch 61 Iteration 100: Loss = 26.585161209106445, Number of mined P N = 324 6156\n",
      "Epoch 61 Iteration 200: Loss = 28.420093536376953, Number of mined P N = 335 5597\n",
      "Epoch 61 Iteration 300: Loss = 28.990036010742188, Number of mined P N = 342 5438\n",
      "Epoch 61 Iteration 400: Loss = 27.077892303466797, Number of mined P N = 310 4344\n",
      "Epoch 61 Iteration 500: Loss = 27.371397018432617, Number of mined P N = 329 4901\n",
      "Epoch 61 Iteration 600: Loss = 27.701229095458984, Number of mined P N = 320 5493\n",
      "Epoch 61 Iteration 700: Loss = 26.913799285888672, Number of mined P N = 326 4764\n",
      "Validation loss:  14.040978031158447\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 62 Iteration 0: Loss = 26.751296997070312, Number of mined P N = 333 5867\n",
      "Epoch 62 Iteration 100: Loss = 27.16277313232422, Number of mined P N = 323 4430\n",
      "Epoch 62 Iteration 200: Loss = 26.555225372314453, Number of mined P N = 330 5818\n",
      "Epoch 62 Iteration 300: Loss = 27.38724136352539, Number of mined P N = 333 5123\n",
      "Epoch 62 Iteration 400: Loss = 28.73006820678711, Number of mined P N = 335 5860\n",
      "Epoch 62 Iteration 500: Loss = 28.358545303344727, Number of mined P N = 330 5830\n",
      "Epoch 62 Iteration 600: Loss = 27.716827392578125, Number of mined P N = 345 4905\n",
      "Epoch 62 Iteration 700: Loss = 24.182809829711914, Number of mined P N = 286 3984\n",
      "Validation loss:  14.502351055145263\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 63 Iteration 0: Loss = 28.387454986572266, Number of mined P N = 344 5594\n",
      "Epoch 63 Iteration 100: Loss = 26.345109939575195, Number of mined P N = 327 5109\n",
      "Epoch 63 Iteration 200: Loss = 25.979915618896484, Number of mined P N = 314 4747\n",
      "Epoch 63 Iteration 300: Loss = 27.422029495239258, Number of mined P N = 302 4783\n",
      "Epoch 63 Iteration 400: Loss = 27.68730354309082, Number of mined P N = 327 5820\n",
      "Epoch 63 Iteration 500: Loss = 27.67871856689453, Number of mined P N = 323 5512\n",
      "Epoch 63 Iteration 600: Loss = 29.298015594482422, Number of mined P N = 333 5248\n",
      "Epoch 63 Iteration 700: Loss = 29.212154388427734, Number of mined P N = 344 5279\n",
      "Validation loss:  14.138681354522705\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 64 Iteration 0: Loss = 29.390579223632812, Number of mined P N = 340 5426\n",
      "Epoch 64 Iteration 100: Loss = 27.969497680664062, Number of mined P N = 320 4199\n",
      "Epoch 64 Iteration 200: Loss = 28.372764587402344, Number of mined P N = 338 6064\n",
      "Epoch 64 Iteration 300: Loss = 24.762149810791016, Number of mined P N = 300 4910\n",
      "Epoch 64 Iteration 400: Loss = 27.944377899169922, Number of mined P N = 325 5861\n",
      "Epoch 64 Iteration 500: Loss = 25.160491943359375, Number of mined P N = 315 3984\n",
      "Epoch 64 Iteration 600: Loss = 25.397132873535156, Number of mined P N = 292 5507\n",
      "Epoch 64 Iteration 700: Loss = 29.044010162353516, Number of mined P N = 337 5162\n",
      "Validation loss:  14.767545490264892\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 65 Iteration 0: Loss = 25.628620147705078, Number of mined P N = 300 4462\n",
      "Epoch 65 Iteration 100: Loss = 28.893821716308594, Number of mined P N = 344 6084\n",
      "Epoch 65 Iteration 200: Loss = 25.81414794921875, Number of mined P N = 304 4970\n",
      "Epoch 65 Iteration 300: Loss = 28.111581802368164, Number of mined P N = 322 5011\n",
      "Epoch 65 Iteration 400: Loss = 27.426563262939453, Number of mined P N = 324 5322\n",
      "Epoch 65 Iteration 500: Loss = 26.948711395263672, Number of mined P N = 309 5262\n",
      "Epoch 65 Iteration 600: Loss = 27.040531158447266, Number of mined P N = 325 4504\n",
      "Epoch 65 Iteration 700: Loss = 26.252784729003906, Number of mined P N = 317 4200\n",
      "Validation loss:  14.90159507751465\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 66 Iteration 0: Loss = 27.10753631591797, Number of mined P N = 330 6415\n",
      "Epoch 66 Iteration 100: Loss = 25.776723861694336, Number of mined P N = 320 3982\n",
      "Epoch 66 Iteration 200: Loss = 24.983135223388672, Number of mined P N = 301 4393\n",
      "Epoch 66 Iteration 300: Loss = 25.95033073425293, Number of mined P N = 317 5934\n",
      "Epoch 66 Iteration 400: Loss = 29.253284454345703, Number of mined P N = 327 5000\n",
      "Epoch 66 Iteration 500: Loss = 25.660898208618164, Number of mined P N = 312 4115\n",
      "Epoch 66 Iteration 600: Loss = 28.77596664428711, Number of mined P N = 338 6325\n",
      "Epoch 66 Iteration 700: Loss = 29.034778594970703, Number of mined P N = 347 5068\n",
      "Validation loss:  15.070340843200684\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 67 Iteration 0: Loss = 27.52823257446289, Number of mined P N = 315 4062\n",
      "Epoch 67 Iteration 100: Loss = 25.641429901123047, Number of mined P N = 303 4551\n",
      "Epoch 67 Iteration 200: Loss = 26.795913696289062, Number of mined P N = 317 4899\n",
      "Epoch 67 Iteration 300: Loss = 26.243471145629883, Number of mined P N = 309 4556\n",
      "Epoch 67 Iteration 400: Loss = 24.213016510009766, Number of mined P N = 307 4566\n",
      "Epoch 67 Iteration 500: Loss = 29.541799545288086, Number of mined P N = 336 5257\n",
      "Epoch 67 Iteration 600: Loss = 26.748779296875, Number of mined P N = 318 4681\n",
      "Epoch 67 Iteration 700: Loss = 26.62820816040039, Number of mined P N = 341 4908\n",
      "Validation loss:  14.373162002563477\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 68 Iteration 0: Loss = 28.318984985351562, Number of mined P N = 335 4928\n",
      "Epoch 68 Iteration 100: Loss = 28.047618865966797, Number of mined P N = 316 4907\n",
      "Epoch 68 Iteration 200: Loss = 26.94253158569336, Number of mined P N = 317 5129\n",
      "Epoch 68 Iteration 300: Loss = 26.119640350341797, Number of mined P N = 307 4156\n",
      "Epoch 68 Iteration 400: Loss = 25.346887588500977, Number of mined P N = 296 5321\n",
      "Epoch 68 Iteration 500: Loss = 27.204315185546875, Number of mined P N = 323 3497\n",
      "Epoch 68 Iteration 600: Loss = 26.61575698852539, Number of mined P N = 300 5012\n",
      "Epoch 68 Iteration 700: Loss = 28.456005096435547, Number of mined P N = 326 4227\n",
      "Validation loss:  14.450900173187256\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 69 Iteration 0: Loss = 27.408302307128906, Number of mined P N = 330 4497\n",
      "Epoch 69 Iteration 100: Loss = 25.2445068359375, Number of mined P N = 294 4180\n",
      "Epoch 69 Iteration 200: Loss = 26.90076446533203, Number of mined P N = 324 4957\n",
      "Epoch 69 Iteration 300: Loss = 27.355587005615234, Number of mined P N = 328 5264\n",
      "Epoch 69 Iteration 400: Loss = 26.071487426757812, Number of mined P N = 311 4855\n",
      "Epoch 69 Iteration 500: Loss = 26.69867515563965, Number of mined P N = 334 5612\n",
      "Epoch 69 Iteration 600: Loss = 27.326663970947266, Number of mined P N = 339 6529\n",
      "Epoch 69 Iteration 700: Loss = 28.95024299621582, Number of mined P N = 334 5636\n",
      "Validation loss:  14.08655673980713\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 70 Iteration 0: Loss = 26.73361587524414, Number of mined P N = 311 5687\n",
      "Epoch 70 Iteration 100: Loss = 25.444583892822266, Number of mined P N = 295 4262\n",
      "Epoch 70 Iteration 200: Loss = 27.28118133544922, Number of mined P N = 324 4866\n",
      "Epoch 70 Iteration 300: Loss = 27.966812133789062, Number of mined P N = 330 5768\n",
      "Epoch 70 Iteration 400: Loss = 26.660524368286133, Number of mined P N = 304 5427\n",
      "Epoch 70 Iteration 500: Loss = 28.909530639648438, Number of mined P N = 324 6259\n",
      "Epoch 70 Iteration 600: Loss = 26.762584686279297, Number of mined P N = 330 5437\n",
      "Epoch 70 Iteration 700: Loss = 25.41799545288086, Number of mined P N = 308 4856\n",
      "Validation loss:  14.952794971466064\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 71 Iteration 0: Loss = 27.279064178466797, Number of mined P N = 329 4978\n",
      "Epoch 71 Iteration 100: Loss = 27.537609100341797, Number of mined P N = 324 4825\n",
      "Epoch 71 Iteration 200: Loss = 28.19524574279785, Number of mined P N = 346 5557\n",
      "Epoch 71 Iteration 300: Loss = 26.632572174072266, Number of mined P N = 316 5994\n",
      "Epoch 71 Iteration 400: Loss = 26.619670867919922, Number of mined P N = 318 5653\n",
      "Epoch 71 Iteration 500: Loss = 26.830785751342773, Number of mined P N = 321 3957\n",
      "Epoch 71 Iteration 600: Loss = 27.708717346191406, Number of mined P N = 322 4823\n",
      "Epoch 71 Iteration 700: Loss = 28.332096099853516, Number of mined P N = 336 5417\n",
      "Validation loss:  13.764052391052246\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 72 Iteration 0: Loss = 28.817325592041016, Number of mined P N = 332 5261\n",
      "Epoch 72 Iteration 100: Loss = 26.270401000976562, Number of mined P N = 320 5388\n",
      "Epoch 72 Iteration 200: Loss = 24.398277282714844, Number of mined P N = 295 3810\n",
      "Epoch 72 Iteration 300: Loss = 25.51327133178711, Number of mined P N = 298 5147\n",
      "Epoch 72 Iteration 400: Loss = 27.260242462158203, Number of mined P N = 334 5335\n",
      "Epoch 72 Iteration 500: Loss = 27.55661392211914, Number of mined P N = 332 5173\n",
      "Epoch 72 Iteration 600: Loss = 23.90642547607422, Number of mined P N = 302 3866\n",
      "Epoch 72 Iteration 700: Loss = 26.29254150390625, Number of mined P N = 325 5163\n",
      "Validation loss:  14.568496646881103\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 73 Iteration 0: Loss = 26.266647338867188, Number of mined P N = 307 4949\n",
      "Epoch 73 Iteration 100: Loss = 23.908935546875, Number of mined P N = 300 5142\n",
      "Epoch 73 Iteration 200: Loss = 26.0363712310791, Number of mined P N = 321 3968\n",
      "Epoch 73 Iteration 300: Loss = 24.5179443359375, Number of mined P N = 285 4714\n",
      "Epoch 73 Iteration 400: Loss = 28.081064224243164, Number of mined P N = 334 6375\n",
      "Epoch 73 Iteration 500: Loss = 29.241613388061523, Number of mined P N = 335 5287\n",
      "Epoch 73 Iteration 600: Loss = 26.629728317260742, Number of mined P N = 341 5571\n",
      "Epoch 73 Iteration 700: Loss = 25.47386932373047, Number of mined P N = 314 5534\n",
      "Validation loss:  13.732492408752442\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 74 Iteration 0: Loss = 26.419578552246094, Number of mined P N = 335 4856\n",
      "Epoch 74 Iteration 100: Loss = 28.045387268066406, Number of mined P N = 339 5560\n",
      "Epoch 74 Iteration 200: Loss = 31.123977661132812, Number of mined P N = 356 5737\n",
      "Epoch 74 Iteration 300: Loss = 24.763307571411133, Number of mined P N = 296 3677\n",
      "Epoch 74 Iteration 400: Loss = 25.781368255615234, Number of mined P N = 311 6286\n",
      "Epoch 74 Iteration 500: Loss = 26.04602813720703, Number of mined P N = 336 4132\n",
      "Epoch 74 Iteration 600: Loss = 26.19725799560547, Number of mined P N = 302 3535\n",
      "Epoch 74 Iteration 700: Loss = 23.325305938720703, Number of mined P N = 286 3700\n",
      "Validation loss:  14.438250217437744\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 75 Iteration 0: Loss = 28.198848724365234, Number of mined P N = 326 5755\n",
      "Epoch 75 Iteration 100: Loss = 24.155651092529297, Number of mined P N = 307 4947\n",
      "Epoch 75 Iteration 200: Loss = 27.509662628173828, Number of mined P N = 321 5419\n",
      "Epoch 75 Iteration 300: Loss = 28.39860725402832, Number of mined P N = 335 4484\n",
      "Epoch 75 Iteration 400: Loss = 25.008075714111328, Number of mined P N = 304 4644\n",
      "Epoch 75 Iteration 500: Loss = 27.00029945373535, Number of mined P N = 325 5632\n",
      "Epoch 75 Iteration 600: Loss = 26.619110107421875, Number of mined P N = 298 5277\n",
      "Epoch 75 Iteration 700: Loss = 29.468891143798828, Number of mined P N = 358 6787\n",
      "Validation loss:  14.036919651031495\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 76 Iteration 0: Loss = 27.783668518066406, Number of mined P N = 324 5586\n",
      "Epoch 76 Iteration 100: Loss = 27.84336280822754, Number of mined P N = 339 6176\n",
      "Epoch 76 Iteration 200: Loss = 26.58541488647461, Number of mined P N = 297 4645\n",
      "Epoch 76 Iteration 300: Loss = 25.0565242767334, Number of mined P N = 299 4696\n",
      "Epoch 76 Iteration 400: Loss = 27.713741302490234, Number of mined P N = 337 5741\n",
      "Epoch 76 Iteration 500: Loss = 29.547119140625, Number of mined P N = 346 5680\n",
      "Epoch 76 Iteration 600: Loss = 27.99864387512207, Number of mined P N = 317 4547\n",
      "Epoch 76 Iteration 700: Loss = 28.937992095947266, Number of mined P N = 338 6027\n",
      "Validation loss:  13.833428211212158\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 77 Iteration 0: Loss = 27.462080001831055, Number of mined P N = 334 4897\n",
      "Epoch 77 Iteration 100: Loss = 26.514772415161133, Number of mined P N = 321 6147\n",
      "Epoch 77 Iteration 200: Loss = 25.00334930419922, Number of mined P N = 286 3846\n",
      "Epoch 77 Iteration 300: Loss = 25.016008377075195, Number of mined P N = 301 4061\n",
      "Epoch 77 Iteration 400: Loss = 25.74361801147461, Number of mined P N = 303 4661\n",
      "Epoch 77 Iteration 500: Loss = 25.913307189941406, Number of mined P N = 298 4897\n",
      "Epoch 77 Iteration 600: Loss = 27.137495040893555, Number of mined P N = 324 5915\n",
      "Epoch 77 Iteration 700: Loss = 26.434825897216797, Number of mined P N = 296 4365\n",
      "Validation loss:  14.50802984237671\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 78 Iteration 0: Loss = 26.110563278198242, Number of mined P N = 311 4252\n",
      "Epoch 78 Iteration 100: Loss = 28.00564956665039, Number of mined P N = 328 5330\n",
      "Epoch 78 Iteration 200: Loss = 27.079299926757812, Number of mined P N = 321 4953\n",
      "Epoch 78 Iteration 300: Loss = 27.364742279052734, Number of mined P N = 331 5174\n",
      "Epoch 78 Iteration 400: Loss = 24.827943801879883, Number of mined P N = 284 3861\n",
      "Epoch 78 Iteration 500: Loss = 25.794754028320312, Number of mined P N = 299 4416\n",
      "Epoch 78 Iteration 600: Loss = 28.32969856262207, Number of mined P N = 324 5440\n",
      "Epoch 78 Iteration 700: Loss = 28.32761001586914, Number of mined P N = 327 5431\n",
      "Validation loss:  14.440057010650635\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 79 Iteration 0: Loss = 27.54665756225586, Number of mined P N = 326 4363\n",
      "Epoch 79 Iteration 100: Loss = 27.71027946472168, Number of mined P N = 343 4996\n",
      "Epoch 79 Iteration 200: Loss = 25.324668884277344, Number of mined P N = 312 4976\n",
      "Epoch 79 Iteration 300: Loss = 27.49781608581543, Number of mined P N = 325 4933\n",
      "Epoch 79 Iteration 400: Loss = 24.836320877075195, Number of mined P N = 305 3622\n",
      "Epoch 79 Iteration 500: Loss = 28.992538452148438, Number of mined P N = 348 5163\n",
      "Epoch 79 Iteration 600: Loss = 27.457340240478516, Number of mined P N = 340 5411\n",
      "Epoch 79 Iteration 700: Loss = 29.813629150390625, Number of mined P N = 352 6283\n",
      "Validation loss:  14.759762573242188\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 80 Iteration 0: Loss = 26.51702880859375, Number of mined P N = 317 5098\n",
      "Epoch 80 Iteration 100: Loss = 25.094932556152344, Number of mined P N = 309 4520\n",
      "Epoch 80 Iteration 200: Loss = 28.804628372192383, Number of mined P N = 327 5654\n",
      "Epoch 80 Iteration 300: Loss = 29.505905151367188, Number of mined P N = 352 6006\n",
      "Epoch 80 Iteration 400: Loss = 26.40412139892578, Number of mined P N = 310 4945\n",
      "Epoch 80 Iteration 500: Loss = 28.676315307617188, Number of mined P N = 329 5568\n",
      "Epoch 80 Iteration 600: Loss = 29.030845642089844, Number of mined P N = 337 5128\n",
      "Epoch 80 Iteration 700: Loss = 26.793296813964844, Number of mined P N = 330 5249\n",
      "Validation loss:  14.594771709442139\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 81 Iteration 0: Loss = 25.238628387451172, Number of mined P N = 317 5970\n",
      "Epoch 81 Iteration 100: Loss = 26.294801712036133, Number of mined P N = 323 4777\n",
      "Epoch 81 Iteration 200: Loss = 26.881019592285156, Number of mined P N = 332 5863\n",
      "Epoch 81 Iteration 300: Loss = 26.040271759033203, Number of mined P N = 308 4200\n",
      "Epoch 81 Iteration 400: Loss = 25.453092575073242, Number of mined P N = 305 5898\n",
      "Epoch 81 Iteration 500: Loss = 26.850706100463867, Number of mined P N = 305 4434\n",
      "Epoch 81 Iteration 600: Loss = 29.91175079345703, Number of mined P N = 355 5147\n",
      "Epoch 81 Iteration 700: Loss = 27.04281234741211, Number of mined P N = 327 5283\n",
      "Validation loss:  14.515835227966308\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 82 Iteration 0: Loss = 29.392196655273438, Number of mined P N = 348 6147\n",
      "Epoch 82 Iteration 100: Loss = 24.664573669433594, Number of mined P N = 294 4887\n",
      "Epoch 82 Iteration 200: Loss = 24.420001983642578, Number of mined P N = 301 5086\n",
      "Epoch 82 Iteration 300: Loss = 26.754907608032227, Number of mined P N = 307 4656\n",
      "Epoch 82 Iteration 400: Loss = 26.910919189453125, Number of mined P N = 323 5636\n",
      "Epoch 82 Iteration 500: Loss = 24.438350677490234, Number of mined P N = 310 3177\n",
      "Epoch 82 Iteration 600: Loss = 26.029678344726562, Number of mined P N = 318 4781\n",
      "Epoch 82 Iteration 700: Loss = 28.083988189697266, Number of mined P N = 327 5225\n",
      "Validation loss:  14.680444126129151\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 83 Iteration 0: Loss = 28.986568450927734, Number of mined P N = 324 4326\n",
      "Epoch 83 Iteration 100: Loss = 24.61428451538086, Number of mined P N = 302 4425\n",
      "Epoch 83 Iteration 200: Loss = 22.316322326660156, Number of mined P N = 256 3743\n",
      "Epoch 83 Iteration 300: Loss = 28.48571014404297, Number of mined P N = 334 6441\n",
      "Epoch 83 Iteration 400: Loss = 27.60742950439453, Number of mined P N = 323 4559\n",
      "Epoch 83 Iteration 500: Loss = 28.80107879638672, Number of mined P N = 335 5660\n",
      "Epoch 83 Iteration 600: Loss = 27.60892105102539, Number of mined P N = 319 4915\n",
      "Epoch 83 Iteration 700: Loss = 28.717029571533203, Number of mined P N = 331 5680\n",
      "Validation loss:  13.631124324798584\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 84 Iteration 0: Loss = 27.214506149291992, Number of mined P N = 332 4660\n",
      "Epoch 84 Iteration 100: Loss = 25.587120056152344, Number of mined P N = 289 4122\n",
      "Epoch 84 Iteration 200: Loss = 27.24717140197754, Number of mined P N = 313 4328\n",
      "Epoch 84 Iteration 300: Loss = 24.33363914489746, Number of mined P N = 288 4963\n",
      "Epoch 84 Iteration 400: Loss = 29.219158172607422, Number of mined P N = 330 5440\n",
      "Epoch 84 Iteration 500: Loss = 26.027496337890625, Number of mined P N = 323 5041\n",
      "Epoch 84 Iteration 600: Loss = 26.363218307495117, Number of mined P N = 326 5320\n",
      "Epoch 84 Iteration 700: Loss = 25.891448974609375, Number of mined P N = 297 5028\n",
      "Validation loss:  13.587329006195068\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 85 Iteration 0: Loss = 27.51695442199707, Number of mined P N = 320 4571\n",
      "Epoch 85 Iteration 100: Loss = 27.042232513427734, Number of mined P N = 332 4563\n",
      "Epoch 85 Iteration 200: Loss = 25.903533935546875, Number of mined P N = 310 4970\n",
      "Epoch 85 Iteration 300: Loss = 26.70382308959961, Number of mined P N = 339 5346\n",
      "Epoch 85 Iteration 400: Loss = 28.287574768066406, Number of mined P N = 336 5259\n",
      "Epoch 85 Iteration 500: Loss = 28.584178924560547, Number of mined P N = 352 5979\n",
      "Epoch 85 Iteration 600: Loss = 28.018795013427734, Number of mined P N = 337 5061\n",
      "Epoch 85 Iteration 700: Loss = 25.221294403076172, Number of mined P N = 292 4884\n",
      "Validation loss:  14.264010696411132\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 86 Iteration 0: Loss = 26.497753143310547, Number of mined P N = 340 5109\n",
      "Epoch 86 Iteration 100: Loss = 23.038530349731445, Number of mined P N = 291 4614\n",
      "Epoch 86 Iteration 200: Loss = 27.452455520629883, Number of mined P N = 325 5736\n",
      "Epoch 86 Iteration 300: Loss = 26.27511215209961, Number of mined P N = 309 6185\n",
      "Epoch 86 Iteration 400: Loss = 26.17526626586914, Number of mined P N = 314 4522\n",
      "Epoch 86 Iteration 500: Loss = 24.099082946777344, Number of mined P N = 296 4881\n",
      "Epoch 86 Iteration 600: Loss = 29.01058578491211, Number of mined P N = 342 7302\n",
      "Epoch 86 Iteration 700: Loss = 27.61578941345215, Number of mined P N = 315 4564\n",
      "Validation loss:  14.176399402618408\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 87 Iteration 0: Loss = 25.54501724243164, Number of mined P N = 308 5507\n",
      "Epoch 87 Iteration 100: Loss = 26.329416275024414, Number of mined P N = 302 4434\n",
      "Epoch 87 Iteration 200: Loss = 25.179393768310547, Number of mined P N = 326 3631\n",
      "Epoch 87 Iteration 300: Loss = 26.35195541381836, Number of mined P N = 310 4578\n",
      "Epoch 87 Iteration 400: Loss = 27.41555404663086, Number of mined P N = 320 5263\n",
      "Epoch 87 Iteration 500: Loss = 29.066143035888672, Number of mined P N = 335 5226\n",
      "Epoch 87 Iteration 600: Loss = 26.930652618408203, Number of mined P N = 326 4410\n",
      "Epoch 87 Iteration 700: Loss = 27.870574951171875, Number of mined P N = 337 5179\n",
      "Validation loss:  13.20747943878174\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 88 Iteration 0: Loss = 24.91115951538086, Number of mined P N = 299 3110\n",
      "Epoch 88 Iteration 100: Loss = 27.39926528930664, Number of mined P N = 313 4299\n",
      "Epoch 88 Iteration 200: Loss = 27.542871475219727, Number of mined P N = 344 5507\n",
      "Epoch 88 Iteration 300: Loss = 28.27325439453125, Number of mined P N = 326 5639\n",
      "Epoch 88 Iteration 400: Loss = 23.894866943359375, Number of mined P N = 291 4837\n",
      "Epoch 88 Iteration 500: Loss = 25.679290771484375, Number of mined P N = 318 5969\n",
      "Epoch 88 Iteration 600: Loss = 25.177894592285156, Number of mined P N = 314 4324\n",
      "Epoch 88 Iteration 700: Loss = 24.69921875, Number of mined P N = 299 4752\n",
      "Validation loss:  14.445258674621583\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 89 Iteration 0: Loss = 25.398136138916016, Number of mined P N = 319 5640\n",
      "Epoch 89 Iteration 100: Loss = 27.320741653442383, Number of mined P N = 320 4416\n",
      "Epoch 89 Iteration 200: Loss = 25.111404418945312, Number of mined P N = 297 4569\n",
      "Epoch 89 Iteration 300: Loss = 25.558122634887695, Number of mined P N = 314 4067\n",
      "Epoch 89 Iteration 400: Loss = 25.949337005615234, Number of mined P N = 304 6094\n",
      "Epoch 89 Iteration 500: Loss = 27.765621185302734, Number of mined P N = 321 5562\n",
      "Epoch 89 Iteration 600: Loss = 28.101078033447266, Number of mined P N = 338 6901\n",
      "Epoch 89 Iteration 700: Loss = 27.305633544921875, Number of mined P N = 344 4273\n",
      "Validation loss:  14.261171360015869\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 90 Iteration 0: Loss = 22.750774383544922, Number of mined P N = 281 3746\n",
      "Epoch 90 Iteration 100: Loss = 28.20229721069336, Number of mined P N = 336 5826\n",
      "Epoch 90 Iteration 200: Loss = 22.71328353881836, Number of mined P N = 279 3332\n",
      "Epoch 90 Iteration 300: Loss = 26.366744995117188, Number of mined P N = 320 5378\n",
      "Epoch 90 Iteration 400: Loss = 26.81385612487793, Number of mined P N = 305 5909\n",
      "Epoch 90 Iteration 500: Loss = 24.564027786254883, Number of mined P N = 294 4453\n",
      "Epoch 90 Iteration 600: Loss = 25.951805114746094, Number of mined P N = 318 6148\n",
      "Epoch 90 Iteration 700: Loss = 26.336353302001953, Number of mined P N = 314 5363\n",
      "Validation loss:  14.152509803771972\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 91 Iteration 0: Loss = 27.30605697631836, Number of mined P N = 315 4789\n",
      "Epoch 91 Iteration 100: Loss = 28.857194900512695, Number of mined P N = 336 4785\n",
      "Epoch 91 Iteration 200: Loss = 26.427122116088867, Number of mined P N = 336 4515\n",
      "Epoch 91 Iteration 300: Loss = 25.236434936523438, Number of mined P N = 311 5647\n",
      "Epoch 91 Iteration 400: Loss = 24.99927520751953, Number of mined P N = 310 4786\n",
      "Epoch 91 Iteration 500: Loss = 27.152599334716797, Number of mined P N = 306 4765\n",
      "Epoch 91 Iteration 600: Loss = 25.719451904296875, Number of mined P N = 318 4400\n",
      "Epoch 91 Iteration 700: Loss = 29.110267639160156, Number of mined P N = 342 4902\n",
      "Validation loss:  14.406088809967041\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 92 Iteration 0: Loss = 24.672941207885742, Number of mined P N = 320 5246\n",
      "Epoch 92 Iteration 100: Loss = 29.023876190185547, Number of mined P N = 358 6510\n",
      "Epoch 92 Iteration 200: Loss = 27.709453582763672, Number of mined P N = 330 5227\n",
      "Epoch 92 Iteration 300: Loss = 26.441465377807617, Number of mined P N = 323 4357\n",
      "Epoch 92 Iteration 400: Loss = 25.726123809814453, Number of mined P N = 327 4221\n",
      "Epoch 92 Iteration 500: Loss = 25.166866302490234, Number of mined P N = 317 4622\n",
      "Epoch 92 Iteration 600: Loss = 25.28264617919922, Number of mined P N = 296 4672\n",
      "Epoch 92 Iteration 700: Loss = 27.265567779541016, Number of mined P N = 336 5053\n",
      "Validation loss:  13.820320339202881\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 93 Iteration 0: Loss = 26.567094802856445, Number of mined P N = 315 4283\n",
      "Epoch 93 Iteration 100: Loss = 26.80076026916504, Number of mined P N = 312 5209\n",
      "Epoch 93 Iteration 200: Loss = 30.280132293701172, Number of mined P N = 346 5571\n",
      "Epoch 93 Iteration 300: Loss = 26.23172378540039, Number of mined P N = 330 4448\n",
      "Epoch 93 Iteration 400: Loss = 25.769956588745117, Number of mined P N = 306 4363\n",
      "Epoch 93 Iteration 500: Loss = 25.529888153076172, Number of mined P N = 324 4382\n",
      "Epoch 93 Iteration 600: Loss = 26.704092025756836, Number of mined P N = 334 6784\n",
      "Epoch 93 Iteration 700: Loss = 24.82160186767578, Number of mined P N = 297 4826\n",
      "Validation loss:  13.525448875427246\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 94 Iteration 0: Loss = 24.329631805419922, Number of mined P N = 318 4298\n",
      "Epoch 94 Iteration 100: Loss = 26.131427764892578, Number of mined P N = 322 4967\n",
      "Epoch 94 Iteration 200: Loss = 27.764007568359375, Number of mined P N = 329 4406\n",
      "Epoch 94 Iteration 300: Loss = 29.908987045288086, Number of mined P N = 333 5852\n",
      "Epoch 94 Iteration 400: Loss = 25.454200744628906, Number of mined P N = 305 4813\n",
      "Epoch 94 Iteration 500: Loss = 26.075111389160156, Number of mined P N = 308 4393\n",
      "Epoch 94 Iteration 600: Loss = 24.89299774169922, Number of mined P N = 300 4180\n",
      "Epoch 94 Iteration 700: Loss = 26.690853118896484, Number of mined P N = 316 4773\n",
      "Validation loss:  13.597557373046875\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 95 Iteration 0: Loss = 24.120403289794922, Number of mined P N = 290 4597\n",
      "Epoch 95 Iteration 100: Loss = 23.98985481262207, Number of mined P N = 293 4097\n",
      "Epoch 95 Iteration 200: Loss = 29.18386459350586, Number of mined P N = 345 6192\n",
      "Epoch 95 Iteration 300: Loss = 25.347396850585938, Number of mined P N = 294 4609\n",
      "Epoch 95 Iteration 400: Loss = 26.527204513549805, Number of mined P N = 309 5150\n",
      "Epoch 95 Iteration 500: Loss = 20.639442443847656, Number of mined P N = 255 4319\n",
      "Epoch 95 Iteration 600: Loss = 24.8984375, Number of mined P N = 327 4442\n",
      "Epoch 95 Iteration 700: Loss = 26.5855770111084, Number of mined P N = 318 5695\n",
      "Validation loss:  13.28746057510376\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 96 Iteration 0: Loss = 24.07921600341797, Number of mined P N = 304 5472\n",
      "Epoch 96 Iteration 100: Loss = 24.860578536987305, Number of mined P N = 313 5585\n",
      "Epoch 96 Iteration 200: Loss = 29.22208595275879, Number of mined P N = 331 5435\n",
      "Epoch 96 Iteration 300: Loss = 29.213390350341797, Number of mined P N = 351 7228\n",
      "Epoch 96 Iteration 400: Loss = 25.38548469543457, Number of mined P N = 303 3594\n",
      "Epoch 96 Iteration 500: Loss = 27.37061309814453, Number of mined P N = 327 6661\n",
      "Epoch 96 Iteration 600: Loss = 29.188190460205078, Number of mined P N = 349 6601\n",
      "Epoch 96 Iteration 700: Loss = 26.29132080078125, Number of mined P N = 327 4363\n",
      "Validation loss:  13.375947189331054\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 97 Iteration 0: Loss = 20.430009841918945, Number of mined P N = 246 4294\n",
      "Epoch 97 Iteration 100: Loss = 22.454280853271484, Number of mined P N = 294 4663\n",
      "Epoch 97 Iteration 200: Loss = 25.21224594116211, Number of mined P N = 304 4171\n",
      "Epoch 97 Iteration 300: Loss = 25.917682647705078, Number of mined P N = 325 4885\n",
      "Epoch 97 Iteration 400: Loss = 25.43646240234375, Number of mined P N = 302 5144\n",
      "Epoch 97 Iteration 500: Loss = 27.577346801757812, Number of mined P N = 334 5709\n",
      "Epoch 97 Iteration 600: Loss = 27.86859703063965, Number of mined P N = 324 5108\n",
      "Epoch 97 Iteration 700: Loss = 25.221572875976562, Number of mined P N = 311 4588\n",
      "Validation loss:  13.549798049926757\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 98 Iteration 0: Loss = 23.017953872680664, Number of mined P N = 282 3484\n",
      "Epoch 98 Iteration 100: Loss = 26.180044174194336, Number of mined P N = 315 4468\n",
      "Epoch 98 Iteration 200: Loss = 26.14238166809082, Number of mined P N = 313 5730\n",
      "Epoch 98 Iteration 300: Loss = 27.326793670654297, Number of mined P N = 322 4267\n",
      "Epoch 98 Iteration 400: Loss = 26.272308349609375, Number of mined P N = 323 5664\n",
      "Epoch 98 Iteration 500: Loss = 27.40873908996582, Number of mined P N = 335 6221\n",
      "Epoch 98 Iteration 600: Loss = 25.736413955688477, Number of mined P N = 328 4214\n",
      "Epoch 98 Iteration 700: Loss = 25.984962463378906, Number of mined P N = 320 5022\n",
      "Validation loss:  13.51212080001831\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 99 Iteration 0: Loss = 29.285484313964844, Number of mined P N = 348 6389\n",
      "Epoch 99 Iteration 100: Loss = 26.205066680908203, Number of mined P N = 301 4813\n",
      "Epoch 99 Iteration 200: Loss = 26.859912872314453, Number of mined P N = 319 5836\n",
      "Epoch 99 Iteration 300: Loss = 24.370777130126953, Number of mined P N = 286 4677\n",
      "Epoch 99 Iteration 400: Loss = 23.164365768432617, Number of mined P N = 270 4860\n",
      "Epoch 99 Iteration 500: Loss = 29.08902931213379, Number of mined P N = 346 6171\n",
      "Epoch 99 Iteration 600: Loss = 25.73215103149414, Number of mined P N = 310 4604\n",
      "Epoch 99 Iteration 700: Loss = 25.76250457763672, Number of mined P N = 323 6330\n",
      "Validation loss:  14.581687622070312\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "feature= \"psd\"\n",
    "sample_len = 129\n",
    "num_epochs=99\n",
    "batch_s= 128\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "from pytorch_metric_learning.distances import LpDistance, CosineSimilarity,SNRDistance\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "\n",
    "        # Access the data and labels from the HDF5 file\n",
    "        self.x_data = self.h5_file['data']  # EEG data (use memory-mapped access)\n",
    "        self.y_data = self.h5_file['labels'][:]  # Labels (load fully into memory)\n",
    "        self.s_data = self.h5_file['sessions'][:]  # Sessions (load fully into memory)\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        #print(self.subject_map)\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Convert to torch tensor\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "    def close(self):\n",
    "        self.h5_file.close()\n",
    "\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "            # Load the data, labels, and sessions fully into memory\n",
    "            self.x_data = np.array(h5_file['data'])  # Load EEG data into memory\n",
    "            self.y_data = np.array(h5_file['labels'])  # Load labels into memory\n",
    "            self.s_data = np.array(h5_file['sessions'])  # Load sessions into memory\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        print(len(unique_subjects))\n",
    "        self.subject_map = {subject: idx for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert data and labels into torch tensors\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Fetch EEG data\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Fetch the session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "\n",
    "# Usage example\n",
    "h5_file_path_t = f'../Data/train_{feature}.h5'\n",
    "h5_file_path_v = f'../Data/valid_{feature}.h5'\n",
    "train_dataset = EEGDataset(h5_file_path_t)\n",
    "valid_dataset = EEGDataset(h5_file_path_v)\n",
    "#valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "subject_ids = train_dataset.targets  # Replace with train_dataset.targets\n",
    "session_ids = train_dataset.s_data          # Replace with train_dataset.s_data\n",
    "\n",
    "# Combine subject and session IDs into unique pairs\n",
    "pairs = list(zip(subject_ids.tolist(), session_ids.tolist()))\n",
    "\n",
    "# Create a mapping from pairs to unique IDs\n",
    "unique_pairs = list(set(pairs))  # Get unique pairs\n",
    "pair_to_id = {pair: idx for idx, pair in enumerate(unique_pairs)}\n",
    "\n",
    "# Map each pair to its unique ID\n",
    "unique_ids = torch.tensor([pair_to_id[pair] for pair in pairs])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate(model, loader, loss_func, mining_func, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation loader (using the provided loader, not train_loader)\n",
    "        for batch_idx, (data, labels, sessions) in enumerate(loader):\n",
    "            # Move data and labels to the specified device\n",
    "            inputs = data.to(device)\n",
    "            targets = labels.to(device)\n",
    "\n",
    "            # Compute embeddings using the model\n",
    "            embeddings = model(inputs)\n",
    "            \n",
    "            # Get mining output for the embeddings\n",
    "            mined_indices = mining_func(embeddings, targets)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_func(embeddings, targets, mined_indices)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "    # Compute the average validation loss\n",
    "    average_loss = total_loss / total_batches if total_batches > 0 else 0\n",
    "    return average_loss\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet7, self).__init__()\n",
    "        # InstanceNorm1d normalizes each channel across its 500 values for each sample\n",
    "        self.norm = nn.InstanceNorm1d(93, affine=False)  # Normalizes across the 500 values in each of the 93 channels\n",
    "        self.act = nn.ReLU()  # or nn.SELU() , ReLU\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.conv1 = nn.Conv2d(1, 256, (1, 4), padding='same')\n",
    "        self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 192, (4, 1), padding='same')\n",
    "        self.pool2 = nn.MaxPool2d((2, 1))\n",
    "        self.conv3 = nn.Conv2d(192, 128, (1, 4), padding='same')\n",
    "        self.pool3 = nn.MaxPool2d((1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 96, (4, 1), padding='same')\n",
    "        self.pool4 = nn.MaxPool2d((2, 1))\n",
    "        self.conv5 = nn.Conv2d(96, 64, (1, 4), padding='same')\n",
    "        self.pool5 = nn.MaxPool2d((1, 2))\n",
    "        self.conv6 = nn.Conv2d(64, 32, (4, 1), padding='same')\n",
    "        self.pool6 = nn.MaxPool2d((2, 1))\n",
    "        self.conv7 = nn.Conv2d(32, 16, (1, 2), padding='same')\n",
    "        self.conv8 = nn.Conv2d(16, 2, (2, 1), padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.embedding = nn.Linear(352, 128)  # Embedding layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #if x.dim() == 3:\n",
    "            #x = x.unsqueeze(1)  # Adding a channel dimension if input is 3D\n",
    "        x = self.norm(x)  # Apply InstanceNorm along the channel dimension (squeeze to 1D first)\n",
    "        x = x.unsqueeze(1)  # Reshape to 4D again for Conv2d\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.act(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        x = self.act(self.conv6(x))\n",
    "        x = self.pool6(x)\n",
    "        x = self.act(self.conv7(x))\n",
    "        x = self.act(self.conv8(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch, test_loader):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    print(f\"Total number of batches in train_loader: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        with autocast():\n",
    "            embeddings = model(data)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels)\n",
    "\n",
    "        # Scales the loss, and backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales gradients and optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined P N = {} {}\".format(\n",
    "                    epoch, batch_idx, loss.item(), mining_func.num_pos_pairs, mining_func.num_neg_pairs  \n",
    "                ))\n",
    "    val_loss = validate(model, test_loader, loss_func, mining_func, device)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trunk = EEGNet7().to(device)\n",
    "summary(trunk, (93, sample_len)) \n",
    "\n",
    "\n",
    "loss_func = losses.SupConLoss(temperature=0.1).to(device)\n",
    "\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, batch_size=batch_s)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_s, sampler=sampler)\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001)\n",
    "#mining_func = miners.PairMarginMiner(pos_margin=0.20, neg_margin=0.8)\n",
    "mining_func = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "sampler2 = samplers.MPerClassSampler(valid_dataset.targets, m=4, batch_size=32)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_s, sampler=sampler2)\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(trunk, loss_func, mining_func, device, train_loader, trunk_optimizer, epoch,valid_loader)\n",
    "    #test(trunk, loss_func, mining_func, device, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(trunk.state_dict(), './model/SupConLoss128_m4_e99_psd.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29a89d-f3c4-4573-84df-71c4215daa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13101496-c347-4c6f-ad48-aa2b6f13a370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
