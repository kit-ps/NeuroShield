{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5531bb8-1801-4494-b04c-55cbb7127c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved as train_raw_unconnected.h5.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "with h5py.File(\"./data/train_raw.h5\", \"r\") as f:\n",
    "    X_test = f['data'][:]\n",
    "    Y_test = f['labels'][:]\n",
    "    S_test = f['sessions'][:]\n",
    "    H_test = f['hardwares'][:]\n",
    "\n",
    "# Initialize a new list to store indices to keep\n",
    "indices_to_keep = []\n",
    "\n",
    "# Find unique labels\n",
    "unique_labels = np.unique(Y_test)\n",
    "\n",
    "# Process each label\n",
    "for label in unique_labels:\n",
    "    # Get indices of the current label\n",
    "    label_indices = np.where(Y_test == label)[0]\n",
    "    # Extract hardware types for the current label\n",
    "    hardware_for_label = H_test[label_indices]\n",
    "    # Count occurrences of each hardware\n",
    "    hardware_counts = Counter(hardware_for_label)\n",
    "    # Find the hardware with the majority occurrences\n",
    "    majority_hardware = max(hardware_counts, key=hardware_counts.get)\n",
    "    # Keep indices for the majority hardware\n",
    "    majority_indices = label_indices[hardware_for_label == majority_hardware]\n",
    "    indices_to_keep.extend(majority_indices)\n",
    "\n",
    "# Filter the dataset\n",
    "indices_to_keep = np.array(indices_to_keep)\n",
    "X_filtered = X_test[indices_to_keep]\n",
    "Y_filtered = Y_test[indices_to_keep]\n",
    "S_filtered = S_test[indices_to_keep]\n",
    "H_filtered = H_test[indices_to_keep]\n",
    "\n",
    "# Save the filtered dataset\n",
    "with h5py.File(\"./data/train_raw_unconnected.h5\", \"w\") as f_out:\n",
    "    f_out.create_dataset('data', data=X_filtered)\n",
    "    f_out.create_dataset('labels', data=Y_filtered)\n",
    "    f_out.create_dataset('sessions', data=S_filtered)\n",
    "    f_out.create_dataset('hardwares', data=H_filtered)\n",
    "\n",
    "print(\"Filtered dataset saved as train_raw_unconnected.h5.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf0c551-cedf-4192-837a-61e9253dc383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({b'BioSemi': 400})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardware_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b170621-4a00-4097-99ef-213acc7152ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique (label, session, hardware) triplets in the dataset: 3091\n",
      "Number of unique triplets per hardware:\n",
      "Hardware HydroCe: 1751 times\n",
      "Hardware Geodisi: 435 times\n",
      "Hardware BioSemi: 905 times\n",
      "All possible hardware pairs used by subjects including same hardware in different sessions:\n",
      "Pair (b'HydroCe', b'HydroCe'): 14294 times\n",
      "Pair (b'Geodisi', b'Geodisi'): 2830 times\n",
      "Pair (b'BioSemi', b'BioSemi'): 9224 times\n"
     ]
    }
   ],
   "source": [
    "# Calculate unique triplets (label, session, hardware) and count them by hardware\n",
    "def count_unique_triplets(data):\n",
    "    triplets = np.core.records.fromarrays([data['Y'], data['S'], data['H']], names='label, session, hardware')\n",
    "    unique_triplets = np.unique(triplets)\n",
    "    hardware_counts = {}\n",
    "    for triplet in unique_triplets:\n",
    "        hardware = triplet['hardware']\n",
    "        if hardware in hardware_counts:\n",
    "            hardware_counts[hardware] += 1\n",
    "        else:\n",
    "            hardware_counts[hardware] = 1\n",
    "    return unique_triplets, hardware_counts\n",
    "\n",
    "unique_triplets, hardware_counts = count_unique_triplets(data)\n",
    "print(f\"Total number of unique (label, session, hardware) triplets in the dataset: {len(unique_triplets)}\")\n",
    "print(\"Number of unique triplets per hardware:\")\n",
    "for hardware, count in hardware_counts.items():\n",
    "    print(f\"Hardware {hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware}: {count} times\")\n",
    "\n",
    "\n",
    "# Function to calculate all possible hardware pairs from unique triplets\n",
    "def calculate_hardware_pairs(unique_triplets):\n",
    "    all_pairs = {}\n",
    "    subjects = np.unique(unique_triplets['label'])\n",
    "\n",
    "    for subject in subjects:\n",
    "        subject_triplets = unique_triplets[unique_triplets['label'] == subject]\n",
    "        hardware_combinations = subject_triplets['hardware']\n",
    "\n",
    "        # Generate all pairs for this subject including pairs from the same hardware in different sessions\n",
    "        for i in range(len(hardware_combinations)):\n",
    "            for j in range(i + 1, len(hardware_combinations)):\n",
    "                pair = tuple(sorted((hardware_combinations[i], hardware_combinations[j])))\n",
    "                all_pairs[pair] = all_pairs.get(pair, 0) + 1\n",
    "\n",
    "    return all_pairs\n",
    "\n",
    "hardware_pairs = calculate_hardware_pairs(unique_triplets)\n",
    "\n",
    "print(\"All possible hardware pairs used by subjects including same hardware in different sessions:\")\n",
    "for pair, count in hardware_pairs.items():\n",
    "    print(f\"Pair {pair}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3920cbc-76d3-456c-972f-08249460833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for hardware BioSemi saved to ./data/train_unconnected_hardware_BioSemi.h5\n",
      "Data for hardware Geodisi saved to ./data/train_unconnected_hardware_Geodisi.h5\n",
      "Data for hardware HydroCe saved to ./data/train_unconnected_hardware_HydroCe.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load data function\n",
    "def load_data(file_path):\n",
    "    with h5py.File(file_path, \"r\") as file:\n",
    "        data = {\n",
    "            'X': file['data'][:],\n",
    "            'Y': file['labels'][:],\n",
    "            'S': file['sessions'][:],\n",
    "            'H': file['hardwares'][:]\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# Load and combine datasets\n",
    "data_test = load_data(\"./data/train_raw_unconnected.h5\")\n",
    "\n",
    "\n",
    "\n",
    "# Shuffle the combined data\n",
    "indices = np.random.permutation(len(data_test['X']))\n",
    "for key in data_test:\n",
    "    data_test[key] = data_test[key][indices]\n",
    "\n",
    "# Split data based on hardware\n",
    "def split_and_save_data(data):\n",
    "    unique_hardware = np.unique(data['H'])\n",
    "    for hardware in unique_hardware:\n",
    "        # Filter data for each hardware\n",
    "        mask = data['H'] == hardware\n",
    "        filtered_data = {\n",
    "            'data': data['X'][mask],\n",
    "            'labels': data['Y'][mask],\n",
    "            'sessions': data['S'][mask],\n",
    "            'hardwares': data['H'][mask]\n",
    "        }\n",
    "        \n",
    "        # Save filtered data to a new HDF5 file\n",
    "        file_name = f\"./data/train_unconnected_hardware_{hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware}.h5\"\n",
    "        with h5py.File(file_name, 'w') as f:\n",
    "            for key, value in filtered_data.items():\n",
    "                f.create_dataset(key, data=value)\n",
    "        print(f\"Data for hardware {hardware.decode('utf-8') if isinstance(hardware, bytes) else hardware} saved to {file_name}\")\n",
    "\n",
    "split_and_save_data(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d0863-ad85-48c8-9833-d34a4c02d16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f69f7f-b593-4b30-9b5d-46da2e7ffe83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481000c7-36de-4dca-9568-5f5f9886d7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8517db7-1964-4c67-95b1-013888ee2709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998d0be7-b2bf-4599-8837-bfe9ebc4646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"./data/train_raw.h5\", \"r\") as f:\n",
    "    X = f['labels'][:]\n",
    "\n",
    "train = np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574cf6a-fd0c-4074-bf7d-07516ed119d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"./data/test_raw.h5\", \"r\") as f:\n",
    "    X = f['data'][:]\n",
    "\n",
    "test = np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff294df-9aaa-49ba-a74d-0d6c4d2d149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"./data/valid_raw.h5\", \"r\") as f:\n",
    "    X = f['data'][:]\n",
    "\n",
    "valid = np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6691f2e-0e2f-4b04-9130-05f054eed005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(\"./data/neg_raw.h5\", \"r\") as f:\n",
    "    X = f['data'][:]\n",
    "\n",
    "neg = np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd75d8-39d3-4793-a2ba-ff91c9aa90ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1aa9c-2f64-4832-9bd7-ab1f5ee79142",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_subjects = np.unique(np.concatenate([train, test, valid, neg]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
