{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9166b40a-7bbe-44b9-b318-75d390807900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 230\n",
      "Number of unique subjects: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    InstanceNorm1d-1              [-1, 14, 500]               0\n",
      "            Conv2d-2         [-1, 256, 14, 500]           1,280\n",
      "              ReLU-3         [-1, 256, 14, 500]               0\n",
      "         MaxPool2d-4         [-1, 256, 14, 250]               0\n",
      "            Conv2d-5         [-1, 192, 14, 250]         196,800\n",
      "              ReLU-6         [-1, 192, 14, 250]               0\n",
      "         MaxPool2d-7          [-1, 192, 7, 250]               0\n",
      "            Conv2d-8          [-1, 128, 7, 250]          98,432\n",
      "              ReLU-9          [-1, 128, 7, 250]               0\n",
      "           Conv2d-10           [-1, 96, 7, 250]          49,248\n",
      "             ReLU-11           [-1, 96, 7, 250]               0\n",
      "           Conv2d-12           [-1, 64, 7, 250]          24,640\n",
      "             ReLU-13           [-1, 64, 7, 250]               0\n",
      "           Conv2d-14           [-1, 32, 7, 250]           8,224\n",
      "             ReLU-15           [-1, 32, 7, 250]               0\n",
      "           Conv2d-16           [-1, 16, 7, 250]           1,040\n",
      "             ReLU-17           [-1, 16, 7, 250]               0\n",
      "           Conv2d-18            [-1, 2, 7, 250]              66\n",
      "             ReLU-19            [-1, 2, 7, 250]               0\n",
      "          Flatten-20                 [-1, 3500]               0\n",
      "           Linear-21                  [-1, 128]         448,128\n",
      "================================================================\n",
      "Total params: 827,858\n",
      "Trainable params: 827,858\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 56.10\n",
      "Params size (MB): 3.16\n",
      "Estimated Total Size (MB): 59.29\n",
      "----------------------------------------------------------------\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 1 Iteration 0: Loss = 4.844089031219482, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 100: Loss = 4.298134803771973, Number of mined P N = 384 9901\n",
      "Epoch 1 Iteration 200: Loss = 4.204197406768799, Number of mined P N = 384 9137\n",
      "Epoch 1 Iteration 300: Loss = 4.277190685272217, Number of mined P N = 384 10527\n",
      "Epoch 1 Iteration 400: Loss = 4.296147346496582, Number of mined P N = 384 10974\n",
      "Epoch 1 Iteration 500: Loss = 4.190911293029785, Number of mined P N = 384 9063\n",
      "Epoch 1 Iteration 600: Loss = 4.241868495941162, Number of mined P N = 384 10167\n",
      "Epoch 1 Iteration 700: Loss = 4.153357028961182, Number of mined P N = 384 9844\n",
      "Validation loss:  4.102350931167603\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 2 Iteration 0: Loss = 3.997654676437378, Number of mined P N = 384 8698\n",
      "Epoch 2 Iteration 100: Loss = 3.9697248935699463, Number of mined P N = 384 7715\n",
      "Epoch 2 Iteration 200: Loss = 4.122170448303223, Number of mined P N = 384 9009\n",
      "Epoch 2 Iteration 300: Loss = 3.872424840927124, Number of mined P N = 383 7331\n",
      "Epoch 2 Iteration 400: Loss = 4.205780506134033, Number of mined P N = 384 10433\n",
      "Epoch 2 Iteration 500: Loss = 4.0179595947265625, Number of mined P N = 384 8565\n",
      "Epoch 2 Iteration 600: Loss = 3.8172874450683594, Number of mined P N = 384 7924\n",
      "Epoch 2 Iteration 700: Loss = 4.053843021392822, Number of mined P N = 383 8847\n",
      "Validation loss:  3.880656008720398\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 3 Iteration 0: Loss = 3.8970630168914795, Number of mined P N = 384 8318\n",
      "Epoch 3 Iteration 100: Loss = 3.7219393253326416, Number of mined P N = 381 7317\n",
      "Epoch 3 Iteration 200: Loss = 3.866305351257324, Number of mined P N = 381 8027\n",
      "Epoch 3 Iteration 300: Loss = 3.739259719848633, Number of mined P N = 384 6874\n",
      "Epoch 3 Iteration 400: Loss = 3.641815185546875, Number of mined P N = 384 6786\n",
      "Epoch 3 Iteration 500: Loss = 4.088330268859863, Number of mined P N = 384 8397\n",
      "Epoch 3 Iteration 600: Loss = 3.7209312915802, Number of mined P N = 381 6602\n",
      "Epoch 3 Iteration 700: Loss = 3.804215669631958, Number of mined P N = 382 7637\n",
      "Validation loss:  3.747938632965088\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 4 Iteration 0: Loss = 3.7365708351135254, Number of mined P N = 382 7077\n",
      "Epoch 4 Iteration 100: Loss = 3.559999465942383, Number of mined P N = 384 6111\n",
      "Epoch 4 Iteration 200: Loss = 3.86159610748291, Number of mined P N = 384 7072\n",
      "Epoch 4 Iteration 300: Loss = 3.7851386070251465, Number of mined P N = 384 7883\n",
      "Epoch 4 Iteration 400: Loss = 3.946990966796875, Number of mined P N = 384 8071\n",
      "Epoch 4 Iteration 500: Loss = 3.772054433822632, Number of mined P N = 384 6718\n",
      "Epoch 4 Iteration 600: Loss = 3.764528274536133, Number of mined P N = 384 7529\n",
      "Epoch 4 Iteration 700: Loss = 3.5750041007995605, Number of mined P N = 378 6447\n",
      "Validation loss:  3.5742813968658447\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 5 Iteration 0: Loss = 3.385479211807251, Number of mined P N = 375 5415\n",
      "Epoch 5 Iteration 100: Loss = 3.5067360401153564, Number of mined P N = 381 5954\n",
      "Epoch 5 Iteration 200: Loss = 3.3236804008483887, Number of mined P N = 375 5155\n",
      "Epoch 5 Iteration 300: Loss = 3.5625953674316406, Number of mined P N = 381 6067\n",
      "Epoch 5 Iteration 400: Loss = 3.6352031230926514, Number of mined P N = 379 6594\n",
      "Epoch 5 Iteration 500: Loss = 3.4679126739501953, Number of mined P N = 380 5775\n",
      "Epoch 5 Iteration 600: Loss = 3.5840611457824707, Number of mined P N = 382 6080\n",
      "Epoch 5 Iteration 700: Loss = 3.6768319606781006, Number of mined P N = 381 7205\n",
      "Validation loss:  3.5238969135284424\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 6 Iteration 0: Loss = 3.512476682662964, Number of mined P N = 382 6386\n",
      "Epoch 6 Iteration 100: Loss = 3.3790175914764404, Number of mined P N = 382 5323\n",
      "Epoch 6 Iteration 200: Loss = 3.678771734237671, Number of mined P N = 378 6458\n",
      "Epoch 6 Iteration 300: Loss = 3.4221177101135254, Number of mined P N = 379 5078\n",
      "Epoch 6 Iteration 400: Loss = 3.6008214950561523, Number of mined P N = 384 6815\n",
      "Epoch 6 Iteration 500: Loss = 3.4561877250671387, Number of mined P N = 382 5320\n",
      "Epoch 6 Iteration 600: Loss = 3.3387351036071777, Number of mined P N = 381 4890\n",
      "Epoch 6 Iteration 700: Loss = 3.5393118858337402, Number of mined P N = 384 5457\n",
      "Validation loss:  3.3650028705596924\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 7 Iteration 0: Loss = 3.1667964458465576, Number of mined P N = 378 4461\n",
      "Epoch 7 Iteration 100: Loss = 3.315122604370117, Number of mined P N = 366 5167\n",
      "Epoch 7 Iteration 200: Loss = 3.6610934734344482, Number of mined P N = 383 6369\n",
      "Epoch 7 Iteration 300: Loss = 3.2660632133483887, Number of mined P N = 377 5094\n",
      "Epoch 7 Iteration 400: Loss = 3.1497726440429688, Number of mined P N = 384 4455\n",
      "Epoch 7 Iteration 500: Loss = 3.2547497749328613, Number of mined P N = 375 4653\n",
      "Epoch 7 Iteration 600: Loss = 3.292328119277954, Number of mined P N = 374 5250\n",
      "Epoch 7 Iteration 700: Loss = 3.1904850006103516, Number of mined P N = 374 4330\n",
      "Validation loss:  3.3221093034744262\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 8 Iteration 0: Loss = 3.414708375930786, Number of mined P N = 379 5768\n",
      "Epoch 8 Iteration 100: Loss = 3.164820432662964, Number of mined P N = 366 4519\n",
      "Epoch 8 Iteration 200: Loss = 3.229795217514038, Number of mined P N = 376 4642\n",
      "Epoch 8 Iteration 300: Loss = 3.2079174518585205, Number of mined P N = 370 5071\n",
      "Epoch 8 Iteration 400: Loss = 3.384957790374756, Number of mined P N = 370 6156\n",
      "Epoch 8 Iteration 500: Loss = 3.117718458175659, Number of mined P N = 364 4745\n",
      "Epoch 8 Iteration 600: Loss = 3.225337028503418, Number of mined P N = 373 5050\n",
      "Epoch 8 Iteration 700: Loss = 3.4268300533294678, Number of mined P N = 384 5068\n",
      "Validation loss:  3.2074201917648315\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 9 Iteration 0: Loss = 3.4084105491638184, Number of mined P N = 371 5418\n",
      "Epoch 9 Iteration 100: Loss = 3.376159191131592, Number of mined P N = 381 4958\n",
      "Epoch 9 Iteration 200: Loss = 2.9928135871887207, Number of mined P N = 364 4555\n",
      "Epoch 9 Iteration 300: Loss = 3.0919840335845947, Number of mined P N = 360 4479\n",
      "Epoch 9 Iteration 400: Loss = 3.022735118865967, Number of mined P N = 362 4370\n",
      "Epoch 9 Iteration 500: Loss = 3.0471348762512207, Number of mined P N = 374 3863\n",
      "Epoch 9 Iteration 600: Loss = 3.2216806411743164, Number of mined P N = 367 4649\n",
      "Epoch 9 Iteration 700: Loss = 3.033125638961792, Number of mined P N = 371 3973\n",
      "Validation loss:  3.156213889122009\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 10 Iteration 0: Loss = 3.0714635848999023, Number of mined P N = 368 4270\n",
      "Epoch 10 Iteration 100: Loss = 3.1663894653320312, Number of mined P N = 363 4400\n",
      "Epoch 10 Iteration 200: Loss = 3.403921604156494, Number of mined P N = 368 5849\n",
      "Epoch 10 Iteration 300: Loss = 3.4396228790283203, Number of mined P N = 374 5691\n",
      "Epoch 10 Iteration 400: Loss = 3.2274701595306396, Number of mined P N = 377 4859\n",
      "Epoch 10 Iteration 500: Loss = 3.126831531524658, Number of mined P N = 375 4391\n",
      "Epoch 10 Iteration 600: Loss = 3.2754335403442383, Number of mined P N = 368 4933\n",
      "Epoch 10 Iteration 700: Loss = 3.4343597888946533, Number of mined P N = 374 6072\n",
      "Validation loss:  3.0478248834609984\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 11 Iteration 0: Loss = 3.2071900367736816, Number of mined P N = 383 4518\n",
      "Epoch 11 Iteration 100: Loss = 3.1267776489257812, Number of mined P N = 359 4183\n",
      "Epoch 11 Iteration 200: Loss = 3.036456346511841, Number of mined P N = 367 4417\n",
      "Epoch 11 Iteration 300: Loss = 2.985161304473877, Number of mined P N = 370 3851\n",
      "Epoch 11 Iteration 400: Loss = 3.10593318939209, Number of mined P N = 380 4385\n",
      "Epoch 11 Iteration 500: Loss = 3.035715341567993, Number of mined P N = 361 3707\n",
      "Epoch 11 Iteration 600: Loss = 3.1206321716308594, Number of mined P N = 375 4788\n",
      "Epoch 11 Iteration 700: Loss = 3.005781888961792, Number of mined P N = 374 3929\n",
      "Validation loss:  3.1008653688430785\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 12 Iteration 0: Loss = 3.0859923362731934, Number of mined P N = 377 4201\n",
      "Epoch 12 Iteration 100: Loss = 3.1526737213134766, Number of mined P N = 374 4430\n",
      "Epoch 12 Iteration 200: Loss = 3.123929262161255, Number of mined P N = 370 4424\n",
      "Epoch 12 Iteration 300: Loss = 3.2164154052734375, Number of mined P N = 383 4388\n",
      "Epoch 12 Iteration 400: Loss = 2.8542640209198, Number of mined P N = 372 3469\n",
      "Epoch 12 Iteration 500: Loss = 2.9826719760894775, Number of mined P N = 368 4243\n",
      "Epoch 12 Iteration 600: Loss = 2.9444692134857178, Number of mined P N = 368 3450\n",
      "Epoch 12 Iteration 700: Loss = 3.3069372177124023, Number of mined P N = 376 5126\n",
      "Validation loss:  3.0667165184020995\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 13 Iteration 0: Loss = 2.8268351554870605, Number of mined P N = 357 3311\n",
      "Epoch 13 Iteration 100: Loss = 3.313776969909668, Number of mined P N = 378 4871\n",
      "Epoch 13 Iteration 200: Loss = 3.1554508209228516, Number of mined P N = 377 4415\n",
      "Epoch 13 Iteration 300: Loss = 3.02988338470459, Number of mined P N = 364 4125\n",
      "Epoch 13 Iteration 400: Loss = 3.109410285949707, Number of mined P N = 374 4076\n",
      "Epoch 13 Iteration 500: Loss = 2.9503684043884277, Number of mined P N = 368 3651\n",
      "Epoch 13 Iteration 600: Loss = 2.956721782684326, Number of mined P N = 377 3852\n",
      "Epoch 13 Iteration 700: Loss = 3.0732779502868652, Number of mined P N = 373 4293\n",
      "Validation loss:  2.9906933641433717\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 14 Iteration 0: Loss = 2.864530324935913, Number of mined P N = 378 3264\n",
      "Epoch 14 Iteration 100: Loss = 3.1559150218963623, Number of mined P N = 375 4628\n",
      "Epoch 14 Iteration 200: Loss = 3.060328722000122, Number of mined P N = 372 4073\n",
      "Epoch 14 Iteration 300: Loss = 2.920896053314209, Number of mined P N = 352 3795\n",
      "Epoch 14 Iteration 400: Loss = 3.0123419761657715, Number of mined P N = 369 4122\n",
      "Epoch 14 Iteration 500: Loss = 2.771592855453491, Number of mined P N = 345 3014\n",
      "Epoch 14 Iteration 600: Loss = 3.176440715789795, Number of mined P N = 367 4286\n",
      "Epoch 14 Iteration 700: Loss = 3.111039400100708, Number of mined P N = 368 4175\n",
      "Validation loss:  3.0384372425079347\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 15 Iteration 0: Loss = 3.0336594581604004, Number of mined P N = 370 4156\n",
      "Epoch 15 Iteration 100: Loss = 2.813697099685669, Number of mined P N = 369 3446\n",
      "Epoch 15 Iteration 200: Loss = 2.919015884399414, Number of mined P N = 374 3791\n",
      "Epoch 15 Iteration 300: Loss = 2.8714566230773926, Number of mined P N = 368 3323\n",
      "Epoch 15 Iteration 400: Loss = 3.123314380645752, Number of mined P N = 368 4642\n",
      "Epoch 15 Iteration 500: Loss = 2.84743070602417, Number of mined P N = 370 3790\n",
      "Epoch 15 Iteration 600: Loss = 2.8373091220855713, Number of mined P N = 356 3573\n",
      "Epoch 15 Iteration 700: Loss = 2.819448471069336, Number of mined P N = 365 3530\n",
      "Validation loss:  2.9351598167419435\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 16 Iteration 0: Loss = 3.0563154220581055, Number of mined P N = 374 3616\n",
      "Epoch 16 Iteration 100: Loss = 2.748073101043701, Number of mined P N = 360 3029\n",
      "Epoch 16 Iteration 200: Loss = 2.8977160453796387, Number of mined P N = 365 3975\n",
      "Epoch 16 Iteration 300: Loss = 2.937419891357422, Number of mined P N = 349 3763\n",
      "Epoch 16 Iteration 400: Loss = 2.8039844036102295, Number of mined P N = 366 3259\n",
      "Epoch 16 Iteration 500: Loss = 3.2095727920532227, Number of mined P N = 369 4571\n",
      "Epoch 16 Iteration 600: Loss = 2.63494610786438, Number of mined P N = 354 2865\n",
      "Epoch 16 Iteration 700: Loss = 2.92795467376709, Number of mined P N = 375 3352\n",
      "Validation loss:  2.95979070186615\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 17 Iteration 0: Loss = 2.8979740142822266, Number of mined P N = 368 3954\n",
      "Epoch 17 Iteration 100: Loss = 2.7823643684387207, Number of mined P N = 367 3633\n",
      "Epoch 17 Iteration 200: Loss = 3.1890692710876465, Number of mined P N = 368 4906\n",
      "Epoch 17 Iteration 300: Loss = 2.8072688579559326, Number of mined P N = 365 3222\n",
      "Epoch 17 Iteration 400: Loss = 2.8379621505737305, Number of mined P N = 369 3255\n",
      "Epoch 17 Iteration 500: Loss = 2.8812742233276367, Number of mined P N = 365 3427\n",
      "Epoch 17 Iteration 600: Loss = 2.8041839599609375, Number of mined P N = 360 3453\n",
      "Epoch 17 Iteration 700: Loss = 2.8653628826141357, Number of mined P N = 362 3448\n",
      "Validation loss:  2.8982445192337036\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 18 Iteration 0: Loss = 2.8085460662841797, Number of mined P N = 362 3755\n",
      "Epoch 18 Iteration 100: Loss = 2.8271405696868896, Number of mined P N = 362 3416\n",
      "Epoch 18 Iteration 200: Loss = 2.9752261638641357, Number of mined P N = 367 4027\n",
      "Epoch 18 Iteration 300: Loss = 2.653653144836426, Number of mined P N = 363 2872\n",
      "Epoch 18 Iteration 400: Loss = 2.7726330757141113, Number of mined P N = 347 3186\n",
      "Epoch 18 Iteration 500: Loss = 2.8228092193603516, Number of mined P N = 356 3564\n",
      "Epoch 18 Iteration 600: Loss = 2.791926860809326, Number of mined P N = 377 3057\n",
      "Epoch 18 Iteration 700: Loss = 3.0868821144104004, Number of mined P N = 380 4450\n",
      "Validation loss:  2.880583167076111\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 19 Iteration 0: Loss = 2.594208002090454, Number of mined P N = 350 3012\n",
      "Epoch 19 Iteration 100: Loss = 2.738759994506836, Number of mined P N = 371 2946\n",
      "Epoch 19 Iteration 200: Loss = 2.8763697147369385, Number of mined P N = 357 3420\n",
      "Epoch 19 Iteration 300: Loss = 3.038966655731201, Number of mined P N = 354 4416\n",
      "Epoch 19 Iteration 400: Loss = 3.2241013050079346, Number of mined P N = 366 4628\n",
      "Epoch 19 Iteration 500: Loss = 3.3092756271362305, Number of mined P N = 379 5010\n",
      "Epoch 19 Iteration 600: Loss = 2.904892921447754, Number of mined P N = 366 3626\n",
      "Epoch 19 Iteration 700: Loss = 2.5244534015655518, Number of mined P N = 361 2570\n",
      "Validation loss:  2.870239462852478\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 20 Iteration 0: Loss = 3.1981163024902344, Number of mined P N = 363 4569\n",
      "Epoch 20 Iteration 100: Loss = 2.914066791534424, Number of mined P N = 356 3332\n",
      "Epoch 20 Iteration 200: Loss = 2.8007500171661377, Number of mined P N = 356 3148\n",
      "Epoch 20 Iteration 300: Loss = 2.7763142585754395, Number of mined P N = 365 3083\n",
      "Epoch 20 Iteration 400: Loss = 2.7936248779296875, Number of mined P N = 332 3270\n",
      "Epoch 20 Iteration 500: Loss = 2.8073678016662598, Number of mined P N = 353 3155\n",
      "Epoch 20 Iteration 600: Loss = 2.4974281787872314, Number of mined P N = 339 2393\n",
      "Epoch 20 Iteration 700: Loss = 2.8243234157562256, Number of mined P N = 358 3444\n",
      "Validation loss:  2.9049172735214235\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 21 Iteration 0: Loss = 3.0808818340301514, Number of mined P N = 375 4188\n",
      "Epoch 21 Iteration 100: Loss = 2.528902769088745, Number of mined P N = 340 2327\n",
      "Epoch 21 Iteration 200: Loss = 2.938490629196167, Number of mined P N = 357 3865\n",
      "Epoch 21 Iteration 300: Loss = 2.839893102645874, Number of mined P N = 364 3703\n",
      "Epoch 21 Iteration 400: Loss = 2.884392738342285, Number of mined P N = 363 3529\n",
      "Epoch 21 Iteration 500: Loss = 3.1358132362365723, Number of mined P N = 374 4568\n",
      "Epoch 21 Iteration 600: Loss = 2.5953080654144287, Number of mined P N = 334 2621\n",
      "Epoch 21 Iteration 700: Loss = 2.9871671199798584, Number of mined P N = 365 3856\n",
      "Validation loss:  2.811434016227722\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 22 Iteration 0: Loss = 2.689093828201294, Number of mined P N = 337 2770\n",
      "Epoch 22 Iteration 100: Loss = 2.7143912315368652, Number of mined P N = 350 3095\n",
      "Epoch 22 Iteration 200: Loss = 2.839078664779663, Number of mined P N = 364 3240\n",
      "Epoch 22 Iteration 300: Loss = 2.8188419342041016, Number of mined P N = 364 3449\n",
      "Epoch 22 Iteration 400: Loss = 2.684217929840088, Number of mined P N = 342 3066\n",
      "Epoch 22 Iteration 500: Loss = 2.7123923301696777, Number of mined P N = 367 3500\n",
      "Epoch 22 Iteration 600: Loss = 2.7324702739715576, Number of mined P N = 333 2822\n",
      "Epoch 22 Iteration 700: Loss = 2.7378640174865723, Number of mined P N = 370 3279\n",
      "Validation loss:  2.7788654375076294\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 23 Iteration 0: Loss = 3.1448137760162354, Number of mined P N = 368 4320\n",
      "Epoch 23 Iteration 100: Loss = 2.73342227935791, Number of mined P N = 363 3355\n",
      "Epoch 23 Iteration 200: Loss = 2.7163045406341553, Number of mined P N = 348 2946\n",
      "Epoch 23 Iteration 300: Loss = 2.8878016471862793, Number of mined P N = 345 3694\n",
      "Epoch 23 Iteration 400: Loss = 3.0320377349853516, Number of mined P N = 368 4153\n",
      "Epoch 23 Iteration 500: Loss = 2.6681716442108154, Number of mined P N = 356 2761\n",
      "Epoch 23 Iteration 600: Loss = 2.6407134532928467, Number of mined P N = 360 3108\n",
      "Epoch 23 Iteration 700: Loss = 2.795924186706543, Number of mined P N = 344 3750\n",
      "Validation loss:  2.7568119859695432\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 24 Iteration 0: Loss = 2.5972490310668945, Number of mined P N = 348 2488\n",
      "Epoch 24 Iteration 100: Loss = 2.713189125061035, Number of mined P N = 335 3071\n",
      "Epoch 24 Iteration 200: Loss = 2.819185733795166, Number of mined P N = 367 3099\n",
      "Epoch 24 Iteration 300: Loss = 2.940897226333618, Number of mined P N = 345 3409\n",
      "Epoch 24 Iteration 400: Loss = 2.8910443782806396, Number of mined P N = 351 3734\n",
      "Epoch 24 Iteration 500: Loss = 2.760824680328369, Number of mined P N = 362 3449\n",
      "Epoch 24 Iteration 600: Loss = 2.635246992111206, Number of mined P N = 362 2819\n",
      "Epoch 24 Iteration 700: Loss = 2.870429515838623, Number of mined P N = 377 3338\n",
      "Validation loss:  2.8139645767211916\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 25 Iteration 0: Loss = 2.9608840942382812, Number of mined P N = 351 3643\n",
      "Epoch 25 Iteration 100: Loss = 2.608452081680298, Number of mined P N = 368 2887\n",
      "Epoch 25 Iteration 200: Loss = 2.879418134689331, Number of mined P N = 357 3445\n",
      "Epoch 25 Iteration 300: Loss = 2.7337000370025635, Number of mined P N = 337 3228\n",
      "Epoch 25 Iteration 400: Loss = 2.715085506439209, Number of mined P N = 360 3024\n",
      "Epoch 25 Iteration 500: Loss = 2.5261006355285645, Number of mined P N = 358 2429\n",
      "Epoch 25 Iteration 600: Loss = 2.8114187717437744, Number of mined P N = 349 2995\n",
      "Epoch 25 Iteration 700: Loss = 2.851613998413086, Number of mined P N = 360 3314\n",
      "Validation loss:  2.7678998041152956\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 26 Iteration 0: Loss = 2.4328670501708984, Number of mined P N = 357 2323\n",
      "Epoch 26 Iteration 100: Loss = 2.9166929721832275, Number of mined P N = 358 3932\n",
      "Epoch 26 Iteration 200: Loss = 2.8772101402282715, Number of mined P N = 339 3293\n",
      "Epoch 26 Iteration 300: Loss = 2.8603267669677734, Number of mined P N = 368 3496\n",
      "Epoch 26 Iteration 400: Loss = 2.763843059539795, Number of mined P N = 356 3016\n",
      "Epoch 26 Iteration 500: Loss = 2.6948840618133545, Number of mined P N = 353 3128\n",
      "Epoch 26 Iteration 600: Loss = 2.61064076423645, Number of mined P N = 361 2741\n",
      "Epoch 26 Iteration 700: Loss = 2.88100266456604, Number of mined P N = 366 3547\n",
      "Validation loss:  2.68810715675354\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 27 Iteration 0: Loss = 2.846191883087158, Number of mined P N = 354 3228\n",
      "Epoch 27 Iteration 100: Loss = 2.8283016681671143, Number of mined P N = 367 3098\n",
      "Epoch 27 Iteration 200: Loss = 2.719834804534912, Number of mined P N = 343 2870\n",
      "Epoch 27 Iteration 300: Loss = 2.846379518508911, Number of mined P N = 336 3069\n",
      "Epoch 27 Iteration 400: Loss = 3.053112268447876, Number of mined P N = 363 3843\n",
      "Epoch 27 Iteration 500: Loss = 2.840955972671509, Number of mined P N = 368 2895\n",
      "Epoch 27 Iteration 600: Loss = 2.8702638149261475, Number of mined P N = 356 3480\n",
      "Epoch 27 Iteration 700: Loss = 2.617156982421875, Number of mined P N = 363 2730\n",
      "Validation loss:  2.7219818449020385\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 28 Iteration 0: Loss = 2.5078861713409424, Number of mined P N = 348 2434\n",
      "Epoch 28 Iteration 100: Loss = 2.7525272369384766, Number of mined P N = 364 2756\n",
      "Epoch 28 Iteration 200: Loss = 2.804945230484009, Number of mined P N = 361 3158\n",
      "Epoch 28 Iteration 300: Loss = 2.6106045246124268, Number of mined P N = 340 2480\n",
      "Epoch 28 Iteration 400: Loss = 2.95637845993042, Number of mined P N = 376 3864\n",
      "Epoch 28 Iteration 500: Loss = 3.0442874431610107, Number of mined P N = 364 3872\n",
      "Epoch 28 Iteration 600: Loss = 2.680110454559326, Number of mined P N = 356 2915\n",
      "Epoch 28 Iteration 700: Loss = 2.8748176097869873, Number of mined P N = 364 3253\n",
      "Validation loss:  2.739712996482849\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 29 Iteration 0: Loss = 2.7097954750061035, Number of mined P N = 359 3057\n",
      "Epoch 29 Iteration 100: Loss = 2.6882781982421875, Number of mined P N = 364 2734\n",
      "Epoch 29 Iteration 200: Loss = 2.6212384700775146, Number of mined P N = 362 2808\n",
      "Epoch 29 Iteration 300: Loss = 2.7602274417877197, Number of mined P N = 347 3065\n",
      "Epoch 29 Iteration 400: Loss = 2.675074338912964, Number of mined P N = 361 2713\n",
      "Epoch 29 Iteration 500: Loss = 2.592982292175293, Number of mined P N = 338 2636\n",
      "Epoch 29 Iteration 600: Loss = 2.774503469467163, Number of mined P N = 373 3127\n",
      "Epoch 29 Iteration 700: Loss = 2.545992612838745, Number of mined P N = 345 2466\n",
      "Validation loss:  2.7072338914871215\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 30 Iteration 0: Loss = 2.6477952003479004, Number of mined P N = 355 2941\n",
      "Epoch 30 Iteration 100: Loss = 2.5076866149902344, Number of mined P N = 357 2579\n",
      "Epoch 30 Iteration 200: Loss = 2.805644989013672, Number of mined P N = 366 3173\n",
      "Epoch 30 Iteration 300: Loss = 2.8511970043182373, Number of mined P N = 371 3498\n",
      "Epoch 30 Iteration 400: Loss = 2.921969175338745, Number of mined P N = 355 3741\n",
      "Epoch 30 Iteration 500: Loss = 2.6038177013397217, Number of mined P N = 364 2691\n",
      "Epoch 30 Iteration 600: Loss = 2.4912004470825195, Number of mined P N = 319 2688\n",
      "Epoch 30 Iteration 700: Loss = 2.5584518909454346, Number of mined P N = 342 2688\n",
      "Validation loss:  2.723031506538391\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 31 Iteration 0: Loss = 2.8156707286834717, Number of mined P N = 361 3185\n",
      "Epoch 31 Iteration 100: Loss = 2.699209213256836, Number of mined P N = 366 2970\n",
      "Epoch 31 Iteration 200: Loss = 2.7268881797790527, Number of mined P N = 330 2986\n",
      "Epoch 31 Iteration 300: Loss = 2.5904133319854736, Number of mined P N = 352 2829\n",
      "Epoch 31 Iteration 400: Loss = 2.7360401153564453, Number of mined P N = 362 2970\n",
      "Epoch 31 Iteration 500: Loss = 2.5935254096984863, Number of mined P N = 348 2669\n",
      "Epoch 31 Iteration 600: Loss = 2.5528900623321533, Number of mined P N = 326 2655\n",
      "Epoch 31 Iteration 700: Loss = 2.2868120670318604, Number of mined P N = 318 1825\n",
      "Validation loss:  2.6963616609573364\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 32 Iteration 0: Loss = 2.7979607582092285, Number of mined P N = 364 3090\n",
      "Epoch 32 Iteration 100: Loss = 2.9524543285369873, Number of mined P N = 342 3411\n",
      "Epoch 32 Iteration 200: Loss = 2.5530905723571777, Number of mined P N = 358 2462\n",
      "Epoch 32 Iteration 300: Loss = 2.64831280708313, Number of mined P N = 353 2720\n",
      "Epoch 32 Iteration 400: Loss = 2.6010708808898926, Number of mined P N = 329 2690\n",
      "Epoch 32 Iteration 500: Loss = 2.6721503734588623, Number of mined P N = 345 2964\n",
      "Epoch 32 Iteration 600: Loss = 2.7119534015655518, Number of mined P N = 355 2876\n",
      "Epoch 32 Iteration 700: Loss = 2.5208818912506104, Number of mined P N = 348 2429\n",
      "Validation loss:  2.6489126300811767\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 33 Iteration 0: Loss = 2.5123162269592285, Number of mined P N = 340 2177\n",
      "Epoch 33 Iteration 100: Loss = 2.4415862560272217, Number of mined P N = 318 2238\n",
      "Epoch 33 Iteration 200: Loss = 2.798509359359741, Number of mined P N = 358 2775\n",
      "Epoch 33 Iteration 300: Loss = 2.6059348583221436, Number of mined P N = 352 2721\n",
      "Epoch 33 Iteration 400: Loss = 2.925079822540283, Number of mined P N = 355 3504\n",
      "Epoch 33 Iteration 500: Loss = 2.7579596042633057, Number of mined P N = 335 3018\n",
      "Epoch 33 Iteration 600: Loss = 2.6108758449554443, Number of mined P N = 357 2740\n",
      "Epoch 33 Iteration 700: Loss = 2.6975433826446533, Number of mined P N = 358 2738\n",
      "Validation loss:  2.6699863338470458\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 34 Iteration 0: Loss = 2.5693838596343994, Number of mined P N = 329 2601\n",
      "Epoch 34 Iteration 100: Loss = 2.676032304763794, Number of mined P N = 335 3423\n",
      "Epoch 34 Iteration 200: Loss = 2.7458269596099854, Number of mined P N = 359 3071\n",
      "Epoch 34 Iteration 300: Loss = 2.6726772785186768, Number of mined P N = 343 2891\n",
      "Epoch 34 Iteration 400: Loss = 2.8535959720611572, Number of mined P N = 339 3262\n",
      "Epoch 34 Iteration 500: Loss = 2.4938907623291016, Number of mined P N = 342 2442\n",
      "Epoch 34 Iteration 600: Loss = 2.680823802947998, Number of mined P N = 350 3187\n",
      "Epoch 34 Iteration 700: Loss = 2.683706283569336, Number of mined P N = 360 2747\n",
      "Validation loss:  2.643808946609497\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 35 Iteration 0: Loss = 2.4609084129333496, Number of mined P N = 334 2208\n",
      "Epoch 35 Iteration 100: Loss = 2.7767221927642822, Number of mined P N = 358 2940\n",
      "Epoch 35 Iteration 200: Loss = 2.865187168121338, Number of mined P N = 369 3403\n",
      "Epoch 35 Iteration 300: Loss = 2.5818207263946533, Number of mined P N = 327 2489\n",
      "Epoch 35 Iteration 400: Loss = 2.879103899002075, Number of mined P N = 359 3355\n",
      "Epoch 35 Iteration 500: Loss = 2.371492624282837, Number of mined P N = 328 2139\n",
      "Epoch 35 Iteration 600: Loss = 2.6581549644470215, Number of mined P N = 341 2618\n",
      "Epoch 35 Iteration 700: Loss = 2.362814426422119, Number of mined P N = 327 2097\n",
      "Validation loss:  2.6613464069366457\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 36 Iteration 0: Loss = 2.5741477012634277, Number of mined P N = 326 2498\n",
      "Epoch 36 Iteration 100: Loss = 2.7456252574920654, Number of mined P N = 353 2906\n",
      "Epoch 36 Iteration 200: Loss = 2.513653039932251, Number of mined P N = 364 2245\n",
      "Epoch 36 Iteration 300: Loss = 2.846181869506836, Number of mined P N = 362 3492\n",
      "Epoch 36 Iteration 400: Loss = 2.9950342178344727, Number of mined P N = 360 4189\n",
      "Epoch 36 Iteration 500: Loss = 2.7944552898406982, Number of mined P N = 345 3076\n",
      "Epoch 36 Iteration 600: Loss = 2.7518551349639893, Number of mined P N = 360 2985\n",
      "Epoch 36 Iteration 700: Loss = 2.541903495788574, Number of mined P N = 352 2398\n",
      "Validation loss:  2.6615193128585815\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 37 Iteration 0: Loss = 2.526832103729248, Number of mined P N = 311 2411\n",
      "Epoch 37 Iteration 100: Loss = 2.717351198196411, Number of mined P N = 361 2814\n",
      "Epoch 37 Iteration 200: Loss = 2.675558090209961, Number of mined P N = 344 2884\n",
      "Epoch 37 Iteration 300: Loss = 2.4859633445739746, Number of mined P N = 341 2129\n",
      "Epoch 37 Iteration 400: Loss = 2.7766871452331543, Number of mined P N = 363 3417\n",
      "Epoch 37 Iteration 500: Loss = 2.4132649898529053, Number of mined P N = 331 2416\n",
      "Epoch 37 Iteration 600: Loss = 2.726499319076538, Number of mined P N = 317 2911\n",
      "Epoch 37 Iteration 700: Loss = 2.633241653442383, Number of mined P N = 312 2385\n",
      "Validation loss:  2.637228455543518\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 38 Iteration 0: Loss = 2.7624871730804443, Number of mined P N = 346 3174\n",
      "Epoch 38 Iteration 100: Loss = 2.555924892425537, Number of mined P N = 338 2674\n",
      "Epoch 38 Iteration 200: Loss = 2.5100457668304443, Number of mined P N = 318 2336\n",
      "Epoch 38 Iteration 300: Loss = 2.6442248821258545, Number of mined P N = 350 2819\n",
      "Epoch 38 Iteration 400: Loss = 2.3607139587402344, Number of mined P N = 345 1990\n",
      "Epoch 38 Iteration 500: Loss = 2.4164278507232666, Number of mined P N = 333 2221\n",
      "Epoch 38 Iteration 600: Loss = 2.695543050765991, Number of mined P N = 344 2862\n",
      "Epoch 38 Iteration 700: Loss = 2.6194052696228027, Number of mined P N = 328 2553\n",
      "Validation loss:  2.6224802780151366\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 39 Iteration 0: Loss = 2.3708815574645996, Number of mined P N = 320 2132\n",
      "Epoch 39 Iteration 100: Loss = 2.5721030235290527, Number of mined P N = 348 3057\n",
      "Epoch 39 Iteration 200: Loss = 2.4247207641601562, Number of mined P N = 338 2084\n",
      "Epoch 39 Iteration 300: Loss = 2.2857418060302734, Number of mined P N = 330 1903\n",
      "Epoch 39 Iteration 400: Loss = 2.7787892818450928, Number of mined P N = 337 3244\n",
      "Epoch 39 Iteration 500: Loss = 2.7440810203552246, Number of mined P N = 349 2987\n",
      "Epoch 39 Iteration 600: Loss = 2.59909987449646, Number of mined P N = 330 2426\n",
      "Epoch 39 Iteration 700: Loss = 2.7579965591430664, Number of mined P N = 337 2664\n",
      "Validation loss:  2.5818088722229002\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 40 Iteration 0: Loss = 2.376098155975342, Number of mined P N = 353 2183\n",
      "Epoch 40 Iteration 100: Loss = 2.5833358764648438, Number of mined P N = 335 2623\n",
      "Epoch 40 Iteration 200: Loss = 2.577059745788574, Number of mined P N = 341 2779\n",
      "Epoch 40 Iteration 300: Loss = 2.6415865421295166, Number of mined P N = 352 2592\n",
      "Epoch 40 Iteration 400: Loss = 2.4769794940948486, Number of mined P N = 364 2587\n",
      "Epoch 40 Iteration 500: Loss = 2.7310361862182617, Number of mined P N = 355 3029\n",
      "Epoch 40 Iteration 600: Loss = 2.6392557621002197, Number of mined P N = 346 2794\n",
      "Epoch 40 Iteration 700: Loss = 2.613825559616089, Number of mined P N = 340 2641\n",
      "Validation loss:  2.6026471567153933\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 41 Iteration 0: Loss = 2.8360300064086914, Number of mined P N = 342 3141\n",
      "Epoch 41 Iteration 100: Loss = 2.3583199977874756, Number of mined P N = 323 1805\n",
      "Epoch 41 Iteration 200: Loss = 2.6966521739959717, Number of mined P N = 328 2465\n",
      "Epoch 41 Iteration 300: Loss = 2.6178674697875977, Number of mined P N = 350 2524\n",
      "Epoch 41 Iteration 400: Loss = 2.639859676361084, Number of mined P N = 344 2489\n",
      "Epoch 41 Iteration 500: Loss = 2.4608426094055176, Number of mined P N = 343 2066\n",
      "Epoch 41 Iteration 600: Loss = 2.8393375873565674, Number of mined P N = 357 3232\n",
      "Epoch 41 Iteration 700: Loss = 2.4389872550964355, Number of mined P N = 342 2342\n",
      "Validation loss:  2.55107168674469\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 42 Iteration 0: Loss = 2.378425359725952, Number of mined P N = 329 2052\n",
      "Epoch 42 Iteration 100: Loss = 2.7299373149871826, Number of mined P N = 350 2913\n",
      "Epoch 42 Iteration 200: Loss = 2.5658793449401855, Number of mined P N = 327 2338\n",
      "Epoch 42 Iteration 300: Loss = 2.6717257499694824, Number of mined P N = 356 2789\n",
      "Epoch 42 Iteration 400: Loss = 2.504132032394409, Number of mined P N = 333 2460\n",
      "Epoch 42 Iteration 500: Loss = 2.580296516418457, Number of mined P N = 357 2455\n",
      "Epoch 42 Iteration 600: Loss = 2.5217435359954834, Number of mined P N = 336 2395\n",
      "Epoch 42 Iteration 700: Loss = 2.6659233570098877, Number of mined P N = 326 2700\n",
      "Validation loss:  2.5540395641326903\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 43 Iteration 0: Loss = 2.5350537300109863, Number of mined P N = 332 2589\n",
      "Epoch 43 Iteration 100: Loss = 2.611055850982666, Number of mined P N = 325 3163\n",
      "Epoch 43 Iteration 200: Loss = 2.5703046321868896, Number of mined P N = 342 2281\n",
      "Epoch 43 Iteration 300: Loss = 2.3286983966827393, Number of mined P N = 326 1921\n",
      "Epoch 43 Iteration 400: Loss = 2.946988105773926, Number of mined P N = 351 3784\n",
      "Epoch 43 Iteration 500: Loss = 2.9435179233551025, Number of mined P N = 347 3633\n",
      "Epoch 43 Iteration 600: Loss = 2.4765288829803467, Number of mined P N = 349 2122\n",
      "Epoch 43 Iteration 700: Loss = 2.7762722969055176, Number of mined P N = 341 3096\n",
      "Validation loss:  2.526586961746216\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 44 Iteration 0: Loss = 2.5043110847473145, Number of mined P N = 324 2203\n",
      "Epoch 44 Iteration 100: Loss = 2.721832513809204, Number of mined P N = 334 2849\n",
      "Epoch 44 Iteration 200: Loss = 2.3993401527404785, Number of mined P N = 344 2163\n",
      "Epoch 44 Iteration 300: Loss = 2.3008873462677, Number of mined P N = 328 1859\n",
      "Epoch 44 Iteration 400: Loss = 2.676511526107788, Number of mined P N = 351 2987\n",
      "Epoch 44 Iteration 500: Loss = 2.633326292037964, Number of mined P N = 341 2697\n",
      "Epoch 44 Iteration 600: Loss = 2.5389223098754883, Number of mined P N = 331 2305\n",
      "Epoch 44 Iteration 700: Loss = 2.4053823947906494, Number of mined P N = 339 2155\n",
      "Validation loss:  2.5720302486419677\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 45 Iteration 0: Loss = 2.5185842514038086, Number of mined P N = 346 2408\n",
      "Epoch 45 Iteration 100: Loss = 2.5579943656921387, Number of mined P N = 342 2411\n",
      "Epoch 45 Iteration 200: Loss = 2.63156795501709, Number of mined P N = 333 2546\n",
      "Epoch 45 Iteration 300: Loss = 2.5142788887023926, Number of mined P N = 347 2171\n",
      "Epoch 45 Iteration 400: Loss = 2.797098159790039, Number of mined P N = 352 3088\n",
      "Epoch 45 Iteration 500: Loss = 2.1288001537323, Number of mined P N = 325 1702\n",
      "Epoch 45 Iteration 600: Loss = 2.660792350769043, Number of mined P N = 336 2958\n",
      "Epoch 45 Iteration 700: Loss = 2.545746326446533, Number of mined P N = 342 2441\n",
      "Validation loss:  2.5503467321395874\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 46 Iteration 0: Loss = 2.7691736221313477, Number of mined P N = 362 3102\n",
      "Epoch 46 Iteration 100: Loss = 2.5006744861602783, Number of mined P N = 331 2299\n",
      "Epoch 46 Iteration 200: Loss = 2.2049999237060547, Number of mined P N = 304 1834\n",
      "Epoch 46 Iteration 300: Loss = 2.535815477371216, Number of mined P N = 340 2396\n",
      "Epoch 46 Iteration 400: Loss = 2.4745612144470215, Number of mined P N = 334 2180\n",
      "Epoch 46 Iteration 500: Loss = 2.524217367172241, Number of mined P N = 332 2578\n",
      "Epoch 46 Iteration 600: Loss = 2.660520076751709, Number of mined P N = 319 3104\n",
      "Epoch 46 Iteration 700: Loss = 2.063066244125366, Number of mined P N = 301 1381\n",
      "Validation loss:  2.5534288549423216\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 47 Iteration 0: Loss = 2.8206751346588135, Number of mined P N = 336 3247\n",
      "Epoch 47 Iteration 100: Loss = 2.7684032917022705, Number of mined P N = 352 3068\n",
      "Epoch 47 Iteration 200: Loss = 2.7246246337890625, Number of mined P N = 347 3077\n",
      "Epoch 47 Iteration 300: Loss = 2.5379528999328613, Number of mined P N = 344 2304\n",
      "Epoch 47 Iteration 400: Loss = 2.406149387359619, Number of mined P N = 354 2189\n",
      "Epoch 47 Iteration 500: Loss = 2.604119062423706, Number of mined P N = 337 2320\n",
      "Epoch 47 Iteration 600: Loss = 2.508009910583496, Number of mined P N = 324 2369\n",
      "Epoch 47 Iteration 700: Loss = 2.4375157356262207, Number of mined P N = 299 2239\n",
      "Validation loss:  2.5207693719863893\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 48 Iteration 0: Loss = 2.583872079849243, Number of mined P N = 351 2439\n",
      "Epoch 48 Iteration 100: Loss = 2.6113603115081787, Number of mined P N = 322 2890\n",
      "Epoch 48 Iteration 200: Loss = 2.2061972618103027, Number of mined P N = 314 1701\n",
      "Epoch 48 Iteration 300: Loss = 2.6720714569091797, Number of mined P N = 350 2808\n",
      "Epoch 48 Iteration 400: Loss = 2.466797113418579, Number of mined P N = 354 2265\n",
      "Epoch 48 Iteration 500: Loss = 2.505023956298828, Number of mined P N = 332 2287\n",
      "Epoch 48 Iteration 600: Loss = 2.5003788471221924, Number of mined P N = 340 2497\n",
      "Epoch 48 Iteration 700: Loss = 2.5855507850646973, Number of mined P N = 339 2453\n",
      "Validation loss:  2.56480327129364\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 49 Iteration 0: Loss = 2.752948045730591, Number of mined P N = 339 3044\n",
      "Epoch 49 Iteration 100: Loss = 2.2462592124938965, Number of mined P N = 316 1820\n",
      "Epoch 49 Iteration 200: Loss = 2.4005279541015625, Number of mined P N = 306 2224\n",
      "Epoch 49 Iteration 300: Loss = 2.6611850261688232, Number of mined P N = 344 2845\n",
      "Epoch 49 Iteration 400: Loss = 2.392132520675659, Number of mined P N = 350 2078\n",
      "Epoch 49 Iteration 500: Loss = 2.352799654006958, Number of mined P N = 323 1961\n",
      "Epoch 49 Iteration 600: Loss = 2.6574130058288574, Number of mined P N = 344 2846\n",
      "Epoch 49 Iteration 700: Loss = 2.7073452472686768, Number of mined P N = 332 2864\n",
      "Validation loss:  2.527793483734131\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 50 Iteration 0: Loss = 2.2652156352996826, Number of mined P N = 320 2017\n",
      "Epoch 50 Iteration 100: Loss = 2.3856635093688965, Number of mined P N = 340 2355\n",
      "Epoch 50 Iteration 200: Loss = 2.4771957397460938, Number of mined P N = 348 2452\n",
      "Epoch 50 Iteration 300: Loss = 2.5301783084869385, Number of mined P N = 332 2289\n",
      "Epoch 50 Iteration 400: Loss = 2.753826856613159, Number of mined P N = 360 2963\n",
      "Epoch 50 Iteration 500: Loss = 2.740514039993286, Number of mined P N = 329 3110\n",
      "Epoch 50 Iteration 600: Loss = 2.39650297164917, Number of mined P N = 320 1955\n",
      "Epoch 50 Iteration 700: Loss = 2.572497606277466, Number of mined P N = 345 2861\n",
      "Validation loss:  2.5385928916931153\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 51 Iteration 0: Loss = 2.5594987869262695, Number of mined P N = 327 2420\n",
      "Epoch 51 Iteration 100: Loss = 2.4729692935943604, Number of mined P N = 353 2261\n",
      "Epoch 51 Iteration 200: Loss = 2.7162024974823, Number of mined P N = 330 3076\n",
      "Epoch 51 Iteration 300: Loss = 2.0516459941864014, Number of mined P N = 294 1138\n",
      "Epoch 51 Iteration 400: Loss = 2.3403079509735107, Number of mined P N = 349 1850\n",
      "Epoch 51 Iteration 500: Loss = 2.4704766273498535, Number of mined P N = 343 2097\n",
      "Epoch 51 Iteration 600: Loss = 2.576953887939453, Number of mined P N = 328 2548\n",
      "Epoch 51 Iteration 700: Loss = 2.5987911224365234, Number of mined P N = 327 2399\n",
      "Validation loss:  2.511107816696167\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 52 Iteration 0: Loss = 2.6686856746673584, Number of mined P N = 345 2683\n",
      "Epoch 52 Iteration 100: Loss = 2.623798131942749, Number of mined P N = 352 2482\n",
      "Epoch 52 Iteration 200: Loss = 2.4530327320098877, Number of mined P N = 317 2443\n",
      "Epoch 52 Iteration 300: Loss = 2.5551908016204834, Number of mined P N = 309 2269\n",
      "Epoch 52 Iteration 400: Loss = 2.4121086597442627, Number of mined P N = 338 2019\n",
      "Epoch 52 Iteration 500: Loss = 2.671790361404419, Number of mined P N = 346 2523\n",
      "Epoch 52 Iteration 600: Loss = 2.5129036903381348, Number of mined P N = 344 2545\n",
      "Epoch 52 Iteration 700: Loss = 2.3709025382995605, Number of mined P N = 327 2313\n",
      "Validation loss:  2.5147657775878907\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 53 Iteration 0: Loss = 2.1864256858825684, Number of mined P N = 321 1934\n",
      "Epoch 53 Iteration 100: Loss = 2.6240432262420654, Number of mined P N = 360 2848\n",
      "Epoch 53 Iteration 200: Loss = 2.3790135383605957, Number of mined P N = 301 2271\n",
      "Epoch 53 Iteration 300: Loss = 2.6447103023529053, Number of mined P N = 314 2530\n",
      "Epoch 53 Iteration 400: Loss = 2.2918031215667725, Number of mined P N = 304 1850\n",
      "Epoch 53 Iteration 500: Loss = 2.4859578609466553, Number of mined P N = 337 2199\n",
      "Epoch 53 Iteration 600: Loss = 2.4456703662872314, Number of mined P N = 336 2088\n",
      "Epoch 53 Iteration 700: Loss = 2.588515043258667, Number of mined P N = 341 2542\n",
      "Validation loss:  2.5326179599761964\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 54 Iteration 0: Loss = 2.3818185329437256, Number of mined P N = 324 2194\n",
      "Epoch 54 Iteration 100: Loss = 2.6314356327056885, Number of mined P N = 340 2819\n",
      "Epoch 54 Iteration 200: Loss = 2.524500846862793, Number of mined P N = 328 2341\n",
      "Epoch 54 Iteration 300: Loss = 2.1845529079437256, Number of mined P N = 323 1742\n",
      "Epoch 54 Iteration 400: Loss = 2.4900641441345215, Number of mined P N = 347 2180\n",
      "Epoch 54 Iteration 500: Loss = 2.6091225147247314, Number of mined P N = 279 2469\n",
      "Epoch 54 Iteration 600: Loss = 2.352339029312134, Number of mined P N = 341 1973\n",
      "Epoch 54 Iteration 700: Loss = 2.709228992462158, Number of mined P N = 341 2916\n",
      "Validation loss:  2.51030903339386\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 55 Iteration 0: Loss = 2.616636037826538, Number of mined P N = 341 2695\n",
      "Epoch 55 Iteration 100: Loss = 2.2636985778808594, Number of mined P N = 312 1727\n",
      "Epoch 55 Iteration 200: Loss = 2.6005895137786865, Number of mined P N = 346 2618\n",
      "Epoch 55 Iteration 300: Loss = 2.5770232677459717, Number of mined P N = 339 2613\n",
      "Epoch 55 Iteration 400: Loss = 2.5121512413024902, Number of mined P N = 326 2375\n",
      "Epoch 55 Iteration 500: Loss = 2.356384754180908, Number of mined P N = 338 1826\n",
      "Epoch 55 Iteration 600: Loss = 2.31850004196167, Number of mined P N = 309 1823\n",
      "Epoch 55 Iteration 700: Loss = 2.3737969398498535, Number of mined P N = 351 2088\n",
      "Validation loss:  2.478873248100281\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 56 Iteration 0: Loss = 2.451681613922119, Number of mined P N = 318 2520\n",
      "Epoch 56 Iteration 100: Loss = 2.650819778442383, Number of mined P N = 350 2899\n",
      "Epoch 56 Iteration 200: Loss = 2.5598807334899902, Number of mined P N = 343 2542\n",
      "Epoch 56 Iteration 300: Loss = 2.2879481315612793, Number of mined P N = 343 1842\n",
      "Epoch 56 Iteration 400: Loss = 2.6311357021331787, Number of mined P N = 337 2707\n",
      "Epoch 56 Iteration 500: Loss = 2.6332509517669678, Number of mined P N = 339 2521\n",
      "Epoch 56 Iteration 600: Loss = 2.3048095703125, Number of mined P N = 323 1845\n",
      "Epoch 56 Iteration 700: Loss = 2.444429874420166, Number of mined P N = 317 2241\n",
      "Validation loss:  2.5362286376953125\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 57 Iteration 0: Loss = 2.790682077407837, Number of mined P N = 355 3200\n",
      "Epoch 57 Iteration 100: Loss = 2.525388240814209, Number of mined P N = 342 2522\n",
      "Epoch 57 Iteration 200: Loss = 2.5997564792633057, Number of mined P N = 337 2784\n",
      "Epoch 57 Iteration 300: Loss = 2.54475736618042, Number of mined P N = 323 2638\n",
      "Epoch 57 Iteration 400: Loss = 2.455488681793213, Number of mined P N = 317 2494\n",
      "Epoch 57 Iteration 500: Loss = 2.4991884231567383, Number of mined P N = 327 2443\n",
      "Epoch 57 Iteration 600: Loss = 2.3353469371795654, Number of mined P N = 315 1701\n",
      "Epoch 57 Iteration 700: Loss = 2.516611337661743, Number of mined P N = 342 2143\n",
      "Validation loss:  2.496663007736206\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 58 Iteration 0: Loss = 2.393876791000366, Number of mined P N = 326 2476\n",
      "Epoch 58 Iteration 100: Loss = 2.574063777923584, Number of mined P N = 318 2643\n",
      "Epoch 58 Iteration 200: Loss = 2.521125078201294, Number of mined P N = 338 2345\n",
      "Epoch 58 Iteration 300: Loss = 2.579042434692383, Number of mined P N = 337 2450\n",
      "Epoch 58 Iteration 400: Loss = 2.491978168487549, Number of mined P N = 334 2259\n",
      "Epoch 58 Iteration 500: Loss = 2.313406467437744, Number of mined P N = 338 2113\n",
      "Epoch 58 Iteration 600: Loss = 2.3338916301727295, Number of mined P N = 321 1928\n",
      "Epoch 58 Iteration 700: Loss = 2.452014446258545, Number of mined P N = 354 2010\n",
      "Validation loss:  2.4926840353012083\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 59 Iteration 0: Loss = 2.4656593799591064, Number of mined P N = 326 2505\n",
      "Epoch 59 Iteration 100: Loss = 2.494074583053589, Number of mined P N = 319 2503\n",
      "Epoch 59 Iteration 200: Loss = 2.366818904876709, Number of mined P N = 337 2066\n",
      "Epoch 59 Iteration 300: Loss = 2.570927858352661, Number of mined P N = 343 2795\n",
      "Epoch 59 Iteration 400: Loss = 2.4770798683166504, Number of mined P N = 331 2150\n",
      "Epoch 59 Iteration 500: Loss = 2.454798698425293, Number of mined P N = 341 2267\n",
      "Epoch 59 Iteration 600: Loss = 2.6919891834259033, Number of mined P N = 352 2779\n",
      "Epoch 59 Iteration 700: Loss = 2.6975982189178467, Number of mined P N = 330 2581\n",
      "Validation loss:  2.4949381494522096\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 60 Iteration 0: Loss = 2.443528413772583, Number of mined P N = 334 2082\n",
      "Epoch 60 Iteration 100: Loss = 2.4864890575408936, Number of mined P N = 336 2341\n",
      "Epoch 60 Iteration 200: Loss = 2.626310110092163, Number of mined P N = 333 2547\n",
      "Epoch 60 Iteration 300: Loss = 2.6230523586273193, Number of mined P N = 350 2614\n",
      "Epoch 60 Iteration 400: Loss = 2.438105583190918, Number of mined P N = 337 2205\n",
      "Epoch 60 Iteration 500: Loss = 2.475900650024414, Number of mined P N = 306 2227\n",
      "Epoch 60 Iteration 600: Loss = 2.3903419971466064, Number of mined P N = 318 2117\n",
      "Epoch 60 Iteration 700: Loss = 2.3026375770568848, Number of mined P N = 333 1857\n",
      "Validation loss:  2.428878583908081\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 61 Iteration 0: Loss = 2.6469130516052246, Number of mined P N = 316 2965\n",
      "Epoch 61 Iteration 100: Loss = 2.5121071338653564, Number of mined P N = 352 2216\n",
      "Epoch 61 Iteration 200: Loss = 2.3010191917419434, Number of mined P N = 300 1765\n",
      "Epoch 61 Iteration 300: Loss = 2.5362491607666016, Number of mined P N = 329 2395\n",
      "Epoch 61 Iteration 400: Loss = 2.4726314544677734, Number of mined P N = 329 2276\n",
      "Epoch 61 Iteration 500: Loss = 2.7018697261810303, Number of mined P N = 352 2940\n",
      "Epoch 61 Iteration 600: Loss = 2.382262706756592, Number of mined P N = 330 2175\n",
      "Epoch 61 Iteration 700: Loss = 2.666715145111084, Number of mined P N = 356 2771\n",
      "Validation loss:  2.4861594343185427\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 62 Iteration 0: Loss = 2.4302902221679688, Number of mined P N = 317 2044\n",
      "Epoch 62 Iteration 100: Loss = 2.5301012992858887, Number of mined P N = 344 2303\n",
      "Epoch 62 Iteration 200: Loss = 2.4689669609069824, Number of mined P N = 336 2443\n",
      "Epoch 62 Iteration 300: Loss = 2.4512062072753906, Number of mined P N = 346 2337\n",
      "Epoch 62 Iteration 400: Loss = 2.5370802879333496, Number of mined P N = 337 2354\n",
      "Epoch 62 Iteration 500: Loss = 2.5706067085266113, Number of mined P N = 330 2624\n",
      "Epoch 62 Iteration 600: Loss = 2.3343560695648193, Number of mined P N = 331 2098\n",
      "Epoch 62 Iteration 700: Loss = 2.764737367630005, Number of mined P N = 328 2901\n",
      "Validation loss:  2.442695870399475\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 63 Iteration 0: Loss = 2.451080560684204, Number of mined P N = 330 2190\n",
      "Epoch 63 Iteration 100: Loss = 2.5613749027252197, Number of mined P N = 328 2413\n",
      "Epoch 63 Iteration 200: Loss = 2.349039316177368, Number of mined P N = 337 2332\n",
      "Epoch 63 Iteration 300: Loss = 2.609544515609741, Number of mined P N = 349 2603\n",
      "Epoch 63 Iteration 400: Loss = 2.833087205886841, Number of mined P N = 354 3421\n",
      "Epoch 63 Iteration 500: Loss = 2.1429054737091064, Number of mined P N = 304 1599\n",
      "Epoch 63 Iteration 600: Loss = 2.4108917713165283, Number of mined P N = 332 2000\n",
      "Epoch 63 Iteration 700: Loss = 2.310275077819824, Number of mined P N = 314 1951\n",
      "Validation loss:  2.4572867155075073\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 64 Iteration 0: Loss = 2.2802867889404297, Number of mined P N = 309 1828\n",
      "Epoch 64 Iteration 100: Loss = 2.4666106700897217, Number of mined P N = 329 2280\n",
      "Epoch 64 Iteration 200: Loss = 2.71036696434021, Number of mined P N = 363 2625\n",
      "Epoch 64 Iteration 300: Loss = 2.355692148208618, Number of mined P N = 304 1995\n",
      "Epoch 64 Iteration 400: Loss = 2.5183000564575195, Number of mined P N = 348 2441\n",
      "Epoch 64 Iteration 500: Loss = 2.2681968212127686, Number of mined P N = 321 2071\n",
      "Epoch 64 Iteration 600: Loss = 2.6166868209838867, Number of mined P N = 354 2550\n",
      "Epoch 64 Iteration 700: Loss = 2.687338352203369, Number of mined P N = 352 2691\n",
      "Validation loss:  2.476743769645691\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 65 Iteration 0: Loss = 2.5316715240478516, Number of mined P N = 344 2739\n",
      "Epoch 65 Iteration 100: Loss = 2.434934616088867, Number of mined P N = 354 2386\n",
      "Epoch 65 Iteration 200: Loss = 2.4160478115081787, Number of mined P N = 311 2007\n",
      "Epoch 65 Iteration 300: Loss = 2.400482654571533, Number of mined P N = 306 1820\n",
      "Epoch 65 Iteration 400: Loss = 2.3436717987060547, Number of mined P N = 325 1922\n",
      "Epoch 65 Iteration 500: Loss = 2.466670036315918, Number of mined P N = 320 2515\n",
      "Epoch 65 Iteration 600: Loss = 2.5817148685455322, Number of mined P N = 342 2396\n",
      "Epoch 65 Iteration 700: Loss = 2.6627278327941895, Number of mined P N = 361 2473\n",
      "Validation loss:  2.457905158996582\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 66 Iteration 0: Loss = 2.4356439113616943, Number of mined P N = 311 2193\n",
      "Epoch 66 Iteration 100: Loss = 2.4718635082244873, Number of mined P N = 318 2576\n",
      "Epoch 66 Iteration 200: Loss = 2.5182065963745117, Number of mined P N = 348 2096\n",
      "Epoch 66 Iteration 300: Loss = 2.4914350509643555, Number of mined P N = 314 2259\n",
      "Epoch 66 Iteration 400: Loss = 2.2345733642578125, Number of mined P N = 312 1982\n",
      "Epoch 66 Iteration 500: Loss = 2.529982805252075, Number of mined P N = 325 2646\n",
      "Epoch 66 Iteration 600: Loss = 2.567406415939331, Number of mined P N = 328 2610\n",
      "Epoch 66 Iteration 700: Loss = 2.3452706336975098, Number of mined P N = 319 2108\n",
      "Validation loss:  2.4451660823822023\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 67 Iteration 0: Loss = 2.3155205249786377, Number of mined P N = 340 2420\n",
      "Epoch 67 Iteration 100: Loss = 2.541170597076416, Number of mined P N = 355 2297\n",
      "Epoch 67 Iteration 200: Loss = 2.731243848800659, Number of mined P N = 341 3005\n",
      "Epoch 67 Iteration 300: Loss = 2.555518388748169, Number of mined P N = 338 2793\n",
      "Epoch 67 Iteration 400: Loss = 2.5971388816833496, Number of mined P N = 329 2481\n",
      "Epoch 67 Iteration 500: Loss = 2.6282525062561035, Number of mined P N = 360 2543\n",
      "Epoch 67 Iteration 600: Loss = 2.6423861980438232, Number of mined P N = 336 2544\n",
      "Epoch 67 Iteration 700: Loss = 2.399038553237915, Number of mined P N = 325 2037\n",
      "Validation loss:  2.454414892196655\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 68 Iteration 0: Loss = 2.383478879928589, Number of mined P N = 319 1821\n",
      "Epoch 68 Iteration 100: Loss = 2.553687572479248, Number of mined P N = 345 2369\n",
      "Epoch 68 Iteration 200: Loss = 2.500948190689087, Number of mined P N = 331 2268\n",
      "Epoch 68 Iteration 300: Loss = 2.5697779655456543, Number of mined P N = 351 2578\n",
      "Epoch 68 Iteration 400: Loss = 2.605665922164917, Number of mined P N = 334 2590\n",
      "Epoch 68 Iteration 500: Loss = 2.4468014240264893, Number of mined P N = 345 2271\n",
      "Epoch 68 Iteration 600: Loss = 2.371230363845825, Number of mined P N = 319 2061\n",
      "Epoch 68 Iteration 700: Loss = 2.3085439205169678, Number of mined P N = 322 1788\n",
      "Validation loss:  2.391813941001892\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 69 Iteration 0: Loss = 2.3676698207855225, Number of mined P N = 334 2258\n",
      "Epoch 69 Iteration 100: Loss = 2.5198512077331543, Number of mined P N = 347 2817\n",
      "Epoch 69 Iteration 200: Loss = 2.3508055210113525, Number of mined P N = 332 2173\n",
      "Epoch 69 Iteration 300: Loss = 2.5964508056640625, Number of mined P N = 347 2679\n",
      "Epoch 69 Iteration 400: Loss = 2.5536651611328125, Number of mined P N = 344 2687\n",
      "Epoch 69 Iteration 500: Loss = 2.1696062088012695, Number of mined P N = 301 1695\n",
      "Epoch 69 Iteration 600: Loss = 2.3293819427490234, Number of mined P N = 340 1920\n",
      "Epoch 69 Iteration 700: Loss = 2.2578256130218506, Number of mined P N = 314 2050\n",
      "Validation loss:  2.4453938388824463\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 70 Iteration 0: Loss = 2.6298534870147705, Number of mined P N = 351 2900\n",
      "Epoch 70 Iteration 100: Loss = 2.6009042263031006, Number of mined P N = 317 2310\n",
      "Epoch 70 Iteration 200: Loss = 2.513765335083008, Number of mined P N = 331 2425\n",
      "Epoch 70 Iteration 300: Loss = 2.424081325531006, Number of mined P N = 325 2263\n",
      "Epoch 70 Iteration 400: Loss = 2.3275346755981445, Number of mined P N = 337 1999\n",
      "Epoch 70 Iteration 500: Loss = 2.1236190795898438, Number of mined P N = 303 1567\n",
      "Epoch 70 Iteration 600: Loss = 2.5413434505462646, Number of mined P N = 317 2722\n",
      "Epoch 70 Iteration 700: Loss = 2.393500804901123, Number of mined P N = 326 1905\n",
      "Validation loss:  2.4408776569366455\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 71 Iteration 0: Loss = 2.3779821395874023, Number of mined P N = 343 2092\n",
      "Epoch 71 Iteration 100: Loss = 2.3842296600341797, Number of mined P N = 338 2099\n",
      "Epoch 71 Iteration 200: Loss = 2.4282352924346924, Number of mined P N = 354 2090\n",
      "Epoch 71 Iteration 300: Loss = 2.569493532180786, Number of mined P N = 345 2620\n",
      "Epoch 71 Iteration 400: Loss = 2.370511054992676, Number of mined P N = 309 1964\n",
      "Epoch 71 Iteration 500: Loss = 2.5481276512145996, Number of mined P N = 349 2243\n",
      "Epoch 71 Iteration 600: Loss = 2.4389617443084717, Number of mined P N = 333 2387\n",
      "Epoch 71 Iteration 700: Loss = 2.6171460151672363, Number of mined P N = 338 2542\n",
      "Validation loss:  2.431991171836853\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 72 Iteration 0: Loss = 2.6807608604431152, Number of mined P N = 327 3163\n",
      "Epoch 72 Iteration 100: Loss = 2.4710988998413086, Number of mined P N = 333 2107\n",
      "Epoch 72 Iteration 200: Loss = 2.168475389480591, Number of mined P N = 329 1666\n",
      "Epoch 72 Iteration 300: Loss = 2.619117259979248, Number of mined P N = 316 2549\n",
      "Epoch 72 Iteration 400: Loss = 2.2525198459625244, Number of mined P N = 277 1460\n",
      "Epoch 72 Iteration 500: Loss = 2.4804224967956543, Number of mined P N = 316 2232\n",
      "Epoch 72 Iteration 600: Loss = 2.7078487873077393, Number of mined P N = 345 2944\n",
      "Epoch 72 Iteration 700: Loss = 2.2942023277282715, Number of mined P N = 337 1748\n",
      "Validation loss:  2.4096363162994385\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 73 Iteration 0: Loss = 2.2922589778900146, Number of mined P N = 315 1877\n",
      "Epoch 73 Iteration 100: Loss = 2.3068387508392334, Number of mined P N = 313 1900\n",
      "Epoch 73 Iteration 200: Loss = 2.2583301067352295, Number of mined P N = 329 1659\n",
      "Epoch 73 Iteration 300: Loss = 2.5981335639953613, Number of mined P N = 335 2677\n",
      "Epoch 73 Iteration 400: Loss = 2.568962574005127, Number of mined P N = 351 2854\n",
      "Epoch 73 Iteration 500: Loss = 2.3740100860595703, Number of mined P N = 327 2023\n",
      "Epoch 73 Iteration 600: Loss = 2.6404178142547607, Number of mined P N = 307 2331\n",
      "Epoch 73 Iteration 700: Loss = 2.3708364963531494, Number of mined P N = 302 2163\n",
      "Validation loss:  2.3609142875671387\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 74 Iteration 0: Loss = 2.3644447326660156, Number of mined P N = 343 2105\n",
      "Epoch 74 Iteration 100: Loss = 2.468047618865967, Number of mined P N = 313 2141\n",
      "Epoch 74 Iteration 200: Loss = 2.4087071418762207, Number of mined P N = 310 2086\n",
      "Epoch 74 Iteration 300: Loss = 2.3712544441223145, Number of mined P N = 337 1874\n",
      "Epoch 74 Iteration 400: Loss = 2.3164753913879395, Number of mined P N = 294 1935\n",
      "Epoch 74 Iteration 500: Loss = 2.311767578125, Number of mined P N = 328 2067\n",
      "Epoch 74 Iteration 600: Loss = 2.3374252319335938, Number of mined P N = 335 1942\n",
      "Epoch 74 Iteration 700: Loss = 2.4429588317871094, Number of mined P N = 309 2195\n",
      "Validation loss:  2.4261201763153077\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 75 Iteration 0: Loss = 2.4073667526245117, Number of mined P N = 322 2165\n",
      "Epoch 75 Iteration 100: Loss = 2.4106462001800537, Number of mined P N = 328 2160\n",
      "Epoch 75 Iteration 200: Loss = 2.493727207183838, Number of mined P N = 329 2351\n",
      "Epoch 75 Iteration 300: Loss = 2.540081739425659, Number of mined P N = 331 2405\n",
      "Epoch 75 Iteration 400: Loss = 2.413971424102783, Number of mined P N = 333 1997\n",
      "Epoch 75 Iteration 500: Loss = 2.4801673889160156, Number of mined P N = 331 2425\n",
      "Epoch 75 Iteration 600: Loss = 2.2945103645324707, Number of mined P N = 292 2092\n",
      "Epoch 75 Iteration 700: Loss = 2.5979042053222656, Number of mined P N = 322 2623\n",
      "Validation loss:  2.4191968774795534\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 76 Iteration 0: Loss = 2.475146532058716, Number of mined P N = 319 2222\n",
      "Epoch 76 Iteration 100: Loss = 2.4656379222869873, Number of mined P N = 334 2095\n",
      "Epoch 76 Iteration 200: Loss = 2.5658891201019287, Number of mined P N = 304 2361\n",
      "Epoch 76 Iteration 300: Loss = 2.3626039028167725, Number of mined P N = 327 1980\n",
      "Epoch 76 Iteration 400: Loss = 2.1415493488311768, Number of mined P N = 294 1568\n",
      "Epoch 76 Iteration 500: Loss = 2.0361990928649902, Number of mined P N = 330 1414\n",
      "Epoch 76 Iteration 600: Loss = 2.2904670238494873, Number of mined P N = 288 1699\n",
      "Epoch 76 Iteration 700: Loss = 2.2438249588012695, Number of mined P N = 308 1899\n",
      "Validation loss:  2.441820044517517\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 77 Iteration 0: Loss = 2.495412826538086, Number of mined P N = 348 2400\n",
      "Epoch 77 Iteration 100: Loss = 2.5830910205841064, Number of mined P N = 320 2587\n",
      "Epoch 77 Iteration 200: Loss = 2.20973801612854, Number of mined P N = 307 1779\n",
      "Epoch 77 Iteration 300: Loss = 2.5671093463897705, Number of mined P N = 349 2308\n",
      "Epoch 77 Iteration 400: Loss = 2.3935604095458984, Number of mined P N = 328 2204\n",
      "Epoch 77 Iteration 500: Loss = 2.452507495880127, Number of mined P N = 334 1941\n",
      "Epoch 77 Iteration 600: Loss = 2.405097723007202, Number of mined P N = 347 2129\n",
      "Epoch 77 Iteration 700: Loss = 2.474337339401245, Number of mined P N = 328 2365\n",
      "Validation loss:  2.4100653314590454\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 78 Iteration 0: Loss = 2.1947031021118164, Number of mined P N = 285 1498\n",
      "Epoch 78 Iteration 100: Loss = 2.229884386062622, Number of mined P N = 310 1878\n",
      "Epoch 78 Iteration 200: Loss = 2.2557249069213867, Number of mined P N = 301 1654\n",
      "Epoch 78 Iteration 300: Loss = 2.3521578311920166, Number of mined P N = 305 2085\n",
      "Epoch 78 Iteration 400: Loss = 2.5575668811798096, Number of mined P N = 326 2437\n",
      "Epoch 78 Iteration 500: Loss = 2.4109673500061035, Number of mined P N = 319 2099\n",
      "Epoch 78 Iteration 600: Loss = 2.806669235229492, Number of mined P N = 358 3085\n",
      "Epoch 78 Iteration 700: Loss = 2.5893993377685547, Number of mined P N = 312 2174\n",
      "Validation loss:  2.410429444313049\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 79 Iteration 0: Loss = 2.3522913455963135, Number of mined P N = 338 1886\n",
      "Epoch 79 Iteration 100: Loss = 2.2691574096679688, Number of mined P N = 327 1652\n",
      "Epoch 79 Iteration 200: Loss = 2.383296012878418, Number of mined P N = 323 1998\n",
      "Epoch 79 Iteration 300: Loss = 2.1898317337036133, Number of mined P N = 299 1743\n",
      "Epoch 79 Iteration 400: Loss = 2.4615941047668457, Number of mined P N = 332 2047\n",
      "Epoch 79 Iteration 500: Loss = 2.1667280197143555, Number of mined P N = 317 1516\n",
      "Epoch 79 Iteration 600: Loss = 2.324904441833496, Number of mined P N = 319 1978\n",
      "Epoch 79 Iteration 700: Loss = 2.3246495723724365, Number of mined P N = 324 1693\n",
      "Validation loss:  2.383052945137024\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 80 Iteration 0: Loss = 2.332584857940674, Number of mined P N = 341 2020\n",
      "Epoch 80 Iteration 100: Loss = 2.0366785526275635, Number of mined P N = 295 1286\n",
      "Epoch 80 Iteration 200: Loss = 2.4021966457366943, Number of mined P N = 327 2100\n",
      "Epoch 80 Iteration 300: Loss = 2.296621322631836, Number of mined P N = 294 1707\n",
      "Epoch 80 Iteration 400: Loss = 2.1527817249298096, Number of mined P N = 286 1496\n",
      "Epoch 80 Iteration 500: Loss = 2.574054002761841, Number of mined P N = 322 2259\n",
      "Epoch 80 Iteration 600: Loss = 2.0354886054992676, Number of mined P N = 281 1564\n",
      "Epoch 80 Iteration 700: Loss = 2.341543674468994, Number of mined P N = 300 1977\n",
      "Validation loss:  2.431674644947052\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 81 Iteration 0: Loss = 2.68646240234375, Number of mined P N = 330 2653\n",
      "Epoch 81 Iteration 100: Loss = 2.2843613624572754, Number of mined P N = 272 1750\n",
      "Epoch 81 Iteration 200: Loss = 2.4544944763183594, Number of mined P N = 306 2418\n",
      "Epoch 81 Iteration 300: Loss = 2.5843522548675537, Number of mined P N = 321 2513\n",
      "Epoch 81 Iteration 400: Loss = 2.3075199127197266, Number of mined P N = 314 1805\n",
      "Epoch 81 Iteration 500: Loss = 2.5750205516815186, Number of mined P N = 349 2593\n",
      "Epoch 81 Iteration 600: Loss = 2.4153947830200195, Number of mined P N = 340 1931\n",
      "Epoch 81 Iteration 700: Loss = 2.142986536026001, Number of mined P N = 296 1704\n",
      "Validation loss:  2.3785083961486815\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 82 Iteration 0: Loss = 2.325467586517334, Number of mined P N = 289 1810\n",
      "Epoch 82 Iteration 100: Loss = 2.26570200920105, Number of mined P N = 318 1879\n",
      "Epoch 82 Iteration 200: Loss = 2.40226149559021, Number of mined P N = 331 1969\n",
      "Epoch 82 Iteration 300: Loss = 2.4099061489105225, Number of mined P N = 304 2195\n",
      "Epoch 82 Iteration 400: Loss = 2.357363700866699, Number of mined P N = 306 1873\n",
      "Epoch 82 Iteration 500: Loss = 2.4819657802581787, Number of mined P N = 335 2239\n",
      "Epoch 82 Iteration 600: Loss = 2.1646177768707275, Number of mined P N = 334 1590\n",
      "Epoch 82 Iteration 700: Loss = 2.607149362564087, Number of mined P N = 335 2716\n",
      "Validation loss:  2.4014814043045045\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 83 Iteration 0: Loss = 2.2594258785247803, Number of mined P N = 317 1703\n",
      "Epoch 83 Iteration 100: Loss = 2.3119382858276367, Number of mined P N = 302 1628\n",
      "Epoch 83 Iteration 200: Loss = 2.375877857208252, Number of mined P N = 327 2119\n",
      "Epoch 83 Iteration 300: Loss = 2.6393697261810303, Number of mined P N = 320 2495\n",
      "Epoch 83 Iteration 400: Loss = 2.422100305557251, Number of mined P N = 303 2165\n",
      "Epoch 83 Iteration 500: Loss = 2.3291428089141846, Number of mined P N = 319 1676\n",
      "Epoch 83 Iteration 600: Loss = 2.6176905632019043, Number of mined P N = 351 2608\n",
      "Epoch 83 Iteration 700: Loss = 2.3409841060638428, Number of mined P N = 304 2128\n",
      "Validation loss:  2.3925367403030395\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 84 Iteration 0: Loss = 2.4332950115203857, Number of mined P N = 336 2147\n",
      "Epoch 84 Iteration 100: Loss = 2.3410122394561768, Number of mined P N = 321 2182\n",
      "Epoch 84 Iteration 200: Loss = 2.3606700897216797, Number of mined P N = 325 1917\n",
      "Epoch 84 Iteration 300: Loss = 2.389336109161377, Number of mined P N = 303 2013\n",
      "Epoch 84 Iteration 400: Loss = 2.4090447425842285, Number of mined P N = 317 2178\n",
      "Epoch 84 Iteration 500: Loss = 2.238518476486206, Number of mined P N = 299 1643\n",
      "Epoch 84 Iteration 600: Loss = 2.1822009086608887, Number of mined P N = 314 1748\n",
      "Epoch 84 Iteration 700: Loss = 2.2843966484069824, Number of mined P N = 311 1821\n",
      "Validation loss:  2.4336139822006224\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 85 Iteration 0: Loss = 2.503098249435425, Number of mined P N = 339 2293\n",
      "Epoch 85 Iteration 100: Loss = 2.465444803237915, Number of mined P N = 323 2193\n",
      "Epoch 85 Iteration 200: Loss = 2.2533252239227295, Number of mined P N = 330 1755\n",
      "Epoch 85 Iteration 300: Loss = 2.491826057434082, Number of mined P N = 312 2195\n",
      "Epoch 85 Iteration 400: Loss = 2.297116994857788, Number of mined P N = 319 1946\n",
      "Epoch 85 Iteration 500: Loss = 2.4135854244232178, Number of mined P N = 318 1966\n",
      "Epoch 85 Iteration 600: Loss = 2.2635650634765625, Number of mined P N = 292 1819\n",
      "Epoch 85 Iteration 700: Loss = 2.4841108322143555, Number of mined P N = 319 2392\n",
      "Validation loss:  2.3799827241897584\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 86 Iteration 0: Loss = 2.2906126976013184, Number of mined P N = 316 1867\n",
      "Epoch 86 Iteration 100: Loss = 2.660569190979004, Number of mined P N = 318 2580\n",
      "Epoch 86 Iteration 200: Loss = 2.2281274795532227, Number of mined P N = 314 1682\n",
      "Epoch 86 Iteration 300: Loss = 2.3592491149902344, Number of mined P N = 288 1947\n",
      "Epoch 86 Iteration 400: Loss = 2.258024215698242, Number of mined P N = 330 1851\n",
      "Epoch 86 Iteration 500: Loss = 2.240281820297241, Number of mined P N = 289 1528\n",
      "Epoch 86 Iteration 600: Loss = 2.530561685562134, Number of mined P N = 344 2512\n",
      "Epoch 86 Iteration 700: Loss = 2.4528393745422363, Number of mined P N = 292 2113\n",
      "Validation loss:  2.374843621253967\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 87 Iteration 0: Loss = 2.3746089935302734, Number of mined P N = 303 2261\n",
      "Epoch 87 Iteration 100: Loss = 2.4574227333068848, Number of mined P N = 327 2308\n",
      "Epoch 87 Iteration 200: Loss = 2.352391481399536, Number of mined P N = 305 1931\n",
      "Epoch 87 Iteration 300: Loss = 2.2960147857666016, Number of mined P N = 270 1845\n",
      "Epoch 87 Iteration 400: Loss = 2.343411922454834, Number of mined P N = 300 1754\n",
      "Epoch 87 Iteration 500: Loss = 2.2202725410461426, Number of mined P N = 311 1664\n",
      "Epoch 87 Iteration 600: Loss = 2.277479887008667, Number of mined P N = 316 1755\n",
      "Epoch 87 Iteration 700: Loss = 2.5955324172973633, Number of mined P N = 328 2446\n",
      "Validation loss:  2.408710117340088\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 88 Iteration 0: Loss = 2.3128530979156494, Number of mined P N = 312 2258\n",
      "Epoch 88 Iteration 100: Loss = 2.181130886077881, Number of mined P N = 313 1628\n",
      "Epoch 88 Iteration 200: Loss = 2.0218091011047363, Number of mined P N = 300 1159\n",
      "Epoch 88 Iteration 300: Loss = 2.4518370628356934, Number of mined P N = 361 2083\n",
      "Epoch 88 Iteration 400: Loss = 2.1748433113098145, Number of mined P N = 309 1819\n",
      "Epoch 88 Iteration 500: Loss = 2.426642894744873, Number of mined P N = 310 2069\n",
      "Epoch 88 Iteration 600: Loss = 2.33406138420105, Number of mined P N = 313 2096\n",
      "Epoch 88 Iteration 700: Loss = 2.268460750579834, Number of mined P N = 319 1698\n",
      "Validation loss:  2.3857029771804807\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 89 Iteration 0: Loss = 2.255093574523926, Number of mined P N = 307 2004\n",
      "Epoch 89 Iteration 100: Loss = 2.4087934494018555, Number of mined P N = 307 1989\n",
      "Epoch 89 Iteration 200: Loss = 2.354736328125, Number of mined P N = 332 1966\n",
      "Epoch 89 Iteration 300: Loss = 2.286968946456909, Number of mined P N = 314 1643\n",
      "Epoch 89 Iteration 400: Loss = 2.160895586013794, Number of mined P N = 291 1532\n",
      "Epoch 89 Iteration 500: Loss = 2.28083872795105, Number of mined P N = 328 1721\n",
      "Epoch 89 Iteration 600: Loss = 2.2361161708831787, Number of mined P N = 323 1698\n",
      "Epoch 89 Iteration 700: Loss = 2.3099892139434814, Number of mined P N = 318 1951\n",
      "Validation loss:  2.399188618659973\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 90 Iteration 0: Loss = 2.388427257537842, Number of mined P N = 338 2075\n",
      "Epoch 90 Iteration 100: Loss = 2.7037694454193115, Number of mined P N = 330 2840\n",
      "Epoch 90 Iteration 200: Loss = 2.4088048934936523, Number of mined P N = 322 1922\n",
      "Epoch 90 Iteration 300: Loss = 2.6343581676483154, Number of mined P N = 339 2660\n",
      "Epoch 90 Iteration 400: Loss = 2.334602117538452, Number of mined P N = 320 1978\n",
      "Epoch 90 Iteration 500: Loss = 2.467355966567993, Number of mined P N = 330 2190\n",
      "Epoch 90 Iteration 600: Loss = 2.5578420162200928, Number of mined P N = 306 2639\n",
      "Epoch 90 Iteration 700: Loss = 2.63153338432312, Number of mined P N = 329 2550\n",
      "Validation loss:  2.390244846343994\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 91 Iteration 0: Loss = 2.4575884342193604, Number of mined P N = 311 2558\n",
      "Epoch 91 Iteration 100: Loss = 2.1155571937561035, Number of mined P N = 305 1648\n",
      "Epoch 91 Iteration 200: Loss = 2.3611576557159424, Number of mined P N = 290 2075\n",
      "Epoch 91 Iteration 300: Loss = 2.26665997505188, Number of mined P N = 300 1660\n",
      "Epoch 91 Iteration 400: Loss = 2.212843179702759, Number of mined P N = 307 1731\n",
      "Epoch 91 Iteration 500: Loss = 2.348081350326538, Number of mined P N = 340 2021\n",
      "Epoch 91 Iteration 600: Loss = 2.3315913677215576, Number of mined P N = 272 2006\n",
      "Epoch 91 Iteration 700: Loss = 2.423703908920288, Number of mined P N = 311 2007\n",
      "Validation loss:  2.3285950875282286\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 92 Iteration 0: Loss = 2.4106974601745605, Number of mined P N = 302 2059\n",
      "Epoch 92 Iteration 100: Loss = 2.5408430099487305, Number of mined P N = 325 2511\n",
      "Epoch 92 Iteration 200: Loss = 2.1369972229003906, Number of mined P N = 306 1580\n",
      "Epoch 92 Iteration 300: Loss = 2.4125165939331055, Number of mined P N = 330 2131\n",
      "Epoch 92 Iteration 400: Loss = 2.28558611869812, Number of mined P N = 313 1946\n",
      "Epoch 92 Iteration 500: Loss = 2.2956762313842773, Number of mined P N = 327 1788\n",
      "Epoch 92 Iteration 600: Loss = 2.3337337970733643, Number of mined P N = 282 2134\n",
      "Epoch 92 Iteration 700: Loss = 2.3490335941314697, Number of mined P N = 352 1919\n",
      "Validation loss:  2.313348817825317\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 93 Iteration 0: Loss = 2.463254690170288, Number of mined P N = 325 2208\n",
      "Epoch 93 Iteration 100: Loss = 2.782588243484497, Number of mined P N = 332 2746\n",
      "Epoch 93 Iteration 200: Loss = 2.4518091678619385, Number of mined P N = 339 2219\n",
      "Epoch 93 Iteration 300: Loss = 2.0962204933166504, Number of mined P N = 291 1397\n",
      "Epoch 93 Iteration 400: Loss = 2.2214088439941406, Number of mined P N = 316 1761\n",
      "Epoch 93 Iteration 500: Loss = 2.632007598876953, Number of mined P N = 354 2854\n",
      "Epoch 93 Iteration 600: Loss = 2.300957441329956, Number of mined P N = 325 1942\n",
      "Epoch 93 Iteration 700: Loss = 2.3010447025299072, Number of mined P N = 322 1983\n",
      "Validation loss:  2.3937867069244385\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 94 Iteration 0: Loss = 2.3096959590911865, Number of mined P N = 316 1994\n",
      "Epoch 94 Iteration 100: Loss = 2.7205636501312256, Number of mined P N = 331 2997\n",
      "Epoch 94 Iteration 200: Loss = 2.348344087600708, Number of mined P N = 325 2176\n",
      "Epoch 94 Iteration 300: Loss = 2.4266722202301025, Number of mined P N = 299 2094\n",
      "Epoch 94 Iteration 400: Loss = 1.9824328422546387, Number of mined P N = 285 1224\n",
      "Epoch 94 Iteration 500: Loss = 2.4182941913604736, Number of mined P N = 331 1969\n",
      "Epoch 94 Iteration 600: Loss = 2.308521032333374, Number of mined P N = 332 1973\n",
      "Epoch 94 Iteration 700: Loss = 2.4864513874053955, Number of mined P N = 319 2286\n",
      "Validation loss:  2.3542414140701293\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 95 Iteration 0: Loss = 2.2870962619781494, Number of mined P N = 336 1797\n",
      "Epoch 95 Iteration 100: Loss = 2.430912733078003, Number of mined P N = 315 1996\n",
      "Epoch 95 Iteration 200: Loss = 2.2702887058258057, Number of mined P N = 316 1737\n",
      "Epoch 95 Iteration 300: Loss = 2.3407607078552246, Number of mined P N = 315 1813\n",
      "Epoch 95 Iteration 400: Loss = 2.2510249614715576, Number of mined P N = 315 1858\n",
      "Epoch 95 Iteration 500: Loss = 2.337369441986084, Number of mined P N = 332 1970\n",
      "Epoch 95 Iteration 600: Loss = 2.1956558227539062, Number of mined P N = 318 1456\n",
      "Epoch 95 Iteration 700: Loss = 2.380568742752075, Number of mined P N = 318 2021\n",
      "Validation loss:  2.369924240112305\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 96 Iteration 0: Loss = 2.383268117904663, Number of mined P N = 326 2009\n",
      "Epoch 96 Iteration 100: Loss = 2.2487127780914307, Number of mined P N = 337 1754\n",
      "Epoch 96 Iteration 200: Loss = 2.4355597496032715, Number of mined P N = 324 1964\n",
      "Epoch 96 Iteration 300: Loss = 2.1540136337280273, Number of mined P N = 324 1670\n",
      "Epoch 96 Iteration 400: Loss = 2.6805667877197266, Number of mined P N = 327 2890\n",
      "Epoch 96 Iteration 500: Loss = 2.5944037437438965, Number of mined P N = 321 2550\n",
      "Epoch 96 Iteration 600: Loss = 2.266921043395996, Number of mined P N = 296 1828\n",
      "Epoch 96 Iteration 700: Loss = 2.4445033073425293, Number of mined P N = 311 2156\n",
      "Validation loss:  2.3789141845703123\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 97 Iteration 0: Loss = 2.421525716781616, Number of mined P N = 328 2021\n",
      "Epoch 97 Iteration 100: Loss = 2.2170040607452393, Number of mined P N = 318 1691\n",
      "Epoch 97 Iteration 200: Loss = 2.7917158603668213, Number of mined P N = 340 3035\n",
      "Epoch 97 Iteration 300: Loss = 2.330453872680664, Number of mined P N = 293 1938\n",
      "Epoch 97 Iteration 400: Loss = 2.3614578247070312, Number of mined P N = 315 1938\n",
      "Epoch 97 Iteration 500: Loss = 2.1617066860198975, Number of mined P N = 307 1763\n",
      "Epoch 97 Iteration 600: Loss = 2.174546718597412, Number of mined P N = 302 1609\n",
      "Epoch 97 Iteration 700: Loss = 2.5822863578796387, Number of mined P N = 338 2676\n",
      "Validation loss:  2.38705322265625\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 98 Iteration 0: Loss = 2.3310980796813965, Number of mined P N = 332 1971\n",
      "Epoch 98 Iteration 100: Loss = 2.446399450302124, Number of mined P N = 323 2172\n",
      "Epoch 98 Iteration 200: Loss = 2.552039623260498, Number of mined P N = 316 2105\n",
      "Epoch 98 Iteration 300: Loss = 2.41348934173584, Number of mined P N = 320 2204\n",
      "Epoch 98 Iteration 400: Loss = 2.1267220973968506, Number of mined P N = 300 1807\n",
      "Epoch 98 Iteration 500: Loss = 2.1163489818573, Number of mined P N = 289 1558\n",
      "Epoch 98 Iteration 600: Loss = 2.1473047733306885, Number of mined P N = 307 1529\n",
      "Epoch 98 Iteration 700: Loss = 2.3967444896698, Number of mined P N = 295 1984\n",
      "Validation loss:  2.2954504442214967\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 99 Iteration 0: Loss = 2.470442533493042, Number of mined P N = 332 2373\n",
      "Epoch 99 Iteration 100: Loss = 2.526169538497925, Number of mined P N = 340 2672\n",
      "Epoch 99 Iteration 200: Loss = 2.0537679195404053, Number of mined P N = 309 1424\n",
      "Epoch 99 Iteration 300: Loss = 2.4300458431243896, Number of mined P N = 304 2085\n",
      "Epoch 99 Iteration 400: Loss = 2.261042594909668, Number of mined P N = 325 1808\n",
      "Epoch 99 Iteration 500: Loss = 2.4540021419525146, Number of mined P N = 320 2082\n",
      "Epoch 99 Iteration 600: Loss = 2.0750160217285156, Number of mined P N = 324 1587\n",
      "Epoch 99 Iteration 700: Loss = 2.209167957305908, Number of mined P N = 335 1696\n",
      "Validation loss:  2.3815091276168823\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "feature= \"raw\"\n",
    "sample_len = 500\n",
    "num_epochs=99\n",
    "batch_s= 128\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "from pytorch_metric_learning.distances import LpDistance, CosineSimilarity,SNRDistance\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "\n",
    "        # Access the data and labels from the HDF5 file\n",
    "        self.x_data = self.h5_file['data']  # EEG data (use memory-mapped access)\n",
    "        self.y_data = self.h5_file['labels'][:]  # Labels (load fully into memory)\n",
    "        self.s_data = self.h5_file['sessions'][:]  # Sessions (load fully into memory)\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Convert to torch tensor\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "    def close(self):\n",
    "        self.h5_file.close()\n",
    "        \n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "            # Load the data, labels, and sessions fully into memory\n",
    "            #headset_indices= [6, 15, 17, 27, 37, 57, 85, 87, 64, 44, 33, 22, 24, 10]\n",
    "            headset_indices= [6, 15, 17, 27, 37, 58, 79, 81, 66, 44, 33, 21, 23, 10]\n",
    "            #headset_indices= [30, 62, 59, 63, 72, 78, 86]\n",
    "            self.x_data = np.array(h5_file['data'])[:, headset_indices, :]  # Load EEG data into memory\n",
    "            self.y_data = np.array(h5_file['labels'])  # Load labels into memory\n",
    "            self.s_data = np.array(h5_file['sessions'])  # Load sessions into memory\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert data and labels into torch tensors\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Fetch EEG data\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Fetch the session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "# Usage example\n",
    "h5_file_path_t = f'../Data/train_{feature}.h5'\n",
    "h5_file_path_v = f'../Data/valid_{feature}.h5'\n",
    "train_dataset = EEGDataset(h5_file_path_t)\n",
    "valid_dataset = EEGDataset(h5_file_path_v)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "subject_ids = train_dataset.targets  # Replace with train_dataset.targets\n",
    "session_ids = train_dataset.s_data          # Replace with train_dataset.s_data\n",
    "\n",
    "# Combine subject and session IDs into unique pairs\n",
    "pairs = list(zip(subject_ids.tolist(), session_ids.tolist()))\n",
    "\n",
    "# Create a mapping from pairs to unique IDs\n",
    "unique_pairs = list(set(pairs))  # Get unique pairs\n",
    "pair_to_id = {pair: idx for idx, pair in enumerate(unique_pairs)}\n",
    "\n",
    "# Map each pair to its unique ID\n",
    "unique_ids = torch.tensor([pair_to_id[pair] for pair in pairs])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate(model, loader, loss_func, mining_func, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation loader (using the provided loader, not train_loader)\n",
    "        for batch_idx, (data, labels, sessions) in enumerate(loader):\n",
    "            # Move data and labels to the specified device\n",
    "            inputs = data.to(device)\n",
    "            targets = labels.to(device)\n",
    "\n",
    "            # Compute embeddings using the model\n",
    "            embeddings = model(inputs)\n",
    "            \n",
    "            # Get mining output for the embeddings\n",
    "            mined_indices = mining_func(embeddings, targets)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_func(embeddings, targets, mined_indices)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "    # Compute the average validation loss\n",
    "    average_loss = total_loss / total_batches if total_batches > 0 else 0\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet7, self).__init__()\n",
    "        # InstanceNorm1d normalizes each channel across its 500 values for each sample\n",
    "        self.norm = nn.InstanceNorm1d(14, affine=False)  # Normalizes across the 500 values in each of the 93 channels\n",
    "        self.act = nn.ReLU()  # or nn.SELU() , ReLU\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.conv1 = nn.Conv2d(1, 256, (1, 4), padding='same')\n",
    "        self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 192, (4, 1), padding='same')\n",
    "        self.pool2 = nn.MaxPool2d((2, 1))\n",
    "        self.conv3 = nn.Conv2d(192, 128, (1, 4), padding='same')\n",
    "        #self.pool3 = nn.MaxPool2d((1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 96, (4, 1), padding='same')\n",
    "        #self.pool4 = nn.MaxPool2d((2, 1))\n",
    "        self.conv5 = nn.Conv2d(96, 64, (1, 4), padding='same')\n",
    "        #self.pool5 = nn.MaxPool2d((1, 2))\n",
    "        self.conv6 = nn.Conv2d(64, 32, (4, 1), padding='same')\n",
    "        #self.pool6 = nn.MaxPool2d((2, 1))\n",
    "        self.conv7 = nn.Conv2d(32, 16, (1, 2), padding='same')\n",
    "        self.conv8 = nn.Conv2d(16, 2, (2, 1), padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.embedding = nn.Linear(3500, 128)  # Embedding layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #if x.dim() == 3:\n",
    "            #x = x.unsqueeze(1)  # Adding a channel dimension if input is 3D\n",
    "        x = self.norm(x)  # Apply InstanceNorm along the channel dimension (squeeze to 1D first)\n",
    "        x = x.unsqueeze(1)  # Reshape to 4D again for Conv2d\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        #x = self.pool3(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        #x = self.pool4(x)\n",
    "        x = self.act(self.conv5(x))\n",
    "        #x = self.pool5(x)\n",
    "        x = self.act(self.conv6(x))\n",
    "        #x = self.pool6(x)\n",
    "        x = self.act(self.conv7(x))\n",
    "        x = self.act(self.conv8(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch, test_loader):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    print(f\"Total number of batches in train_loader: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use mixed precision training\n",
    "        with autocast():\n",
    "            embeddings = model(data)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        # Scales the loss, and backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales gradients and optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined P N = {} {}\".format(\n",
    "                    epoch, batch_idx, loss.item(), mining_func.num_pos_pairs, mining_func.num_neg_pairs  \n",
    "                )\n",
    "            )\n",
    "    val_loss = validate(model, test_loader, loss_func, mining_func, device)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trunk = EEGNet7().to(device)\n",
    "summary(trunk, (14, sample_len)) \n",
    "\n",
    "loss_func = losses.SupConLoss(temperature=0.1).to(device)\n",
    "#loss_func = losses.LiftedStructureLoss().to(device)\n",
    "\n",
    "#sampler = samplers.MPerClassSampler(unique_ids, m=1, batch_size=batch_s)\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, batch_size=batch_s)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_s, sampler=sampler)\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001)\n",
    "#mining_func = miners.PairMarginMiner(pos_margin=0.20, neg_margin=0.8)\n",
    "mining_func = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(trunk, loss_func, mining_func, device, train_loader, trunk_optimizer, epoch,valid_loader)\n",
    "    #test(trunk, loss_func, mining_func, device, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(trunk.state_dict(), '../model/SupConLossLoss128_m4_e99_emotive.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3d396-7536-4ba4-a9ec-4e35c9449af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
