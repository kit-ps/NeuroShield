{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166b40a-7bbe-44b9-b318-75d390807900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 230\n",
      "Number of unique subjects: 15\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    InstanceNorm1d-1               [-1, 4, 500]               0\n",
      "            Conv2d-2          [-1, 256, 4, 500]           1,280\n",
      "              ReLU-3          [-1, 256, 4, 500]               0\n",
      "            Conv2d-4          [-1, 192, 4, 500]         196,800\n",
      "              ReLU-5          [-1, 192, 4, 500]               0\n",
      "            Conv2d-6          [-1, 128, 4, 500]          98,432\n",
      "              ReLU-7          [-1, 128, 4, 500]               0\n",
      "            Conv2d-8           [-1, 96, 4, 500]          49,248\n",
      "              ReLU-9           [-1, 96, 4, 500]               0\n",
      "           Conv2d-10           [-1, 64, 4, 500]          24,640\n",
      "             ReLU-11           [-1, 64, 4, 500]               0\n",
      "           Conv2d-12           [-1, 32, 4, 500]           8,224\n",
      "             ReLU-13           [-1, 32, 4, 500]               0\n",
      "           Conv2d-14           [-1, 16, 4, 500]           1,040\n",
      "             ReLU-15           [-1, 16, 4, 500]               0\n",
      "           Conv2d-16            [-1, 2, 4, 500]              66\n",
      "             ReLU-17            [-1, 2, 4, 500]               0\n",
      "          Flatten-18                 [-1, 4000]               0\n",
      "           Linear-19                  [-1, 128]         512,128\n",
      "================================================================\n",
      "Total params: 891,858\n",
      "Trainable params: 891,858\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 24.03\n",
      "Params size (MB): 3.40\n",
      "Estimated Total Size (MB): 27.44\n",
      "----------------------------------------------------------------\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 1 Iteration 0: Loss = 4.8440446853637695, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 100: Loss = 4.431011199951172, Number of mined P N = 384 11751\n",
      "Epoch 1 Iteration 200: Loss = 4.531064987182617, Number of mined P N = 384 12244\n",
      "Epoch 1 Iteration 300: Loss = 4.37638521194458, Number of mined P N = 384 9982\n",
      "Epoch 1 Iteration 400: Loss = 4.2986369132995605, Number of mined P N = 384 9463\n",
      "Epoch 1 Iteration 500: Loss = 4.260561943054199, Number of mined P N = 384 10332\n",
      "Epoch 1 Iteration 600: Loss = 4.136484622955322, Number of mined P N = 384 8363\n",
      "Epoch 1 Iteration 700: Loss = 4.437762260437012, Number of mined P N = 384 11781\n",
      "Validation loss:  4.22336178779602\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 2 Iteration 0: Loss = 4.056554794311523, Number of mined P N = 384 7901\n",
      "Epoch 2 Iteration 100: Loss = 4.144374847412109, Number of mined P N = 384 8677\n",
      "Epoch 2 Iteration 200: Loss = 4.014312267303467, Number of mined P N = 384 8787\n",
      "Epoch 2 Iteration 300: Loss = 4.243687629699707, Number of mined P N = 384 10170\n",
      "Epoch 2 Iteration 400: Loss = 4.096762657165527, Number of mined P N = 384 8810\n",
      "Epoch 2 Iteration 500: Loss = 4.05047607421875, Number of mined P N = 384 8895\n",
      "Epoch 2 Iteration 600: Loss = 4.048435211181641, Number of mined P N = 384 8543\n",
      "Epoch 2 Iteration 700: Loss = 3.9909520149230957, Number of mined P N = 384 9284\n",
      "Validation loss:  4.1192519474029545\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 3 Iteration 0: Loss = 4.077915668487549, Number of mined P N = 384 9559\n",
      "Epoch 3 Iteration 100: Loss = 4.1399030685424805, Number of mined P N = 384 8656\n",
      "Epoch 3 Iteration 200: Loss = 4.076572418212891, Number of mined P N = 384 9145\n",
      "Epoch 3 Iteration 300: Loss = 4.03908634185791, Number of mined P N = 384 9467\n",
      "Epoch 3 Iteration 400: Loss = 3.860053062438965, Number of mined P N = 384 7855\n",
      "Epoch 3 Iteration 500: Loss = 3.8694989681243896, Number of mined P N = 378 7515\n",
      "Epoch 3 Iteration 600: Loss = 3.989931583404541, Number of mined P N = 384 8610\n",
      "Epoch 3 Iteration 700: Loss = 3.868617057800293, Number of mined P N = 384 7197\n",
      "Validation loss:  3.9968118715286254\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 4 Iteration 0: Loss = 4.128567695617676, Number of mined P N = 384 9885\n",
      "Epoch 4 Iteration 100: Loss = 4.0716753005981445, Number of mined P N = 384 9168\n",
      "Epoch 4 Iteration 200: Loss = 4.031661033630371, Number of mined P N = 384 7963\n",
      "Epoch 4 Iteration 300: Loss = 4.029574394226074, Number of mined P N = 384 8366\n",
      "Epoch 4 Iteration 400: Loss = 3.978064775466919, Number of mined P N = 384 8267\n",
      "Epoch 4 Iteration 500: Loss = 4.0543413162231445, Number of mined P N = 384 8755\n",
      "Epoch 4 Iteration 600: Loss = 4.058355808258057, Number of mined P N = 384 8277\n",
      "Epoch 4 Iteration 700: Loss = 3.863379955291748, Number of mined P N = 384 8068\n",
      "Validation loss:  3.9567076921463014\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 5 Iteration 0: Loss = 3.94700288772583, Number of mined P N = 384 8463\n",
      "Epoch 5 Iteration 100: Loss = 4.0174880027771, Number of mined P N = 384 8623\n",
      "Epoch 5 Iteration 200: Loss = 3.84127140045166, Number of mined P N = 384 7316\n",
      "Epoch 5 Iteration 300: Loss = 3.9331536293029785, Number of mined P N = 384 8296\n",
      "Epoch 5 Iteration 400: Loss = 4.036580562591553, Number of mined P N = 384 8979\n",
      "Epoch 5 Iteration 500: Loss = 4.013701438903809, Number of mined P N = 384 8412\n",
      "Epoch 5 Iteration 600: Loss = 3.80633282661438, Number of mined P N = 384 7493\n",
      "Epoch 5 Iteration 700: Loss = 3.9089062213897705, Number of mined P N = 384 8105\n",
      "Validation loss:  3.900707130432129\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 6 Iteration 0: Loss = 3.919743061065674, Number of mined P N = 384 7681\n",
      "Epoch 6 Iteration 100: Loss = 3.9872255325317383, Number of mined P N = 384 8620\n",
      "Epoch 6 Iteration 200: Loss = 3.9370055198669434, Number of mined P N = 384 7700\n",
      "Epoch 6 Iteration 300: Loss = 3.795600652694702, Number of mined P N = 384 6979\n",
      "Epoch 6 Iteration 400: Loss = 3.8470916748046875, Number of mined P N = 384 8252\n",
      "Epoch 6 Iteration 500: Loss = 4.0016069412231445, Number of mined P N = 384 8684\n",
      "Epoch 6 Iteration 600: Loss = 3.8979339599609375, Number of mined P N = 384 8198\n",
      "Epoch 6 Iteration 700: Loss = 3.954742431640625, Number of mined P N = 384 8718\n",
      "Validation loss:  3.89921573638916\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 7 Iteration 0: Loss = 3.933044195175171, Number of mined P N = 384 8502\n",
      "Epoch 7 Iteration 100: Loss = 3.975064516067505, Number of mined P N = 384 8139\n",
      "Epoch 7 Iteration 200: Loss = 3.9064388275146484, Number of mined P N = 384 7566\n",
      "Epoch 7 Iteration 300: Loss = 3.7761316299438477, Number of mined P N = 384 6705\n",
      "Epoch 7 Iteration 400: Loss = 4.0218000411987305, Number of mined P N = 384 8623\n",
      "Epoch 7 Iteration 500: Loss = 3.7686374187469482, Number of mined P N = 384 7235\n",
      "Epoch 7 Iteration 600: Loss = 4.017831802368164, Number of mined P N = 384 8116\n",
      "Epoch 7 Iteration 700: Loss = 3.769653797149658, Number of mined P N = 384 6938\n",
      "Validation loss:  3.8968749237060547\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 8 Iteration 0: Loss = 4.062527179718018, Number of mined P N = 384 9094\n",
      "Epoch 8 Iteration 100: Loss = 3.9185376167297363, Number of mined P N = 384 8464\n",
      "Epoch 8 Iteration 200: Loss = 3.859767436981201, Number of mined P N = 384 6851\n",
      "Epoch 8 Iteration 300: Loss = 3.8029892444610596, Number of mined P N = 384 7637\n",
      "Epoch 8 Iteration 400: Loss = 4.0128631591796875, Number of mined P N = 384 9032\n",
      "Epoch 8 Iteration 500: Loss = 3.8826563358306885, Number of mined P N = 383 6802\n",
      "Epoch 8 Iteration 600: Loss = 3.84682297706604, Number of mined P N = 384 7641\n",
      "Epoch 8 Iteration 700: Loss = 4.1418843269348145, Number of mined P N = 382 8374\n",
      "Validation loss:  3.906872730255127\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 9 Iteration 0: Loss = 3.836202621459961, Number of mined P N = 384 7316\n",
      "Epoch 9 Iteration 100: Loss = 3.7862160205841064, Number of mined P N = 384 7150\n",
      "Epoch 9 Iteration 200: Loss = 3.9656946659088135, Number of mined P N = 384 8678\n",
      "Epoch 9 Iteration 300: Loss = 4.001363277435303, Number of mined P N = 384 9283\n",
      "Epoch 9 Iteration 400: Loss = 3.926182270050049, Number of mined P N = 384 7885\n",
      "Epoch 9 Iteration 500: Loss = 3.8109123706817627, Number of mined P N = 384 7804\n",
      "Epoch 9 Iteration 600: Loss = 3.8209621906280518, Number of mined P N = 384 7006\n",
      "Epoch 9 Iteration 700: Loss = 3.917293071746826, Number of mined P N = 384 8399\n",
      "Validation loss:  3.8799976921081543\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 10 Iteration 0: Loss = 3.84603214263916, Number of mined P N = 384 7105\n",
      "Epoch 10 Iteration 100: Loss = 3.9802377223968506, Number of mined P N = 384 8124\n",
      "Epoch 10 Iteration 200: Loss = 3.9172048568725586, Number of mined P N = 384 8541\n",
      "Epoch 10 Iteration 300: Loss = 3.7591934204101562, Number of mined P N = 384 7495\n",
      "Epoch 10 Iteration 400: Loss = 3.936858654022217, Number of mined P N = 384 8451\n",
      "Epoch 10 Iteration 500: Loss = 3.7694239616394043, Number of mined P N = 384 6806\n",
      "Epoch 10 Iteration 600: Loss = 3.8513641357421875, Number of mined P N = 384 7374\n",
      "Epoch 10 Iteration 700: Loss = 4.069100379943848, Number of mined P N = 384 9807\n",
      "Validation loss:  3.8282511329650877\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 11 Iteration 0: Loss = 3.938051700592041, Number of mined P N = 382 8042\n",
      "Epoch 11 Iteration 100: Loss = 3.842752456665039, Number of mined P N = 384 7606\n",
      "Epoch 11 Iteration 200: Loss = 3.7556188106536865, Number of mined P N = 384 6960\n",
      "Epoch 11 Iteration 300: Loss = 3.7404046058654785, Number of mined P N = 383 6664\n",
      "Epoch 11 Iteration 400: Loss = 3.772301197052002, Number of mined P N = 383 6601\n",
      "Epoch 11 Iteration 500: Loss = 3.7741904258728027, Number of mined P N = 384 7077\n",
      "Epoch 11 Iteration 600: Loss = 3.747722625732422, Number of mined P N = 384 6769\n",
      "Epoch 11 Iteration 700: Loss = 3.988798141479492, Number of mined P N = 384 8301\n",
      "Validation loss:  3.861056756973267\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 12 Iteration 0: Loss = 3.6209511756896973, Number of mined P N = 384 6230\n",
      "Epoch 12 Iteration 100: Loss = 3.7076544761657715, Number of mined P N = 384 6374\n",
      "Epoch 12 Iteration 200: Loss = 3.90443754196167, Number of mined P N = 384 7520\n",
      "Epoch 12 Iteration 300: Loss = 3.6419765949249268, Number of mined P N = 384 6346\n",
      "Epoch 12 Iteration 400: Loss = 3.841623544692993, Number of mined P N = 378 7154\n",
      "Epoch 12 Iteration 500: Loss = 4.111440658569336, Number of mined P N = 384 8949\n",
      "Epoch 12 Iteration 600: Loss = 3.6019444465637207, Number of mined P N = 384 6721\n",
      "Epoch 12 Iteration 700: Loss = 3.9741015434265137, Number of mined P N = 384 7678\n",
      "Validation loss:  3.821807804107666\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 13 Iteration 0: Loss = 3.7922210693359375, Number of mined P N = 381 7129\n",
      "Epoch 13 Iteration 100: Loss = 3.96271014213562, Number of mined P N = 384 8019\n",
      "Epoch 13 Iteration 200: Loss = 3.887890338897705, Number of mined P N = 384 7753\n",
      "Epoch 13 Iteration 300: Loss = 3.8834574222564697, Number of mined P N = 384 7412\n",
      "Epoch 13 Iteration 400: Loss = 4.008689880371094, Number of mined P N = 384 8291\n",
      "Epoch 13 Iteration 500: Loss = 3.7511565685272217, Number of mined P N = 384 6203\n",
      "Epoch 13 Iteration 600: Loss = 3.820557117462158, Number of mined P N = 384 7214\n",
      "Epoch 13 Iteration 700: Loss = 3.9647743701934814, Number of mined P N = 384 7904\n",
      "Validation loss:  3.8222606992721557\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 14 Iteration 0: Loss = 3.6984286308288574, Number of mined P N = 384 6574\n",
      "Epoch 14 Iteration 100: Loss = 3.5994009971618652, Number of mined P N = 384 6619\n",
      "Epoch 14 Iteration 200: Loss = 3.690298080444336, Number of mined P N = 384 6353\n",
      "Epoch 14 Iteration 300: Loss = 3.930837631225586, Number of mined P N = 384 7755\n",
      "Epoch 14 Iteration 400: Loss = 3.673135757446289, Number of mined P N = 383 6353\n",
      "Epoch 14 Iteration 500: Loss = 3.7889692783355713, Number of mined P N = 381 6598\n",
      "Epoch 14 Iteration 600: Loss = 3.7426092624664307, Number of mined P N = 384 6849\n",
      "Epoch 14 Iteration 700: Loss = 3.7059669494628906, Number of mined P N = 380 6643\n",
      "Validation loss:  3.81159348487854\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 15 Iteration 0: Loss = 3.7272744178771973, Number of mined P N = 384 6341\n",
      "Epoch 15 Iteration 100: Loss = 3.991999626159668, Number of mined P N = 384 8769\n",
      "Epoch 15 Iteration 200: Loss = 3.869558334350586, Number of mined P N = 384 7209\n",
      "Epoch 15 Iteration 300: Loss = 3.8119089603424072, Number of mined P N = 382 7516\n",
      "Epoch 15 Iteration 400: Loss = 3.7133665084838867, Number of mined P N = 383 6472\n",
      "Epoch 15 Iteration 500: Loss = 3.758157730102539, Number of mined P N = 384 6778\n",
      "Epoch 15 Iteration 600: Loss = 3.880605459213257, Number of mined P N = 384 7136\n",
      "Epoch 15 Iteration 700: Loss = 3.6690824031829834, Number of mined P N = 384 6966\n",
      "Validation loss:  3.7923985052108766\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 16 Iteration 0: Loss = 3.5759081840515137, Number of mined P N = 383 5576\n",
      "Epoch 16 Iteration 100: Loss = 3.9443721771240234, Number of mined P N = 384 7930\n",
      "Epoch 16 Iteration 200: Loss = 3.7189905643463135, Number of mined P N = 384 6380\n",
      "Epoch 16 Iteration 300: Loss = 3.7336783409118652, Number of mined P N = 384 7159\n",
      "Epoch 16 Iteration 400: Loss = 3.5550358295440674, Number of mined P N = 384 6011\n",
      "Epoch 16 Iteration 500: Loss = 3.907371997833252, Number of mined P N = 384 7189\n",
      "Epoch 16 Iteration 600: Loss = 3.575812816619873, Number of mined P N = 384 6217\n",
      "Epoch 16 Iteration 700: Loss = 3.8016293048858643, Number of mined P N = 384 7272\n",
      "Validation loss:  3.7543697214126586\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 17 Iteration 0: Loss = 3.714473009109497, Number of mined P N = 384 6446\n",
      "Epoch 17 Iteration 100: Loss = 3.614816188812256, Number of mined P N = 384 6469\n",
      "Epoch 17 Iteration 200: Loss = 3.9082417488098145, Number of mined P N = 384 8347\n",
      "Epoch 17 Iteration 300: Loss = 3.7970876693725586, Number of mined P N = 384 7379\n",
      "Epoch 17 Iteration 400: Loss = 3.785738945007324, Number of mined P N = 384 8245\n",
      "Epoch 17 Iteration 500: Loss = 3.7907915115356445, Number of mined P N = 382 7362\n",
      "Epoch 17 Iteration 600: Loss = 3.794980049133301, Number of mined P N = 384 6976\n",
      "Epoch 17 Iteration 700: Loss = 3.6476917266845703, Number of mined P N = 383 5922\n",
      "Validation loss:  3.812693490982056\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 18 Iteration 0: Loss = 3.901371955871582, Number of mined P N = 384 7762\n",
      "Epoch 18 Iteration 100: Loss = 3.4903602600097656, Number of mined P N = 384 5619\n",
      "Epoch 18 Iteration 200: Loss = 3.734605073928833, Number of mined P N = 384 6830\n",
      "Epoch 18 Iteration 300: Loss = 3.943012237548828, Number of mined P N = 384 8155\n",
      "Epoch 18 Iteration 400: Loss = 3.7819321155548096, Number of mined P N = 383 7051\n",
      "Epoch 18 Iteration 500: Loss = 3.682913303375244, Number of mined P N = 384 6397\n",
      "Epoch 18 Iteration 600: Loss = 3.832794427871704, Number of mined P N = 384 6878\n",
      "Epoch 18 Iteration 700: Loss = 3.64620041847229, Number of mined P N = 384 6634\n",
      "Validation loss:  3.8136547088623045\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 19 Iteration 0: Loss = 3.8872740268707275, Number of mined P N = 384 7815\n",
      "Epoch 19 Iteration 100: Loss = 3.6483986377716064, Number of mined P N = 384 6330\n",
      "Epoch 19 Iteration 200: Loss = 3.681185245513916, Number of mined P N = 384 6497\n",
      "Epoch 19 Iteration 300: Loss = 3.9660825729370117, Number of mined P N = 382 7688\n",
      "Epoch 19 Iteration 400: Loss = 3.539144992828369, Number of mined P N = 384 6003\n",
      "Epoch 19 Iteration 500: Loss = 3.8839306831359863, Number of mined P N = 384 7155\n",
      "Epoch 19 Iteration 600: Loss = 3.6980133056640625, Number of mined P N = 384 6457\n",
      "Epoch 19 Iteration 700: Loss = 3.4474191665649414, Number of mined P N = 384 5706\n",
      "Validation loss:  3.73207275390625\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 20 Iteration 0: Loss = 3.917391538619995, Number of mined P N = 384 8731\n",
      "Epoch 20 Iteration 100: Loss = 3.971405506134033, Number of mined P N = 384 8455\n",
      "Epoch 20 Iteration 200: Loss = 3.785977840423584, Number of mined P N = 379 7277\n",
      "Epoch 20 Iteration 300: Loss = 3.6472725868225098, Number of mined P N = 384 6780\n",
      "Epoch 20 Iteration 400: Loss = 3.817061424255371, Number of mined P N = 384 6698\n",
      "Epoch 20 Iteration 500: Loss = 3.8287277221679688, Number of mined P N = 384 7118\n",
      "Epoch 20 Iteration 600: Loss = 3.8616943359375, Number of mined P N = 384 7738\n",
      "Epoch 20 Iteration 700: Loss = 3.777144193649292, Number of mined P N = 384 7688\n",
      "Validation loss:  3.748360300064087\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 21 Iteration 0: Loss = 3.7246408462524414, Number of mined P N = 384 6698\n",
      "Epoch 21 Iteration 100: Loss = 3.612542152404785, Number of mined P N = 384 6022\n",
      "Epoch 21 Iteration 200: Loss = 3.8259799480438232, Number of mined P N = 384 7615\n",
      "Epoch 21 Iteration 300: Loss = 3.675997495651245, Number of mined P N = 382 6800\n",
      "Epoch 21 Iteration 400: Loss = 3.6412110328674316, Number of mined P N = 384 6595\n",
      "Epoch 21 Iteration 500: Loss = 3.6679890155792236, Number of mined P N = 384 6399\n",
      "Epoch 21 Iteration 600: Loss = 3.8433079719543457, Number of mined P N = 384 8317\n",
      "Epoch 21 Iteration 700: Loss = 3.721719264984131, Number of mined P N = 384 7010\n",
      "Validation loss:  3.718782830238342\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 22 Iteration 0: Loss = 3.8043572902679443, Number of mined P N = 384 7346\n",
      "Epoch 22 Iteration 100: Loss = 3.6958842277526855, Number of mined P N = 384 6224\n",
      "Epoch 22 Iteration 200: Loss = 3.582428455352783, Number of mined P N = 384 6087\n",
      "Epoch 22 Iteration 300: Loss = 3.631990432739258, Number of mined P N = 384 6501\n",
      "Epoch 22 Iteration 400: Loss = 3.768503427505493, Number of mined P N = 384 7459\n",
      "Epoch 22 Iteration 500: Loss = 3.6848318576812744, Number of mined P N = 384 6988\n",
      "Epoch 22 Iteration 600: Loss = 3.691725730895996, Number of mined P N = 384 6950\n",
      "Epoch 22 Iteration 700: Loss = 3.4403862953186035, Number of mined P N = 383 5212\n",
      "Validation loss:  3.7517010593414306\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 23 Iteration 0: Loss = 3.690873146057129, Number of mined P N = 384 6021\n",
      "Epoch 23 Iteration 100: Loss = 3.7107629776000977, Number of mined P N = 384 6384\n",
      "Epoch 23 Iteration 200: Loss = 3.7152137756347656, Number of mined P N = 384 6644\n",
      "Epoch 23 Iteration 300: Loss = 3.739840030670166, Number of mined P N = 384 7178\n",
      "Epoch 23 Iteration 400: Loss = 3.855940341949463, Number of mined P N = 384 8047\n",
      "Epoch 23 Iteration 500: Loss = 3.89748477935791, Number of mined P N = 382 7363\n",
      "Epoch 23 Iteration 600: Loss = 3.745783805847168, Number of mined P N = 383 6972\n",
      "Epoch 23 Iteration 700: Loss = 3.767031192779541, Number of mined P N = 384 6632\n",
      "Validation loss:  3.7254272222518923\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 24 Iteration 0: Loss = 3.467951536178589, Number of mined P N = 384 5843\n",
      "Epoch 24 Iteration 100: Loss = 3.9960665702819824, Number of mined P N = 383 7900\n",
      "Epoch 24 Iteration 200: Loss = 3.534600019454956, Number of mined P N = 382 5673\n",
      "Epoch 24 Iteration 300: Loss = 3.7386350631713867, Number of mined P N = 384 6317\n",
      "Epoch 24 Iteration 400: Loss = 3.645418643951416, Number of mined P N = 384 6016\n",
      "Epoch 24 Iteration 500: Loss = 3.541764497756958, Number of mined P N = 384 5916\n",
      "Epoch 24 Iteration 600: Loss = 3.7259130477905273, Number of mined P N = 384 6726\n",
      "Epoch 24 Iteration 700: Loss = 3.9128901958465576, Number of mined P N = 383 7480\n",
      "Validation loss:  3.704789538383484\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 25 Iteration 0: Loss = 3.5723371505737305, Number of mined P N = 384 5590\n",
      "Epoch 25 Iteration 100: Loss = 3.822601556777954, Number of mined P N = 384 6757\n",
      "Epoch 25 Iteration 200: Loss = 3.465113639831543, Number of mined P N = 382 5359\n",
      "Epoch 25 Iteration 300: Loss = 3.6585984230041504, Number of mined P N = 384 6766\n",
      "Epoch 25 Iteration 400: Loss = 3.7581372261047363, Number of mined P N = 383 7390\n",
      "Epoch 25 Iteration 500: Loss = 3.590240240097046, Number of mined P N = 384 6030\n",
      "Epoch 25 Iteration 600: Loss = 3.7259774208068848, Number of mined P N = 381 6576\n",
      "Epoch 25 Iteration 700: Loss = 3.8408994674682617, Number of mined P N = 384 6611\n",
      "Validation loss:  3.674937562942505\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 26 Iteration 0: Loss = 3.704664707183838, Number of mined P N = 379 6706\n",
      "Epoch 26 Iteration 100: Loss = 3.8249645233154297, Number of mined P N = 377 7097\n",
      "Epoch 26 Iteration 200: Loss = 3.6954922676086426, Number of mined P N = 384 6685\n",
      "Epoch 26 Iteration 300: Loss = 3.6846773624420166, Number of mined P N = 384 6079\n",
      "Epoch 26 Iteration 400: Loss = 3.641350746154785, Number of mined P N = 384 6926\n",
      "Epoch 26 Iteration 500: Loss = 3.6329612731933594, Number of mined P N = 384 6113\n",
      "Epoch 26 Iteration 600: Loss = 3.636563301086426, Number of mined P N = 380 6283\n",
      "Epoch 26 Iteration 700: Loss = 3.751511335372925, Number of mined P N = 384 6279\n",
      "Validation loss:  3.6708888101577757\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 27 Iteration 0: Loss = 3.9399502277374268, Number of mined P N = 384 7551\n",
      "Epoch 27 Iteration 100: Loss = 3.790477991104126, Number of mined P N = 384 7078\n",
      "Epoch 27 Iteration 200: Loss = 3.4569458961486816, Number of mined P N = 384 5447\n",
      "Epoch 27 Iteration 300: Loss = 3.6868152618408203, Number of mined P N = 384 7274\n",
      "Epoch 27 Iteration 400: Loss = 3.540329933166504, Number of mined P N = 384 6677\n",
      "Epoch 27 Iteration 500: Loss = 3.7640533447265625, Number of mined P N = 384 7273\n",
      "Epoch 27 Iteration 600: Loss = 3.4813363552093506, Number of mined P N = 383 6030\n",
      "Epoch 27 Iteration 700: Loss = 3.7359886169433594, Number of mined P N = 384 6539\n",
      "Validation loss:  3.6483846044540407\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 28 Iteration 0: Loss = 3.584204912185669, Number of mined P N = 384 5970\n",
      "Epoch 28 Iteration 100: Loss = 3.631673812866211, Number of mined P N = 384 6003\n",
      "Epoch 28 Iteration 200: Loss = 3.836068630218506, Number of mined P N = 384 7184\n",
      "Epoch 28 Iteration 300: Loss = 3.678429126739502, Number of mined P N = 383 6671\n",
      "Epoch 28 Iteration 400: Loss = 3.785205364227295, Number of mined P N = 384 6793\n",
      "Epoch 28 Iteration 500: Loss = 3.8281970024108887, Number of mined P N = 384 7248\n",
      "Epoch 28 Iteration 600: Loss = 3.6323354244232178, Number of mined P N = 384 5975\n",
      "Epoch 28 Iteration 700: Loss = 3.4865622520446777, Number of mined P N = 384 5357\n",
      "Validation loss:  3.6594893407821654\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 29 Iteration 0: Loss = 3.5362250804901123, Number of mined P N = 384 5837\n",
      "Epoch 29 Iteration 100: Loss = 3.5707643032073975, Number of mined P N = 382 6144\n",
      "Epoch 29 Iteration 200: Loss = 3.6614279747009277, Number of mined P N = 384 6540\n",
      "Epoch 29 Iteration 300: Loss = 3.7292320728302, Number of mined P N = 384 7014\n",
      "Epoch 29 Iteration 400: Loss = 3.8113927841186523, Number of mined P N = 384 7120\n",
      "Epoch 29 Iteration 500: Loss = 3.7083916664123535, Number of mined P N = 384 6400\n",
      "Epoch 29 Iteration 600: Loss = 3.5176305770874023, Number of mined P N = 384 6184\n",
      "Epoch 29 Iteration 700: Loss = 3.9632492065429688, Number of mined P N = 384 8338\n",
      "Validation loss:  3.6764630651474\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 30 Iteration 0: Loss = 3.5134196281433105, Number of mined P N = 379 5492\n",
      "Epoch 30 Iteration 100: Loss = 3.5645077228546143, Number of mined P N = 379 6696\n",
      "Epoch 30 Iteration 200: Loss = 3.9054107666015625, Number of mined P N = 384 6433\n",
      "Epoch 30 Iteration 300: Loss = 3.7598679065704346, Number of mined P N = 384 7325\n",
      "Epoch 30 Iteration 400: Loss = 3.850269079208374, Number of mined P N = 383 7218\n",
      "Epoch 30 Iteration 500: Loss = 3.752995014190674, Number of mined P N = 384 7714\n",
      "Epoch 30 Iteration 600: Loss = 3.472792863845825, Number of mined P N = 382 5905\n",
      "Epoch 30 Iteration 700: Loss = 3.380929946899414, Number of mined P N = 383 5218\n",
      "Validation loss:  3.683705043792725\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 31 Iteration 0: Loss = 3.7518489360809326, Number of mined P N = 383 7703\n",
      "Epoch 31 Iteration 100: Loss = 3.6750504970550537, Number of mined P N = 384 6207\n",
      "Epoch 31 Iteration 200: Loss = 3.668534278869629, Number of mined P N = 384 6221\n",
      "Epoch 31 Iteration 300: Loss = 3.9381065368652344, Number of mined P N = 384 7927\n",
      "Epoch 31 Iteration 400: Loss = 3.688546657562256, Number of mined P N = 383 6631\n",
      "Epoch 31 Iteration 500: Loss = 3.637006998062134, Number of mined P N = 384 6244\n",
      "Epoch 31 Iteration 600: Loss = 3.786982536315918, Number of mined P N = 383 6575\n",
      "Epoch 31 Iteration 700: Loss = 3.739276885986328, Number of mined P N = 384 6755\n",
      "Validation loss:  3.6478695821762086\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 32 Iteration 0: Loss = 3.5268895626068115, Number of mined P N = 384 5203\n",
      "Epoch 32 Iteration 100: Loss = 3.5533313751220703, Number of mined P N = 382 5921\n",
      "Epoch 32 Iteration 200: Loss = 3.7984883785247803, Number of mined P N = 378 6478\n",
      "Epoch 32 Iteration 300: Loss = 3.473038673400879, Number of mined P N = 383 5772\n",
      "Epoch 32 Iteration 400: Loss = 3.8866569995880127, Number of mined P N = 384 7380\n",
      "Epoch 32 Iteration 500: Loss = 3.3330960273742676, Number of mined P N = 381 5202\n",
      "Epoch 32 Iteration 600: Loss = 3.5101194381713867, Number of mined P N = 384 6042\n",
      "Epoch 32 Iteration 700: Loss = 3.5520644187927246, Number of mined P N = 381 6011\n",
      "Validation loss:  3.613501777648926\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 33 Iteration 0: Loss = 3.632049083709717, Number of mined P N = 384 6444\n",
      "Epoch 33 Iteration 100: Loss = 3.9320192337036133, Number of mined P N = 381 8623\n",
      "Epoch 33 Iteration 200: Loss = 3.5859713554382324, Number of mined P N = 380 5661\n",
      "Epoch 33 Iteration 300: Loss = 3.556537389755249, Number of mined P N = 384 5715\n",
      "Epoch 33 Iteration 400: Loss = 3.644862413406372, Number of mined P N = 384 6157\n",
      "Epoch 33 Iteration 500: Loss = 3.584514856338501, Number of mined P N = 384 6851\n",
      "Epoch 33 Iteration 600: Loss = 3.841527223587036, Number of mined P N = 384 6797\n",
      "Epoch 33 Iteration 700: Loss = 3.6846563816070557, Number of mined P N = 384 7065\n",
      "Validation loss:  3.62505868434906\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 34 Iteration 0: Loss = 3.633467197418213, Number of mined P N = 384 6231\n",
      "Epoch 34 Iteration 100: Loss = 3.6655516624450684, Number of mined P N = 379 5928\n",
      "Epoch 34 Iteration 200: Loss = 3.8011982440948486, Number of mined P N = 384 6418\n",
      "Epoch 34 Iteration 300: Loss = 3.9638731479644775, Number of mined P N = 384 7570\n",
      "Epoch 34 Iteration 400: Loss = 3.402585029602051, Number of mined P N = 383 5126\n",
      "Epoch 34 Iteration 500: Loss = 3.7125062942504883, Number of mined P N = 383 6741\n",
      "Epoch 34 Iteration 600: Loss = 3.5004637241363525, Number of mined P N = 377 5336\n",
      "Epoch 34 Iteration 700: Loss = 3.631411552429199, Number of mined P N = 384 5842\n",
      "Validation loss:  3.597392911911011\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 35 Iteration 0: Loss = 3.842726230621338, Number of mined P N = 382 7491\n",
      "Epoch 35 Iteration 100: Loss = 3.679647445678711, Number of mined P N = 381 5938\n",
      "Epoch 35 Iteration 200: Loss = 3.3821372985839844, Number of mined P N = 384 5149\n",
      "Epoch 35 Iteration 300: Loss = 3.4575400352478027, Number of mined P N = 384 5362\n",
      "Epoch 35 Iteration 400: Loss = 3.512725353240967, Number of mined P N = 380 5763\n",
      "Epoch 35 Iteration 500: Loss = 3.4890666007995605, Number of mined P N = 383 5698\n",
      "Epoch 35 Iteration 600: Loss = 3.66919207572937, Number of mined P N = 382 6621\n",
      "Epoch 35 Iteration 700: Loss = 3.850152015686035, Number of mined P N = 384 7139\n",
      "Validation loss:  3.641784234046936\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 36 Iteration 0: Loss = 3.5568432807922363, Number of mined P N = 384 6623\n",
      "Epoch 36 Iteration 100: Loss = 3.5770463943481445, Number of mined P N = 383 5801\n",
      "Epoch 36 Iteration 200: Loss = 3.7578680515289307, Number of mined P N = 384 6492\n",
      "Epoch 36 Iteration 300: Loss = 3.471815586090088, Number of mined P N = 384 5419\n",
      "Epoch 36 Iteration 400: Loss = 3.6825110912323, Number of mined P N = 384 6326\n",
      "Epoch 36 Iteration 500: Loss = 3.6090407371520996, Number of mined P N = 384 6437\n",
      "Epoch 36 Iteration 600: Loss = 3.4644899368286133, Number of mined P N = 384 5315\n",
      "Epoch 36 Iteration 700: Loss = 3.5875024795532227, Number of mined P N = 384 6529\n",
      "Validation loss:  3.606177496910095\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 37 Iteration 0: Loss = 3.7051520347595215, Number of mined P N = 384 6235\n",
      "Epoch 37 Iteration 100: Loss = 3.4940896034240723, Number of mined P N = 372 5765\n",
      "Epoch 37 Iteration 200: Loss = 3.751652956008911, Number of mined P N = 384 6713\n",
      "Epoch 37 Iteration 300: Loss = 3.4913887977600098, Number of mined P N = 381 6004\n",
      "Epoch 37 Iteration 400: Loss = 3.6268863677978516, Number of mined P N = 384 6368\n",
      "Epoch 37 Iteration 500: Loss = 3.6785454750061035, Number of mined P N = 384 7359\n",
      "Epoch 37 Iteration 600: Loss = 3.516676425933838, Number of mined P N = 384 6016\n",
      "Epoch 37 Iteration 700: Loss = 3.720022201538086, Number of mined P N = 384 6665\n",
      "Validation loss:  3.5878158521652224\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 38 Iteration 0: Loss = 3.6188836097717285, Number of mined P N = 384 5754\n",
      "Epoch 38 Iteration 100: Loss = 3.7552647590637207, Number of mined P N = 384 7315\n",
      "Epoch 38 Iteration 200: Loss = 3.706613779067993, Number of mined P N = 384 5965\n",
      "Epoch 38 Iteration 300: Loss = 3.8192481994628906, Number of mined P N = 384 7835\n",
      "Epoch 38 Iteration 400: Loss = 3.5377020835876465, Number of mined P N = 381 6475\n",
      "Epoch 38 Iteration 500: Loss = 3.5552256107330322, Number of mined P N = 382 6048\n",
      "Epoch 38 Iteration 600: Loss = 3.5642788410186768, Number of mined P N = 383 6032\n",
      "Epoch 38 Iteration 700: Loss = 3.7773027420043945, Number of mined P N = 384 7071\n",
      "Validation loss:  3.5948022747039796\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 39 Iteration 0: Loss = 3.542128324508667, Number of mined P N = 382 5874\n",
      "Epoch 39 Iteration 100: Loss = 3.732600688934326, Number of mined P N = 384 7214\n",
      "Epoch 39 Iteration 200: Loss = 3.6827034950256348, Number of mined P N = 382 6073\n",
      "Epoch 39 Iteration 300: Loss = 3.4554176330566406, Number of mined P N = 380 5714\n",
      "Epoch 39 Iteration 400: Loss = 3.9270341396331787, Number of mined P N = 384 7323\n",
      "Epoch 39 Iteration 500: Loss = 3.6684799194335938, Number of mined P N = 380 6454\n",
      "Epoch 39 Iteration 600: Loss = 3.5110106468200684, Number of mined P N = 380 6612\n",
      "Epoch 39 Iteration 700: Loss = 3.670043468475342, Number of mined P N = 384 6670\n",
      "Validation loss:  3.5880317068099976\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 40 Iteration 0: Loss = 3.6229248046875, Number of mined P N = 384 6331\n",
      "Epoch 40 Iteration 100: Loss = 3.7200088500976562, Number of mined P N = 383 6573\n",
      "Epoch 40 Iteration 200: Loss = 3.668734550476074, Number of mined P N = 384 6998\n",
      "Epoch 40 Iteration 300: Loss = 3.3785223960876465, Number of mined P N = 378 5952\n",
      "Epoch 40 Iteration 400: Loss = 3.2983438968658447, Number of mined P N = 383 5041\n",
      "Epoch 40 Iteration 500: Loss = 3.6877756118774414, Number of mined P N = 384 6521\n",
      "Epoch 40 Iteration 600: Loss = 3.581728458404541, Number of mined P N = 375 5832\n",
      "Epoch 40 Iteration 700: Loss = 3.724764585494995, Number of mined P N = 376 6516\n",
      "Validation loss:  3.6044582653045656\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 41 Iteration 0: Loss = 3.509572982788086, Number of mined P N = 384 6010\n",
      "Epoch 41 Iteration 100: Loss = 3.503526210784912, Number of mined P N = 379 5964\n",
      "Epoch 41 Iteration 200: Loss = 3.5182595252990723, Number of mined P N = 374 5388\n",
      "Epoch 41 Iteration 300: Loss = 3.371433734893799, Number of mined P N = 381 4937\n",
      "Epoch 41 Iteration 400: Loss = 3.636979103088379, Number of mined P N = 384 6310\n",
      "Epoch 41 Iteration 500: Loss = 3.6263108253479004, Number of mined P N = 383 6021\n",
      "Epoch 41 Iteration 600: Loss = 3.6502974033355713, Number of mined P N = 377 5960\n",
      "Epoch 41 Iteration 700: Loss = 3.514575958251953, Number of mined P N = 384 6023\n",
      "Validation loss:  3.558884496688843\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 42 Iteration 0: Loss = 3.7568724155426025, Number of mined P N = 383 6944\n",
      "Epoch 42 Iteration 100: Loss = 3.2911252975463867, Number of mined P N = 384 5034\n",
      "Epoch 42 Iteration 200: Loss = 3.5243544578552246, Number of mined P N = 384 5569\n",
      "Epoch 42 Iteration 300: Loss = 3.4247443675994873, Number of mined P N = 380 5537\n",
      "Epoch 42 Iteration 400: Loss = 3.340587615966797, Number of mined P N = 372 4731\n",
      "Epoch 42 Iteration 500: Loss = 3.426985263824463, Number of mined P N = 383 5818\n",
      "Epoch 42 Iteration 600: Loss = 3.71975040435791, Number of mined P N = 383 6681\n",
      "Epoch 42 Iteration 700: Loss = 3.4684810638427734, Number of mined P N = 383 5684\n",
      "Validation loss:  3.5483655643463137\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 43 Iteration 0: Loss = 3.477522611618042, Number of mined P N = 383 5376\n",
      "Epoch 43 Iteration 100: Loss = 3.678135395050049, Number of mined P N = 384 6461\n",
      "Epoch 43 Iteration 200: Loss = 3.580620288848877, Number of mined P N = 383 6048\n",
      "Epoch 43 Iteration 300: Loss = 3.370058536529541, Number of mined P N = 380 5302\n",
      "Epoch 43 Iteration 400: Loss = 3.6181795597076416, Number of mined P N = 384 6515\n",
      "Epoch 43 Iteration 500: Loss = 3.5445151329040527, Number of mined P N = 384 5736\n",
      "Epoch 43 Iteration 600: Loss = 3.540982961654663, Number of mined P N = 384 5760\n",
      "Epoch 43 Iteration 700: Loss = 3.550663471221924, Number of mined P N = 379 6428\n",
      "Validation loss:  3.5567667055130006\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 44 Iteration 0: Loss = 3.450822353363037, Number of mined P N = 384 6014\n",
      "Epoch 44 Iteration 100: Loss = 3.6979990005493164, Number of mined P N = 384 6316\n",
      "Epoch 44 Iteration 200: Loss = 3.610825300216675, Number of mined P N = 383 5903\n",
      "Epoch 44 Iteration 300: Loss = 3.4280965328216553, Number of mined P N = 378 5659\n",
      "Epoch 44 Iteration 400: Loss = 3.606597900390625, Number of mined P N = 384 6089\n",
      "Epoch 44 Iteration 500: Loss = 3.3734607696533203, Number of mined P N = 384 4761\n",
      "Epoch 44 Iteration 600: Loss = 3.497757911682129, Number of mined P N = 384 5727\n",
      "Epoch 44 Iteration 700: Loss = 3.6468276977539062, Number of mined P N = 380 6280\n",
      "Validation loss:  3.536634168624878\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 45 Iteration 0: Loss = 3.4194610118865967, Number of mined P N = 383 5683\n",
      "Epoch 45 Iteration 100: Loss = 3.710330009460449, Number of mined P N = 384 6951\n",
      "Epoch 45 Iteration 200: Loss = 3.3921027183532715, Number of mined P N = 380 5724\n",
      "Epoch 45 Iteration 300: Loss = 3.571187973022461, Number of mined P N = 382 6409\n",
      "Epoch 45 Iteration 400: Loss = 3.6293649673461914, Number of mined P N = 384 6906\n",
      "Epoch 45 Iteration 500: Loss = 3.41267991065979, Number of mined P N = 378 5118\n",
      "Epoch 45 Iteration 600: Loss = 3.6670384407043457, Number of mined P N = 382 6449\n",
      "Epoch 45 Iteration 700: Loss = 3.5803585052490234, Number of mined P N = 384 5845\n",
      "Validation loss:  3.5570355463027954\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 46 Iteration 0: Loss = 3.407303810119629, Number of mined P N = 383 6165\n",
      "Epoch 46 Iteration 100: Loss = 3.621134042739868, Number of mined P N = 383 6651\n",
      "Epoch 46 Iteration 200: Loss = 3.5962319374084473, Number of mined P N = 382 6612\n",
      "Epoch 46 Iteration 300: Loss = 3.691375732421875, Number of mined P N = 381 6580\n",
      "Epoch 46 Iteration 400: Loss = 3.522442579269409, Number of mined P N = 384 5176\n",
      "Epoch 46 Iteration 500: Loss = 3.4591662883758545, Number of mined P N = 372 4914\n",
      "Epoch 46 Iteration 600: Loss = 3.6282031536102295, Number of mined P N = 382 5904\n",
      "Epoch 46 Iteration 700: Loss = 3.2592782974243164, Number of mined P N = 383 4952\n",
      "Validation loss:  3.54078399181366\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 47 Iteration 0: Loss = 3.614180564880371, Number of mined P N = 384 6284\n",
      "Epoch 47 Iteration 100: Loss = 3.6427834033966064, Number of mined P N = 372 6197\n",
      "Epoch 47 Iteration 200: Loss = 3.6984286308288574, Number of mined P N = 382 6839\n",
      "Epoch 47 Iteration 300: Loss = 3.4643752574920654, Number of mined P N = 376 6145\n",
      "Epoch 47 Iteration 400: Loss = 3.5932488441467285, Number of mined P N = 381 6486\n",
      "Epoch 47 Iteration 500: Loss = 3.491152763366699, Number of mined P N = 379 5698\n",
      "Epoch 47 Iteration 600: Loss = 3.6956050395965576, Number of mined P N = 384 7183\n",
      "Epoch 47 Iteration 700: Loss = 3.5156002044677734, Number of mined P N = 384 6019\n",
      "Validation loss:  3.516355233192444\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 48 Iteration 0: Loss = 3.4432826042175293, Number of mined P N = 374 5577\n",
      "Epoch 48 Iteration 100: Loss = 3.364165782928467, Number of mined P N = 380 5339\n",
      "Epoch 48 Iteration 200: Loss = 3.541118860244751, Number of mined P N = 375 5861\n",
      "Epoch 48 Iteration 300: Loss = 3.396406888961792, Number of mined P N = 379 5265\n",
      "Epoch 48 Iteration 400: Loss = 3.561264991760254, Number of mined P N = 384 6259\n",
      "Epoch 48 Iteration 500: Loss = 3.488455057144165, Number of mined P N = 381 6366\n",
      "Epoch 48 Iteration 600: Loss = 3.8803277015686035, Number of mined P N = 384 6888\n",
      "Epoch 48 Iteration 700: Loss = 3.726492404937744, Number of mined P N = 382 6140\n",
      "Validation loss:  3.5348220109939574\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 49 Iteration 0: Loss = 3.3964409828186035, Number of mined P N = 371 4965\n",
      "Epoch 49 Iteration 100: Loss = 3.437465190887451, Number of mined P N = 382 5180\n",
      "Epoch 49 Iteration 200: Loss = 3.553340196609497, Number of mined P N = 382 6309\n",
      "Epoch 49 Iteration 300: Loss = 3.4140641689300537, Number of mined P N = 374 5357\n",
      "Epoch 49 Iteration 400: Loss = 3.7282521724700928, Number of mined P N = 384 6256\n",
      "Epoch 49 Iteration 500: Loss = 3.435300350189209, Number of mined P N = 384 5401\n",
      "Epoch 49 Iteration 600: Loss = 3.4299046993255615, Number of mined P N = 375 5908\n",
      "Epoch 49 Iteration 700: Loss = 3.175107717514038, Number of mined P N = 375 4435\n",
      "Validation loss:  3.5032941722869873\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 50 Iteration 0: Loss = 3.3691515922546387, Number of mined P N = 383 5532\n",
      "Epoch 50 Iteration 100: Loss = 3.566678762435913, Number of mined P N = 383 6215\n",
      "Epoch 50 Iteration 200: Loss = 3.3281052112579346, Number of mined P N = 382 5261\n",
      "Epoch 50 Iteration 300: Loss = 3.6258633136749268, Number of mined P N = 381 5733\n",
      "Epoch 50 Iteration 400: Loss = 3.4301252365112305, Number of mined P N = 384 5764\n",
      "Epoch 50 Iteration 500: Loss = 3.50866961479187, Number of mined P N = 371 6557\n",
      "Epoch 50 Iteration 600: Loss = 3.3417515754699707, Number of mined P N = 383 5534\n",
      "Epoch 50 Iteration 700: Loss = 3.482455015182495, Number of mined P N = 378 5568\n",
      "Validation loss:  3.4974260330200195\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 51 Iteration 0: Loss = 3.5668647289276123, Number of mined P N = 384 6004\n",
      "Epoch 51 Iteration 100: Loss = 3.4940977096557617, Number of mined P N = 379 5910\n",
      "Epoch 51 Iteration 200: Loss = 3.6548681259155273, Number of mined P N = 383 6207\n",
      "Epoch 51 Iteration 300: Loss = 3.5572502613067627, Number of mined P N = 383 6311\n",
      "Epoch 51 Iteration 400: Loss = 3.558006525039673, Number of mined P N = 381 6465\n",
      "Epoch 51 Iteration 500: Loss = 3.624323844909668, Number of mined P N = 378 6077\n",
      "Epoch 51 Iteration 600: Loss = 3.4736993312835693, Number of mined P N = 374 5884\n",
      "Epoch 51 Iteration 700: Loss = 3.4454214572906494, Number of mined P N = 383 5752\n",
      "Validation loss:  3.5033938217163088\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 52 Iteration 0: Loss = 3.721590042114258, Number of mined P N = 383 7594\n",
      "Epoch 52 Iteration 100: Loss = 3.468667984008789, Number of mined P N = 382 5888\n",
      "Epoch 52 Iteration 200: Loss = 3.7010092735290527, Number of mined P N = 372 6777\n",
      "Epoch 52 Iteration 300: Loss = 3.5760984420776367, Number of mined P N = 382 5767\n",
      "Epoch 52 Iteration 400: Loss = 3.708303928375244, Number of mined P N = 382 5810\n",
      "Epoch 52 Iteration 500: Loss = 3.3717448711395264, Number of mined P N = 383 5541\n",
      "Epoch 52 Iteration 600: Loss = 3.3956408500671387, Number of mined P N = 382 5281\n",
      "Epoch 52 Iteration 700: Loss = 3.477534532546997, Number of mined P N = 382 6260\n",
      "Validation loss:  3.4733297443389892\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 53 Iteration 0: Loss = 3.265484571456909, Number of mined P N = 373 4330\n",
      "Epoch 53 Iteration 100: Loss = 3.5442473888397217, Number of mined P N = 380 5813\n",
      "Epoch 53 Iteration 200: Loss = 3.448087453842163, Number of mined P N = 384 5118\n",
      "Epoch 53 Iteration 300: Loss = 3.192312002182007, Number of mined P N = 384 4489\n",
      "Epoch 53 Iteration 400: Loss = 3.514143943786621, Number of mined P N = 381 5755\n",
      "Epoch 53 Iteration 500: Loss = 3.515612840652466, Number of mined P N = 384 5875\n",
      "Epoch 53 Iteration 600: Loss = 3.494572639465332, Number of mined P N = 383 5727\n",
      "Epoch 53 Iteration 700: Loss = 3.3476972579956055, Number of mined P N = 380 5695\n",
      "Validation loss:  3.5166725015640257\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 54 Iteration 0: Loss = 3.2684240341186523, Number of mined P N = 380 4805\n",
      "Epoch 54 Iteration 100: Loss = 3.5424160957336426, Number of mined P N = 377 6214\n",
      "Epoch 54 Iteration 200: Loss = 3.6042444705963135, Number of mined P N = 372 5752\n",
      "Epoch 54 Iteration 300: Loss = 3.4556427001953125, Number of mined P N = 370 5758\n",
      "Epoch 54 Iteration 400: Loss = 3.603067398071289, Number of mined P N = 383 6188\n",
      "Epoch 54 Iteration 500: Loss = 3.593228340148926, Number of mined P N = 383 6107\n",
      "Epoch 54 Iteration 600: Loss = 3.632927656173706, Number of mined P N = 378 6274\n",
      "Epoch 54 Iteration 700: Loss = 3.485107421875, Number of mined P N = 379 6013\n",
      "Validation loss:  3.4989061689376832\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 55 Iteration 0: Loss = 3.4735803604125977, Number of mined P N = 380 6050\n",
      "Epoch 55 Iteration 100: Loss = 3.544930934906006, Number of mined P N = 384 6054\n",
      "Epoch 55 Iteration 200: Loss = 3.7213501930236816, Number of mined P N = 383 7197\n",
      "Epoch 55 Iteration 300: Loss = 3.6611785888671875, Number of mined P N = 382 6763\n",
      "Epoch 55 Iteration 400: Loss = 3.583094596862793, Number of mined P N = 383 6058\n",
      "Epoch 55 Iteration 500: Loss = 3.7186875343322754, Number of mined P N = 378 6595\n",
      "Epoch 55 Iteration 600: Loss = 3.635845899581909, Number of mined P N = 371 5673\n",
      "Epoch 55 Iteration 700: Loss = 3.4267163276672363, Number of mined P N = 381 5435\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "feature= \"raw\"\n",
    "sample_len = 500\n",
    "num_epochs=99\n",
    "batch_s= 128\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "from pytorch_metric_learning.distances import LpDistance, CosineSimilarity,SNRDistance\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "\n",
    "        # Access the data and labels from the HDF5 file\n",
    "        self.x_data = self.h5_file['data']  # EEG data (use memory-mapped access)\n",
    "        self.y_data = self.h5_file['labels'][:]  # Labels (load fully into memory)\n",
    "        self.s_data = self.h5_file['sessions'][:]  # Sessions (load fully into memory)\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Convert to torch tensor\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "    def close(self):\n",
    "        self.h5_file.close()\n",
    "        \n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "            # Load the data, labels, and sessions fully into memory\n",
    "            #headset_indices= [6, 15, 17, 27, 37, 57, 85, 87, 64, 44, 33, 22, 24, 10]\n",
    "            #headset_indices = [45, 4, 12, 54]\n",
    "            headset_indices = [46, 4, 12, 56]\n",
    "            #headset_indices= [30, 62, 59, 63, 72, 78, 86]\n",
    "            self.x_data = np.array(h5_file['data'])[:, headset_indices, :]  # Load EEG data into memory\n",
    "            self.y_data = np.array(h5_file['labels'])  # Load labels into memory\n",
    "            self.s_data = np.array(h5_file['sessions'])  # Load sessions into memory\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert data and labels into torch tensors\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Fetch EEG data\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Fetch the session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "# Usage example\n",
    "h5_file_path_t = f'../Data/train_{feature}.h5'\n",
    "h5_file_path_v = f'../Data/valid_{feature}.h5'\n",
    "train_dataset = EEGDataset(h5_file_path_t)\n",
    "valid_dataset = EEGDataset(h5_file_path_v)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "subject_ids = train_dataset.targets  # Replace with train_dataset.targets\n",
    "session_ids = train_dataset.s_data          # Replace with train_dataset.s_data\n",
    "\n",
    "# Combine subject and session IDs into unique pairs\n",
    "pairs = list(zip(subject_ids.tolist(), session_ids.tolist()))\n",
    "\n",
    "# Create a mapping from pairs to unique IDs\n",
    "unique_pairs = list(set(pairs))  # Get unique pairs\n",
    "pair_to_id = {pair: idx for idx, pair in enumerate(unique_pairs)}\n",
    "\n",
    "# Map each pair to its unique ID\n",
    "unique_ids = torch.tensor([pair_to_id[pair] for pair in pairs])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate(model, loader, loss_func, mining_func, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_batches = 0\n",
    "    iteration_count = 0  # Initialize a counter for iterations\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "            if iteration_count >= 50:  # Break the loop after 5 iterations\n",
    "                break\n",
    "            inputs = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            embeddings = model(inputs)\n",
    "            miner_output = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, miner_output)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            iteration_count += 1  # Increment the iteration counter\n",
    "\n",
    "    return val_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet7, self).__init__()\n",
    "        # InstanceNorm1d normalizes each channel across its 500 values for each sample\n",
    "        self.norm = nn.InstanceNorm1d(14, affine=False)  # Normalizes across the 500 values in each of the 93 channels\n",
    "        self.act = nn.ReLU()  # or nn.SELU() , ReLU\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.conv1 = nn.Conv2d(1, 256, (1, 4), padding='same')\n",
    "        #self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 192, (4, 1), padding='same')\n",
    "        #self.pool2 = nn.MaxPool2d((2, 1))\n",
    "        self.conv3 = nn.Conv2d(192, 128, (1, 4), padding='same')\n",
    "        #self.pool3 = nn.MaxPool2d((1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 96, (4, 1), padding='same')\n",
    "        #self.pool4 = nn.MaxPool2d((2, 1))\n",
    "        self.conv5 = nn.Conv2d(96, 64, (1, 4), padding='same')\n",
    "        #self.pool5 = nn.MaxPool2d((1, 2))\n",
    "        self.conv6 = nn.Conv2d(64, 32, (4, 1), padding='same')\n",
    "        #self.pool6 = nn.MaxPool2d((2, 1))\n",
    "        self.conv7 = nn.Conv2d(32, 16, (1, 2), padding='same')\n",
    "        self.conv8 = nn.Conv2d(16, 2, (2, 1), padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.embedding = nn.Linear(4000, 128)  # Embedding layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #if x.dim() == 3:\n",
    "            #x = x.unsqueeze(1)  # Adding a channel dimension if input is 3D\n",
    "        x = self.norm(x)  # Apply InstanceNorm along the channel dimension (squeeze to 1D first)\n",
    "        x = x.unsqueeze(1)  # Reshape to 4D again for Conv2d\n",
    "        x = self.act(self.conv1(x))\n",
    "        #x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        #x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        #x = self.pool3(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        #x = self.pool4(x)\n",
    "        x = self.act(self.conv5(x))\n",
    "        #x = self.pool5(x)\n",
    "        x = self.act(self.conv6(x))\n",
    "        #x = self.pool6(x)\n",
    "        x = self.act(self.conv7(x))\n",
    "        x = self.act(self.conv8(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch, test_loader):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    print(f\"Total number of batches in train_loader: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use mixed precision training\n",
    "        with autocast():\n",
    "            embeddings = model(data)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        # Scales the loss, and backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales gradients and optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined P N = {} {}\".format(\n",
    "                    epoch, batch_idx, loss.item(), mining_func.num_pos_pairs, mining_func.num_neg_pairs  \n",
    "                )\n",
    "            )\n",
    "    val_loss = validate(model, test_loader, loss_func, mining_func, device)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trunk = EEGNet7().to(device)\n",
    "summary(trunk, (4, sample_len)) \n",
    "\n",
    "loss_func = losses.SupConLoss(temperature=0.1).to(device)\n",
    "#loss_func = losses.LiftedStructureLoss().to(device)\n",
    "\n",
    "#sampler = samplers.MPerClassSampler(unique_ids, m=1, batch_size=batch_s)\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, batch_size=batch_s)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_s, sampler=sampler)\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001)\n",
    "#mining_func = miners.PairMarginMiner(pos_margin=0.20, neg_margin=0.8)\n",
    "mining_func = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(trunk, loss_func, mining_func, device, train_loader, trunk_optimizer, epoch,valid_loader)\n",
    "    #test(trunk, loss_func, mining_func, device, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(trunk.state_dict(), '../model/SupConLossLoss128_m4_e99_Muse.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51313506-7688-415a-a931-8ea781feacf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d93eae-27f0-41ff-8b61-8d7d1b01c41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a7d12-4440-4593-91e3-f14b56b909c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3d396-7536-4ba4-a9ec-4e35c9449af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "oml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
