{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9166b40a-7bbe-44b9-b318-75d390807900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 230\n",
      "Number of unique subjects: 15\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    InstanceNorm1d-1               [-1, 7, 500]               0\n",
      "            Conv2d-2          [-1, 256, 7, 500]           1,280\n",
      "              ReLU-3          [-1, 256, 7, 500]               0\n",
      "         MaxPool2d-4          [-1, 256, 7, 250]               0\n",
      "            Conv2d-5          [-1, 192, 7, 250]         196,800\n",
      "              ReLU-6          [-1, 192, 7, 250]               0\n",
      "            Conv2d-7          [-1, 128, 7, 250]          98,432\n",
      "              ReLU-8          [-1, 128, 7, 250]               0\n",
      "            Conv2d-9           [-1, 96, 7, 250]          49,248\n",
      "             ReLU-10           [-1, 96, 7, 250]               0\n",
      "           Conv2d-11           [-1, 64, 7, 250]          24,640\n",
      "             ReLU-12           [-1, 64, 7, 250]               0\n",
      "           Conv2d-13           [-1, 32, 7, 250]           8,224\n",
      "             ReLU-14           [-1, 32, 7, 250]               0\n",
      "           Conv2d-15           [-1, 16, 7, 250]           1,040\n",
      "             ReLU-16           [-1, 16, 7, 250]               0\n",
      "           Conv2d-17            [-1, 2, 7, 250]              66\n",
      "             ReLU-18            [-1, 2, 7, 250]               0\n",
      "          Flatten-19                 [-1, 3500]               0\n",
      "           Linear-20                  [-1, 128]         448,128\n",
      "================================================================\n",
      "Total params: 827,858\n",
      "Trainable params: 827,858\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 31.30\n",
      "Params size (MB): 3.16\n",
      "Estimated Total Size (MB): 34.47\n",
      "----------------------------------------------------------------\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 1 Iteration 0: Loss = 4.844089031219482, Number of mined P N = 384 15872\n",
      "Epoch 1 Iteration 100: Loss = 4.782942771911621, Number of mined P N = 384 15528\n",
      "Epoch 1 Iteration 200: Loss = 4.3001251220703125, Number of mined P N = 384 11103\n",
      "Epoch 1 Iteration 300: Loss = 4.374535083770752, Number of mined P N = 384 10945\n",
      "Epoch 1 Iteration 400: Loss = 4.231642723083496, Number of mined P N = 384 9993\n",
      "Epoch 1 Iteration 500: Loss = 4.086115837097168, Number of mined P N = 384 8570\n",
      "Epoch 1 Iteration 600: Loss = 4.1139984130859375, Number of mined P N = 384 9328\n",
      "Epoch 1 Iteration 700: Loss = 4.13167667388916, Number of mined P N = 384 9654\n",
      "Validation loss:  4.154739184379578\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 2 Iteration 0: Loss = 4.1312642097473145, Number of mined P N = 384 8932\n",
      "Epoch 2 Iteration 100: Loss = 4.091128826141357, Number of mined P N = 384 9085\n",
      "Epoch 2 Iteration 200: Loss = 3.9720730781555176, Number of mined P N = 384 8138\n",
      "Epoch 2 Iteration 300: Loss = 4.1603875160217285, Number of mined P N = 384 10210\n",
      "Epoch 2 Iteration 400: Loss = 3.949509620666504, Number of mined P N = 384 8097\n",
      "Epoch 2 Iteration 500: Loss = 4.045951843261719, Number of mined P N = 384 9180\n",
      "Epoch 2 Iteration 600: Loss = 4.108500003814697, Number of mined P N = 383 9226\n",
      "Epoch 2 Iteration 700: Loss = 4.071112632751465, Number of mined P N = 384 9322\n",
      "Validation loss:  4.004238905906678\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 3 Iteration 0: Loss = 3.980219602584839, Number of mined P N = 384 9181\n",
      "Epoch 3 Iteration 100: Loss = 3.971407413482666, Number of mined P N = 382 7942\n",
      "Epoch 3 Iteration 200: Loss = 4.185750484466553, Number of mined P N = 384 9685\n",
      "Epoch 3 Iteration 300: Loss = 3.9063162803649902, Number of mined P N = 384 8953\n",
      "Epoch 3 Iteration 400: Loss = 4.12302303314209, Number of mined P N = 384 9477\n",
      "Epoch 3 Iteration 500: Loss = 3.8014543056488037, Number of mined P N = 382 8064\n",
      "Epoch 3 Iteration 600: Loss = 3.902174472808838, Number of mined P N = 384 8575\n",
      "Epoch 3 Iteration 700: Loss = 3.8215363025665283, Number of mined P N = 384 7757\n",
      "Validation loss:  3.8999919939041137\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 4 Iteration 0: Loss = 3.867672920227051, Number of mined P N = 384 8356\n",
      "Epoch 4 Iteration 100: Loss = 3.818500518798828, Number of mined P N = 384 7508\n",
      "Epoch 4 Iteration 200: Loss = 3.762922525405884, Number of mined P N = 381 7440\n",
      "Epoch 4 Iteration 300: Loss = 3.7989420890808105, Number of mined P N = 382 7944\n",
      "Epoch 4 Iteration 400: Loss = 3.943021297454834, Number of mined P N = 382 8532\n",
      "Epoch 4 Iteration 500: Loss = 4.108645439147949, Number of mined P N = 384 10531\n",
      "Epoch 4 Iteration 600: Loss = 3.860304832458496, Number of mined P N = 384 7164\n",
      "Epoch 4 Iteration 700: Loss = 3.834582567214966, Number of mined P N = 382 7075\n",
      "Validation loss:  3.837183313369751\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 5 Iteration 0: Loss = 3.874325752258301, Number of mined P N = 384 7568\n",
      "Epoch 5 Iteration 100: Loss = 4.002840995788574, Number of mined P N = 384 9317\n",
      "Epoch 5 Iteration 200: Loss = 3.8052196502685547, Number of mined P N = 382 7588\n",
      "Epoch 5 Iteration 300: Loss = 3.5684151649475098, Number of mined P N = 383 6504\n",
      "Epoch 5 Iteration 400: Loss = 3.96738862991333, Number of mined P N = 384 8543\n",
      "Epoch 5 Iteration 500: Loss = 3.8842387199401855, Number of mined P N = 380 8366\n",
      "Epoch 5 Iteration 600: Loss = 3.827070713043213, Number of mined P N = 384 7882\n",
      "Epoch 5 Iteration 700: Loss = 3.6904375553131104, Number of mined P N = 382 6812\n",
      "Validation loss:  3.759975414276123\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 6 Iteration 0: Loss = 3.7263174057006836, Number of mined P N = 384 7745\n",
      "Epoch 6 Iteration 100: Loss = 3.7377476692199707, Number of mined P N = 382 7059\n",
      "Epoch 6 Iteration 200: Loss = 3.7036635875701904, Number of mined P N = 381 7064\n",
      "Epoch 6 Iteration 300: Loss = 3.973299264907837, Number of mined P N = 384 8618\n",
      "Epoch 6 Iteration 400: Loss = 3.903959274291992, Number of mined P N = 384 8495\n",
      "Epoch 6 Iteration 500: Loss = 3.6454901695251465, Number of mined P N = 382 6195\n",
      "Epoch 6 Iteration 600: Loss = 3.9010798931121826, Number of mined P N = 379 7395\n",
      "Epoch 6 Iteration 700: Loss = 3.964782953262329, Number of mined P N = 384 9175\n",
      "Validation loss:  3.7181272888183594\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 7 Iteration 0: Loss = 3.7479076385498047, Number of mined P N = 383 7062\n",
      "Epoch 7 Iteration 100: Loss = 3.737997055053711, Number of mined P N = 380 7345\n",
      "Epoch 7 Iteration 200: Loss = 3.7029638290405273, Number of mined P N = 384 6785\n",
      "Epoch 7 Iteration 300: Loss = 3.6518118381500244, Number of mined P N = 382 6444\n",
      "Epoch 7 Iteration 400: Loss = 3.782653331756592, Number of mined P N = 384 8110\n",
      "Epoch 7 Iteration 500: Loss = 3.800689697265625, Number of mined P N = 382 7299\n",
      "Epoch 7 Iteration 600: Loss = 3.7455735206604004, Number of mined P N = 382 7571\n",
      "Epoch 7 Iteration 700: Loss = 3.4642233848571777, Number of mined P N = 378 5724\n",
      "Validation loss:  3.656076683998108\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 8 Iteration 0: Loss = 3.661604404449463, Number of mined P N = 379 7107\n",
      "Epoch 8 Iteration 100: Loss = 3.3994715213775635, Number of mined P N = 379 5428\n",
      "Epoch 8 Iteration 200: Loss = 3.606189250946045, Number of mined P N = 374 6837\n",
      "Epoch 8 Iteration 300: Loss = 3.921839475631714, Number of mined P N = 381 9085\n",
      "Epoch 8 Iteration 400: Loss = 3.6667866706848145, Number of mined P N = 382 7374\n",
      "Epoch 8 Iteration 500: Loss = 3.5328445434570312, Number of mined P N = 384 6435\n",
      "Epoch 8 Iteration 600: Loss = 3.9134929180145264, Number of mined P N = 384 7539\n",
      "Epoch 8 Iteration 700: Loss = 3.562903881072998, Number of mined P N = 381 7070\n",
      "Validation loss:  3.671318244934082\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 9 Iteration 0: Loss = 3.7582383155822754, Number of mined P N = 384 6910\n",
      "Epoch 9 Iteration 100: Loss = 3.666653871536255, Number of mined P N = 380 6962\n",
      "Epoch 9 Iteration 200: Loss = 3.623434543609619, Number of mined P N = 374 6490\n",
      "Epoch 9 Iteration 300: Loss = 3.4238505363464355, Number of mined P N = 381 5898\n",
      "Epoch 9 Iteration 400: Loss = 3.6450042724609375, Number of mined P N = 380 7069\n",
      "Epoch 9 Iteration 500: Loss = 3.689690351486206, Number of mined P N = 382 7225\n",
      "Epoch 9 Iteration 600: Loss = 3.642726421356201, Number of mined P N = 384 6760\n",
      "Epoch 9 Iteration 700: Loss = 3.4157891273498535, Number of mined P N = 378 6217\n",
      "Validation loss:  3.597947373390198\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 10 Iteration 0: Loss = 3.6046481132507324, Number of mined P N = 381 7372\n",
      "Epoch 10 Iteration 100: Loss = 3.6178202629089355, Number of mined P N = 381 5858\n",
      "Epoch 10 Iteration 200: Loss = 3.475921154022217, Number of mined P N = 379 6077\n",
      "Epoch 10 Iteration 300: Loss = 3.5613749027252197, Number of mined P N = 383 7024\n",
      "Epoch 10 Iteration 400: Loss = 3.4304986000061035, Number of mined P N = 379 6220\n",
      "Epoch 10 Iteration 500: Loss = 3.6755030155181885, Number of mined P N = 380 6529\n",
      "Epoch 10 Iteration 600: Loss = 3.409079074859619, Number of mined P N = 378 5524\n",
      "Epoch 10 Iteration 700: Loss = 3.544377326965332, Number of mined P N = 381 6211\n",
      "Validation loss:  3.5088230657577513\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 11 Iteration 0: Loss = 3.41268253326416, Number of mined P N = 376 6176\n",
      "Epoch 11 Iteration 100: Loss = 3.8412327766418457, Number of mined P N = 383 7753\n",
      "Epoch 11 Iteration 200: Loss = 3.5913429260253906, Number of mined P N = 377 6353\n",
      "Epoch 11 Iteration 300: Loss = 3.546661138534546, Number of mined P N = 378 5880\n",
      "Epoch 11 Iteration 400: Loss = 3.5066585540771484, Number of mined P N = 381 6193\n",
      "Epoch 11 Iteration 500: Loss = 3.5602164268493652, Number of mined P N = 381 6105\n",
      "Epoch 11 Iteration 600: Loss = 3.6749348640441895, Number of mined P N = 382 6782\n",
      "Epoch 11 Iteration 700: Loss = 3.4486560821533203, Number of mined P N = 379 5972\n",
      "Validation loss:  3.4973705911636355\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 12 Iteration 0: Loss = 3.4554126262664795, Number of mined P N = 374 5540\n",
      "Epoch 12 Iteration 100: Loss = 3.584493398666382, Number of mined P N = 369 6753\n",
      "Epoch 12 Iteration 200: Loss = 3.545778512954712, Number of mined P N = 380 5959\n",
      "Epoch 12 Iteration 300: Loss = 3.477498769760132, Number of mined P N = 384 5850\n",
      "Epoch 12 Iteration 400: Loss = 3.5708189010620117, Number of mined P N = 380 6954\n",
      "Epoch 12 Iteration 500: Loss = 3.4035732746124268, Number of mined P N = 383 5699\n",
      "Epoch 12 Iteration 600: Loss = 3.598141670227051, Number of mined P N = 380 6798\n",
      "Epoch 12 Iteration 700: Loss = 3.3775439262390137, Number of mined P N = 378 5814\n",
      "Validation loss:  3.4623345518112183\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 13 Iteration 0: Loss = 3.4847755432128906, Number of mined P N = 380 5812\n",
      "Epoch 13 Iteration 100: Loss = 3.516385316848755, Number of mined P N = 380 5772\n",
      "Epoch 13 Iteration 200: Loss = 3.2164859771728516, Number of mined P N = 374 4892\n",
      "Epoch 13 Iteration 300: Loss = 3.5082247257232666, Number of mined P N = 378 6102\n",
      "Epoch 13 Iteration 400: Loss = 3.504298448562622, Number of mined P N = 379 6322\n",
      "Epoch 13 Iteration 500: Loss = 3.497445583343506, Number of mined P N = 379 6442\n",
      "Epoch 13 Iteration 600: Loss = 3.4211654663085938, Number of mined P N = 363 5960\n",
      "Epoch 13 Iteration 700: Loss = 3.298199415206909, Number of mined P N = 373 5215\n",
      "Validation loss:  3.427508997917175\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 14 Iteration 0: Loss = 3.4263803958892822, Number of mined P N = 369 5306\n",
      "Epoch 14 Iteration 100: Loss = 3.4040489196777344, Number of mined P N = 375 6471\n",
      "Epoch 14 Iteration 200: Loss = 3.2373833656311035, Number of mined P N = 372 5201\n",
      "Epoch 14 Iteration 300: Loss = 3.4228971004486084, Number of mined P N = 382 5533\n",
      "Epoch 14 Iteration 400: Loss = 3.348930597305298, Number of mined P N = 355 5377\n",
      "Epoch 14 Iteration 500: Loss = 3.4230079650878906, Number of mined P N = 380 5686\n",
      "Epoch 14 Iteration 600: Loss = 3.27595853805542, Number of mined P N = 380 5403\n",
      "Epoch 14 Iteration 700: Loss = 3.492485523223877, Number of mined P N = 378 5887\n",
      "Validation loss:  3.37327428817749\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 15 Iteration 0: Loss = 3.203963279724121, Number of mined P N = 377 5131\n",
      "Epoch 15 Iteration 100: Loss = 3.5974926948547363, Number of mined P N = 381 6513\n",
      "Epoch 15 Iteration 200: Loss = 3.3547916412353516, Number of mined P N = 380 5516\n",
      "Epoch 15 Iteration 300: Loss = 3.3861279487609863, Number of mined P N = 375 5539\n",
      "Epoch 15 Iteration 400: Loss = 3.329862356185913, Number of mined P N = 376 4798\n",
      "Epoch 15 Iteration 500: Loss = 3.1739349365234375, Number of mined P N = 370 4606\n",
      "Epoch 15 Iteration 600: Loss = 3.36252498626709, Number of mined P N = 379 5335\n",
      "Epoch 15 Iteration 700: Loss = 3.456148624420166, Number of mined P N = 373 5637\n",
      "Validation loss:  3.369658417701721\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 16 Iteration 0: Loss = 3.3252763748168945, Number of mined P N = 376 5350\n",
      "Epoch 16 Iteration 100: Loss = 3.4504075050354004, Number of mined P N = 378 6214\n",
      "Epoch 16 Iteration 200: Loss = 3.325223445892334, Number of mined P N = 379 5106\n",
      "Epoch 16 Iteration 300: Loss = 3.2605466842651367, Number of mined P N = 378 4646\n",
      "Epoch 16 Iteration 400: Loss = 3.025827646255493, Number of mined P N = 370 4318\n",
      "Epoch 16 Iteration 500: Loss = 3.3050780296325684, Number of mined P N = 374 5401\n",
      "Epoch 16 Iteration 600: Loss = 3.3192217350006104, Number of mined P N = 378 5222\n",
      "Epoch 16 Iteration 700: Loss = 3.2884936332702637, Number of mined P N = 373 4819\n",
      "Validation loss:  3.368247685432434\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 17 Iteration 0: Loss = 3.278252601623535, Number of mined P N = 372 5083\n",
      "Epoch 17 Iteration 100: Loss = 3.5602264404296875, Number of mined P N = 384 6435\n",
      "Epoch 17 Iteration 200: Loss = 3.394702672958374, Number of mined P N = 380 5810\n",
      "Epoch 17 Iteration 300: Loss = 3.290271759033203, Number of mined P N = 381 5747\n",
      "Epoch 17 Iteration 400: Loss = 3.2763819694519043, Number of mined P N = 366 5270\n",
      "Epoch 17 Iteration 500: Loss = 3.0706450939178467, Number of mined P N = 362 3796\n",
      "Epoch 17 Iteration 600: Loss = 3.407452344894409, Number of mined P N = 372 5200\n",
      "Epoch 17 Iteration 700: Loss = 3.4060070514678955, Number of mined P N = 382 5665\n",
      "Validation loss:  3.3633669805526734\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 18 Iteration 0: Loss = 3.574538230895996, Number of mined P N = 376 6652\n",
      "Epoch 18 Iteration 100: Loss = 3.3921215534210205, Number of mined P N = 373 5614\n",
      "Epoch 18 Iteration 200: Loss = 3.3023459911346436, Number of mined P N = 362 4884\n",
      "Epoch 18 Iteration 300: Loss = 3.216947078704834, Number of mined P N = 372 5213\n",
      "Epoch 18 Iteration 400: Loss = 3.5196409225463867, Number of mined P N = 381 5443\n",
      "Epoch 18 Iteration 500: Loss = 3.3485002517700195, Number of mined P N = 373 5984\n",
      "Epoch 18 Iteration 600: Loss = 3.488030433654785, Number of mined P N = 372 6266\n",
      "Epoch 18 Iteration 700: Loss = 3.385693073272705, Number of mined P N = 376 5556\n",
      "Validation loss:  3.3207672739028933\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 19 Iteration 0: Loss = 3.6145713329315186, Number of mined P N = 379 6269\n",
      "Epoch 19 Iteration 100: Loss = 3.389681100845337, Number of mined P N = 378 5117\n",
      "Epoch 19 Iteration 200: Loss = 3.183281660079956, Number of mined P N = 374 4605\n",
      "Epoch 19 Iteration 300: Loss = 3.259516716003418, Number of mined P N = 374 4800\n",
      "Epoch 19 Iteration 400: Loss = 3.3589794635772705, Number of mined P N = 374 5538\n",
      "Epoch 19 Iteration 500: Loss = 3.1894025802612305, Number of mined P N = 376 4661\n",
      "Epoch 19 Iteration 600: Loss = 3.4039182662963867, Number of mined P N = 379 5225\n",
      "Epoch 19 Iteration 700: Loss = 3.155139446258545, Number of mined P N = 373 4765\n",
      "Validation loss:  3.333586974143982\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 20 Iteration 0: Loss = 3.7375192642211914, Number of mined P N = 368 7125\n",
      "Epoch 20 Iteration 100: Loss = 3.3041086196899414, Number of mined P N = 380 5125\n",
      "Epoch 20 Iteration 200: Loss = 3.116671323776245, Number of mined P N = 377 4779\n",
      "Epoch 20 Iteration 300: Loss = 3.148756980895996, Number of mined P N = 370 4838\n",
      "Epoch 20 Iteration 400: Loss = 3.203895330429077, Number of mined P N = 375 4719\n",
      "Epoch 20 Iteration 500: Loss = 3.1226656436920166, Number of mined P N = 371 4853\n",
      "Epoch 20 Iteration 600: Loss = 3.486314296722412, Number of mined P N = 375 5781\n",
      "Epoch 20 Iteration 700: Loss = 3.3234739303588867, Number of mined P N = 367 5709\n",
      "Validation loss:  3.32556782245636\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 21 Iteration 0: Loss = 3.383742570877075, Number of mined P N = 377 5457\n",
      "Epoch 21 Iteration 100: Loss = 3.215837001800537, Number of mined P N = 368 4915\n",
      "Epoch 21 Iteration 200: Loss = 3.4372146129608154, Number of mined P N = 373 5802\n",
      "Epoch 21 Iteration 300: Loss = 3.3790154457092285, Number of mined P N = 371 4999\n",
      "Epoch 21 Iteration 400: Loss = 3.4271278381347656, Number of mined P N = 374 5691\n",
      "Epoch 21 Iteration 500: Loss = 3.264683246612549, Number of mined P N = 373 5247\n",
      "Epoch 21 Iteration 600: Loss = 3.2235071659088135, Number of mined P N = 353 5049\n",
      "Epoch 21 Iteration 700: Loss = 3.525527000427246, Number of mined P N = 381 6635\n",
      "Validation loss:  3.2833649587631224\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 22 Iteration 0: Loss = 3.5078468322753906, Number of mined P N = 372 6150\n",
      "Epoch 22 Iteration 100: Loss = 3.2384586334228516, Number of mined P N = 364 5343\n",
      "Epoch 22 Iteration 200: Loss = 3.0841832160949707, Number of mined P N = 367 4339\n",
      "Epoch 22 Iteration 300: Loss = 3.268254280090332, Number of mined P N = 367 5632\n",
      "Epoch 22 Iteration 400: Loss = 3.353637933731079, Number of mined P N = 368 5417\n",
      "Epoch 22 Iteration 500: Loss = 2.8792502880096436, Number of mined P N = 358 3651\n",
      "Epoch 22 Iteration 600: Loss = 3.383183002471924, Number of mined P N = 375 5421\n",
      "Epoch 22 Iteration 700: Loss = 3.2302968502044678, Number of mined P N = 380 4558\n",
      "Validation loss:  3.2372253847122194\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 23 Iteration 0: Loss = 3.079770565032959, Number of mined P N = 364 4520\n",
      "Epoch 23 Iteration 100: Loss = 3.0590317249298096, Number of mined P N = 378 4156\n",
      "Epoch 23 Iteration 200: Loss = 3.2134623527526855, Number of mined P N = 368 4687\n",
      "Epoch 23 Iteration 300: Loss = 3.3422532081604004, Number of mined P N = 379 5539\n",
      "Epoch 23 Iteration 400: Loss = 3.177802562713623, Number of mined P N = 367 5430\n",
      "Epoch 23 Iteration 500: Loss = 2.9412484169006348, Number of mined P N = 353 3927\n",
      "Epoch 23 Iteration 600: Loss = 3.4693615436553955, Number of mined P N = 377 5411\n",
      "Epoch 23 Iteration 700: Loss = 3.2939181327819824, Number of mined P N = 379 5732\n",
      "Validation loss:  3.280145010948181\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 24 Iteration 0: Loss = 3.2732038497924805, Number of mined P N = 367 5344\n",
      "Epoch 24 Iteration 100: Loss = 3.1908183097839355, Number of mined P N = 362 4735\n",
      "Epoch 24 Iteration 200: Loss = 3.2893314361572266, Number of mined P N = 361 4862\n",
      "Epoch 24 Iteration 300: Loss = 3.1955244541168213, Number of mined P N = 362 4873\n",
      "Epoch 24 Iteration 400: Loss = 3.1752994060516357, Number of mined P N = 370 4347\n",
      "Epoch 24 Iteration 500: Loss = 3.5542187690734863, Number of mined P N = 377 6229\n",
      "Epoch 24 Iteration 600: Loss = 3.2565197944641113, Number of mined P N = 363 4736\n",
      "Epoch 24 Iteration 700: Loss = 3.175792932510376, Number of mined P N = 356 4430\n",
      "Validation loss:  3.2699344110488893\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 25 Iteration 0: Loss = 3.0896620750427246, Number of mined P N = 364 4995\n",
      "Epoch 25 Iteration 100: Loss = 3.2357375621795654, Number of mined P N = 356 4991\n",
      "Epoch 25 Iteration 200: Loss = 3.3931798934936523, Number of mined P N = 378 6216\n",
      "Epoch 25 Iteration 300: Loss = 3.287161111831665, Number of mined P N = 368 5544\n",
      "Epoch 25 Iteration 400: Loss = 3.236959457397461, Number of mined P N = 368 5009\n",
      "Epoch 25 Iteration 500: Loss = 3.200634479522705, Number of mined P N = 377 4506\n",
      "Epoch 25 Iteration 600: Loss = 3.3421902656555176, Number of mined P N = 379 5571\n",
      "Epoch 25 Iteration 700: Loss = 2.9840898513793945, Number of mined P N = 363 4459\n",
      "Validation loss:  3.2193395280838013\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 26 Iteration 0: Loss = 3.063951253890991, Number of mined P N = 354 4225\n",
      "Epoch 26 Iteration 100: Loss = 3.3498339653015137, Number of mined P N = 376 5386\n",
      "Epoch 26 Iteration 200: Loss = 3.031737804412842, Number of mined P N = 370 4231\n",
      "Epoch 26 Iteration 300: Loss = 3.50380802154541, Number of mined P N = 369 5562\n",
      "Epoch 26 Iteration 400: Loss = 3.032066822052002, Number of mined P N = 361 4251\n",
      "Epoch 26 Iteration 500: Loss = 3.30132794380188, Number of mined P N = 369 5637\n",
      "Epoch 26 Iteration 600: Loss = 3.35981822013855, Number of mined P N = 368 5694\n",
      "Epoch 26 Iteration 700: Loss = 3.000187635421753, Number of mined P N = 357 4344\n",
      "Validation loss:  3.2514076089859008\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 27 Iteration 0: Loss = 3.0929884910583496, Number of mined P N = 376 4644\n",
      "Epoch 27 Iteration 100: Loss = 3.158550262451172, Number of mined P N = 366 4830\n",
      "Epoch 27 Iteration 200: Loss = 3.253899574279785, Number of mined P N = 373 5142\n",
      "Epoch 27 Iteration 300: Loss = 3.1777496337890625, Number of mined P N = 354 5355\n",
      "Epoch 27 Iteration 400: Loss = 3.087428092956543, Number of mined P N = 363 4507\n",
      "Epoch 27 Iteration 500: Loss = 3.1616597175598145, Number of mined P N = 376 4758\n",
      "Epoch 27 Iteration 600: Loss = 3.337690830230713, Number of mined P N = 378 5346\n",
      "Epoch 27 Iteration 700: Loss = 3.343721628189087, Number of mined P N = 377 5592\n",
      "Validation loss:  3.2543046474456787\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 28 Iteration 0: Loss = 3.2487611770629883, Number of mined P N = 373 4695\n",
      "Epoch 28 Iteration 100: Loss = 3.11856746673584, Number of mined P N = 354 4956\n",
      "Epoch 28 Iteration 200: Loss = 3.257317066192627, Number of mined P N = 363 4718\n",
      "Epoch 28 Iteration 300: Loss = 3.3859777450561523, Number of mined P N = 377 5389\n",
      "Epoch 28 Iteration 400: Loss = 3.3094522953033447, Number of mined P N = 374 4816\n",
      "Epoch 28 Iteration 500: Loss = 3.1625471115112305, Number of mined P N = 357 4973\n",
      "Epoch 28 Iteration 600: Loss = 2.9201858043670654, Number of mined P N = 362 3956\n",
      "Epoch 28 Iteration 700: Loss = 2.980715036392212, Number of mined P N = 364 3890\n",
      "Validation loss:  3.1456260871887207\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 29 Iteration 0: Loss = 3.2593026161193848, Number of mined P N = 365 5743\n",
      "Epoch 29 Iteration 100: Loss = 3.3298802375793457, Number of mined P N = 368 5447\n",
      "Epoch 29 Iteration 200: Loss = 3.2296652793884277, Number of mined P N = 358 4542\n",
      "Epoch 29 Iteration 300: Loss = 3.1310348510742188, Number of mined P N = 361 4458\n",
      "Epoch 29 Iteration 400: Loss = 3.133474826812744, Number of mined P N = 375 5039\n",
      "Epoch 29 Iteration 500: Loss = 3.2462027072906494, Number of mined P N = 367 4801\n",
      "Epoch 29 Iteration 600: Loss = 3.2746429443359375, Number of mined P N = 373 4800\n",
      "Epoch 29 Iteration 700: Loss = 3.070843458175659, Number of mined P N = 360 4418\n",
      "Validation loss:  3.1686569833755494\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 30 Iteration 0: Loss = 3.086668014526367, Number of mined P N = 369 4754\n",
      "Epoch 30 Iteration 100: Loss = 3.4241433143615723, Number of mined P N = 371 5402\n",
      "Epoch 30 Iteration 200: Loss = 3.0758283138275146, Number of mined P N = 362 4251\n",
      "Epoch 30 Iteration 300: Loss = 3.1659133434295654, Number of mined P N = 371 4349\n",
      "Epoch 30 Iteration 400: Loss = 3.1651337146759033, Number of mined P N = 377 4248\n",
      "Epoch 30 Iteration 500: Loss = 3.1709654331207275, Number of mined P N = 367 4687\n",
      "Epoch 30 Iteration 600: Loss = 3.1436054706573486, Number of mined P N = 372 4633\n",
      "Epoch 30 Iteration 700: Loss = 3.400601625442505, Number of mined P N = 361 5828\n",
      "Validation loss:  3.1427012348175047\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 31 Iteration 0: Loss = 3.122851610183716, Number of mined P N = 374 4666\n",
      "Epoch 31 Iteration 100: Loss = 3.3079674243927, Number of mined P N = 382 5068\n",
      "Epoch 31 Iteration 200: Loss = 2.9270029067993164, Number of mined P N = 354 3639\n",
      "Epoch 31 Iteration 300: Loss = 3.000033378601074, Number of mined P N = 361 4210\n",
      "Epoch 31 Iteration 400: Loss = 3.1713314056396484, Number of mined P N = 354 4497\n",
      "Epoch 31 Iteration 500: Loss = 3.0883209705352783, Number of mined P N = 354 4374\n",
      "Epoch 31 Iteration 600: Loss = 3.204368829727173, Number of mined P N = 359 4607\n",
      "Epoch 31 Iteration 700: Loss = 3.2514851093292236, Number of mined P N = 370 4825\n",
      "Validation loss:  3.170581784248352\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 32 Iteration 0: Loss = 3.439549684524536, Number of mined P N = 368 5531\n",
      "Epoch 32 Iteration 100: Loss = 3.149024486541748, Number of mined P N = 376 4238\n",
      "Epoch 32 Iteration 200: Loss = 3.04384183883667, Number of mined P N = 360 4137\n",
      "Epoch 32 Iteration 300: Loss = 3.279146432876587, Number of mined P N = 371 4886\n",
      "Epoch 32 Iteration 400: Loss = 3.03385591506958, Number of mined P N = 369 4156\n",
      "Epoch 32 Iteration 500: Loss = 3.2815914154052734, Number of mined P N = 369 4890\n",
      "Epoch 32 Iteration 600: Loss = 3.3292653560638428, Number of mined P N = 368 4630\n",
      "Epoch 32 Iteration 700: Loss = 3.2085750102996826, Number of mined P N = 371 4597\n",
      "Validation loss:  3.1776716566085814\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 33 Iteration 0: Loss = 3.2987146377563477, Number of mined P N = 370 4952\n",
      "Epoch 33 Iteration 100: Loss = 2.962937831878662, Number of mined P N = 365 3865\n",
      "Epoch 33 Iteration 200: Loss = 3.0236077308654785, Number of mined P N = 367 3850\n",
      "Epoch 33 Iteration 300: Loss = 3.0196011066436768, Number of mined P N = 361 4319\n",
      "Epoch 33 Iteration 400: Loss = 3.0509955883026123, Number of mined P N = 372 4195\n",
      "Epoch 33 Iteration 500: Loss = 3.2330682277679443, Number of mined P N = 362 4837\n",
      "Epoch 33 Iteration 600: Loss = 2.923396348953247, Number of mined P N = 360 3749\n",
      "Epoch 33 Iteration 700: Loss = 3.3081822395324707, Number of mined P N = 366 5871\n",
      "Validation loss:  3.202527346611023\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 34 Iteration 0: Loss = 3.3233511447906494, Number of mined P N = 363 5063\n",
      "Epoch 34 Iteration 100: Loss = 3.181199312210083, Number of mined P N = 350 4240\n",
      "Epoch 34 Iteration 200: Loss = 2.957928419113159, Number of mined P N = 365 3604\n",
      "Epoch 34 Iteration 300: Loss = 3.093200206756592, Number of mined P N = 359 4519\n",
      "Epoch 34 Iteration 400: Loss = 2.833242177963257, Number of mined P N = 356 3501\n",
      "Epoch 34 Iteration 500: Loss = 2.8075432777404785, Number of mined P N = 372 3613\n",
      "Epoch 34 Iteration 600: Loss = 3.1653544902801514, Number of mined P N = 365 4827\n",
      "Epoch 34 Iteration 700: Loss = 3.107621192932129, Number of mined P N = 348 4825\n",
      "Validation loss:  3.1218159008026123\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 35 Iteration 0: Loss = 3.3723766803741455, Number of mined P N = 362 5266\n",
      "Epoch 35 Iteration 100: Loss = 3.24202823638916, Number of mined P N = 373 5071\n",
      "Epoch 35 Iteration 200: Loss = 3.0523881912231445, Number of mined P N = 364 4144\n",
      "Epoch 35 Iteration 300: Loss = 3.2225422859191895, Number of mined P N = 379 4551\n",
      "Epoch 35 Iteration 400: Loss = 3.0072696208953857, Number of mined P N = 357 3729\n",
      "Epoch 35 Iteration 500: Loss = 3.10975980758667, Number of mined P N = 366 4409\n",
      "Epoch 35 Iteration 600: Loss = 3.1450324058532715, Number of mined P N = 365 4846\n",
      "Epoch 35 Iteration 700: Loss = 2.946268320083618, Number of mined P N = 338 4062\n",
      "Validation loss:  3.1356322717666627\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 36 Iteration 0: Loss = 2.842867136001587, Number of mined P N = 346 3716\n",
      "Epoch 36 Iteration 100: Loss = 2.8449270725250244, Number of mined P N = 364 3406\n",
      "Epoch 36 Iteration 200: Loss = 3.2146530151367188, Number of mined P N = 370 4793\n",
      "Epoch 36 Iteration 300: Loss = 2.8221986293792725, Number of mined P N = 344 3702\n",
      "Epoch 36 Iteration 400: Loss = 3.1072423458099365, Number of mined P N = 365 4353\n",
      "Epoch 36 Iteration 500: Loss = 3.250669240951538, Number of mined P N = 369 5229\n",
      "Epoch 36 Iteration 600: Loss = 3.111717700958252, Number of mined P N = 373 4330\n",
      "Epoch 36 Iteration 700: Loss = 3.072401523590088, Number of mined P N = 362 4462\n",
      "Validation loss:  3.1582522773742676\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 37 Iteration 0: Loss = 3.0036842823028564, Number of mined P N = 357 3902\n",
      "Epoch 37 Iteration 100: Loss = 2.9880480766296387, Number of mined P N = 368 4218\n",
      "Epoch 37 Iteration 200: Loss = 3.0775797367095947, Number of mined P N = 363 4064\n",
      "Epoch 37 Iteration 300: Loss = 3.0455000400543213, Number of mined P N = 362 3974\n",
      "Epoch 37 Iteration 400: Loss = 2.9950993061065674, Number of mined P N = 370 4432\n",
      "Epoch 37 Iteration 500: Loss = 3.209763526916504, Number of mined P N = 366 5142\n",
      "Epoch 37 Iteration 600: Loss = 3.0965981483459473, Number of mined P N = 367 4124\n",
      "Epoch 37 Iteration 700: Loss = 3.141690254211426, Number of mined P N = 359 4210\n",
      "Validation loss:  3.1614814376831055\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 38 Iteration 0: Loss = 3.1971936225891113, Number of mined P N = 369 5296\n",
      "Epoch 38 Iteration 100: Loss = 2.93308162689209, Number of mined P N = 375 3748\n",
      "Epoch 38 Iteration 200: Loss = 3.284604787826538, Number of mined P N = 371 5696\n",
      "Epoch 38 Iteration 300: Loss = 2.9512248039245605, Number of mined P N = 358 3968\n",
      "Epoch 38 Iteration 400: Loss = 2.9954395294189453, Number of mined P N = 358 4205\n",
      "Epoch 38 Iteration 500: Loss = 2.849464178085327, Number of mined P N = 336 3976\n",
      "Epoch 38 Iteration 600: Loss = 2.9694931507110596, Number of mined P N = 363 3866\n",
      "Epoch 38 Iteration 700: Loss = 2.9866714477539062, Number of mined P N = 343 4092\n",
      "Validation loss:  3.1070896911621095\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 39 Iteration 0: Loss = 2.891615152359009, Number of mined P N = 356 3797\n",
      "Epoch 39 Iteration 100: Loss = 3.293567657470703, Number of mined P N = 370 4632\n",
      "Epoch 39 Iteration 200: Loss = 3.0359725952148438, Number of mined P N = 365 4028\n",
      "Epoch 39 Iteration 300: Loss = 3.306591510772705, Number of mined P N = 373 5050\n",
      "Epoch 39 Iteration 400: Loss = 3.183455467224121, Number of mined P N = 366 4489\n",
      "Epoch 39 Iteration 500: Loss = 3.2355713844299316, Number of mined P N = 361 4763\n",
      "Epoch 39 Iteration 600: Loss = 3.289788246154785, Number of mined P N = 370 5092\n",
      "Epoch 39 Iteration 700: Loss = 3.070521831512451, Number of mined P N = 366 3939\n",
      "Validation loss:  3.137625913619995\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 40 Iteration 0: Loss = 2.9272801876068115, Number of mined P N = 347 3581\n",
      "Epoch 40 Iteration 100: Loss = 3.0070996284484863, Number of mined P N = 344 4168\n",
      "Epoch 40 Iteration 200: Loss = 3.1168010234832764, Number of mined P N = 382 4597\n",
      "Epoch 40 Iteration 300: Loss = 2.961348533630371, Number of mined P N = 366 3785\n",
      "Epoch 40 Iteration 400: Loss = 3.107572555541992, Number of mined P N = 366 4383\n",
      "Epoch 40 Iteration 500: Loss = 3.094073534011841, Number of mined P N = 372 4276\n",
      "Epoch 40 Iteration 600: Loss = 3.112034797668457, Number of mined P N = 378 4073\n",
      "Epoch 40 Iteration 700: Loss = 3.1926684379577637, Number of mined P N = 348 4690\n",
      "Validation loss:  3.0855734872817995\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 41 Iteration 0: Loss = 2.985867500305176, Number of mined P N = 356 4000\n",
      "Epoch 41 Iteration 100: Loss = 3.353851795196533, Number of mined P N = 367 5392\n",
      "Epoch 41 Iteration 200: Loss = 3.0203611850738525, Number of mined P N = 350 4032\n",
      "Epoch 41 Iteration 300: Loss = 3.3932406902313232, Number of mined P N = 365 5094\n",
      "Epoch 41 Iteration 400: Loss = 3.064700126647949, Number of mined P N = 353 4074\n",
      "Epoch 41 Iteration 500: Loss = 2.8825318813323975, Number of mined P N = 359 4155\n",
      "Epoch 41 Iteration 600: Loss = 3.207904815673828, Number of mined P N = 364 5267\n",
      "Epoch 41 Iteration 700: Loss = 2.789954662322998, Number of mined P N = 353 3725\n",
      "Validation loss:  3.0740769720077514\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 42 Iteration 0: Loss = 3.303010940551758, Number of mined P N = 368 4712\n",
      "Epoch 42 Iteration 100: Loss = 3.024139404296875, Number of mined P N = 361 4085\n",
      "Epoch 42 Iteration 200: Loss = 2.86948561668396, Number of mined P N = 359 3767\n",
      "Epoch 42 Iteration 300: Loss = 3.3218472003936768, Number of mined P N = 369 5064\n",
      "Epoch 42 Iteration 400: Loss = 3.038318634033203, Number of mined P N = 361 4330\n",
      "Epoch 42 Iteration 500: Loss = 2.9665956497192383, Number of mined P N = 349 3763\n",
      "Epoch 42 Iteration 600: Loss = 3.2908477783203125, Number of mined P N = 363 5398\n",
      "Epoch 42 Iteration 700: Loss = 3.098684549331665, Number of mined P N = 361 4276\n",
      "Validation loss:  3.020443654060364\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 43 Iteration 0: Loss = 3.1047534942626953, Number of mined P N = 372 4424\n",
      "Epoch 43 Iteration 100: Loss = 3.1515378952026367, Number of mined P N = 366 4576\n",
      "Epoch 43 Iteration 200: Loss = 3.08431077003479, Number of mined P N = 365 4393\n",
      "Epoch 43 Iteration 300: Loss = 3.070666551589966, Number of mined P N = 364 4458\n",
      "Epoch 43 Iteration 400: Loss = 2.915125608444214, Number of mined P N = 349 3972\n",
      "Epoch 43 Iteration 500: Loss = 3.282303810119629, Number of mined P N = 367 5701\n",
      "Epoch 43 Iteration 600: Loss = 3.301623821258545, Number of mined P N = 375 5333\n",
      "Epoch 43 Iteration 700: Loss = 3.359856605529785, Number of mined P N = 367 5713\n",
      "Validation loss:  3.070156569480896\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 44 Iteration 0: Loss = 3.1409811973571777, Number of mined P N = 360 4395\n",
      "Epoch 44 Iteration 100: Loss = 2.9325714111328125, Number of mined P N = 365 3677\n",
      "Epoch 44 Iteration 200: Loss = 2.8365492820739746, Number of mined P N = 359 3727\n",
      "Epoch 44 Iteration 300: Loss = 3.0735549926757812, Number of mined P N = 368 4330\n",
      "Epoch 44 Iteration 400: Loss = 2.7930195331573486, Number of mined P N = 367 3708\n",
      "Epoch 44 Iteration 500: Loss = 3.0819406509399414, Number of mined P N = 357 3968\n",
      "Epoch 44 Iteration 600: Loss = 2.9777779579162598, Number of mined P N = 365 4058\n",
      "Epoch 44 Iteration 700: Loss = 3.0986006259918213, Number of mined P N = 351 3856\n",
      "Validation loss:  3.059218797683716\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 45 Iteration 0: Loss = 3.210080146789551, Number of mined P N = 373 4606\n",
      "Epoch 45 Iteration 100: Loss = 2.8010993003845215, Number of mined P N = 347 3621\n",
      "Epoch 45 Iteration 200: Loss = 3.0756096839904785, Number of mined P N = 366 4498\n",
      "Epoch 45 Iteration 300: Loss = 3.0393056869506836, Number of mined P N = 367 4214\n",
      "Epoch 45 Iteration 400: Loss = 2.863950490951538, Number of mined P N = 343 3205\n",
      "Epoch 45 Iteration 500: Loss = 2.899456024169922, Number of mined P N = 379 3594\n",
      "Epoch 45 Iteration 600: Loss = 2.9929182529449463, Number of mined P N = 344 4475\n",
      "Epoch 45 Iteration 700: Loss = 3.5039615631103516, Number of mined P N = 380 5908\n",
      "Validation loss:  3.062308039665222\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 46 Iteration 0: Loss = 2.9769797325134277, Number of mined P N = 363 3813\n",
      "Epoch 46 Iteration 100: Loss = 2.96620774269104, Number of mined P N = 362 4005\n",
      "Epoch 46 Iteration 200: Loss = 3.1102912425994873, Number of mined P N = 368 4282\n",
      "Epoch 46 Iteration 300: Loss = 2.800265073776245, Number of mined P N = 371 3228\n",
      "Epoch 46 Iteration 400: Loss = 2.917512893676758, Number of mined P N = 351 4015\n",
      "Epoch 46 Iteration 500: Loss = 3.384171962738037, Number of mined P N = 369 5259\n",
      "Epoch 46 Iteration 600: Loss = 3.108408212661743, Number of mined P N = 359 4201\n",
      "Epoch 46 Iteration 700: Loss = 3.187694549560547, Number of mined P N = 344 4508\n",
      "Validation loss:  3.0763588190078734\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 47 Iteration 0: Loss = 3.090681314468384, Number of mined P N = 365 4450\n",
      "Epoch 47 Iteration 100: Loss = 2.9590678215026855, Number of mined P N = 367 3530\n",
      "Epoch 47 Iteration 200: Loss = 3.167724847793579, Number of mined P N = 354 4955\n",
      "Epoch 47 Iteration 300: Loss = 2.8130910396575928, Number of mined P N = 359 3605\n",
      "Epoch 47 Iteration 400: Loss = 2.7798399925231934, Number of mined P N = 363 3302\n",
      "Epoch 47 Iteration 500: Loss = 3.1443381309509277, Number of mined P N = 368 4815\n",
      "Epoch 47 Iteration 600: Loss = 2.9391517639160156, Number of mined P N = 345 3531\n",
      "Epoch 47 Iteration 700: Loss = 3.0859713554382324, Number of mined P N = 359 4369\n",
      "Validation loss:  3.0456087398529053\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 48 Iteration 0: Loss = 2.745588779449463, Number of mined P N = 350 3106\n",
      "Epoch 48 Iteration 100: Loss = 3.0579237937927246, Number of mined P N = 367 4521\n",
      "Epoch 48 Iteration 200: Loss = 3.131762981414795, Number of mined P N = 356 4623\n",
      "Epoch 48 Iteration 300: Loss = 3.0663301944732666, Number of mined P N = 359 4679\n",
      "Epoch 48 Iteration 400: Loss = 3.1410152912139893, Number of mined P N = 359 4110\n",
      "Epoch 48 Iteration 500: Loss = 3.1715288162231445, Number of mined P N = 362 4573\n",
      "Epoch 48 Iteration 600: Loss = 3.3507447242736816, Number of mined P N = 372 5373\n",
      "Epoch 48 Iteration 700: Loss = 2.766491651535034, Number of mined P N = 345 3038\n",
      "Validation loss:  3.05520311832428\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 49 Iteration 0: Loss = 3.141021728515625, Number of mined P N = 366 4755\n",
      "Epoch 49 Iteration 100: Loss = 3.131834030151367, Number of mined P N = 364 5105\n",
      "Epoch 49 Iteration 200: Loss = 2.9520764350891113, Number of mined P N = 371 3750\n",
      "Epoch 49 Iteration 300: Loss = 3.0049664974212646, Number of mined P N = 366 4054\n",
      "Epoch 49 Iteration 400: Loss = 3.2145843505859375, Number of mined P N = 367 5530\n",
      "Epoch 49 Iteration 500: Loss = 3.1756319999694824, Number of mined P N = 364 4470\n",
      "Epoch 49 Iteration 600: Loss = 3.1539626121520996, Number of mined P N = 363 4061\n",
      "Epoch 49 Iteration 700: Loss = 3.185457706451416, Number of mined P N = 372 4766\n",
      "Validation loss:  3.0225192403793333\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 50 Iteration 0: Loss = 3.045715570449829, Number of mined P N = 355 4144\n",
      "Epoch 50 Iteration 100: Loss = 2.9269769191741943, Number of mined P N = 373 3948\n",
      "Epoch 50 Iteration 200: Loss = 3.136584997177124, Number of mined P N = 348 4778\n",
      "Epoch 50 Iteration 300: Loss = 3.121089458465576, Number of mined P N = 361 4537\n",
      "Epoch 50 Iteration 400: Loss = 3.0829901695251465, Number of mined P N = 363 4273\n",
      "Epoch 50 Iteration 500: Loss = 3.000873565673828, Number of mined P N = 350 4299\n",
      "Epoch 50 Iteration 600: Loss = 3.072685956954956, Number of mined P N = 365 4045\n",
      "Epoch 50 Iteration 700: Loss = 3.1784629821777344, Number of mined P N = 372 4449\n",
      "Validation loss:  3.00429940700531\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 51 Iteration 0: Loss = 2.895897150039673, Number of mined P N = 346 4286\n",
      "Epoch 51 Iteration 100: Loss = 2.9736931324005127, Number of mined P N = 351 3912\n",
      "Epoch 51 Iteration 200: Loss = 3.067730665206909, Number of mined P N = 359 4103\n",
      "Epoch 51 Iteration 300: Loss = 2.693229913711548, Number of mined P N = 339 2933\n",
      "Epoch 51 Iteration 400: Loss = 3.2685561180114746, Number of mined P N = 355 5180\n",
      "Epoch 51 Iteration 500: Loss = 2.828488349914551, Number of mined P N = 371 3508\n",
      "Epoch 51 Iteration 600: Loss = 3.1215338706970215, Number of mined P N = 366 4084\n",
      "Epoch 51 Iteration 700: Loss = 2.983893871307373, Number of mined P N = 351 3936\n",
      "Validation loss:  3.034723834991455\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 52 Iteration 0: Loss = 3.005039930343628, Number of mined P N = 376 4413\n",
      "Epoch 52 Iteration 100: Loss = 2.8066964149475098, Number of mined P N = 364 3800\n",
      "Epoch 52 Iteration 200: Loss = 2.8425920009613037, Number of mined P N = 359 3203\n",
      "Epoch 52 Iteration 300: Loss = 3.089111566543579, Number of mined P N = 361 4194\n",
      "Epoch 52 Iteration 400: Loss = 3.146265983581543, Number of mined P N = 371 4272\n",
      "Epoch 52 Iteration 500: Loss = 3.113001585006714, Number of mined P N = 377 4868\n",
      "Epoch 52 Iteration 600: Loss = 3.0092103481292725, Number of mined P N = 354 3618\n",
      "Epoch 52 Iteration 700: Loss = 2.842928647994995, Number of mined P N = 352 4355\n",
      "Validation loss:  3.025586576461792\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 53 Iteration 0: Loss = 3.0844714641571045, Number of mined P N = 372 4221\n",
      "Epoch 53 Iteration 100: Loss = 3.0186853408813477, Number of mined P N = 363 3631\n",
      "Epoch 53 Iteration 200: Loss = 2.7642359733581543, Number of mined P N = 354 3278\n",
      "Epoch 53 Iteration 300: Loss = 3.149069309234619, Number of mined P N = 375 4109\n",
      "Epoch 53 Iteration 400: Loss = 2.817343235015869, Number of mined P N = 360 3473\n",
      "Epoch 53 Iteration 500: Loss = 3.09330415725708, Number of mined P N = 352 4211\n",
      "Epoch 53 Iteration 600: Loss = 2.987391948699951, Number of mined P N = 364 4058\n",
      "Epoch 53 Iteration 700: Loss = 3.0383832454681396, Number of mined P N = 359 4127\n",
      "Validation loss:  3.013830614089966\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 54 Iteration 0: Loss = 2.8742740154266357, Number of mined P N = 353 3557\n",
      "Epoch 54 Iteration 100: Loss = 2.8945305347442627, Number of mined P N = 363 3477\n",
      "Epoch 54 Iteration 200: Loss = 3.0047383308410645, Number of mined P N = 358 4266\n",
      "Epoch 54 Iteration 300: Loss = 2.625542402267456, Number of mined P N = 339 2899\n",
      "Epoch 54 Iteration 400: Loss = 2.9753124713897705, Number of mined P N = 369 4138\n",
      "Epoch 54 Iteration 500: Loss = 2.973902463912964, Number of mined P N = 355 3701\n",
      "Epoch 54 Iteration 600: Loss = 2.9337189197540283, Number of mined P N = 346 4039\n",
      "Epoch 54 Iteration 700: Loss = 3.1905927658081055, Number of mined P N = 362 4439\n",
      "Validation loss:  2.9844846391677855\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 55 Iteration 0: Loss = 3.0460972785949707, Number of mined P N = 347 4206\n",
      "Epoch 55 Iteration 100: Loss = 3.0561280250549316, Number of mined P N = 349 4296\n",
      "Epoch 55 Iteration 200: Loss = 2.9939777851104736, Number of mined P N = 341 4014\n",
      "Epoch 55 Iteration 300: Loss = 2.8911139965057373, Number of mined P N = 361 3699\n",
      "Epoch 55 Iteration 400: Loss = 2.9741291999816895, Number of mined P N = 354 3770\n",
      "Epoch 55 Iteration 500: Loss = 3.284294605255127, Number of mined P N = 375 5139\n",
      "Epoch 55 Iteration 600: Loss = 3.026256799697876, Number of mined P N = 354 4440\n",
      "Epoch 55 Iteration 700: Loss = 2.866223096847534, Number of mined P N = 361 3626\n",
      "Validation loss:  3.0172670221328737\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 56 Iteration 0: Loss = 2.952496290206909, Number of mined P N = 362 3583\n",
      "Epoch 56 Iteration 100: Loss = 2.9584901332855225, Number of mined P N = 363 4012\n",
      "Epoch 56 Iteration 200: Loss = 2.989631175994873, Number of mined P N = 375 4348\n",
      "Epoch 56 Iteration 300: Loss = 2.842813491821289, Number of mined P N = 329 3533\n",
      "Epoch 56 Iteration 400: Loss = 3.2061238288879395, Number of mined P N = 373 4832\n",
      "Epoch 56 Iteration 500: Loss = 2.917161464691162, Number of mined P N = 337 3580\n",
      "Epoch 56 Iteration 600: Loss = 3.2024528980255127, Number of mined P N = 369 4904\n",
      "Epoch 56 Iteration 700: Loss = 3.1844842433929443, Number of mined P N = 360 4531\n",
      "Validation loss:  3.0074560928344725\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 57 Iteration 0: Loss = 3.343665599822998, Number of mined P N = 357 5111\n",
      "Epoch 57 Iteration 100: Loss = 2.898994207382202, Number of mined P N = 358 3726\n",
      "Epoch 57 Iteration 200: Loss = 3.0044827461242676, Number of mined P N = 338 4059\n",
      "Epoch 57 Iteration 300: Loss = 3.0465240478515625, Number of mined P N = 369 4466\n",
      "Epoch 57 Iteration 400: Loss = 3.2469849586486816, Number of mined P N = 376 4622\n",
      "Epoch 57 Iteration 500: Loss = 2.987215042114258, Number of mined P N = 367 4219\n",
      "Epoch 57 Iteration 600: Loss = 3.1166367530822754, Number of mined P N = 370 4560\n",
      "Epoch 57 Iteration 700: Loss = 3.0220999717712402, Number of mined P N = 374 4378\n",
      "Validation loss:  2.9832652378082276\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 58 Iteration 0: Loss = 3.163515567779541, Number of mined P N = 358 4501\n",
      "Epoch 58 Iteration 100: Loss = 2.805419921875, Number of mined P N = 337 3346\n",
      "Epoch 58 Iteration 200: Loss = 3.0788209438323975, Number of mined P N = 369 4534\n",
      "Epoch 58 Iteration 300: Loss = 2.8741660118103027, Number of mined P N = 365 3767\n",
      "Epoch 58 Iteration 400: Loss = 2.804119825363159, Number of mined P N = 347 3633\n",
      "Epoch 58 Iteration 500: Loss = 2.764765977859497, Number of mined P N = 347 3157\n",
      "Epoch 58 Iteration 600: Loss = 2.9722962379455566, Number of mined P N = 346 3696\n",
      "Epoch 58 Iteration 700: Loss = 3.2176425457000732, Number of mined P N = 368 5116\n",
      "Validation loss:  2.97257474899292\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 59 Iteration 0: Loss = 2.9390769004821777, Number of mined P N = 348 3608\n",
      "Epoch 59 Iteration 100: Loss = 2.7999749183654785, Number of mined P N = 352 3729\n",
      "Epoch 59 Iteration 200: Loss = 2.8738369941711426, Number of mined P N = 367 3600\n",
      "Epoch 59 Iteration 300: Loss = 2.921168804168701, Number of mined P N = 354 3942\n",
      "Epoch 59 Iteration 400: Loss = 2.926567554473877, Number of mined P N = 369 3495\n",
      "Epoch 59 Iteration 500: Loss = 3.0490102767944336, Number of mined P N = 369 4344\n",
      "Epoch 59 Iteration 600: Loss = 2.7418160438537598, Number of mined P N = 345 3389\n",
      "Epoch 59 Iteration 700: Loss = 3.0553700923919678, Number of mined P N = 351 4484\n",
      "Validation loss:  2.9956106615066527\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 60 Iteration 0: Loss = 2.75433087348938, Number of mined P N = 359 3649\n",
      "Epoch 60 Iteration 100: Loss = 2.638232707977295, Number of mined P N = 334 2990\n",
      "Epoch 60 Iteration 200: Loss = 2.746936559677124, Number of mined P N = 315 3196\n",
      "Epoch 60 Iteration 300: Loss = 2.7295467853546143, Number of mined P N = 342 3724\n",
      "Epoch 60 Iteration 400: Loss = 2.9292163848876953, Number of mined P N = 333 3601\n",
      "Epoch 60 Iteration 500: Loss = 3.041269063949585, Number of mined P N = 355 4351\n",
      "Epoch 60 Iteration 600: Loss = 3.3411316871643066, Number of mined P N = 368 4699\n",
      "Epoch 60 Iteration 700: Loss = 2.7513020038604736, Number of mined P N = 353 3676\n",
      "Validation loss:  2.9660738134384155\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 61 Iteration 0: Loss = 2.883657693862915, Number of mined P N = 366 3597\n",
      "Epoch 61 Iteration 100: Loss = 3.0754997730255127, Number of mined P N = 363 4098\n",
      "Epoch 61 Iteration 200: Loss = 3.117220401763916, Number of mined P N = 360 4173\n",
      "Epoch 61 Iteration 300: Loss = 2.884679079055786, Number of mined P N = 360 3745\n",
      "Epoch 61 Iteration 400: Loss = 3.0017898082733154, Number of mined P N = 349 4344\n",
      "Epoch 61 Iteration 500: Loss = 3.094459295272827, Number of mined P N = 364 4309\n",
      "Epoch 61 Iteration 600: Loss = 2.874276638031006, Number of mined P N = 351 3819\n",
      "Epoch 61 Iteration 700: Loss = 3.127143383026123, Number of mined P N = 358 4817\n",
      "Validation loss:  2.9815060186386106\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 62 Iteration 0: Loss = 3.086585283279419, Number of mined P N = 362 4259\n",
      "Epoch 62 Iteration 100: Loss = 3.1648786067962646, Number of mined P N = 356 4397\n",
      "Epoch 62 Iteration 200: Loss = 2.852137565612793, Number of mined P N = 348 3246\n",
      "Epoch 62 Iteration 300: Loss = 2.710798740386963, Number of mined P N = 362 3361\n",
      "Epoch 62 Iteration 400: Loss = 2.7484607696533203, Number of mined P N = 348 3703\n",
      "Epoch 62 Iteration 500: Loss = 2.7610349655151367, Number of mined P N = 361 3116\n",
      "Epoch 62 Iteration 600: Loss = 3.01216983795166, Number of mined P N = 358 4205\n",
      "Epoch 62 Iteration 700: Loss = 3.102893352508545, Number of mined P N = 349 4530\n",
      "Validation loss:  2.9580490589141846\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 63 Iteration 0: Loss = 3.2873895168304443, Number of mined P N = 339 4777\n",
      "Epoch 63 Iteration 100: Loss = 2.717799425125122, Number of mined P N = 344 3419\n",
      "Epoch 63 Iteration 200: Loss = 2.865993022918701, Number of mined P N = 357 3501\n",
      "Epoch 63 Iteration 300: Loss = 3.022648811340332, Number of mined P N = 356 4040\n",
      "Epoch 63 Iteration 400: Loss = 2.9149911403656006, Number of mined P N = 353 4181\n",
      "Epoch 63 Iteration 500: Loss = 2.842010259628296, Number of mined P N = 338 4136\n",
      "Epoch 63 Iteration 600: Loss = 2.7831172943115234, Number of mined P N = 342 3521\n",
      "Epoch 63 Iteration 700: Loss = 2.9419054985046387, Number of mined P N = 365 3810\n",
      "Validation loss:  2.9925747966766356\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 64 Iteration 0: Loss = 3.037379264831543, Number of mined P N = 354 3662\n",
      "Epoch 64 Iteration 100: Loss = 2.690291404724121, Number of mined P N = 335 2874\n",
      "Epoch 64 Iteration 200: Loss = 2.9718377590179443, Number of mined P N = 347 3578\n",
      "Epoch 64 Iteration 300: Loss = 2.8841776847839355, Number of mined P N = 355 3693\n",
      "Epoch 64 Iteration 400: Loss = 2.7566494941711426, Number of mined P N = 354 3151\n",
      "Epoch 64 Iteration 500: Loss = 2.8953397274017334, Number of mined P N = 359 3558\n",
      "Epoch 64 Iteration 600: Loss = 3.1395506858825684, Number of mined P N = 364 4581\n",
      "Epoch 64 Iteration 700: Loss = 2.910700798034668, Number of mined P N = 360 3638\n",
      "Validation loss:  2.940677828788757\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 65 Iteration 0: Loss = 3.032667636871338, Number of mined P N = 362 4002\n",
      "Epoch 65 Iteration 100: Loss = 2.889075756072998, Number of mined P N = 334 3972\n",
      "Epoch 65 Iteration 200: Loss = 2.712449073791504, Number of mined P N = 348 3084\n",
      "Epoch 65 Iteration 300: Loss = 2.8709919452667236, Number of mined P N = 362 3875\n",
      "Epoch 65 Iteration 400: Loss = 3.1028847694396973, Number of mined P N = 374 4078\n",
      "Epoch 65 Iteration 500: Loss = 2.586683511734009, Number of mined P N = 352 2893\n",
      "Epoch 65 Iteration 600: Loss = 3.074913740158081, Number of mined P N = 351 4055\n",
      "Epoch 65 Iteration 700: Loss = 3.046152353286743, Number of mined P N = 352 4400\n",
      "Validation loss:  2.965729479789734\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 66 Iteration 0: Loss = 3.037741184234619, Number of mined P N = 351 4269\n",
      "Epoch 66 Iteration 100: Loss = 2.7520620822906494, Number of mined P N = 361 3473\n",
      "Epoch 66 Iteration 200: Loss = 3.2577462196350098, Number of mined P N = 370 4830\n",
      "Epoch 66 Iteration 300: Loss = 2.785761594772339, Number of mined P N = 349 3047\n",
      "Epoch 66 Iteration 400: Loss = 2.9532861709594727, Number of mined P N = 364 3995\n",
      "Epoch 66 Iteration 500: Loss = 2.7744150161743164, Number of mined P N = 357 3183\n",
      "Epoch 66 Iteration 600: Loss = 2.5746283531188965, Number of mined P N = 345 2980\n",
      "Epoch 66 Iteration 700: Loss = 2.9414634704589844, Number of mined P N = 360 3714\n",
      "Validation loss:  2.9588496494293213\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 67 Iteration 0: Loss = 2.698876142501831, Number of mined P N = 348 3453\n",
      "Epoch 67 Iteration 100: Loss = 2.839759111404419, Number of mined P N = 355 3613\n",
      "Epoch 67 Iteration 200: Loss = 2.7309064865112305, Number of mined P N = 344 3195\n",
      "Epoch 67 Iteration 300: Loss = 2.8822147846221924, Number of mined P N = 366 3405\n",
      "Epoch 67 Iteration 400: Loss = 2.9781486988067627, Number of mined P N = 354 3943\n",
      "Epoch 67 Iteration 500: Loss = 3.133992910385132, Number of mined P N = 345 4371\n",
      "Epoch 67 Iteration 600: Loss = 2.947246789932251, Number of mined P N = 339 3348\n",
      "Epoch 67 Iteration 700: Loss = 2.906095504760742, Number of mined P N = 363 3579\n",
      "Validation loss:  2.9679263973236085\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 68 Iteration 0: Loss = 3.2314560413360596, Number of mined P N = 363 4868\n",
      "Epoch 68 Iteration 100: Loss = 2.977461099624634, Number of mined P N = 360 4390\n",
      "Epoch 68 Iteration 200: Loss = 2.919524669647217, Number of mined P N = 360 4006\n",
      "Epoch 68 Iteration 300: Loss = 3.0417356491088867, Number of mined P N = 359 4124\n",
      "Epoch 68 Iteration 400: Loss = 2.699084758758545, Number of mined P N = 342 3020\n",
      "Epoch 68 Iteration 500: Loss = 2.814481019973755, Number of mined P N = 343 3708\n",
      "Epoch 68 Iteration 600: Loss = 2.9837679862976074, Number of mined P N = 367 3922\n",
      "Epoch 68 Iteration 700: Loss = 2.900148630142212, Number of mined P N = 354 3618\n",
      "Validation loss:  2.9375658798217774\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 69 Iteration 0: Loss = 2.8955817222595215, Number of mined P N = 351 3752\n",
      "Epoch 69 Iteration 100: Loss = 2.6073381900787354, Number of mined P N = 329 2858\n",
      "Epoch 69 Iteration 200: Loss = 3.0081095695495605, Number of mined P N = 346 4058\n",
      "Epoch 69 Iteration 300: Loss = 2.947537660598755, Number of mined P N = 344 4155\n",
      "Epoch 69 Iteration 400: Loss = 2.786590814590454, Number of mined P N = 358 3404\n",
      "Epoch 69 Iteration 500: Loss = 2.924245834350586, Number of mined P N = 340 3437\n",
      "Epoch 69 Iteration 600: Loss = 2.8293657302856445, Number of mined P N = 338 3658\n",
      "Epoch 69 Iteration 700: Loss = 2.817365884780884, Number of mined P N = 336 3010\n",
      "Validation loss:  2.9439583110809324\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 70 Iteration 0: Loss = 2.9535341262817383, Number of mined P N = 362 4134\n",
      "Epoch 70 Iteration 100: Loss = 2.823615550994873, Number of mined P N = 343 3219\n",
      "Epoch 70 Iteration 200: Loss = 2.7282135486602783, Number of mined P N = 354 3315\n",
      "Epoch 70 Iteration 300: Loss = 3.021822929382324, Number of mined P N = 371 4478\n",
      "Epoch 70 Iteration 400: Loss = 2.86244535446167, Number of mined P N = 354 3780\n",
      "Epoch 70 Iteration 500: Loss = 2.947073459625244, Number of mined P N = 361 3832\n",
      "Epoch 70 Iteration 600: Loss = 2.8587379455566406, Number of mined P N = 369 3526\n",
      "Epoch 70 Iteration 700: Loss = 2.830773115158081, Number of mined P N = 359 3437\n",
      "Validation loss:  2.8675059127807616\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 71 Iteration 0: Loss = 2.782546043395996, Number of mined P N = 357 3460\n",
      "Epoch 71 Iteration 100: Loss = 2.8759078979492188, Number of mined P N = 364 3730\n",
      "Epoch 71 Iteration 200: Loss = 2.9504997730255127, Number of mined P N = 357 4194\n",
      "Epoch 71 Iteration 300: Loss = 2.9915966987609863, Number of mined P N = 343 3926\n",
      "Epoch 71 Iteration 400: Loss = 2.930232048034668, Number of mined P N = 358 4317\n",
      "Epoch 71 Iteration 500: Loss = 3.1847469806671143, Number of mined P N = 375 4451\n",
      "Epoch 71 Iteration 600: Loss = 3.288691759109497, Number of mined P N = 363 4735\n",
      "Epoch 71 Iteration 700: Loss = 3.1992995738983154, Number of mined P N = 367 4386\n",
      "Validation loss:  2.9308063554763795\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 72 Iteration 0: Loss = 2.873011350631714, Number of mined P N = 352 3420\n",
      "Epoch 72 Iteration 100: Loss = 2.5436298847198486, Number of mined P N = 325 2720\n",
      "Epoch 72 Iteration 200: Loss = 2.8153116703033447, Number of mined P N = 352 4110\n",
      "Epoch 72 Iteration 300: Loss = 2.666783571243286, Number of mined P N = 323 3064\n",
      "Epoch 72 Iteration 400: Loss = 3.204394578933716, Number of mined P N = 356 5068\n",
      "Epoch 72 Iteration 500: Loss = 3.014446496963501, Number of mined P N = 367 4415\n",
      "Epoch 72 Iteration 600: Loss = 2.746756076812744, Number of mined P N = 349 3447\n",
      "Epoch 72 Iteration 700: Loss = 3.188326835632324, Number of mined P N = 376 5036\n",
      "Validation loss:  2.947239179611206\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 73 Iteration 0: Loss = 3.0448193550109863, Number of mined P N = 361 4207\n",
      "Epoch 73 Iteration 100: Loss = 2.6961662769317627, Number of mined P N = 350 3105\n",
      "Epoch 73 Iteration 200: Loss = 2.9378228187561035, Number of mined P N = 363 3991\n",
      "Epoch 73 Iteration 300: Loss = 2.94840669631958, Number of mined P N = 359 4108\n",
      "Epoch 73 Iteration 400: Loss = 2.999739408493042, Number of mined P N = 367 4057\n",
      "Epoch 73 Iteration 500: Loss = 3.075742244720459, Number of mined P N = 360 4273\n",
      "Epoch 73 Iteration 600: Loss = 2.57110857963562, Number of mined P N = 337 3114\n",
      "Epoch 73 Iteration 700: Loss = 2.839351177215576, Number of mined P N = 347 3474\n",
      "Validation loss:  2.9318670320510862\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 74 Iteration 0: Loss = 2.6043217182159424, Number of mined P N = 348 2715\n",
      "Epoch 74 Iteration 100: Loss = 3.100529193878174, Number of mined P N = 374 4219\n",
      "Epoch 74 Iteration 200: Loss = 3.0353140830993652, Number of mined P N = 359 3763\n",
      "Epoch 74 Iteration 300: Loss = 3.093012809753418, Number of mined P N = 363 4568\n",
      "Epoch 74 Iteration 400: Loss = 3.0607097148895264, Number of mined P N = 353 4095\n",
      "Epoch 74 Iteration 500: Loss = 2.7487385272979736, Number of mined P N = 350 3153\n",
      "Epoch 74 Iteration 600: Loss = 3.0117478370666504, Number of mined P N = 350 4371\n",
      "Epoch 74 Iteration 700: Loss = 2.9925665855407715, Number of mined P N = 359 3520\n",
      "Validation loss:  2.8968456411361694\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 75 Iteration 0: Loss = 2.8374171257019043, Number of mined P N = 347 3739\n",
      "Epoch 75 Iteration 100: Loss = 3.0272717475891113, Number of mined P N = 364 4022\n",
      "Epoch 75 Iteration 200: Loss = 3.2467572689056396, Number of mined P N = 371 4993\n",
      "Epoch 75 Iteration 300: Loss = 2.9506101608276367, Number of mined P N = 362 3639\n",
      "Epoch 75 Iteration 400: Loss = 2.9596309661865234, Number of mined P N = 369 4016\n",
      "Epoch 75 Iteration 500: Loss = 2.8682796955108643, Number of mined P N = 365 3529\n",
      "Epoch 75 Iteration 600: Loss = 3.0331320762634277, Number of mined P N = 350 3741\n",
      "Epoch 75 Iteration 700: Loss = 2.8743343353271484, Number of mined P N = 351 3448\n",
      "Validation loss:  2.938512921333313\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 76 Iteration 0: Loss = 2.7537992000579834, Number of mined P N = 320 3251\n",
      "Epoch 76 Iteration 100: Loss = 2.9271955490112305, Number of mined P N = 356 3599\n",
      "Epoch 76 Iteration 200: Loss = 2.8869900703430176, Number of mined P N = 348 3861\n",
      "Epoch 76 Iteration 300: Loss = 2.7668025493621826, Number of mined P N = 354 3483\n",
      "Epoch 76 Iteration 400: Loss = 3.3293309211730957, Number of mined P N = 358 4905\n",
      "Epoch 76 Iteration 500: Loss = 3.058619260787964, Number of mined P N = 371 4297\n",
      "Epoch 76 Iteration 600: Loss = 2.7699642181396484, Number of mined P N = 350 3227\n",
      "Epoch 76 Iteration 700: Loss = 2.7355380058288574, Number of mined P N = 350 3385\n",
      "Validation loss:  2.931774387359619\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 77 Iteration 0: Loss = 2.751819133758545, Number of mined P N = 357 3375\n",
      "Epoch 77 Iteration 100: Loss = 3.127854585647583, Number of mined P N = 374 4262\n",
      "Epoch 77 Iteration 200: Loss = 2.693594455718994, Number of mined P N = 354 2970\n",
      "Epoch 77 Iteration 300: Loss = 2.7225286960601807, Number of mined P N = 345 3134\n",
      "Epoch 77 Iteration 400: Loss = 2.9882779121398926, Number of mined P N = 374 4443\n",
      "Epoch 77 Iteration 500: Loss = 2.777974843978882, Number of mined P N = 341 3166\n",
      "Epoch 77 Iteration 600: Loss = 2.7178924083709717, Number of mined P N = 339 3178\n",
      "Epoch 77 Iteration 700: Loss = 3.105940818786621, Number of mined P N = 362 4021\n",
      "Validation loss:  2.886637263298035\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 78 Iteration 0: Loss = 2.5198609828948975, Number of mined P N = 334 2389\n",
      "Epoch 78 Iteration 100: Loss = 2.8799588680267334, Number of mined P N = 354 3707\n",
      "Epoch 78 Iteration 200: Loss = 2.907789945602417, Number of mined P N = 361 3681\n",
      "Epoch 78 Iteration 300: Loss = 2.830528736114502, Number of mined P N = 352 3701\n",
      "Epoch 78 Iteration 400: Loss = 2.7370519638061523, Number of mined P N = 357 3143\n",
      "Epoch 78 Iteration 500: Loss = 2.800529718399048, Number of mined P N = 346 3396\n",
      "Epoch 78 Iteration 600: Loss = 2.7010300159454346, Number of mined P N = 331 3207\n",
      "Epoch 78 Iteration 700: Loss = 3.155571460723877, Number of mined P N = 363 4144\n",
      "Validation loss:  2.9158287048339844\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 79 Iteration 0: Loss = 2.8486173152923584, Number of mined P N = 352 3656\n",
      "Epoch 79 Iteration 100: Loss = 3.0046980381011963, Number of mined P N = 342 3826\n",
      "Epoch 79 Iteration 200: Loss = 2.856186866760254, Number of mined P N = 358 3591\n",
      "Epoch 79 Iteration 300: Loss = 2.843320608139038, Number of mined P N = 343 3476\n",
      "Epoch 79 Iteration 400: Loss = 2.924532413482666, Number of mined P N = 331 3887\n",
      "Epoch 79 Iteration 500: Loss = 2.873626947402954, Number of mined P N = 348 3441\n",
      "Epoch 79 Iteration 600: Loss = 2.8228278160095215, Number of mined P N = 350 3797\n",
      "Epoch 79 Iteration 700: Loss = 2.886991024017334, Number of mined P N = 338 3415\n",
      "Validation loss:  2.8831571531295777\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 80 Iteration 0: Loss = 2.892326831817627, Number of mined P N = 351 3774\n",
      "Epoch 80 Iteration 100: Loss = 2.7446086406707764, Number of mined P N = 358 3337\n",
      "Epoch 80 Iteration 200: Loss = 3.15338134765625, Number of mined P N = 366 4789\n",
      "Epoch 80 Iteration 300: Loss = 2.9591519832611084, Number of mined P N = 338 3976\n",
      "Epoch 80 Iteration 400: Loss = 2.772237777709961, Number of mined P N = 358 3556\n",
      "Epoch 80 Iteration 500: Loss = 3.011219024658203, Number of mined P N = 350 3569\n",
      "Epoch 80 Iteration 600: Loss = 2.9383275508880615, Number of mined P N = 365 3617\n",
      "Epoch 80 Iteration 700: Loss = 2.882411479949951, Number of mined P N = 336 3398\n",
      "Validation loss:  2.9218781852722167\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 81 Iteration 0: Loss = 2.7182705402374268, Number of mined P N = 359 3450\n",
      "Epoch 81 Iteration 100: Loss = 2.8186933994293213, Number of mined P N = 346 3116\n",
      "Epoch 81 Iteration 200: Loss = 2.734422206878662, Number of mined P N = 360 2914\n",
      "Epoch 81 Iteration 300: Loss = 2.7619073390960693, Number of mined P N = 347 3523\n",
      "Epoch 81 Iteration 400: Loss = 3.004607915878296, Number of mined P N = 364 4454\n",
      "Epoch 81 Iteration 500: Loss = 2.7460646629333496, Number of mined P N = 330 3383\n",
      "Epoch 81 Iteration 600: Loss = 2.8789167404174805, Number of mined P N = 359 3468\n",
      "Epoch 81 Iteration 700: Loss = 2.879706382751465, Number of mined P N = 349 3661\n",
      "Validation loss:  2.8837588262557983\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 82 Iteration 0: Loss = 3.1455609798431396, Number of mined P N = 358 4413\n",
      "Epoch 82 Iteration 100: Loss = 2.5697388648986816, Number of mined P N = 349 2942\n",
      "Epoch 82 Iteration 200: Loss = 2.93878436088562, Number of mined P N = 331 3533\n",
      "Epoch 82 Iteration 300: Loss = 2.7718114852905273, Number of mined P N = 363 3172\n",
      "Epoch 82 Iteration 400: Loss = 3.045729875564575, Number of mined P N = 335 3927\n",
      "Epoch 82 Iteration 500: Loss = 2.5547935962677, Number of mined P N = 333 2687\n",
      "Epoch 82 Iteration 600: Loss = 3.255844831466675, Number of mined P N = 356 4985\n",
      "Epoch 82 Iteration 700: Loss = 2.81449818611145, Number of mined P N = 356 3326\n",
      "Validation loss:  2.8727973318099975\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 83 Iteration 0: Loss = 2.8984344005584717, Number of mined P N = 348 3496\n",
      "Epoch 83 Iteration 100: Loss = 2.922297239303589, Number of mined P N = 353 3841\n",
      "Epoch 83 Iteration 200: Loss = 3.009599208831787, Number of mined P N = 364 4562\n",
      "Epoch 83 Iteration 300: Loss = 2.922999143600464, Number of mined P N = 351 3565\n",
      "Epoch 83 Iteration 400: Loss = 2.776824712753296, Number of mined P N = 346 3422\n",
      "Epoch 83 Iteration 500: Loss = 2.971384048461914, Number of mined P N = 335 3641\n",
      "Epoch 83 Iteration 600: Loss = 2.835085391998291, Number of mined P N = 322 3264\n",
      "Epoch 83 Iteration 700: Loss = 2.9318530559539795, Number of mined P N = 354 3440\n",
      "Validation loss:  2.895639123916626\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 84 Iteration 0: Loss = 2.851951837539673, Number of mined P N = 352 3195\n",
      "Epoch 84 Iteration 100: Loss = 2.9028127193450928, Number of mined P N = 350 3653\n",
      "Epoch 84 Iteration 200: Loss = 2.7627484798431396, Number of mined P N = 352 3197\n",
      "Epoch 84 Iteration 300: Loss = 3.1060631275177, Number of mined P N = 363 4062\n",
      "Epoch 84 Iteration 400: Loss = 3.109370231628418, Number of mined P N = 367 4430\n",
      "Epoch 84 Iteration 500: Loss = 2.726759910583496, Number of mined P N = 355 3148\n",
      "Epoch 84 Iteration 600: Loss = 2.7441165447235107, Number of mined P N = 343 3606\n",
      "Epoch 84 Iteration 700: Loss = 2.940372943878174, Number of mined P N = 361 3724\n",
      "Validation loss:  2.876662321090698\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 85 Iteration 0: Loss = 2.8683242797851562, Number of mined P N = 369 3804\n",
      "Epoch 85 Iteration 100: Loss = 2.832218647003174, Number of mined P N = 347 3515\n",
      "Epoch 85 Iteration 200: Loss = 3.2795767784118652, Number of mined P N = 373 5032\n",
      "Epoch 85 Iteration 300: Loss = 2.8783748149871826, Number of mined P N = 343 3976\n",
      "Epoch 85 Iteration 400: Loss = 2.9849369525909424, Number of mined P N = 351 3632\n",
      "Epoch 85 Iteration 500: Loss = 2.67969012260437, Number of mined P N = 330 3395\n",
      "Epoch 85 Iteration 600: Loss = 3.036658525466919, Number of mined P N = 343 3926\n",
      "Epoch 85 Iteration 700: Loss = 2.9383857250213623, Number of mined P N = 352 3883\n",
      "Validation loss:  2.876980800628662\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 86 Iteration 0: Loss = 2.7968950271606445, Number of mined P N = 352 3149\n",
      "Epoch 86 Iteration 100: Loss = 2.6296029090881348, Number of mined P N = 335 3030\n",
      "Epoch 86 Iteration 200: Loss = 2.855555772781372, Number of mined P N = 352 3497\n",
      "Epoch 86 Iteration 300: Loss = 2.805039882659912, Number of mined P N = 363 3780\n",
      "Epoch 86 Iteration 400: Loss = 2.4460320472717285, Number of mined P N = 347 2379\n",
      "Epoch 86 Iteration 500: Loss = 3.1886627674102783, Number of mined P N = 353 4199\n",
      "Epoch 86 Iteration 600: Loss = 3.0295491218566895, Number of mined P N = 365 4036\n",
      "Epoch 86 Iteration 700: Loss = 3.0011043548583984, Number of mined P N = 364 3809\n",
      "Validation loss:  2.862591209411621\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 87 Iteration 0: Loss = 2.8684096336364746, Number of mined P N = 360 3763\n",
      "Epoch 87 Iteration 100: Loss = 3.032745838165283, Number of mined P N = 352 4197\n",
      "Epoch 87 Iteration 200: Loss = 2.886847972869873, Number of mined P N = 353 3276\n",
      "Epoch 87 Iteration 300: Loss = 3.0147364139556885, Number of mined P N = 364 4279\n",
      "Epoch 87 Iteration 400: Loss = 2.6981546878814697, Number of mined P N = 349 3022\n",
      "Epoch 87 Iteration 500: Loss = 2.7946839332580566, Number of mined P N = 355 3646\n",
      "Epoch 87 Iteration 600: Loss = 2.9254629611968994, Number of mined P N = 365 3459\n",
      "Epoch 87 Iteration 700: Loss = 2.7133758068084717, Number of mined P N = 348 3453\n",
      "Validation loss:  2.857665114402771\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 88 Iteration 0: Loss = 2.8186490535736084, Number of mined P N = 334 3501\n",
      "Epoch 88 Iteration 100: Loss = 2.678185224533081, Number of mined P N = 338 3158\n",
      "Epoch 88 Iteration 200: Loss = 2.852332592010498, Number of mined P N = 344 3858\n",
      "Epoch 88 Iteration 300: Loss = 2.703909158706665, Number of mined P N = 340 3069\n",
      "Epoch 88 Iteration 400: Loss = 2.7871034145355225, Number of mined P N = 347 3118\n",
      "Epoch 88 Iteration 500: Loss = 2.9669089317321777, Number of mined P N = 349 3836\n",
      "Epoch 88 Iteration 600: Loss = 2.816587209701538, Number of mined P N = 355 3525\n",
      "Epoch 88 Iteration 700: Loss = 2.675274610519409, Number of mined P N = 340 3527\n",
      "Validation loss:  2.868979048728943\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 89 Iteration 0: Loss = 2.9716336727142334, Number of mined P N = 370 3818\n",
      "Epoch 89 Iteration 100: Loss = 2.813974618911743, Number of mined P N = 334 3573\n",
      "Epoch 89 Iteration 200: Loss = 2.8034698963165283, Number of mined P N = 337 3300\n",
      "Epoch 89 Iteration 300: Loss = 2.890822410583496, Number of mined P N = 343 3801\n",
      "Epoch 89 Iteration 400: Loss = 2.5593271255493164, Number of mined P N = 332 2797\n",
      "Epoch 89 Iteration 500: Loss = 2.9758729934692383, Number of mined P N = 365 3816\n",
      "Epoch 89 Iteration 600: Loss = 2.8551714420318604, Number of mined P N = 331 3456\n",
      "Epoch 89 Iteration 700: Loss = 3.048201322555542, Number of mined P N = 363 3816\n",
      "Validation loss:  2.827391753196716\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 90 Iteration 0: Loss = 3.127997875213623, Number of mined P N = 359 4484\n",
      "Epoch 90 Iteration 100: Loss = 2.8452308177948, Number of mined P N = 344 3925\n",
      "Epoch 90 Iteration 200: Loss = 2.7147626876831055, Number of mined P N = 309 3031\n",
      "Epoch 90 Iteration 300: Loss = 2.871025562286377, Number of mined P N = 373 3578\n",
      "Epoch 90 Iteration 400: Loss = 2.875613212585449, Number of mined P N = 355 3567\n",
      "Epoch 90 Iteration 500: Loss = 2.7553765773773193, Number of mined P N = 340 3457\n",
      "Epoch 90 Iteration 600: Loss = 2.894892692565918, Number of mined P N = 359 3680\n",
      "Epoch 90 Iteration 700: Loss = 2.9370014667510986, Number of mined P N = 334 3340\n",
      "Validation loss:  2.8685901880264284\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 91 Iteration 0: Loss = 2.654858350753784, Number of mined P N = 338 3408\n",
      "Epoch 91 Iteration 100: Loss = 2.7397537231445312, Number of mined P N = 355 3357\n",
      "Epoch 91 Iteration 200: Loss = 2.9486241340637207, Number of mined P N = 364 3621\n",
      "Epoch 91 Iteration 300: Loss = 2.7747557163238525, Number of mined P N = 353 3588\n",
      "Epoch 91 Iteration 400: Loss = 2.7657923698425293, Number of mined P N = 362 3824\n",
      "Epoch 91 Iteration 500: Loss = 3.029841899871826, Number of mined P N = 364 4544\n",
      "Epoch 91 Iteration 600: Loss = 2.974379062652588, Number of mined P N = 364 3583\n",
      "Epoch 91 Iteration 700: Loss = 3.0516276359558105, Number of mined P N = 371 4257\n",
      "Validation loss:  2.839555025100708\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 92 Iteration 0: Loss = 2.642958641052246, Number of mined P N = 352 3048\n",
      "Epoch 92 Iteration 100: Loss = 2.8391246795654297, Number of mined P N = 348 3298\n",
      "Epoch 92 Iteration 200: Loss = 2.8893356323242188, Number of mined P N = 356 3822\n",
      "Epoch 92 Iteration 300: Loss = 3.0520403385162354, Number of mined P N = 346 4424\n",
      "Epoch 92 Iteration 400: Loss = 3.0193610191345215, Number of mined P N = 362 3985\n",
      "Epoch 92 Iteration 500: Loss = 2.8997788429260254, Number of mined P N = 352 3575\n",
      "Epoch 92 Iteration 600: Loss = 2.9149515628814697, Number of mined P N = 363 3764\n",
      "Epoch 92 Iteration 700: Loss = 2.7167797088623047, Number of mined P N = 318 3636\n",
      "Validation loss:  2.8720070219039915\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 93 Iteration 0: Loss = 3.141688823699951, Number of mined P N = 370 4758\n",
      "Epoch 93 Iteration 100: Loss = 2.752072811126709, Number of mined P N = 343 3358\n",
      "Epoch 93 Iteration 200: Loss = 2.6875200271606445, Number of mined P N = 331 3302\n",
      "Epoch 93 Iteration 300: Loss = 2.7123851776123047, Number of mined P N = 327 2748\n",
      "Epoch 93 Iteration 400: Loss = 2.769498348236084, Number of mined P N = 345 3341\n",
      "Epoch 93 Iteration 500: Loss = 3.1624808311462402, Number of mined P N = 374 4190\n",
      "Epoch 93 Iteration 600: Loss = 2.461611747741699, Number of mined P N = 323 2577\n",
      "Epoch 93 Iteration 700: Loss = 2.9386534690856934, Number of mined P N = 337 4124\n",
      "Validation loss:  2.8705693912506103\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 94 Iteration 0: Loss = 3.0345163345336914, Number of mined P N = 353 4304\n",
      "Epoch 94 Iteration 100: Loss = 2.9375977516174316, Number of mined P N = 367 4107\n",
      "Epoch 94 Iteration 200: Loss = 2.8901450634002686, Number of mined P N = 370 3475\n",
      "Epoch 94 Iteration 300: Loss = 2.8483943939208984, Number of mined P N = 337 3482\n",
      "Epoch 94 Iteration 400: Loss = 2.8243777751922607, Number of mined P N = 355 3546\n",
      "Epoch 94 Iteration 500: Loss = 2.932178497314453, Number of mined P N = 349 3652\n",
      "Epoch 94 Iteration 600: Loss = 3.085934638977051, Number of mined P N = 377 4162\n",
      "Epoch 94 Iteration 700: Loss = 2.8761978149414062, Number of mined P N = 355 3950\n",
      "Validation loss:  2.86832989692688\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 95 Iteration 0: Loss = 2.6763243675231934, Number of mined P N = 355 3109\n",
      "Epoch 95 Iteration 100: Loss = 2.892571449279785, Number of mined P N = 355 3259\n",
      "Epoch 95 Iteration 200: Loss = 2.742098808288574, Number of mined P N = 343 2981\n",
      "Epoch 95 Iteration 300: Loss = 2.8164796829223633, Number of mined P N = 346 3771\n",
      "Epoch 95 Iteration 400: Loss = 2.9125123023986816, Number of mined P N = 351 3479\n",
      "Epoch 95 Iteration 500: Loss = 2.6114728450775146, Number of mined P N = 333 3014\n",
      "Epoch 95 Iteration 600: Loss = 2.9057745933532715, Number of mined P N = 342 3586\n",
      "Epoch 95 Iteration 700: Loss = 2.7992873191833496, Number of mined P N = 321 3392\n",
      "Validation loss:  2.8373130702972413\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 96 Iteration 0: Loss = 2.963047504425049, Number of mined P N = 352 3822\n",
      "Epoch 96 Iteration 100: Loss = 2.9766225814819336, Number of mined P N = 369 3819\n",
      "Epoch 96 Iteration 200: Loss = 2.7499067783355713, Number of mined P N = 306 3136\n",
      "Epoch 96 Iteration 300: Loss = 2.704688549041748, Number of mined P N = 343 2902\n",
      "Epoch 96 Iteration 400: Loss = 2.994145631790161, Number of mined P N = 359 3900\n",
      "Epoch 96 Iteration 500: Loss = 2.745540142059326, Number of mined P N = 352 2921\n",
      "Epoch 96 Iteration 600: Loss = 2.7397403717041016, Number of mined P N = 334 3451\n",
      "Epoch 96 Iteration 700: Loss = 2.96386981010437, Number of mined P N = 364 3629\n",
      "Validation loss:  2.8574303817749023\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 97 Iteration 0: Loss = 3.0479185581207275, Number of mined P N = 372 4304\n",
      "Epoch 97 Iteration 100: Loss = 2.69281005859375, Number of mined P N = 343 3160\n",
      "Epoch 97 Iteration 200: Loss = 2.685807704925537, Number of mined P N = 350 3465\n",
      "Epoch 97 Iteration 300: Loss = 2.952610492706299, Number of mined P N = 356 4288\n",
      "Epoch 97 Iteration 400: Loss = 2.846982479095459, Number of mined P N = 332 3333\n",
      "Epoch 97 Iteration 500: Loss = 2.6854708194732666, Number of mined P N = 347 3281\n",
      "Epoch 97 Iteration 600: Loss = 2.975156545639038, Number of mined P N = 354 4318\n",
      "Epoch 97 Iteration 700: Loss = 2.8624675273895264, Number of mined P N = 351 3304\n",
      "Validation loss:  2.8294801187515257\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 98 Iteration 0: Loss = 2.777580738067627, Number of mined P N = 345 3052\n",
      "Epoch 98 Iteration 100: Loss = 2.7533631324768066, Number of mined P N = 349 3237\n",
      "Epoch 98 Iteration 200: Loss = 3.082577705383301, Number of mined P N = 365 4528\n",
      "Epoch 98 Iteration 300: Loss = 3.0884196758270264, Number of mined P N = 349 4316\n",
      "Epoch 98 Iteration 400: Loss = 2.8260486125946045, Number of mined P N = 363 3230\n",
      "Epoch 98 Iteration 500: Loss = 2.8079946041107178, Number of mined P N = 337 3346\n",
      "Epoch 98 Iteration 600: Loss = 3.0074987411499023, Number of mined P N = 357 3747\n",
      "Epoch 98 Iteration 700: Loss = 2.8901710510253906, Number of mined P N = 324 3687\n",
      "Validation loss:  2.874737982749939\n",
      "Total number of batches in train_loader: 781\n",
      "Epoch 99 Iteration 0: Loss = 2.635266065597534, Number of mined P N = 343 3234\n",
      "Epoch 99 Iteration 100: Loss = 2.796154737472534, Number of mined P N = 347 3075\n",
      "Epoch 99 Iteration 200: Loss = 2.678286075592041, Number of mined P N = 347 2930\n",
      "Epoch 99 Iteration 300: Loss = 2.9150760173797607, Number of mined P N = 364 3535\n",
      "Epoch 99 Iteration 400: Loss = 2.99242901802063, Number of mined P N = 346 4222\n",
      "Epoch 99 Iteration 500: Loss = 2.759881019592285, Number of mined P N = 341 3496\n",
      "Epoch 99 Iteration 600: Loss = 2.84936261177063, Number of mined P N = 355 3444\n",
      "Epoch 99 Iteration 700: Loss = 2.7850499153137207, Number of mined P N = 358 3460\n",
      "Validation loss:  2.826510400772095\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "feature= \"raw\"\n",
    "sample_len = 500\n",
    "num_epochs=99\n",
    "batch_s= 128\n",
    "\n",
    "from torch.optim import Adam, AdamW, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers, testers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning import losses, miners, samplers, testers, trainers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import losses, regularizers\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "from pytorch_metric_learning.distances import LpDistance, CosineSimilarity,SNRDistance\n",
    "\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "\n",
    "        # Access the data and labels from the HDF5 file\n",
    "        self.x_data = self.h5_file['data']  # EEG data (use memory-mapped access)\n",
    "        self.y_data = self.h5_file['labels'][:]  # Labels (load fully into memory)\n",
    "        self.s_data = self.h5_file['sessions'][:]  # Sessions (load fully into memory)\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Convert to torch tensor\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "\n",
    "    def close(self):\n",
    "        self.h5_file.close()\n",
    "        \n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, h5_file_path):\n",
    "        # Open the HDF5 file\n",
    "        with h5py.File(h5_file_path, 'r') as h5_file:\n",
    "            # Load the data, labels, and sessions fully into memory\n",
    "            #headset_indices= [6, 15, 17, 27, 37, 57, 85, 87, 64, 44, 33, 22, 24, 10]\n",
    "            #headset_indices= [30, 62, 59, 63, 72, 78, 86]\n",
    "            headset_indices= [30, 62, 60, 64, 69, 77, 80]\n",
    "            self.x_data = np.array(h5_file['data'])[:, headset_indices, :]  # Load EEG data into memory\n",
    "            self.y_data = np.array(h5_file['labels'])  # Load labels into memory\n",
    "            self.s_data = np.array(h5_file['sessions'])  # Load sessions into memory\n",
    "\n",
    "        # Create a mapping from original subject labels to new integer labels (starting from 1)\n",
    "        unique_subjects = np.unique(self.y_data)  # Get unique subject labels\n",
    "        self.subject_map = {subject: idx + 1 for idx, subject in enumerate(unique_subjects)}  # Map to range [1, len(unique_subjects)]\n",
    "\n",
    "        # Map the y_data labels using the subject_map\n",
    "        self.y_data_mapped = np.array([self.subject_map[subject] for subject in self.y_data])\n",
    "\n",
    "        # Convert labels to torch tensors\n",
    "        self.targets = torch.tensor(self.y_data_mapped, dtype=torch.long)\n",
    "\n",
    "        # Print the number of unique subjects (labels)\n",
    "        print(f'Number of unique subjects: {len(unique_subjects)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert data and labels into torch tensors\n",
    "        x_tensor = torch.tensor(self.x_data[idx], dtype=torch.float32)  # Fetch EEG data\n",
    "        y_tensor = self.targets[idx]  # Fetch the preloaded label tensor\n",
    "        session = self.s_data[idx]  # Fetch the session info\n",
    "\n",
    "        return x_tensor, y_tensor, session\n",
    "# Usage example\n",
    "h5_file_path_t = f'../Data/train_{feature}.h5'\n",
    "h5_file_path_v = f'../Data/valid_{feature}.h5'\n",
    "train_dataset = EEGDataset(h5_file_path_t)\n",
    "valid_dataset = EEGDataset(h5_file_path_v)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "subject_ids = train_dataset.targets  # Replace with train_dataset.targets\n",
    "session_ids = train_dataset.s_data          # Replace with train_dataset.s_data\n",
    "\n",
    "# Combine subject and session IDs into unique pairs\n",
    "pairs = list(zip(subject_ids.tolist(), session_ids.tolist()))\n",
    "\n",
    "# Create a mapping from pairs to unique IDs\n",
    "unique_pairs = list(set(pairs))  # Get unique pairs\n",
    "pair_to_id = {pair: idx for idx, pair in enumerate(unique_pairs)}\n",
    "\n",
    "# Map each pair to its unique ID\n",
    "unique_ids = torch.tensor([pair_to_id[pair] for pair in pairs])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def validate(model, loader, loss_func, mining_func, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_batches = 0\n",
    "    iteration_count = 0  # Initialize a counter for iterations\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "            if iteration_count >= 50:  # Break the loop after 5 iterations\n",
    "                break\n",
    "            inputs = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            embeddings = model(inputs)\n",
    "            miner_output = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, miner_output)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            iteration_count += 1  # Increment the iteration counter\n",
    "\n",
    "    return val_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class EEGNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet7, self).__init__()\n",
    "        # InstanceNorm1d normalizes each channel across its 500 values for each sample\n",
    "        self.norm = nn.InstanceNorm1d(14, affine=False)  # Normalizes across the 500 values in each of the 93 channels\n",
    "        self.act = nn.ReLU()  # or nn.SELU() , ReLU\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.conv1 = nn.Conv2d(1, 256, (1, 4), padding='same')\n",
    "        self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 192, (4, 1), padding='same')\n",
    "        #self.pool2 = nn.MaxPool2d((2, 1))\n",
    "        self.conv3 = nn.Conv2d(192, 128, (1, 4), padding='same')\n",
    "        #self.pool3 = nn.MaxPool2d((1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 96, (4, 1), padding='same')\n",
    "        #self.pool4 = nn.MaxPool2d((2, 1))\n",
    "        self.conv5 = nn.Conv2d(96, 64, (1, 4), padding='same')\n",
    "        #self.pool5 = nn.MaxPool2d((1, 2))\n",
    "        self.conv6 = nn.Conv2d(64, 32, (4, 1), padding='same')\n",
    "        #self.pool6 = nn.MaxPool2d((2, 1))\n",
    "        self.conv7 = nn.Conv2d(32, 16, (1, 2), padding='same')\n",
    "        self.conv8 = nn.Conv2d(16, 2, (2, 1), padding='same')\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.embedding = nn.Linear(3500, 128)  # Embedding layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        #if x.dim() == 3:\n",
    "            #x = x.unsqueeze(1)  # Adding a channel dimension if input is 3D\n",
    "        x = self.norm(x)  # Apply InstanceNorm along the channel dimension (squeeze to 1D first)\n",
    "        x = x.unsqueeze(1)  # Reshape to 4D again for Conv2d\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        #x = self.pool2(x)\n",
    "        x = self.act(self.conv3(x))\n",
    "        #x = self.pool3(x)\n",
    "        x = self.act(self.conv4(x))\n",
    "        #x = self.pool4(x)\n",
    "        x = self.act(self.conv5(x))\n",
    "        #x = self.pool5(x)\n",
    "        x = self.act(self.conv6(x))\n",
    "        #x = self.pool6(x)\n",
    "        x = self.act(self.conv7(x))\n",
    "        x = self.act(self.conv8(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch, test_loader):\n",
    "    model.train()\n",
    "    total_batches = len(train_loader)\n",
    "    print(f\"Total number of batches in train_loader: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (data, labels, sessions) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use mixed precision training\n",
    "        with autocast():\n",
    "            embeddings = model(data)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        # Scales the loss, and backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscales gradients and optimizer step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}, Number of mined P N = {} {}\".format(\n",
    "                    epoch, batch_idx, loss.item(), mining_func.num_pos_pairs, mining_func.num_neg_pairs  \n",
    "                )\n",
    "            )\n",
    "    val_loss = validate(model, test_loader, loss_func, mining_func, device)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trunk = EEGNet7().to(device)\n",
    "summary(trunk, (7, sample_len)) \n",
    "\n",
    "loss_func = losses.SupConLoss(temperature=0.1).to(device)\n",
    "#loss_func = losses.LiftedStructureLoss().to(device)\n",
    "\n",
    "#sampler = samplers.MPerClassSampler(unique_ids, m=1, batch_size=batch_s)\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, batch_size=batch_s)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_s, sampler=sampler)\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.0001)\n",
    "#mining_func = miners.PairMarginMiner(pos_margin=0.20, neg_margin=0.8)\n",
    "mining_func = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(trunk, loss_func, mining_func, device, train_loader, trunk_optimizer, epoch,valid_loader)\n",
    "    #test(trunk, loss_func, mining_func, device, test_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.save(trunk.state_dict(), '../model/SupConLossLoss128_m4_e99_DSIVR300.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51313506-7688-415a-a931-8ea781feacf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d93eae-27f0-41ff-8b61-8d7d1b01c41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a7d12-4440-4593-91e3-f14b56b909c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3d396-7536-4ba4-a9ec-4e35c9449af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "oml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
