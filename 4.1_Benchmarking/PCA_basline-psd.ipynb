{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e289ac31-794e-4dc4-a63c-28d291e4e536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 70, Number of unique sessions: 19\n",
      "Subject 86, Number of unique sessions: 19\n",
      "Subject 96, Number of unique sessions: 18\n",
      "Subject 125, Number of unique sessions: 19\n",
      "Subject 129, Number of unique sessions: 5\n",
      "Subject 167, Number of unique sessions: 2\n",
      "Subject 174, Number of unique sessions: 19\n",
      "Subject 175, Number of unique sessions: 6\n",
      "Subject 183, Number of unique sessions: 6\n",
      "Subject 194, Number of unique sessions: 19\n",
      "Subject 197, Number of unique sessions: 19\n",
      "Subject 199, Number of unique sessions: 19\n",
      "Subject 201, Number of unique sessions: 19\n",
      "Subject 203, Number of unique sessions: 6\n",
      "Subject 206, Number of unique sessions: 6\n",
      "Subject 207, Number of unique sessions: 41\n",
      "Subject 214, Number of unique sessions: 18\n",
      "Subject 219, Number of unique sessions: 5\n",
      "Subject 230, Number of unique sessions: 6\n",
      "Subject 236, Number of unique sessions: 42\n",
      "Subject 245, Number of unique sessions: 6\n",
      "Subject 250, Number of unique sessions: 41\n",
      "Subject 257, Number of unique sessions: 6\n",
      "Subject 260, Number of unique sessions: 49\n",
      "Subject 261, Number of unique sessions: 10\n",
      "Subject 262, Number of unique sessions: 6\n",
      "Subject 265, Number of unique sessions: 40\n",
      "Subject 268, Number of unique sessions: 19\n",
      "Subject 270, Number of unique sessions: 19\n",
      "Subject 281, Number of unique sessions: 19\n",
      "Subject 291, Number of unique sessions: 19\n",
      "Subject 296, Number of unique sessions: 23\n",
      "Subject 299, Number of unique sessions: 22\n",
      "Subject 303, Number of unique sessions: 21\n",
      "Subject 306, Number of unique sessions: 23\n",
      "Subject 314, Number of unique sessions: 6\n",
      "Subject 322, Number of unique sessions: 21\n",
      "Subject 325, Number of unique sessions: 22\n",
      "Subject 342, Number of unique sessions: 23\n",
      "Subject 348, Number of unique sessions: 23\n",
      "Subject 357, Number of unique sessions: 22\n",
      "Subject 364, Number of unique sessions: 22\n",
      "Subject 374, Number of unique sessions: 20\n",
      "Subject 407, Number of unique sessions: 9\n",
      "Subject 414, Number of unique sessions: 9\n",
      "Subject 415, Number of unique sessions: 9\n",
      "Subject 418, Number of unique sessions: 9\n",
      "Subject 419, Number of unique sessions: 9\n",
      "Subject 422, Number of unique sessions: 8\n",
      "Subject 436, Number of unique sessions: 8\n"
     ]
    }
   ],
   "source": [
    "# import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load test data from test_raw.h5\n",
    "with h5py.File(\"./data/test_psd.h5\", \"r\") as f_test:\n",
    "    X_test = f_test['data'][:]\n",
    "    Y_test = f_test['labels'][:]\n",
    "    S_test = f_test['sessions'][:]\n",
    "    #H_test = f_test['hardwares'][:]  # Load the 'hardwares' dataset as h_test\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, S_combined, and h_combined contain the merged data\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, and S_combined contain the merged data\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Reorder the arrays according to the shuffled indices\n",
    "x_test = X_test[indices]\n",
    "y_test = Y_test[indices]\n",
    "s_test = S_test[indices]\n",
    "#h_test = H_test[indices]\n",
    "\n",
    "\n",
    "# Find unique subjects\n",
    "unique_subjects = np.unique(y_test)\n",
    "\n",
    "# Initialize lists to hold the data for x_test_e and x_test_v\n",
    "x_test_e_list = []\n",
    "y_test_e_list = []\n",
    "s_test_e_list = []\n",
    "h_test_e_list = []\n",
    "\n",
    "x_test_v_list = []\n",
    "y_test_v_list = []\n",
    "s_test_v_list = []\n",
    "h_test_v_list = []\n",
    "\n",
    "# Assign the minimum session for each subject to x_test_e and the rest to x_test_v\n",
    "for subject in unique_subjects:\n",
    "    subject_indices = np.where(y_test == subject)[0]\n",
    "    subject_sessions = s_test[subject_indices]\n",
    "    \n",
    "    # Skip subjects with fewer than two unique sessions\n",
    "    if len(np.unique(subject_sessions)) < 2:\n",
    "        continue\n",
    "\n",
    "    print(f\"Subject {subject}, Number of unique sessions: {len(np.unique(subject_sessions))}\")\n",
    "    \n",
    "    # Assign the minimum session to the evaluation set (x_test_e)\n",
    "    min_session = np.min(subject_sessions)\n",
    "    \n",
    "    # Append data to the evaluation set (min session)\n",
    "    x_test_e_list.extend(x_test[subject_indices][subject_sessions == min_session])\n",
    "    y_test_e_list.extend(y_test[subject_indices][subject_sessions == min_session])\n",
    "    s_test_e_list.extend(s_test[subject_indices][subject_sessions == min_session])\n",
    "    #h_test_e_list.extend(h_test[subject_indices][subject_sessions == min_session])\n",
    "\n",
    "    # Append remaining sessions to the validation set (x_test_v)\n",
    "    x_test_v_list.extend(x_test[subject_indices][subject_sessions != min_session])\n",
    "    y_test_v_list.extend(y_test[subject_indices][subject_sessions != min_session])\n",
    "    s_test_v_list.extend(s_test[subject_indices][subject_sessions != min_session])\n",
    "    #h_test_v_list.extend(h_test[subject_indices][subject_sessions != min_session])\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_e\n",
    "indices_e = np.arange(len(x_test_e_list))\n",
    "np.random.shuffle(indices_e)\n",
    "\n",
    "x_test_e = np.array(x_test_e_list)[indices_e]\n",
    "y_test_e = np.array(y_test_e_list)[indices_e]\n",
    "s_test_e = np.array(s_test_e_list)[indices_e]\n",
    "#h_test_e = np.array(h_test_v_list)[indices_e]\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_v\n",
    "indices_v = np.arange(len(x_test_v_list))\n",
    "np.random.shuffle(indices_v)\n",
    "\n",
    "x_test_v = np.array(x_test_v_list)[indices_v]\n",
    "y_test_v = np.array(y_test_v_list)[indices_v]\n",
    "s_test_v = np.array(s_test_v_list)[indices_v]\n",
    "#h_test_v = np.array(h_test_v_list)[indices_v]\n",
    "# Optional: Save the new test evaluation and validation sets to npy files (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342a14d9-7aa4-46d2-a8ac-bdb6361c2ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 93, 129)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f9712c-552c-493e-9ec2-992a9fdb45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_test, x_test_e_list, x_test_v_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d25af7-6d2e-4d38-b3bd-7d3e528dbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"./data/neg_psd.h5\", \"r\") as f:\n",
    "    x_neg_r = f['data'][:]\n",
    "    y_neg = f['labels'][:]\n",
    "    s_neg = f['sessions'][:]\n",
    "\n",
    "\n",
    "#X_neg_r_reshaped = X_neg_r.reshape(X_neg_r.shape[0], -1)\n",
    "#X_neg_r_scaled = scaler.transform(X_neg_r_reshaped)\n",
    "#X_neg_r = pca.transform(X_neg_r_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5cfa57-b691-4240-a863-e3d9d4ab2f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing channel 1/93...\n",
      "Processing channel 2/93...\n",
      "Processing channel 3/93...\n",
      "Processing channel 4/93...\n",
      "Processing channel 5/93...\n",
      "Processing channel 6/93...\n",
      "Processing channel 7/93...\n",
      "Processing channel 8/93...\n",
      "Processing channel 9/93...\n",
      "Processing channel 10/93...\n",
      "Processing channel 11/93...\n",
      "Processing channel 12/93...\n",
      "Processing channel 13/93...\n",
      "Processing channel 14/93...\n",
      "Processing channel 15/93...\n",
      "Processing channel 16/93...\n",
      "Processing channel 17/93...\n",
      "Processing channel 18/93...\n",
      "Processing channel 19/93...\n",
      "Processing channel 20/93...\n",
      "Processing channel 21/93...\n",
      "Processing channel 22/93...\n",
      "Processing channel 23/93...\n",
      "Processing channel 24/93...\n",
      "Processing channel 25/93...\n",
      "Processing channel 26/93...\n",
      "Processing channel 27/93...\n",
      "Processing channel 28/93...\n",
      "Processing channel 29/93...\n",
      "Processing channel 30/93...\n",
      "Processing channel 31/93...\n",
      "Processing channel 32/93...\n",
      "Processing channel 33/93...\n",
      "Processing channel 34/93...\n",
      "Processing channel 35/93...\n",
      "Processing channel 36/93...\n",
      "Processing channel 37/93...\n",
      "Processing channel 38/93...\n",
      "Processing channel 39/93...\n",
      "Processing channel 40/93...\n",
      "Processing channel 41/93...\n",
      "Processing channel 42/93...\n",
      "Processing channel 43/93...\n",
      "Processing channel 44/93...\n",
      "Processing channel 45/93...\n",
      "Processing channel 46/93...\n",
      "Processing channel 47/93...\n",
      "Processing channel 48/93...\n",
      "Processing channel 49/93...\n",
      "Processing channel 50/93...\n",
      "Processing channel 51/93...\n",
      "Processing channel 52/93...\n",
      "Processing channel 53/93...\n",
      "Processing channel 54/93...\n",
      "Processing channel 55/93...\n",
      "Processing channel 56/93...\n",
      "Processing channel 57/93...\n",
      "Processing channel 58/93...\n",
      "Processing channel 59/93...\n",
      "Processing channel 60/93...\n",
      "Processing channel 61/93...\n",
      "Processing channel 62/93...\n",
      "Processing channel 63/93...\n",
      "Processing channel 64/93...\n",
      "Processing channel 65/93...\n",
      "Processing channel 66/93...\n",
      "Processing channel 67/93...\n",
      "Processing channel 68/93...\n",
      "Processing channel 69/93...\n",
      "Processing channel 70/93...\n",
      "Processing channel 71/93...\n",
      "Processing channel 72/93...\n",
      "Processing channel 73/93...\n",
      "Processing channel 74/93...\n",
      "Processing channel 75/93...\n",
      "Processing channel 76/93...\n",
      "Processing channel 77/93...\n",
      "Processing channel 78/93...\n",
      "Processing channel 79/93...\n",
      "Processing channel 80/93...\n",
      "Processing channel 81/93...\n",
      "Processing channel 82/93...\n",
      "Processing channel 83/93...\n",
      "Processing channel 84/93...\n",
      "Processing channel 85/93...\n",
      "Processing channel 86/93...\n",
      "Processing channel 87/93...\n",
      "Processing channel 88/93...\n",
      "Processing channel 89/93...\n",
      "Processing channel 90/93...\n",
      "Processing channel 91/93...\n",
      "Processing channel 92/93...\n",
      "Processing channel 93/93...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppose x_test_e.shape is (N, C, L) = (100000, 93, 500)\n",
    "# and x_test_v is for verification, shape (M, C, L).\n",
    "\n",
    "############################\n",
    "# Change 1: Define lists to store a separate scaler and PCA for each channel.\n",
    "############################\n",
    "scalers = []\n",
    "pcas = []\n",
    "\n",
    "############################\n",
    "# Change 2: Create empty lists to collect the transformed PCA data \n",
    "# for x_test_e and x_test_v per channel.\n",
    "############################\n",
    "x_test_e_pca_list = []\n",
    "x_test_v_pca_list = []\n",
    "x_test_n_pca_list = []\n",
    "\n",
    "\n",
    "x_test_e_pca_lists = []\n",
    "x_test_v_pca_lists = []\n",
    "x_test_n_pca_lists = []\n",
    "############################\n",
    "# Change 3: Iterate over each channel once, handle both x_test_e and x_test_v,\n",
    "# and add progress output.\n",
    "############################\n",
    "num_channels = x_test_e.shape[1]\n",
    "\n",
    "for ch in range(num_channels):\n",
    "    # ---- Progress Report ----\n",
    "    print(f\"Processing channel {ch+1}/{num_channels}...\")\n",
    "\n",
    "    # Extract data for current channel from x_test_e and x_test_v\n",
    "    channel_data_e = x_test_e[:, ch, :]  # shape (N, L)\n",
    "    channel_data_v = x_test_v[:, ch, :]  # shape (M, L)\n",
    "    channel_data_n = x_neg_r[:, ch, :]\n",
    "    \n",
    "    # 3A. Fit and transform x_test_e for this channel\n",
    "    scaler_ch = StandardScaler()\n",
    "    channel_data_e_scaled = scaler_ch.fit_transform(channel_data_e)\n",
    "    channel_data_v_scaled = scaler_ch.transform(channel_data_v)\n",
    "    channel_data_n_scaled =  scaler_ch.transform(channel_data_n)\n",
    "\n",
    "    pca_ch = PCA(n_components=5)\n",
    "    channel_data_e_pca = pca_ch.fit_transform(channel_data_e_scaled)\n",
    "    channel_data_v_pca = pca_ch.transform(channel_data_v_scaled)\n",
    "    channel_data_n_pca = pca_ch.transform(channel_data_n_scaled)\n",
    "    \n",
    "    # 3C. Save the scaler and PCA objects if needed later (for other data)\n",
    "    #scalers.append(scaler_ch)\n",
    "    #pcas.append(pca_ch)\n",
    "    \n",
    "    # 3D. Collect the PCA-transformed data for each channel\n",
    "    x_test_e_pca_list.append(channel_data_e_pca)\n",
    "    x_test_v_pca_list.append(channel_data_v_pca)\n",
    "    x_test_n_pca_list.append(channel_data_n_pca)\n",
    "\n",
    "############################\n",
    "# Change 4: Stack the list back into single arrays.\n",
    "# Now x_test_e has shape (N, C, 5) and x_test_v has shape (M, C, 5).\n",
    "############################\n",
    "\n",
    "\n",
    "x_test_e = np.stack(x_test_e_pca_list, axis=1)\n",
    "x_test_v = np.stack(x_test_v_pca_list, axis=1)\n",
    "x_test_n = np.stack(x_test_n_pca_list, axis=1)\n",
    "############################\n",
    "# Optional: Inspect explained variance ratio per channel if needed\n",
    "############################\n",
    "# for i, pca_ch in enumerate(pcas):\n",
    "#     print(f\"Channel {i}, PCA explained variance ratio: {pca_ch.explained_variance_ratio_}\")\n",
    "\n",
    "def compute_embedding_batch_two(x_test_batch, embedding_network=None):\n",
    "    print(x_test_batch.shape)\n",
    "    return x_test_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd31a68-7c05-4a91-8781-421c96ce576a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 93, 5), (80643, 93, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_e.shape, x_test_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebcb4fc2-7a49-4626-92c9-196cefd40966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 129)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_data_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743650c9-91f0-47a1-97d4-6359755a11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "\n",
    "def EERf(resutls):\n",
    "    resutls= np.array(resutls)\n",
    "    genuine  = resutls[resutls[:, 1] == 1][:, 0]\n",
    "    impostor = resutls[resutls[:, 1] == 0][:, 0]\n",
    "    stats_a = get_eer_stats(genuine, impostor)\n",
    "    return(stats_a.eer,stats_a.fmr100)\n",
    "\n",
    "def calculate_and_print_averages(y_train, resutls3):\n",
    "    u, counts = np.unique(y_train, return_counts=True)\n",
    "    eer_values = []\n",
    "    ii = 0\n",
    "\n",
    "    for i in resutls3.keys():\n",
    "        re = EERf(resutls3[i])\n",
    "        eer = re[0]\n",
    "        print(f\"{i}: EER = {re[0]:.4f}, FMR100 = {re[1]:.4f}, Count = {counts[ii]}\")\n",
    "        eer_values.append(eer)\n",
    "        ii += 1\n",
    "\n",
    "    average_eer = np.mean(eer_values) * 100\n",
    "    std_eer = np.std(eer_values) * 100\n",
    "    \n",
    "    print(f\"Final Average EER: {average_eer:.4f}\")\n",
    "    print(f\"Final EER Standard Deviation: {std_eer:.4f}\")\n",
    "    print(f\"${average_eer:.2f} \\\\pm {std_eer:.2f}$\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def calculate_similarity_scores_two(enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance):\n",
    "    similarity_results = []\n",
    "    similarity_results_by_class = []\n",
    "    similarity_results_by_class_dict = defaultdict(list)\n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    class_indices = [np.where(y_enrollment == cls)[0] for cls in unique_classes]\n",
    "    print(verification_embeddings.shape, enrollment_embeddings.shape)\n",
    "    if distance == \"cd\":\n",
    "        similarity_matrix = -1 * cd(verification_embeddings, enrollment_embeddings)\n",
    "    elif distance == \"ed\":\n",
    "        similarity_matrix = -1 * ed(verification_embeddings, enrollment_embeddings)\n",
    "\n",
    "    for i in range(similarity_matrix.shape[0]):\n",
    "        current_class = y_verification[i]\n",
    "        predicted_scores = similarity_matrix[i]\n",
    "        same_class_indices = class_indices[np.where(unique_classes == current_class)[0][0]]\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            same_class_indices = class_indices[np.where(unique_classes == cls)[0][0]]\n",
    "            max_score = sum(sorted(predicted_scores[same_class_indices], reverse=True)[:10]) / 10\n",
    "            if current_class == cls:\n",
    "                similarity_results_by_class.append([max_score, 1, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 1, current_class, cls, i, cls])\n",
    "            else:\n",
    "                similarity_results_by_class.append([max_score, 0, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 0, current_class, cls, i, cls])\n",
    "\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def assessment_model_data_two(enrollment_data, ye, verification_data, yv, e_network, distance):\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    similarity_results_by_class, similarity_results_by_class_dict = calculate_similarity_scores_two(\n",
    "        enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance\n",
    "    )\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def compute_embedding_batch_two(x_test_batch, embedding_network=None):\n",
    "    print(x_test_batch.shape)\n",
    "    return x_test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d5743e-32f4-40bc-a92e-443523aa59e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n",
      "70: EER = 0.4818, FMR100 = 0.9367, Count = 100\n",
      "86: EER = 0.3933, FMR100 = 0.7944, Count = 100\n",
      "96: EER = 0.3076, FMR100 = 0.9747, Count = 100\n",
      "125: EER = 0.3150, FMR100 = 0.7633, Count = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129: EER = 0.6025, FMR100 = 0.9750, Count = 100\n",
      "167: EER = 0.6700, FMR100 = 1.0000, Count = 100\n",
      "174: EER = 0.5467, FMR100 = 0.9411, Count = 100\n",
      "175: EER = 0.8622, FMR100 = 0.9060, Count = 100\n",
      "183: EER = 0.5940, FMR100 = 0.9620, Count = 100\n",
      "194: EER = 0.6606, FMR100 = 0.8961, Count = 100\n",
      "197: EER = 0.3844, FMR100 = 0.9117, Count = 100\n",
      "199: EER = 0.4067, FMR100 = 0.9428, Count = 100\n",
      "201: EER = 0.6140, FMR100 = 0.9150, Count = 100\n",
      "203: EER = 0.3440, FMR100 = 0.4780, Count = 100\n",
      "206: EER = 0.8305, FMR100 = 0.9360, Count = 100\n",
      "207: EER = 0.5470, FMR100 = 0.9607, Count = 100\n",
      "214: EER = 0.5475, FMR100 = 0.8976, Count = 100\n",
      "219: EER = 0.4741, FMR100 = 0.6056, Count = 100\n",
      "230: EER = 0.5080, FMR100 = 0.8100, Count = 100\n",
      "236: EER = 0.6217, FMR100 = 0.9837, Count = 100\n",
      "245: EER = 0.4380, FMR100 = 0.8620, Count = 100\n",
      "250: EER = 0.5257, FMR100 = 0.9745, Count = 100\n",
      "257: EER = 0.2260, FMR100 = 1.0000, Count = 100\n",
      "260: EER = 0.4052, FMR100 = 0.9106, Count = 100\n",
      "261: EER = 0.4400, FMR100 = 0.9733, Count = 100\n",
      "262: EER = 0.3500, FMR100 = 0.5560, Count = 100\n",
      "265: EER = 0.2876, FMR100 = 0.9387, Count = 100\n",
      "268: EER = 0.3911, FMR100 = 0.9372, Count = 100\n",
      "270: EER = 0.4907, FMR100 = 0.9744, Count = 100\n",
      "281: EER = 0.3794, FMR100 = 0.8806, Count = 100\n",
      "291: EER = 0.4129, FMR100 = 0.9850, Count = 100\n",
      "296: EER = 0.5383, FMR100 = 1.0000, Count = 100\n",
      "299: EER = 0.4324, FMR100 = 0.9500, Count = 100\n",
      "303: EER = 0.6096, FMR100 = 0.8430, Count = 100\n",
      "306: EER = 0.4214, FMR100 = 0.8636, Count = 100\n",
      "314: EER = 0.4080, FMR100 = 0.7680, Count = 100\n",
      "322: EER = 0.5515, FMR100 = 0.8790, Count = 100\n",
      "325: EER = 0.4587, FMR100 = 0.8100, Count = 100\n",
      "342: EER = 0.2389, FMR100 = 0.8105, Count = 100\n",
      "348: EER = 0.4120, FMR100 = 0.9450, Count = 100\n",
      "357: EER = 0.2582, FMR100 = 0.8333, Count = 100\n",
      "364: EER = 0.3059, FMR100 = 0.9371, Count = 100\n",
      "374: EER = 0.3010, FMR100 = 0.9532, Count = 100\n",
      "407: EER = 0.6526, FMR100 = 0.9875, Count = 100\n",
      "414: EER = 0.2400, FMR100 = 0.6300, Count = 100\n",
      "415: EER = 0.2038, FMR100 = 0.9513, Count = 100\n",
      "418: EER = 0.2875, FMR100 = 0.9038, Count = 100\n",
      "419: EER = 0.2904, FMR100 = 0.9313, Count = 100\n",
      "422: EER = 0.1414, FMR100 = 0.8286, Count = 100\n",
      "436: EER = 0.2600, FMR100 = 0.7214, Count = 100\n",
      "Final Average EER: 44.1394\n",
      "Final EER Standard Deviation: 15.5155\n",
      "$44.14 \\pm 15.52$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"ed\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2777931b-417c-4537-81bd-ba298c885fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n",
      "70: EER = 0.4853, FMR100 = 0.9472, Count = 100\n",
      "86: EER = 0.3928, FMR100 = 0.7950, Count = 100\n",
      "96: EER = 0.3900, FMR100 = 0.9724, Count = 100\n",
      "125: EER = 0.3157, FMR100 = 0.7272, Count = 100\n",
      "129: EER = 0.6035, FMR100 = 0.9775, Count = 100\n",
      "167: EER = 0.6700, FMR100 = 1.0000, Count = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174: EER = 0.5483, FMR100 = 0.9539, Count = 100\n",
      "175: EER = 0.7720, FMR100 = 0.7800, Count = 100\n",
      "183: EER = 0.5940, FMR100 = 0.9620, Count = 100\n",
      "194: EER = 0.6736, FMR100 = 0.8978, Count = 100\n",
      "197: EER = 0.3801, FMR100 = 0.9244, Count = 100\n",
      "199: EER = 0.4006, FMR100 = 0.9461, Count = 100\n",
      "201: EER = 0.6146, FMR100 = 0.9411, Count = 100\n",
      "203: EER = 0.4100, FMR100 = 0.5520, Count = 100\n",
      "206: EER = 0.7360, FMR100 = 0.8520, Count = 100\n",
      "207: EER = 0.5490, FMR100 = 0.9633, Count = 100\n",
      "214: EER = 0.5510, FMR100 = 0.8982, Count = 100\n",
      "219: EER = 0.5388, FMR100 = 0.6207, Count = 100\n",
      "230: EER = 0.5080, FMR100 = 0.8900, Count = 100\n",
      "236: EER = 0.6225, FMR100 = 0.9866, Count = 100\n",
      "245: EER = 0.4400, FMR100 = 0.8840, Count = 100\n",
      "250: EER = 0.5247, FMR100 = 0.9802, Count = 100\n",
      "257: EER = 0.4282, FMR100 = 0.9980, Count = 100\n",
      "260: EER = 0.4067, FMR100 = 0.8933, Count = 100\n",
      "261: EER = 0.4402, FMR100 = 0.9733, Count = 100\n",
      "262: EER = 0.3628, FMR100 = 0.5920, Count = 100\n",
      "265: EER = 0.2580, FMR100 = 0.9372, Count = 100\n",
      "268: EER = 0.3967, FMR100 = 0.9606, Count = 100\n",
      "270: EER = 0.5647, FMR100 = 0.9656, Count = 100\n",
      "281: EER = 0.3818, FMR100 = 0.8839, Count = 100\n",
      "291: EER = 0.4056, FMR100 = 0.9967, Count = 100\n",
      "296: EER = 0.5382, FMR100 = 1.0000, Count = 100\n",
      "299: EER = 0.4312, FMR100 = 0.9614, Count = 100\n",
      "303: EER = 0.6110, FMR100 = 0.9155, Count = 100\n",
      "306: EER = 0.4728, FMR100 = 0.8605, Count = 100\n",
      "314: EER = 0.4540, FMR100 = 0.8060, Count = 100\n",
      "322: EER = 0.5555, FMR100 = 0.8920, Count = 100\n",
      "325: EER = 0.4626, FMR100 = 0.8376, Count = 100\n",
      "342: EER = 0.2618, FMR100 = 0.8123, Count = 100\n",
      "348: EER = 0.4304, FMR100 = 0.9486, Count = 100\n",
      "357: EER = 0.2767, FMR100 = 0.8424, Count = 100\n",
      "364: EER = 0.3334, FMR100 = 0.9400, Count = 100\n",
      "374: EER = 0.3221, FMR100 = 0.9526, Count = 100\n",
      "407: EER = 0.6631, FMR100 = 0.9875, Count = 100\n",
      "414: EER = 0.2512, FMR100 = 0.6475, Count = 100\n",
      "415: EER = 0.2330, FMR100 = 0.9487, Count = 100\n",
      "418: EER = 0.3152, FMR100 = 0.9050, Count = 100\n",
      "419: EER = 0.3253, FMR100 = 0.9363, Count = 100\n",
      "422: EER = 0.1600, FMR100 = 0.8214, Count = 100\n",
      "436: EER = 0.2715, FMR100 = 0.7214, Count = 100\n",
      "Final Average EER: 45.4678\n",
      "Final EER Standard Deviation: 13.8460\n",
      "$45.47 \\pm 13.85$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"cd\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d6238-6ab4-4907-899c-452199065860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a044fd-4897-4c89-80f8-7c9de3f794b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c169d80d-2c6a-451f-8014-ad58ae358173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each array from 3D to 2D\n",
    "x_test_e = x_test_e.reshape(x_test_e.shape[0], -1)\n",
    "x_test_v= x_test_v.reshape(x_test_v.shape[0], -1)\n",
    "x_test_n = x_test_n.reshape(x_test_n.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307153b-9ca9-4d26-8675-e96e95632329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef34723f-9f8f-469f-b1bd-6300870474e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        # Replace RandomForest with Linear SVM + Kernel Approximation\n",
    "        pipeline = Pipeline([\n",
    "            #('scaler', StandardScaler()),\n",
    "            ('kernel_approximation', RBFSampler(gamma=1, random_state=42, n_components=500)),  # Approximate RBF kernel\n",
    "            ('classifier', SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, class_weight='balanced', random_state=42, n_jobs=20))\n",
    "        ])\n",
    "        \n",
    "        # Shuffle and split the data\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        \n",
    "        # Train the pipeline\n",
    "        pipeline.fit(X, y)\n",
    "        \n",
    "        # Predict probabilities for the test set\n",
    "        # Note: SGDClassifier doesn't provide probabilities directly, so we use decision_function\n",
    "        decision_scores = pipeline.decision_function(test_embeddings)\n",
    "        probabilities = 1 / (1 + np.exp(-decision_scores))  # Sigmoid function to map decision scores to probabilities\n",
    "        \n",
    "        # Calculate EER\n",
    "        svm_eer = calculate_eer(test_labels, probabilities)\n",
    "        \n",
    "        print(f\"Class {cls}: Linear SVM with Kernel Approximation EER = {svm_eer:.4f}\")\n",
    "        \n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': svm_eer}\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e318bd-774b-4957-8d9d-57a0be1bfb09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(84408, 465)\n",
      "Unique classes:  [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\n",
      " 230 236 245 250 257 260 261 262 265 268 270 281 291 296 299 303 306 314\n",
      " 322 325 342 348 357 364 374 407 414 415 418 419 422 436]\n",
      "genuine_scores:  1800 0.16522630124900953 impostor_scores 78843 0.10297767674449007\n",
      "Class 70: Linear SVM with Kernel Approximation EER = 0.3661\n",
      "genuine_scores:  1800 0.6902538130781166 impostor_scores 78843 0.5517351313891914\n",
      "Class 86: Linear SVM with Kernel Approximation EER = 0.3528\n",
      "genuine_scores:  1700 0.010009288082925203 impostor_scores 78943 0.011011972538703313\n",
      "Class 96: Linear SVM with Kernel Approximation EER = 0.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.2764774238434562 impostor_scores 78843 0.11844494509959361\n",
      "Class 125: Linear SVM with Kernel Approximation EER = 0.1844\n",
      "genuine_scores:  400 0.2507747930680317 impostor_scores 80243 0.1612508231715818\n",
      "Class 129: Linear SVM with Kernel Approximation EER = 0.4025\n",
      "genuine_scores:  100 0.2436688140641785 impostor_scores 80543 0.12043063444684375\n",
      "Class 167: Linear SVM with Kernel Approximation EER = 0.3339\n",
      "genuine_scores:  1800 0.1962528959489236 impostor_scores 78843 0.15534976056853395\n",
      "Class 174: Linear SVM with Kernel Approximation EER = 0.4407\n",
      "genuine_scores:  500 0.32153946338428196 impostor_scores 80143 0.053563676487589515\n",
      "Class 175: Linear SVM with Kernel Approximation EER = 0.1348\n",
      "genuine_scores:  500 0.7423990907427852 impostor_scores 80143 0.3668967955486746\n",
      "Class 183: Linear SVM with Kernel Approximation EER = 0.1900\n",
      "genuine_scores:  1800 0.14442094575163636 impostor_scores 78843 0.09214396986009903\n",
      "Class 194: Linear SVM with Kernel Approximation EER = 0.3767\n",
      "genuine_scores:  1800 0.507751980943851 impostor_scores 78843 0.3604446397282849\n",
      "Class 197: Linear SVM with Kernel Approximation EER = 0.3844\n",
      "genuine_scores:  1800 0.21025721935907143 impostor_scores 78843 0.13205346020638706\n",
      "Class 199: Linear SVM with Kernel Approximation EER = 0.3890\n",
      "genuine_scores:  1800 0.3171084866812712 impostor_scores 78843 0.12087383955266304\n",
      "Class 201: Linear SVM with Kernel Approximation EER = 0.4044\n",
      "genuine_scores:  500 0.09110640994971643 impostor_scores 80143 0.02597428839976919\n",
      "Class 203: Linear SVM with Kernel Approximation EER = 0.1445\n",
      "genuine_scores:  500 0.27426612769371944 impostor_scores 80143 0.09009305538245772\n",
      "Class 206: Linear SVM with Kernel Approximation EER = 0.3228\n",
      "genuine_scores:  4000 0.3734783605592373 impostor_scores 76643 0.2955639000886732\n",
      "Class 207: Linear SVM with Kernel Approximation EER = 0.4916\n",
      "genuine_scores:  1679 0.4838518964253782 impostor_scores 78964 0.38842163640407373\n",
      "Class 214: Linear SVM with Kernel Approximation EER = 0.3770\n",
      "genuine_scores:  464 0.06101718753632945 impostor_scores 80179 0.028112764285642473\n",
      "Class 219: Linear SVM with Kernel Approximation EER = 0.3771\n",
      "genuine_scores:  500 0.3046311398746701 impostor_scores 80143 0.26870892527196827\n",
      "Class 230: Linear SVM with Kernel Approximation EER = 0.5040\n",
      "genuine_scores:  4100 0.13107981608834127 impostor_scores 76543 0.1054804027629384\n",
      "Class 236: Linear SVM with Kernel Approximation EER = 0.4807\n",
      "genuine_scores:  500 0.4075908829166234 impostor_scores 80143 0.11187538481043485\n",
      "Class 245: Linear SVM with Kernel Approximation EER = 0.0980\n",
      "genuine_scores:  4000 0.3562018174225735 impostor_scores 76643 0.21825300253869004\n",
      "Class 250: Linear SVM with Kernel Approximation EER = 0.3587\n",
      "genuine_scores:  500 0.0034761972384030593 impostor_scores 80143 0.05132320491493812\n",
      "Class 257: Linear SVM with Kernel Approximation EER = 0.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  4800 0.20791577862440533 impostor_scores 75843 0.15586234250284683\n",
      "Class 260: Linear SVM with Kernel Approximation EER = 0.3531\n",
      "genuine_scores:  900 0.17099192877293115 impostor_scores 79743 0.140088148081569\n",
      "Class 261: Linear SVM with Kernel Approximation EER = 0.4290\n",
      "genuine_scores:  500 0.5626999367075899 impostor_scores 80143 0.15875752560058984\n",
      "Class 262: Linear SVM with Kernel Approximation EER = 0.0786\n",
      "genuine_scores:  3900 0.05237151578526442 impostor_scores 76743 0.011336400512537781\n",
      "Class 265: Linear SVM with Kernel Approximation EER = 0.4890\n",
      "genuine_scores:  1800 0.7109454951050874 impostor_scores 78843 0.39056409120502833\n",
      "Class 268: Linear SVM with Kernel Approximation EER = 0.2435\n",
      "genuine_scores:  1800 0.03024019587134244 impostor_scores 78843 0.026240149189372907\n",
      "Class 270: Linear SVM with Kernel Approximation EER = 0.3978\n",
      "genuine_scores:  1800 0.42530899444561965 impostor_scores 78843 0.21688154845825303\n",
      "Class 281: Linear SVM with Kernel Approximation EER = 0.2546\n",
      "genuine_scores:  1800 0.4769630225340041 impostor_scores 78843 0.3358148646275526\n",
      "Class 291: Linear SVM with Kernel Approximation EER = 0.3668\n",
      "genuine_scores:  2200 0.24797464312408712 impostor_scores 78443 0.24059161470592835\n",
      "Class 296: Linear SVM with Kernel Approximation EER = 0.4873\n",
      "genuine_scores:  2100 0.3485563421218364 impostor_scores 78543 0.1967625747785442\n",
      "Class 299: Linear SVM with Kernel Approximation EER = 0.2790\n",
      "genuine_scores:  2000 0.43399527072701705 impostor_scores 78643 0.10539641841324575\n",
      "Class 303: Linear SVM with Kernel Approximation EER = 0.2490\n",
      "genuine_scores:  2200 0.21831335348462347 impostor_scores 78443 0.05184365531968904\n",
      "Class 306: Linear SVM with Kernel Approximation EER = 0.4115\n",
      "genuine_scores:  500 0.45096751826791104 impostor_scores 80143 0.2111344081618255\n",
      "Class 314: Linear SVM with Kernel Approximation EER = 0.1960\n",
      "genuine_scores:  2000 0.4074145411468901 impostor_scores 78643 0.17362809492352752\n",
      "Class 322: Linear SVM with Kernel Approximation EER = 0.2227\n",
      "genuine_scores:  2100 0.3998749412758644 impostor_scores 78543 0.06933344535568332\n",
      "Class 325: Linear SVM with Kernel Approximation EER = 0.1043\n",
      "genuine_scores:  2200 0.7193863315158617 impostor_scores 78443 0.20357417062633226\n",
      "Class 342: Linear SVM with Kernel Approximation EER = 0.0932\n",
      "genuine_scores:  2200 0.263466794469344 impostor_scores 78443 0.07572747528767126\n",
      "Class 348: Linear SVM with Kernel Approximation EER = 0.1673\n",
      "genuine_scores:  2100 0.2423320054412451 impostor_scores 78543 0.09842267243849369\n",
      "Class 357: Linear SVM with Kernel Approximation EER = 0.1820\n",
      "genuine_scores:  2100 0.7765027409621638 impostor_scores 78543 0.39166533442729906\n",
      "Class 364: Linear SVM with Kernel Approximation EER = 0.2086\n",
      "genuine_scores:  1900 0.5872082165189535 impostor_scores 78743 0.21127328213087807\n",
      "Class 374: Linear SVM with Kernel Approximation EER = 0.1842\n",
      "genuine_scores:  800 0.4435682841757734 impostor_scores 79843 0.29456622815766215\n",
      "Class 407: Linear SVM with Kernel Approximation EER = 0.4200\n",
      "genuine_scores:  800 0.25589979265329227 impostor_scores 79843 0.09215781132168792\n",
      "Class 414: Linear SVM with Kernel Approximation EER = 0.0779\n",
      "genuine_scores:  800 0.7396973671459928 impostor_scores 79843 0.18114915911680787\n",
      "Class 415: Linear SVM with Kernel Approximation EER = 0.0375\n",
      "genuine_scores:  800 0.7535137498506116 impostor_scores 79843 0.23514513320642447\n",
      "Class 418: Linear SVM with Kernel Approximation EER = 0.0991\n",
      "genuine_scores:  800 0.5721643561656324 impostor_scores 79843 0.19159899273098024\n",
      "Class 419: Linear SVM with Kernel Approximation EER = 0.1562\n",
      "genuine_scores:  700 0.6575847071658081 impostor_scores 79943 0.17541431748065925\n",
      "Class 422: Linear SVM with Kernel Approximation EER = 0.1100\n",
      "genuine_scores:  700 0.8094391015196485 impostor_scores 79943 0.31433667753723277\n",
      "Class 436: Linear SVM with Kernel Approximation EER = 0.1371\n",
      "Final Average EER RandomForest: 29.1575\n",
      "Final EER Standard Deviation RandomForest: 14.0349\n",
      "$29.16 \\pm 14.03$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'mean': 29.15748275119936, 'std': 14.034930683156327}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c502ff97-a4ac-426c-a03c-38ed5256ef16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b869a-1185-4cb3-85ca-c6c2c4edd79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a443e2-2b15-49f8-9fe9-78b8df937c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def calculate_eer(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Calculate the Equal Error Rate (EER) and FMR100 using pyeer.\n",
    "    \"\"\"\n",
    "    # Separate genuine and impostor scores\n",
    "    genuine_scores = y_scores[y_true == 1]\n",
    "    impostor_scores = y_scores[y_true == 0]\n",
    "    #print(y_true, y_scores)\n",
    "\n",
    "    #print(genuine_scores, impostor_scores)\n",
    "    print(\"genuine_scores: \", len(genuine_scores), sum(genuine_scores)/len(genuine_scores), \"impostor_scores\", len(impostor_scores), sum(impostor_scores)/len(impostor_scores))\n",
    "    \n",
    "    # Use pyeer to compute EER stats\n",
    "    stats = get_eer_stats(genuine_scores, impostor_scores)\n",
    "    \n",
    "    return stats.eer\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            #('scaler', StandardScaler()),\n",
    "            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=20))\n",
    "            #('classifier', SVC(probability=True, random_state=42, class_weight='balanced'))\n",
    "            #('classifier', KNeighborsClassifier(n_neighbors=20, weights='distance'))\n",
    "        ])\n",
    "        #svm_model = SVC(probability=True, random_state=42, class_weight='balanced')\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        pipeline.fit(X, y)\n",
    "        probabilities = pipeline.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "        # Calculate EER\n",
    "        rf_eer = calculate_eer(test_labels, probabilities)\n",
    "\n",
    "        print(f\"Class {cls}: RandomForest EER = {rf_eer:.4f}\")\n",
    "\n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': rf_eer}\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_mean_std(results):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of EER values for each model in the results dictionary.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): A dictionary where keys are classes, and values are dictionaries containing model metrics.\n",
    "                        Example: {cls: {'RandomForest': {'EER': value}}}\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing mean and std for each model across all classes.\n",
    "    \"\"\"\n",
    "    # Extract EER values for each model\n",
    "    model_eer_values = {}\n",
    "    for cls, metrics in results.items():\n",
    "        for model, model_metrics in metrics.items():\n",
    "            if model not in model_eer_values:\n",
    "                model_eer_values[model] = []\n",
    "            model_eer_values[model].append(model_metrics['EER'])\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    model_stats = {}\n",
    "    for model, eer_values in model_eer_values.items():\n",
    "        mean = np.mean(eer_values) * 100\n",
    "        std = np.std(eer_values) * 100\n",
    "        model_stats[model] = {'mean': mean, 'std': std}\n",
    "        print(f\"Final Average EER {model}: {mean:.4f}\")\n",
    "        print(f\"Final EER Standard Deviation {model}: {std:.4f}\")\n",
    "        print(f\"${mean:.2f} \\\\pm {std:.2f}$\") \n",
    "        \n",
    "   \n",
    "    return model_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29c59424-2982-4306-9b6c-93a4e38ff894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(84408, 465)\n",
      "Unique classes:  [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\n",
      " 230 236 245 250 257 260 261 262 265 268 270 281 291 296 299 303 306 314\n",
      " 322 325 342 348 357 364 374 407 414 415 418 419 422 436]\n",
      "genuine_scores:  1800 0.012955555555555583 impostor_scores 78843 0.0006736171885899784\n",
      "Class 70: RandomForest EER = 0.3868\n",
      "genuine_scores:  1800 0.053966666666666926 impostor_scores 78843 0.00041335311949064767\n",
      "Class 86: RandomForest EER = 0.2346\n",
      "genuine_scores:  1700 0.0025176470588235108 impostor_scores 78943 0.00010703925617217393\n",
      "Class 96: RandomForest EER = 0.4014\n",
      "genuine_scores:  1800 0.042411111111111136 impostor_scores 78843 0.00031340765825755673\n",
      "Class 125: RandomForest EER = 0.3412\n",
      "genuine_scores:  400 0.010374999999999968 impostor_scores 80243 0.0009238189000909845\n",
      "Class 129: RandomForest EER = 0.3573\n",
      "genuine_scores:  100 0.0007000000000000001 impostor_scores 80543 0.0006628757309759979\n",
      "Class 167: RandomForest EER = 0.4871\n",
      "genuine_scores:  1800 0.012800000000000011 impostor_scores 78843 0.0002849967657242929\n",
      "Class 174: RandomForest EER = 0.3986\n",
      "genuine_scores:  500 0.28398000000000045 impostor_scores 80143 0.00013126536316334495\n",
      "Class 175: RandomForest EER = 0.0690\n",
      "genuine_scores:  500 0.027279999999999936 impostor_scores 80143 0.0002552936625781432\n",
      "Class 183: RandomForest EER = 0.2787\n",
      "genuine_scores:  1800 0.023538888888888918 impostor_scores 78843 0.00012987836586634077\n",
      "Class 194: RandomForest EER = 0.3596\n",
      "genuine_scores:  1800 0.03277777777777781 impostor_scores 78843 0.0009792879520059054\n",
      "Class 197: RandomForest EER = 0.3244\n",
      "genuine_scores:  1800 0.012172222222222235 impostor_scores 78843 0.0003159443450908866\n",
      "Class 199: RandomForest EER = 0.3730\n",
      "genuine_scores:  1800 0.07358333333333336 impostor_scores 78843 0.0004739799348071571\n",
      "Class 201: RandomForest EER = 0.3002\n",
      "genuine_scores:  500 0.06428000000000016 impostor_scores 80143 0.000181176147636098\n",
      "Class 203: RandomForest EER = 0.2141\n",
      "genuine_scores:  500 0.15270000000000006 impostor_scores 80143 0.0003043310083226244\n",
      "Class 206: RandomForest EER = 0.1571\n",
      "genuine_scores:  4000 0.02521000000000006 impostor_scores 76643 0.000325143848753317\n",
      "Class 207: RandomForest EER = 0.4067\n",
      "genuine_scores:  1679 0.03637284097677184 impostor_scores 78964 0.0005757053847322839\n",
      "Class 214: RandomForest EER = 0.2773\n",
      "genuine_scores:  464 0.012780172413793067 impostor_scores 80179 0.00037977525287170226\n",
      "Class 219: RandomForest EER = 0.2834\n",
      "genuine_scores:  500 0.03865999999999998 impostor_scores 80143 0.0006741699212657325\n",
      "Class 230: RandomForest EER = 0.3254\n",
      "genuine_scores:  4100 0.006319512195121984 impostor_scores 76543 0.0004402754007551449\n",
      "Class 236: RandomForest EER = 0.4318\n",
      "genuine_scores:  500 0.19676000000000007 impostor_scores 80143 0.001280211621726209\n",
      "Class 245: RandomForest EER = 0.0870\n",
      "genuine_scores:  4000 0.015060000000000002 impostor_scores 76643 0.0005674360346019863\n",
      "Class 250: RandomForest EER = 0.4140\n",
      "genuine_scores:  500 2e-05 impostor_scores 80143 0.0016016370737307174\n",
      "Class 257: RandomForest EER = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  4800 0.009529166666666674 impostor_scores 75843 0.0003188165025117739\n",
      "Class 260: RandomForest EER = 0.3856\n",
      "genuine_scores:  900 0.02077777777777777 impostor_scores 79743 0.0010555158446509593\n",
      "Class 261: RandomForest EER = 0.4299\n",
      "genuine_scores:  500 0.29684000000000027 impostor_scores 80143 0.0006165229651997043\n",
      "Class 262: RandomForest EER = 0.0790\n",
      "genuine_scores:  3900 0.021630769230769238 impostor_scores 76743 0.0006760225688336387\n",
      "Class 265: RandomForest EER = 0.4644\n",
      "genuine_scores:  1800 0.04057777777777775 impostor_scores 78843 0.0003178468602158782\n",
      "Class 268: RandomForest EER = 0.3057\n",
      "genuine_scores:  1800 0.03485555555555557 impostor_scores 78843 0.0005911748665068545\n",
      "Class 270: RandomForest EER = 0.4797\n",
      "genuine_scores:  1800 0.0028166666666666505 impostor_scores 78843 0.0002072473142828123\n",
      "Class 281: RandomForest EER = 0.4331\n",
      "genuine_scores:  1800 0.01232222222222223 impostor_scores 78843 0.0005250941744986893\n",
      "Class 291: RandomForest EER = 0.4368\n",
      "genuine_scores:  2200 0.00153636363636363 impostor_scores 78443 0.00022551406753948592\n",
      "Class 296: RandomForest EER = 0.4567\n",
      "genuine_scores:  2100 0.02397619047619051 impostor_scores 78543 0.0004745171434755578\n",
      "Class 299: RandomForest EER = 0.2498\n",
      "genuine_scores:  2000 0.05364000000000024 impostor_scores 78643 0.00025088056152486614\n",
      "Class 303: RandomForest EER = 0.1936\n",
      "genuine_scores:  2200 0.018845454545454565 impostor_scores 78443 8.553981872187436e-05\n",
      "Class 306: RandomForest EER = 0.3951\n",
      "genuine_scores:  500 0.012659999999999972 impostor_scores 80143 0.00023108693210885533\n",
      "Class 314: RandomForest EER = 0.3463\n",
      "genuine_scores:  2000 0.06842500000000029 impostor_scores 78643 0.0005784367330849564\n",
      "Class 322: RandomForest EER = 0.2429\n",
      "genuine_scores:  2100 0.05362857142857158 impostor_scores 78543 0.00029003221165476665\n",
      "Class 325: RandomForest EER = 0.1542\n",
      "genuine_scores:  2200 0.015077272727272809 impostor_scores 78443 0.0002125109952449534\n",
      "Class 342: RandomForest EER = 0.3330\n",
      "genuine_scores:  2200 0.002236363636363625 impostor_scores 78443 0.00021161862753846613\n",
      "Class 348: RandomForest EER = 0.4529\n",
      "genuine_scores:  2100 0.0012428571428571413 impostor_scores 78543 0.00017939218007969956\n",
      "Class 357: RandomForest EER = 0.4763\n",
      "genuine_scores:  2100 0.0014238095238095197 impostor_scores 78543 0.00017557261627388628\n",
      "Class 364: RandomForest EER = 0.4557\n",
      "genuine_scores:  1900 0.09071578947368436 impostor_scores 78743 0.00150095881538681\n",
      "Class 374: RandomForest EER = 0.1494\n",
      "genuine_scores:  800 0.0373625000000001 impostor_scores 79843 0.00029432761795023156\n",
      "Class 407: RandomForest EER = 0.2301\n",
      "genuine_scores:  800 0.022637499999999946 impostor_scores 79843 7.94058339491245e-05\n",
      "Class 414: RandomForest EER = 0.2797\n",
      "genuine_scores:  800 0.2184125 impostor_scores 79843 0.0009925729243640713\n",
      "Class 415: RandomForest EER = 0.0767\n",
      "genuine_scores:  800 0.023437499999999986 impostor_scores 79843 0.0002898187693348207\n",
      "Class 418: RandomForest EER = 0.4140\n",
      "genuine_scores:  800 0.04496250000000002 impostor_scores 79843 0.0007318111794396469\n",
      "Class 419: RandomForest EER = 0.3222\n",
      "genuine_scores:  700 0.16544285714285725 impostor_scores 79943 0.000639580701249639\n",
      "Class 422: RandomForest EER = 0.0747\n",
      "genuine_scores:  700 0.0384714285714286 impostor_scores 79943 0.0004510713883642157\n",
      "Class 436: RandomForest EER = 0.2874\n",
      "Final Average EER RandomForest: 32.0274\n",
      "Final EER Standard Deviation RandomForest: 12.1312\n",
      "$32.03 \\pm 12.13$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'mean': 32.027384391393525, 'std': 12.13123472355051}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a631497-6453-4b27-8c6a-871746cdea35",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1523724180.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    a = [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "a = [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\n",
    " 230 236 245 250 257 260 261 262 265 268 270 281 291 296 299 303 306 314\n",
    " 322 325 342 348 357 364 374 407 414 415 418 419 422 436]\n",
    "\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf85a0-99f4-411d-b0e7-fe83ff59ed18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
