{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d848a9e-99aa-439c-9830-743f2a258de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 70, Number of unique sessions: 19\n",
      "Subject 86, Number of unique sessions: 19\n",
      "Subject 96, Number of unique sessions: 18\n",
      "Subject 125, Number of unique sessions: 19\n",
      "Subject 129, Number of unique sessions: 5\n",
      "Subject 167, Number of unique sessions: 2\n",
      "Subject 174, Number of unique sessions: 19\n",
      "Subject 175, Number of unique sessions: 6\n",
      "Subject 183, Number of unique sessions: 6\n",
      "Subject 194, Number of unique sessions: 19\n",
      "Subject 197, Number of unique sessions: 19\n",
      "Subject 199, Number of unique sessions: 19\n",
      "Subject 201, Number of unique sessions: 19\n",
      "Subject 203, Number of unique sessions: 6\n",
      "Subject 206, Number of unique sessions: 6\n",
      "Subject 207, Number of unique sessions: 41\n",
      "Subject 214, Number of unique sessions: 18\n",
      "Subject 219, Number of unique sessions: 5\n",
      "Subject 230, Number of unique sessions: 6\n",
      "Subject 236, Number of unique sessions: 42\n",
      "Subject 245, Number of unique sessions: 6\n",
      "Subject 250, Number of unique sessions: 41\n",
      "Subject 257, Number of unique sessions: 6\n",
      "Subject 260, Number of unique sessions: 49\n",
      "Subject 261, Number of unique sessions: 10\n",
      "Subject 262, Number of unique sessions: 6\n",
      "Subject 265, Number of unique sessions: 40\n",
      "Subject 268, Number of unique sessions: 19\n",
      "Subject 270, Number of unique sessions: 19\n",
      "Subject 281, Number of unique sessions: 19\n",
      "Subject 291, Number of unique sessions: 19\n",
      "Subject 296, Number of unique sessions: 23\n",
      "Subject 299, Number of unique sessions: 22\n",
      "Subject 303, Number of unique sessions: 21\n",
      "Subject 306, Number of unique sessions: 23\n",
      "Subject 314, Number of unique sessions: 6\n",
      "Subject 322, Number of unique sessions: 21\n",
      "Subject 325, Number of unique sessions: 22\n",
      "Subject 342, Number of unique sessions: 23\n",
      "Subject 348, Number of unique sessions: 23\n",
      "Subject 357, Number of unique sessions: 22\n",
      "Subject 364, Number of unique sessions: 22\n",
      "Subject 374, Number of unique sessions: 20\n",
      "Subject 407, Number of unique sessions: 9\n",
      "Subject 414, Number of unique sessions: 9\n",
      "Subject 415, Number of unique sessions: 9\n",
      "Subject 418, Number of unique sessions: 9\n",
      "Subject 419, Number of unique sessions: 9\n",
      "Subject 422, Number of unique sessions: 8\n",
      "Subject 436, Number of unique sessions: 8\n"
     ]
    }
   ],
   "source": [
    "# import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load test data from test_raw.h5\n",
    "with h5py.File(\"./data/test_psd_bins.h5\", \"r\") as f_test:\n",
    "    X_test = f_test['data'][:]\n",
    "    Y_test = f_test['labels'][:]\n",
    "    S_test = f_test['sessions'][:]\n",
    "    #H_test = f_test['hardwares'][:]  # Load the 'hardwares' dataset as h_test\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, S_combined, and h_combined contain the merged data\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, and S_combined contain the merged data\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Reorder the arrays according to the shuffled indices\n",
    "x_test = X_test[indices]\n",
    "y_test = Y_test[indices]\n",
    "s_test = S_test[indices]\n",
    "#h_test = H_test[indices]\n",
    "\n",
    "\n",
    "# Find unique subjects\n",
    "unique_subjects = np.unique(y_test)\n",
    "\n",
    "# Initialize lists to hold the data for x_test_e and x_test_v\n",
    "x_test_e_list = []\n",
    "y_test_e_list = []\n",
    "s_test_e_list = []\n",
    "h_test_e_list = []\n",
    "\n",
    "x_test_v_list = []\n",
    "y_test_v_list = []\n",
    "s_test_v_list = []\n",
    "h_test_v_list = []\n",
    "\n",
    "# Assign the minimum session for each subject to x_test_e and the rest to x_test_v\n",
    "for subject in unique_subjects:\n",
    "    subject_indices = np.where(y_test == subject)[0]\n",
    "    subject_sessions = s_test[subject_indices]\n",
    "    \n",
    "    # Skip subjects with fewer than two unique sessions\n",
    "    if len(np.unique(subject_sessions)) < 2:\n",
    "        continue\n",
    "\n",
    "    print(f\"Subject {subject}, Number of unique sessions: {len(np.unique(subject_sessions))}\")\n",
    "    \n",
    "    # Assign the minimum session to the evaluation set (x_test_e)\n",
    "    min_session = np.min(subject_sessions)\n",
    "    \n",
    "    # Append data to the evaluation set (min session)\n",
    "    x_test_e_list.extend(x_test[subject_indices][subject_sessions == min_session])\n",
    "    y_test_e_list.extend(y_test[subject_indices][subject_sessions == min_session])\n",
    "    s_test_e_list.extend(s_test[subject_indices][subject_sessions == min_session])\n",
    "    #h_test_e_list.extend(h_test[subject_indices][subject_sessions == min_session])\n",
    "\n",
    "    # Append remaining sessions to the validation set (x_test_v)\n",
    "    x_test_v_list.extend(x_test[subject_indices][subject_sessions != min_session])\n",
    "    y_test_v_list.extend(y_test[subject_indices][subject_sessions != min_session])\n",
    "    s_test_v_list.extend(s_test[subject_indices][subject_sessions != min_session])\n",
    "    #h_test_v_list.extend(h_test[subject_indices][subject_sessions != min_session])\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_e\n",
    "indices_e = np.arange(len(x_test_e_list))\n",
    "np.random.shuffle(indices_e)\n",
    "\n",
    "x_test_e = np.array(x_test_e_list)[indices_e]\n",
    "y_test_e = np.array(y_test_e_list)[indices_e]\n",
    "s_test_e = np.array(s_test_e_list)[indices_e]\n",
    "#h_test_e = np.array(h_test_v_list)[indices_e]\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_v\n",
    "indices_v = np.arange(len(x_test_v_list))\n",
    "np.random.shuffle(indices_v)\n",
    "\n",
    "x_test_v = np.array(x_test_v_list)[indices_v]\n",
    "y_test_v = np.array(y_test_v_list)[indices_v]\n",
    "s_test_v = np.array(s_test_v_list)[indices_v]\n",
    "#h_test_v = np.array(h_test_v_list)[indices_v]\n",
    "# Optional: Save the new test evaluation and validation sets to npy files (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ef094d6-7a5d-4a6d-932b-8a1a54b43162",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"./data/neg_psd_bins.h5\", \"r\") as f:\n",
    "    x_neg_r = f['data'][:]\n",
    "    y_neg = f['labels'][:]\n",
    "    s_neg = f['sessions'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0da2da3f-5365-46c3-bcd4-8b632d9331ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "\n",
    "def EERf(resutls):\n",
    "    resutls= np.array(resutls)\n",
    "    genuine  = resutls[resutls[:, 1] == 1][:, 0]\n",
    "    impostor = resutls[resutls[:, 1] == 0][:, 0]\n",
    "    stats_a = get_eer_stats(genuine, impostor)\n",
    "    return(stats_a.eer,stats_a.fmr100)\n",
    "\n",
    "def calculate_and_print_averages(y_train, resutls3):\n",
    "    u, counts = np.unique(y_train, return_counts=True)\n",
    "    eer_values = []\n",
    "    ii = 0\n",
    "\n",
    "    for i in resutls3.keys():\n",
    "        re = EERf(resutls3[i])\n",
    "        eer = re[0]\n",
    "        print(f\"{i}: EER = {re[0]:.4f}, FMR100 = {re[1]:.4f}, Count = {counts[ii]}\")\n",
    "        eer_values.append(eer)\n",
    "        ii += 1\n",
    "\n",
    "    average_eer = np.mean(eer_values) * 100\n",
    "    std_eer = np.std(eer_values) * 100\n",
    "    \n",
    "    print(f\"Final Average EER: {average_eer:.4f}\")\n",
    "    print(f\"Final EER Standard Deviation: {std_eer:.4f}\")\n",
    "    print(f\"${average_eer:.2f} \\\\pm {std_eer:.2f}$\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def calculate_similarity_scores_two(enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance):\n",
    "    similarity_results = []\n",
    "    similarity_results_by_class = []\n",
    "    similarity_results_by_class_dict = defaultdict(list)\n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    class_indices = [np.where(y_enrollment == cls)[0] for cls in unique_classes]\n",
    "    print(verification_embeddings.shape, enrollment_embeddings.shape)\n",
    "    if distance == \"cd\":\n",
    "        similarity_matrix = -1 * cd(verification_embeddings, enrollment_embeddings)\n",
    "    elif distance == \"ed\":\n",
    "        similarity_matrix = -1 * ed(verification_embeddings, enrollment_embeddings)\n",
    "\n",
    "    for i in range(similarity_matrix.shape[0]):\n",
    "        current_class = y_verification[i]\n",
    "        predicted_scores = similarity_matrix[i]\n",
    "        same_class_indices = class_indices[np.where(unique_classes == current_class)[0][0]]\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            same_class_indices = class_indices[np.where(unique_classes == cls)[0][0]]\n",
    "            max_score = sum(sorted(predicted_scores[same_class_indices], reverse=True)[:10]) / 10\n",
    "            if current_class == cls:\n",
    "                similarity_results_by_class.append([max_score, 1, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 1, current_class, cls, i, cls])\n",
    "            else:\n",
    "                similarity_results_by_class.append([max_score, 0, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 0, current_class, cls, i, cls])\n",
    "\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def assessment_model_data_two(enrollment_data, ye, verification_data, yv, e_network, distance):\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    similarity_results_by_class, similarity_results_by_class_dict = calculate_similarity_scores_two(\n",
    "        enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance\n",
    "    )\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def compute_embedding_batch_two(x_test_batch, embedding_network=None):\n",
    "    print(x_test_batch.shape)\n",
    "    return x_test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65862e33-7848-4c83-96b4-b17bafaa11a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n",
      "70: EER = 0.5285, FMR100 = 0.9578, Count = 100\n",
      "86: EER = 0.4719, FMR100 = 0.9461, Count = 100\n",
      "96: EER = 0.4361, FMR100 = 0.9718, Count = 100\n",
      "125: EER = 0.2878, FMR100 = 0.8328, Count = 100\n",
      "129: EER = 0.3725, FMR100 = 0.9575, Count = 100\n",
      "167: EER = 0.6544, FMR100 = 0.9900, Count = 100\n",
      "174: EER = 0.5573, FMR100 = 0.9339, Count = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175: EER = 0.8200, FMR100 = 0.8200, Count = 100\n",
      "183: EER = 0.4600, FMR100 = 0.9600, Count = 100\n",
      "194: EER = 0.5739, FMR100 = 0.9017, Count = 100\n",
      "197: EER = 0.5046, FMR100 = 0.9911, Count = 100\n",
      "199: EER = 0.4414, FMR100 = 0.9922, Count = 100\n",
      "201: EER = 0.6172, FMR100 = 0.9839, Count = 100\n",
      "203: EER = 0.4320, FMR100 = 0.8720, Count = 100\n",
      "206: EER = 0.8800, FMR100 = 0.9960, Count = 100\n",
      "207: EER = 0.4924, FMR100 = 0.9788, Count = 100\n",
      "214: EER = 0.4127, FMR100 = 0.9178, Count = 100\n",
      "219: EER = 0.5646, FMR100 = 1.0000, Count = 100\n",
      "230: EER = 0.5407, FMR100 = 0.9180, Count = 100\n",
      "236: EER = 0.5957, FMR100 = 0.9839, Count = 100\n",
      "245: EER = 0.5907, FMR100 = 0.9940, Count = 100\n",
      "250: EER = 0.5677, FMR100 = 0.9885, Count = 100\n",
      "257: EER = 0.3686, FMR100 = 0.9960, Count = 100\n",
      "260: EER = 0.5029, FMR100 = 0.9481, Count = 100\n",
      "261: EER = 0.4890, FMR100 = 0.9956, Count = 100\n",
      "262: EER = 0.3845, FMR100 = 0.7220, Count = 100\n",
      "265: EER = 0.4349, FMR100 = 0.9492, Count = 100\n",
      "268: EER = 0.4761, FMR100 = 0.9583, Count = 100\n",
      "270: EER = 0.6233, FMR100 = 0.9894, Count = 100\n",
      "281: EER = 0.3189, FMR100 = 0.8694, Count = 100\n",
      "291: EER = 0.5044, FMR100 = 0.9872, Count = 100\n",
      "296: EER = 0.5437, FMR100 = 1.0000, Count = 100\n",
      "299: EER = 0.4957, FMR100 = 0.9824, Count = 100\n",
      "303: EER = 0.6431, FMR100 = 0.9685, Count = 100\n",
      "306: EER = 0.3264, FMR100 = 0.9150, Count = 100\n",
      "314: EER = 0.6260, FMR100 = 0.9960, Count = 100\n",
      "322: EER = 0.5475, FMR100 = 0.9405, Count = 100\n",
      "325: EER = 0.3495, FMR100 = 0.8619, Count = 100\n",
      "342: EER = 0.4006, FMR100 = 0.9364, Count = 100\n",
      "348: EER = 0.4860, FMR100 = 0.9364, Count = 100\n",
      "357: EER = 0.4448, FMR100 = 0.9110, Count = 100\n",
      "364: EER = 0.3426, FMR100 = 0.9481, Count = 100\n",
      "374: EER = 0.3938, FMR100 = 0.9853, Count = 100\n",
      "407: EER = 0.7112, FMR100 = 0.9950, Count = 100\n",
      "414: EER = 0.4912, FMR100 = 0.8375, Count = 100\n",
      "415: EER = 0.3175, FMR100 = 0.9425, Count = 100\n",
      "418: EER = 0.3812, FMR100 = 0.9625, Count = 100\n",
      "419: EER = 0.3900, FMR100 = 0.9437, Count = 100\n",
      "422: EER = 0.6329, FMR100 = 0.9929, Count = 100\n",
      "436: EER = 0.3471, FMR100 = 0.8229, Count = 100\n",
      "Final Average EER: 49.5519\n",
      "Final EER Standard Deviation: 12.4545\n",
      "$49.55 \\pm 12.45$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"ed\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213fd628-779c-4b5b-8079-e3f0e1b916c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70: EER = 0.5429, FMR100 = 0.9839, Count = 100\n",
      "86: EER = 0.2979, FMR100 = 0.8167, Count = 100\n",
      "96: EER = 0.5247, FMR100 = 0.9935, Count = 100\n",
      "125: EER = 0.3533, FMR100 = 0.7839, Count = 100\n",
      "129: EER = 0.1700, FMR100 = 0.6975, Count = 100\n",
      "167: EER = 0.3300, FMR100 = 1.0000, Count = 100\n",
      "174: EER = 0.4289, FMR100 = 0.8867, Count = 100\n",
      "175: EER = 0.2243, FMR100 = 0.5460, Count = 100\n",
      "183: EER = 0.2900, FMR100 = 0.6440, Count = 100\n",
      "194: EER = 0.4731, FMR100 = 0.8633, Count = 100\n",
      "197: EER = 0.4341, FMR100 = 0.9267, Count = 100\n",
      "199: EER = 0.3472, FMR100 = 0.8994, Count = 100\n",
      "201: EER = 0.4583, FMR100 = 0.7550, Count = 100\n",
      "203: EER = 0.3180, FMR100 = 0.7960, Count = 100\n",
      "206: EER = 0.3220, FMR100 = 0.8160, Count = 100\n",
      "207: EER = 0.4707, FMR100 = 0.9173, Count = 100\n",
      "214: EER = 0.3800, FMR100 = 0.9559, Count = 100\n",
      "219: EER = 0.6814, FMR100 = 1.0000, Count = 100\n",
      "230: EER = 0.5740, FMR100 = 0.9640, Count = 100\n",
      "236: EER = 0.5428, FMR100 = 0.9754, Count = 100\n",
      "245: EER = 0.4082, FMR100 = 0.9220, Count = 100\n",
      "250: EER = 0.6025, FMR100 = 0.9788, Count = 100\n",
      "257: EER = 0.6600, FMR100 = 0.9920, Count = 100\n",
      "260: EER = 0.4285, FMR100 = 0.9485, Count = 100\n",
      "261: EER = 0.3433, FMR100 = 0.9644, Count = 100\n",
      "262: EER = 0.2340, FMR100 = 0.9980, Count = 100\n",
      "265: EER = 0.4013, FMR100 = 0.9318, Count = 100\n",
      "268: EER = 0.4628, FMR100 = 0.9394, Count = 100\n",
      "270: EER = 0.5806, FMR100 = 0.9661, Count = 100\n",
      "281: EER = 0.2974, FMR100 = 0.7678, Count = 100\n",
      "291: EER = 0.5161, FMR100 = 0.9811, Count = 100\n",
      "296: EER = 0.3910, FMR100 = 0.9277, Count = 100\n",
      "299: EER = 0.2833, FMR100 = 0.7733, Count = 100\n",
      "303: EER = 0.4600, FMR100 = 0.9260, Count = 100\n",
      "306: EER = 0.2187, FMR100 = 0.8277, Count = 100\n",
      "314: EER = 0.4620, FMR100 = 0.9540, Count = 100\n",
      "322: EER = 0.4555, FMR100 = 0.9590, Count = 100\n",
      "325: EER = 0.2314, FMR100 = 0.4843, Count = 100\n",
      "342: EER = 0.2227, FMR100 = 0.8768, Count = 100\n",
      "348: EER = 0.3800, FMR100 = 0.9473, Count = 100\n",
      "357: EER = 0.2452, FMR100 = 0.8586, Count = 100\n",
      "364: EER = 0.3768, FMR100 = 0.9690, Count = 100\n",
      "374: EER = 0.2532, FMR100 = 0.8711, Count = 100\n",
      "407: EER = 0.5087, FMR100 = 0.8838, Count = 100\n",
      "414: EER = 0.2000, FMR100 = 0.6100, Count = 100\n",
      "415: EER = 0.1555, FMR100 = 0.7987, Count = 100\n",
      "418: EER = 0.1969, FMR100 = 0.9125, Count = 100\n",
      "419: EER = 0.3500, FMR100 = 0.8875, Count = 100\n",
      "422: EER = 0.0560, FMR100 = 0.3300, Count = 100\n",
      "436: EER = 0.2157, FMR100 = 0.7543, Count = 100\n",
      "Final Average EER: 37.5222\n",
      "Final EER Standard Deviation: 13.7990\n",
      "$37.52 \\pm 13.80$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"cd\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8fc2c-2bc8-40c9-b56d-dc0528dc3a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70473412-ab01-4892-ae03-bdc02f67c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f9f24ae-287f-4c3e-abfd-48e72277089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each array from 3D to 2D\n",
    "x_test_e = x_test_e.reshape(x_test_e.shape[0], -1)\n",
    "x_test_v= x_test_v.reshape(x_test_v.shape[0], -1)\n",
    "x_test_n = x_neg_r.reshape(x_neg_r.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc48ca50-a3f0-447d-a7cc-a3059540ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def calculate_eer(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Calculate the Equal Error Rate (EER) and FMR100 using pyeer.\n",
    "    \"\"\"\n",
    "    # Separate genuine and impostor scores\n",
    "    genuine_scores = y_scores[y_true == 1]\n",
    "    impostor_scores = y_scores[y_true == 0]\n",
    "    #print(y_true, y_scores)\n",
    "\n",
    "    #print(genuine_scores, impostor_scores)\n",
    "    print(\"genuine_scores: \", len(genuine_scores), sum(genuine_scores)/len(genuine_scores), \"impostor_scores\", len(impostor_scores), sum(impostor_scores)/len(impostor_scores))\n",
    "    \n",
    "    # Use pyeer to compute EER stats\n",
    "    stats = get_eer_stats(genuine_scores, impostor_scores)\n",
    "    \n",
    "    return stats.eer\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=20))\n",
    "            #('classifier', SVC(probability=True, random_state=42, class_weight='balanced'))\n",
    "            #('classifier', KNeighborsClassifier(n_neighbors=20, weights='distance'))\n",
    "        ])\n",
    "        #svm_model = SVC(probability=True, random_state=42, class_weight='balanced')\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        pipeline.fit(X, y)\n",
    "        probabilities = pipeline.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "        # Calculate EER\n",
    "        rf_eer = calculate_eer(test_labels, probabilities)\n",
    "\n",
    "        print(f\"Class {cls}: RandomForest EER = {rf_eer:.4f}\")\n",
    "\n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': rf_eer}\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_mean_std(results):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of EER values for each model in the results dictionary.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): A dictionary where keys are classes, and values are dictionaries containing model metrics.\n",
    "                        Example: {cls: {'RandomForest': {'EER': value}}}\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing mean and std for each model across all classes.\n",
    "    \"\"\"\n",
    "    # Extract EER values for each model\n",
    "    model_eer_values = {}\n",
    "    for cls, metrics in results.items():\n",
    "        for model, model_metrics in metrics.items():\n",
    "            if model not in model_eer_values:\n",
    "                model_eer_values[model] = []\n",
    "            model_eer_values[model].append(model_metrics['EER'])\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    model_stats = {}\n",
    "    for model, eer_values in model_eer_values.items():\n",
    "        mean = np.mean(eer_values) * 100\n",
    "        std = np.std(eer_values) * 100\n",
    "        model_stats[model] = {'mean': mean, 'std': std}\n",
    "        print(f\"Final Average EER {model}: {mean:.4f}\")\n",
    "        print(f\"Final EER Standard Deviation {model}: {std:.4f}\")\n",
    "        print(f\"${mean:.2f} \\\\pm {std:.2f}$\") \n",
    "        \n",
    "   \n",
    "    return model_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8a00601-2b7c-4345-9d08-3faabbb294a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(84408, 465)\n",
      "Unique classes:  [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\n",
      " 230 236 245 250 257 260 261 262 265 268 270 281 291 296 299 303 306 314\n",
      " 322 325 342 348 357 364 374 407 414 415 418 419 422 436]\n",
      "genuine_scores:  1800 0.010850000000000018 impostor_scores 78843 0.0004682723894321727\n",
      "Class 70: RandomForest EER = 0.3753\n",
      "genuine_scores:  1800 0.02878888888888896 impostor_scores 78843 0.000381137196707393\n",
      "Class 86: RandomForest EER = 0.2715\n",
      "genuine_scores:  1700 0.00045882352941176494 impostor_scores 78943 0.00014136782235283575\n",
      "Class 96: RandomForest EER = 0.4846\n",
      "genuine_scores:  1800 0.07516666666666678 impostor_scores 78843 0.00036071686769910914\n",
      "Class 125: RandomForest EER = 0.2861\n",
      "genuine_scores:  400 0.017624999999999957 impostor_scores 80243 0.0008463043505352502\n",
      "Class 129: RandomForest EER = 0.2560\n",
      "genuine_scores:  100 0.0002 impostor_scores 80543 0.001173286319109077\n",
      "Class 167: RandomForest EER = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.02348888888888889 impostor_scores 78843 0.0003954694773156934\n",
      "Class 174: RandomForest EER = 0.3372\n",
      "genuine_scores:  500 0.28780000000000033 impostor_scores 80143 0.0001761850691888246\n",
      "Class 175: RandomForest EER = 0.1282\n",
      "genuine_scores:  500 0.033599999999999915 impostor_scores 80143 0.00020712975556193102\n",
      "Class 183: RandomForest EER = 0.2195\n",
      "genuine_scores:  1800 0.020661111111111137 impostor_scores 78843 9.601359664142617e-05\n",
      "Class 194: RandomForest EER = 0.3964\n",
      "genuine_scores:  1800 0.03044444444444449 impostor_scores 78843 0.000739571046256474\n",
      "Class 197: RandomForest EER = 0.3153\n",
      "genuine_scores:  1800 0.008916666666666625 impostor_scores 78843 0.00032165189046587237\n",
      "Class 199: RandomForest EER = 0.3861\n",
      "genuine_scores:  1800 0.08183888888888906 impostor_scores 78843 0.0006155270601067925\n",
      "Class 201: RandomForest EER = 0.2957\n",
      "genuine_scores:  500 0.08128000000000007 impostor_scores 80143 0.0002076288634066591\n",
      "Class 203: RandomForest EER = 0.2302\n",
      "genuine_scores:  500 0.1470200000000001 impostor_scores 80143 0.000199892691813382\n",
      "Class 206: RandomForest EER = 0.1543\n",
      "genuine_scores:  4000 0.01656000000000002 impostor_scores 76643 0.00031509726915700644\n",
      "Class 207: RandomForest EER = 0.3983\n",
      "genuine_scores:  1679 0.058814770696843724 impostor_scores 78964 0.00038371916316297177\n",
      "Class 214: RandomForest EER = 0.1877\n",
      "genuine_scores:  464 0.005754310344827571 impostor_scores 80179 0.0004045947193155357\n",
      "Class 219: RandomForest EER = 0.3303\n",
      "genuine_scores:  500 0.041939999999999984 impostor_scores 80143 0.0008590893777372954\n",
      "Class 230: RandomForest EER = 0.3104\n",
      "genuine_scores:  4100 0.007426829268292708 impostor_scores 76543 0.00043308989718199097\n",
      "Class 236: RandomForest EER = 0.4317\n",
      "genuine_scores:  500 0.14482000000000025 impostor_scores 80143 0.0013349887076850762\n",
      "Class 245: RandomForest EER = 0.0852\n",
      "genuine_scores:  4000 0.012412499999999984 impostor_scores 76643 0.0003798128987644129\n",
      "Class 250: RandomForest EER = 0.4116\n",
      "genuine_scores:  500 0.0 impostor_scores 80143 0.0015124215464856722\n",
      "Class 257: RandomForest EER = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  4800 0.009902083333333358 impostor_scores 75843 0.0004504041243094413\n",
      "Class 260: RandomForest EER = 0.3829\n",
      "genuine_scores:  900 0.020844444444444443 impostor_scores 79743 0.000859385776807993\n",
      "Class 261: RandomForest EER = 0.4117\n",
      "genuine_scores:  500 0.27718000000000037 impostor_scores 80143 0.00046816315835444616\n",
      "Class 262: RandomForest EER = 0.0496\n",
      "genuine_scores:  3900 0.04377692307692304 impostor_scores 76743 0.001196460915002026\n",
      "Class 265: RandomForest EER = 0.4640\n",
      "genuine_scores:  1800 0.03163888888888893 impostor_scores 78843 0.00041259211344064613\n",
      "Class 268: RandomForest EER = 0.2873\n",
      "genuine_scores:  1800 0.04287777777777779 impostor_scores 78843 0.0004907220679071093\n",
      "Class 270: RandomForest EER = 0.4780\n",
      "genuine_scores:  1800 0.005127777777777751 impostor_scores 78843 0.0001537232220996133\n",
      "Class 281: RandomForest EER = 0.4096\n",
      "genuine_scores:  1800 0.011738888888888896 impostor_scores 78843 0.00035158479509912906\n",
      "Class 291: RandomForest EER = 0.3987\n",
      "genuine_scores:  2200 0.00022272727272727282 impostor_scores 78443 0.00018242545542623083\n",
      "Class 296: RandomForest EER = 0.4969\n",
      "genuine_scores:  2100 0.0663285714285717 impostor_scores 78543 0.0006775906191512864\n",
      "Class 299: RandomForest EER = 0.2225\n",
      "genuine_scores:  2000 0.04398000000000017 impostor_scores 78643 0.00042050786465420883\n",
      "Class 303: RandomForest EER = 0.2227\n",
      "genuine_scores:  2200 0.013209090909090978 impostor_scores 78443 0.0006797292301416245\n",
      "Class 306: RandomForest EER = 0.3416\n",
      "genuine_scores:  500 0.017719999999999944 impostor_scores 80143 0.0004670401657038118\n",
      "Class 314: RandomForest EER = 0.2818\n",
      "genuine_scores:  2000 0.05877500000000025 impostor_scores 78643 0.0007788360057474863\n",
      "Class 322: RandomForest EER = 0.2623\n",
      "genuine_scores:  2100 0.07871428571428564 impostor_scores 78543 0.0003134588696637574\n",
      "Class 325: RandomForest EER = 0.1615\n",
      "genuine_scores:  2200 0.022145454545454572 impostor_scores 78443 0.00029384393763624703\n",
      "Class 342: RandomForest EER = 0.2767\n",
      "genuine_scores:  2200 0.004272727272727254 impostor_scores 78443 0.00015731167854365406\n",
      "Class 348: RandomForest EER = 0.4241\n",
      "genuine_scores:  2100 0.004009523809523784 impostor_scores 78543 0.00025552881860891566\n",
      "Class 357: RandomForest EER = 0.4094\n",
      "genuine_scores:  2100 0.004847619047619007 impostor_scores 78543 0.00034770762512255154\n",
      "Class 364: RandomForest EER = 0.3927\n",
      "genuine_scores:  1900 0.10988421052631571 impostor_scores 78743 0.001806128798750399\n",
      "Class 374: RandomForest EER = 0.1308\n",
      "genuine_scores:  800 0.032062500000000035 impostor_scores 79843 0.00033716167979660697\n",
      "Class 407: RandomForest EER = 0.2057\n",
      "genuine_scores:  800 0.02751250000000004 impostor_scores 79843 0.0001292536603083537\n",
      "Class 414: RandomForest EER = 0.2610\n",
      "genuine_scores:  800 0.24986250000000043 impostor_scores 79843 0.0011099282341595499\n",
      "Class 415: RandomForest EER = 0.0508\n",
      "genuine_scores:  800 0.013012499999999982 impostor_scores 79843 0.00039464949964305415\n",
      "Class 418: RandomForest EER = 0.3963\n",
      "genuine_scores:  800 0.052900000000000065 impostor_scores 79843 0.001206367496211333\n",
      "Class 419: RandomForest EER = 0.2828\n",
      "genuine_scores:  700 0.24957142857142875 impostor_scores 79943 0.0005532692043080696\n",
      "Class 422: RandomForest EER = 0.0504\n",
      "genuine_scores:  700 0.05877142857142859 impostor_scores 79943 0.0004913500869369471\n",
      "Class 436: RandomForest EER = 0.2280\n",
      "Final Average EER RandomForest: 30.5430\n",
      "Final EER Standard Deviation RandomForest: 12.2598\n",
      "$30.54 \\pm 12.26$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'mean': 30.542964936595602, 'std': 12.259794725327}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e5b6d-587c-450e-a4ef-a0b70b1cc162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a9349-089e-4f08-88c5-faf0fa7ea0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf2cbdcc-b16b-4152-9442-843333c6bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        # Replace RandomForest with Linear SVM + Kernel Approximation\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('kernel_approximation', RBFSampler(gamma=1, random_state=42, n_components=500)),  # Approximate RBF kernel\n",
    "            ('classifier', SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, class_weight='balanced', random_state=42, n_jobs=20))\n",
    "        ])\n",
    "        \n",
    "        # Shuffle and split the data\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        \n",
    "        # Train the pipeline\n",
    "        pipeline.fit(X, y)\n",
    "        \n",
    "        # Predict probabilities for the test set\n",
    "        # Note: SGDClassifier doesn't provide probabilities directly, so we use decision_function\n",
    "        decision_scores = pipeline.decision_function(test_embeddings)\n",
    "        probabilities = 1 / (1 + np.exp(-decision_scores))  # Sigmoid function to map decision scores to probabilities\n",
    "        \n",
    "        # Calculate EER\n",
    "        svm_eer = calculate_eer(test_labels, probabilities)\n",
    "        \n",
    "        print(f\"Class {cls}: Linear SVM with Kernel Approximation EER = {svm_eer:.4f}\")\n",
    "        \n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': svm_eer}\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b0bda30-abc5-44ca-9100-a343bc53089e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(84408, 465)\n",
      "Unique classes:  [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\n",
      " 230 236 245 250 257 260 261 262 265 268 270 281 291 296 299 303 306 314\n",
      " 322 325 342 348 357 364 374 407 414 415 418 419 422 436]\n",
      "genuine_scores:  1800 0.391395145360853 impostor_scores 78843 0.24221794715349648\n",
      "Class 70: Linear SVM with Kernel Approximation EER = 0.3262\n",
      "genuine_scores:  1800 0.2797768460010658 impostor_scores 78843 0.19332485919064168\n",
      "Class 86: Linear SVM with Kernel Approximation EER = 0.3408\n",
      "genuine_scores:  1700 0.04409448204338227 impostor_scores 78943 0.024199245605883216\n",
      "Class 96: Linear SVM with Kernel Approximation EER = 0.2841\n",
      "genuine_scores:  1800 0.291677043047633 impostor_scores 78843 0.10903528134190553\n",
      "Class 125: Linear SVM with Kernel Approximation EER = 0.2106\n",
      "genuine_scores:  400 0.23398788580937052 impostor_scores 80243 0.08338927507503575\n",
      "Class 129: Linear SVM with Kernel Approximation EER = 0.2127\n",
      "genuine_scores:  100 0.3280334542622408 impostor_scores 80543 0.23220220379051243\n",
      "Class 167: Linear SVM with Kernel Approximation EER = 0.3800\n",
      "genuine_scores:  1800 0.4045905167255329 impostor_scores 78843 0.3969588338820375\n",
      "Class 174: Linear SVM with Kernel Approximation EER = 0.4756\n",
      "genuine_scores:  500 0.435144423337974 impostor_scores 80143 0.051818621344649075\n",
      "Class 175: Linear SVM with Kernel Approximation EER = 0.1086\n",
      "genuine_scores:  500 0.617762823748398 impostor_scores 80143 0.1920429117168127\n",
      "Class 183: Linear SVM with Kernel Approximation EER = 0.2880\n",
      "genuine_scores:  1800 0.17686106161150592 impostor_scores 78843 0.07668544747717257\n",
      "Class 194: Linear SVM with Kernel Approximation EER = 0.4039\n",
      "genuine_scores:  1800 0.40962456906090366 impostor_scores 78843 0.22605298039482116\n",
      "Class 197: Linear SVM with Kernel Approximation EER = 0.3211\n",
      "genuine_scores:  1800 0.31373770274291435 impostor_scores 78843 0.1968458606286732\n",
      "Class 199: Linear SVM with Kernel Approximation EER = 0.3897\n",
      "genuine_scores:  1800 0.27260462769850663 impostor_scores 78843 0.03248560273568707\n",
      "Class 201: Linear SVM with Kernel Approximation EER = 0.2828\n",
      "genuine_scores:  500 0.36216857668293273 impostor_scores 80143 0.04769884027116078\n",
      "Class 203: Linear SVM with Kernel Approximation EER = 0.1362\n",
      "genuine_scores:  500 0.27324449468987494 impostor_scores 80143 0.08261803253678063\n",
      "Class 206: Linear SVM with Kernel Approximation EER = 0.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  4000 0.31304114922736515 impostor_scores 76643 0.15987752389280313\n",
      "Class 207: Linear SVM with Kernel Approximation EER = 0.4442\n",
      "genuine_scores:  1679 0.6369254187812348 impostor_scores 78964 0.4237648054785813\n",
      "Class 214: Linear SVM with Kernel Approximation EER = 0.3151\n",
      "genuine_scores:  464 0.04225948088421765 impostor_scores 80179 0.018508350789958123\n",
      "Class 219: Linear SVM with Kernel Approximation EER = 0.1640\n",
      "genuine_scores:  500 0.3531057806279102 impostor_scores 80143 0.3068228831277282\n",
      "Class 230: Linear SVM with Kernel Approximation EER = 0.4500\n",
      "genuine_scores:  4100 0.2448774655947762 impostor_scores 76543 0.17872906428975177\n",
      "Class 236: Linear SVM with Kernel Approximation EER = 0.4463\n",
      "genuine_scores:  500 0.6173573279079716 impostor_scores 80143 0.2494955090277853\n",
      "Class 245: Linear SVM with Kernel Approximation EER = 0.1322\n",
      "genuine_scores:  4000 0.5708213844238745 impostor_scores 76643 0.4161724570435328\n",
      "Class 250: Linear SVM with Kernel Approximation EER = 0.3742\n",
      "genuine_scores:  500 0.007025644259924194 impostor_scores 80143 0.029406056311685348\n",
      "Class 257: Linear SVM with Kernel Approximation EER = 0.3043\n",
      "genuine_scores:  4800 0.430659970172094 impostor_scores 75843 0.36437347018284905\n",
      "Class 260: Linear SVM with Kernel Approximation EER = 0.3669\n",
      "genuine_scores:  900 0.19774996071837128 impostor_scores 79743 0.13704021320193585\n",
      "Class 261: Linear SVM with Kernel Approximation EER = 0.3834\n",
      "genuine_scores:  500 0.7640993419865825 impostor_scores 80143 0.1588185750432953\n",
      "Class 262: Linear SVM with Kernel Approximation EER = 0.0624\n",
      "genuine_scores:  3900 0.07763687493242703 impostor_scores 76743 0.02314884577033754\n",
      "Class 265: Linear SVM with Kernel Approximation EER = 0.5733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.36377682042003856 impostor_scores 78843 0.12050214218617858\n",
      "Class 268: Linear SVM with Kernel Approximation EER = 0.2600\n",
      "genuine_scores:  1800 0.04915365127847331 impostor_scores 78843 0.042593042089912665\n",
      "Class 270: Linear SVM with Kernel Approximation EER = 0.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.41516188061994436 impostor_scores 78843 0.16226033384617494\n",
      "Class 281: Linear SVM with Kernel Approximation EER = 0.2234\n",
      "genuine_scores:  1800 0.5820505999489366 impostor_scores 78843 0.4240470835845682\n",
      "Class 291: Linear SVM with Kernel Approximation EER = 0.3683\n",
      "genuine_scores:  2200 0.04541553401391001 impostor_scores 78443 0.06758400682428377\n",
      "Class 296: Linear SVM with Kernel Approximation EER = 0.4761\n",
      "genuine_scores:  2100 0.8722035144227495 impostor_scores 78543 0.45453471084095437\n",
      "Class 299: Linear SVM with Kernel Approximation EER = 0.1090\n",
      "genuine_scores:  2000 0.34366072720245533 impostor_scores 78643 0.0800260950595567\n",
      "Class 303: Linear SVM with Kernel Approximation EER = 0.2515\n",
      "genuine_scores:  2200 0.29255395084177294 impostor_scores 78443 0.20217626197339644\n",
      "Class 306: Linear SVM with Kernel Approximation EER = 0.2932\n",
      "genuine_scores:  500 0.31407980259892865 impostor_scores 80143 0.1251530098447203\n",
      "Class 314: Linear SVM with Kernel Approximation EER = 0.2490\n",
      "genuine_scores:  2000 0.3696275049295132 impostor_scores 78643 0.13119440585499864\n",
      "Class 322: Linear SVM with Kernel Approximation EER = 0.2555\n",
      "genuine_scores:  2100 0.544404384514919 impostor_scores 78543 0.0693209084748005\n",
      "Class 325: Linear SVM with Kernel Approximation EER = 0.1086\n",
      "genuine_scores:  2200 0.911000921997466 impostor_scores 78443 0.3093590588438156\n",
      "Class 342: Linear SVM with Kernel Approximation EER = 0.1006\n",
      "genuine_scores:  2200 0.8713220530802042 impostor_scores 78443 0.3239199800916821\n",
      "Class 348: Linear SVM with Kernel Approximation EER = 0.1482\n",
      "genuine_scores:  2100 0.3970883708119732 impostor_scores 78543 0.10769247125226199\n",
      "Class 357: Linear SVM with Kernel Approximation EER = 0.1296\n",
      "genuine_scores:  2100 0.6587433262441408 impostor_scores 78543 0.16390230699479844\n",
      "Class 364: Linear SVM with Kernel Approximation EER = 0.1253\n",
      "genuine_scores:  1900 0.8573648729489782 impostor_scores 78743 0.3144251266367415\n",
      "Class 374: Linear SVM with Kernel Approximation EER = 0.1600\n",
      "genuine_scores:  800 0.6880505681605322 impostor_scores 79843 0.3211494287339123\n",
      "Class 407: Linear SVM with Kernel Approximation EER = 0.2830\n",
      "genuine_scores:  800 0.23488396156563796 impostor_scores 79843 0.04787024881406973\n",
      "Class 414: Linear SVM with Kernel Approximation EER = 0.1126\n",
      "genuine_scores:  800 0.6944696078757359 impostor_scores 79843 0.13742803711851695\n",
      "Class 415: Linear SVM with Kernel Approximation EER = 0.0614\n",
      "genuine_scores:  800 0.9398224208459635 impostor_scores 79843 0.3209841592367132\n",
      "Class 418: Linear SVM with Kernel Approximation EER = 0.1390\n",
      "genuine_scores:  800 0.6659920469419841 impostor_scores 79843 0.18981160846469586\n",
      "Class 419: Linear SVM with Kernel Approximation EER = 0.1614\n",
      "genuine_scores:  700 0.8805203611969403 impostor_scores 79943 0.2027696196439411\n",
      "Class 422: Linear SVM with Kernel Approximation EER = 0.0329\n",
      "genuine_scores:  700 0.5341537801264262 impostor_scores 79943 0.13294142883709492\n",
      "Class 436: Linear SVM with Kernel Approximation EER = 0.1335\n",
      "Final Average EER RandomForest: 27.1423\n",
      "Final EER Standard Deviation RandomForest: 14.4989\n",
      "$27.14 \\pm 14.50$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'mean': 27.14232370477466, 'std': 14.49889391428663}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc002b35-6858-4314-90f2-712bd4899c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "oml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
