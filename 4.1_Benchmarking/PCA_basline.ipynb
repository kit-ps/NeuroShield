{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e289ac31-794e-4dc4-a63c-28d291e4e536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 70, Number of unique sessions: 19\n",
      "Subject 86, Number of unique sessions: 19\n",
      "Subject 96, Number of unique sessions: 18\n",
      "Subject 125, Number of unique sessions: 19\n",
      "Subject 129, Number of unique sessions: 5\n",
      "Subject 167, Number of unique sessions: 2\n",
      "Subject 174, Number of unique sessions: 19\n",
      "Subject 175, Number of unique sessions: 6\n",
      "Subject 183, Number of unique sessions: 6\n",
      "Subject 194, Number of unique sessions: 19\n",
      "Subject 197, Number of unique sessions: 19\n",
      "Subject 199, Number of unique sessions: 19\n",
      "Subject 201, Number of unique sessions: 19\n",
      "Subject 203, Number of unique sessions: 6\n",
      "Subject 206, Number of unique sessions: 6\n",
      "Subject 207, Number of unique sessions: 41\n",
      "Subject 214, Number of unique sessions: 18\n",
      "Subject 219, Number of unique sessions: 5\n",
      "Subject 230, Number of unique sessions: 6\n",
      "Subject 236, Number of unique sessions: 42\n",
      "Subject 245, Number of unique sessions: 6\n",
      "Subject 250, Number of unique sessions: 41\n",
      "Subject 257, Number of unique sessions: 6\n",
      "Subject 260, Number of unique sessions: 49\n",
      "Subject 261, Number of unique sessions: 10\n",
      "Subject 262, Number of unique sessions: 6\n",
      "Subject 265, Number of unique sessions: 40\n",
      "Subject 268, Number of unique sessions: 19\n",
      "Subject 270, Number of unique sessions: 19\n",
      "Subject 281, Number of unique sessions: 19\n",
      "Subject 291, Number of unique sessions: 19\n",
      "Subject 296, Number of unique sessions: 23\n",
      "Subject 299, Number of unique sessions: 22\n",
      "Subject 303, Number of unique sessions: 21\n",
      "Subject 306, Number of unique sessions: 23\n",
      "Subject 314, Number of unique sessions: 6\n",
      "Subject 322, Number of unique sessions: 21\n",
      "Subject 325, Number of unique sessions: 22\n",
      "Subject 342, Number of unique sessions: 23\n",
      "Subject 348, Number of unique sessions: 23\n",
      "Subject 357, Number of unique sessions: 22\n",
      "Subject 364, Number of unique sessions: 22\n",
      "Subject 374, Number of unique sessions: 20\n",
      "Subject 407, Number of unique sessions: 9\n",
      "Subject 414, Number of unique sessions: 9\n",
      "Subject 415, Number of unique sessions: 9\n",
      "Subject 418, Number of unique sessions: 9\n",
      "Subject 419, Number of unique sessions: 9\n",
      "Subject 422, Number of unique sessions: 8\n",
      "Subject 436, Number of unique sessions: 8\n"
     ]
    }
   ],
   "source": [
    "# import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load test data from test_raw.h5\n",
    "with h5py.File(\"./data/test_raw.h5\", \"r\") as f_test:\n",
    "    X_test = f_test['data'][:]\n",
    "    Y_test = f_test['labels'][:]\n",
    "    S_test = f_test['sessions'][:]\n",
    "    H_test = f_test['hardwares'][:]  # Load the 'hardwares' dataset as h_test\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, S_combined, and h_combined contain the merged data\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, and S_combined contain the merged data\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Reorder the arrays according to the shuffled indices\n",
    "x_test = X_test[indices]\n",
    "y_test = Y_test[indices]\n",
    "s_test = S_test[indices]\n",
    "h_test = H_test[indices]\n",
    "\n",
    "\n",
    "# Find unique subjects\n",
    "unique_subjects = np.unique(y_test)\n",
    "\n",
    "# Initialize lists to hold the data for x_test_e and x_test_v\n",
    "x_test_e_list = []\n",
    "y_test_e_list = []\n",
    "s_test_e_list = []\n",
    "h_test_e_list = []\n",
    "\n",
    "x_test_v_list = []\n",
    "y_test_v_list = []\n",
    "s_test_v_list = []\n",
    "h_test_v_list = []\n",
    "\n",
    "# Assign the minimum session for each subject to x_test_e and the rest to x_test_v\n",
    "for subject in unique_subjects:\n",
    "    subject_indices = np.where(y_test == subject)[0]\n",
    "    subject_sessions = s_test[subject_indices]\n",
    "    \n",
    "    # Skip subjects with fewer than two unique sessions\n",
    "    if len(np.unique(subject_sessions)) < 2:\n",
    "        continue\n",
    "\n",
    "    print(f\"Subject {subject}, Number of unique sessions: {len(np.unique(subject_sessions))}\")\n",
    "    \n",
    "    # Assign the minimum session to the evaluation set (x_test_e)\n",
    "    min_session = np.min(subject_sessions)\n",
    "    \n",
    "    # Append data to the evaluation set (min session)\n",
    "    x_test_e_list.extend(x_test[subject_indices][subject_sessions == min_session])\n",
    "    y_test_e_list.extend(y_test[subject_indices][subject_sessions == min_session])\n",
    "    s_test_e_list.extend(s_test[subject_indices][subject_sessions == min_session])\n",
    "    h_test_e_list.extend(h_test[subject_indices][subject_sessions == min_session])\n",
    "\n",
    "    # Append remaining sessions to the validation set (x_test_v)\n",
    "    x_test_v_list.extend(x_test[subject_indices][subject_sessions != min_session])\n",
    "    y_test_v_list.extend(y_test[subject_indices][subject_sessions != min_session])\n",
    "    s_test_v_list.extend(s_test[subject_indices][subject_sessions != min_session])\n",
    "    h_test_v_list.extend(h_test[subject_indices][subject_sessions != min_session])\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_e\n",
    "indices_e = np.arange(len(x_test_e_list))\n",
    "np.random.shuffle(indices_e)\n",
    "\n",
    "x_test_e = np.array(x_test_e_list)[indices_e]\n",
    "y_test_e = np.array(y_test_e_list)[indices_e]\n",
    "s_test_e = np.array(s_test_e_list)[indices_e]\n",
    "h_test_e = np.array(h_test_v_list)[indices_e]\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_v\n",
    "indices_v = np.arange(len(x_test_v_list))\n",
    "np.random.shuffle(indices_v)\n",
    "\n",
    "x_test_v = np.array(x_test_v_list)[indices_v]\n",
    "y_test_v = np.array(y_test_v_list)[indices_v]\n",
    "s_test_v = np.array(s_test_v_list)[indices_v]\n",
    "h_test_v = np.array(h_test_v_list)[indices_v]\n",
    "# Optional: Save the new test evaluation and validation sets to npy files (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342a14d9-7aa4-46d2-a8ac-bdb6361c2ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 93, 500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f9712c-552c-493e-9ec2-992a9fdb45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_test, x_test_e_list, x_test_v_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d25af7-6d2e-4d38-b3bd-7d3e528dbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"./data/neg_raw.h5\", \"r\") as f:\n",
    "    x_neg_r = f['data'][:]\n",
    "    y_neg = f['labels'][:]\n",
    "    s_neg = f['sessions'][:]\n",
    "\n",
    "\n",
    "#X_neg_r_reshaped = X_neg_r.reshape(X_neg_r.shape[0], -1)\n",
    "#X_neg_r_scaled = scaler.transform(X_neg_r_reshaped)\n",
    "#X_neg_r = pca.transform(X_neg_r_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5cfa57-b691-4240-a863-e3d9d4ab2f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing channel 1/93...\n",
      "Processing channel 2/93...\n",
      "Processing channel 3/93...\n",
      "Processing channel 4/93...\n",
      "Processing channel 5/93...\n",
      "Processing channel 6/93...\n",
      "Processing channel 7/93...\n",
      "Processing channel 8/93...\n",
      "Processing channel 9/93...\n",
      "Processing channel 10/93...\n",
      "Processing channel 11/93...\n",
      "Processing channel 12/93...\n",
      "Processing channel 13/93...\n",
      "Processing channel 14/93...\n",
      "Processing channel 15/93...\n",
      "Processing channel 16/93...\n",
      "Processing channel 17/93...\n",
      "Processing channel 18/93...\n",
      "Processing channel 19/93...\n",
      "Processing channel 20/93...\n",
      "Processing channel 21/93...\n",
      "Processing channel 22/93...\n",
      "Processing channel 23/93...\n",
      "Processing channel 24/93...\n",
      "Processing channel 25/93...\n",
      "Processing channel 26/93...\n",
      "Processing channel 27/93...\n",
      "Processing channel 28/93...\n",
      "Processing channel 29/93...\n",
      "Processing channel 30/93...\n",
      "Processing channel 31/93...\n",
      "Processing channel 32/93...\n",
      "Processing channel 33/93...\n",
      "Processing channel 34/93...\n",
      "Processing channel 35/93...\n",
      "Processing channel 36/93...\n",
      "Processing channel 37/93...\n",
      "Processing channel 38/93...\n",
      "Processing channel 39/93...\n",
      "Processing channel 40/93...\n",
      "Processing channel 41/93...\n",
      "Processing channel 42/93...\n",
      "Processing channel 43/93...\n",
      "Processing channel 44/93...\n",
      "Processing channel 45/93...\n",
      "Processing channel 46/93...\n",
      "Processing channel 47/93...\n",
      "Processing channel 48/93...\n",
      "Processing channel 49/93...\n",
      "Processing channel 50/93...\n",
      "Processing channel 51/93...\n",
      "Processing channel 52/93...\n",
      "Processing channel 53/93...\n",
      "Processing channel 54/93...\n",
      "Processing channel 55/93...\n",
      "Processing channel 56/93...\n",
      "Processing channel 57/93...\n",
      "Processing channel 58/93...\n",
      "Processing channel 59/93...\n",
      "Processing channel 60/93...\n",
      "Processing channel 61/93...\n",
      "Processing channel 62/93...\n",
      "Processing channel 63/93...\n",
      "Processing channel 64/93...\n",
      "Processing channel 65/93...\n",
      "Processing channel 66/93...\n",
      "Processing channel 67/93...\n",
      "Processing channel 68/93...\n",
      "Processing channel 69/93...\n",
      "Processing channel 70/93...\n",
      "Processing channel 71/93...\n",
      "Processing channel 72/93...\n",
      "Processing channel 73/93...\n",
      "Processing channel 74/93...\n",
      "Processing channel 75/93...\n",
      "Processing channel 76/93...\n",
      "Processing channel 77/93...\n",
      "Processing channel 78/93...\n",
      "Processing channel 79/93...\n",
      "Processing channel 80/93...\n",
      "Processing channel 81/93...\n",
      "Processing channel 82/93...\n",
      "Processing channel 83/93...\n",
      "Processing channel 84/93...\n",
      "Processing channel 85/93...\n",
      "Processing channel 86/93...\n",
      "Processing channel 87/93...\n",
      "Processing channel 88/93...\n",
      "Processing channel 89/93...\n",
      "Processing channel 90/93...\n",
      "Processing channel 91/93...\n",
      "Processing channel 92/93...\n",
      "Processing channel 93/93...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppose x_test_e.shape is (N, C, L) = (100000, 93, 500)\n",
    "# and x_test_v is for verification, shape (M, C, L).\n",
    "\n",
    "############################\n",
    "# Change 1: Define lists to store a separate scaler and PCA for each channel.\n",
    "############################\n",
    "scalers = []\n",
    "pcas = []\n",
    "\n",
    "############################\n",
    "# Change 2: Create empty lists to collect the transformed PCA data \n",
    "# for x_test_e and x_test_v per channel.\n",
    "############################\n",
    "x_test_e_pca_list = []\n",
    "x_test_v_pca_list = []\n",
    "x_test_n_pca_list = []\n",
    "\n",
    "\n",
    "x_test_e_pca_lists = []\n",
    "x_test_v_pca_lists = []\n",
    "x_test_n_pca_lists = []\n",
    "############################\n",
    "# Change 3: Iterate over each channel once, handle both x_test_e and x_test_v,\n",
    "# and add progress output.\n",
    "############################\n",
    "num_channels = x_test_e.shape[1]\n",
    "\n",
    "for ch in range(num_channels):\n",
    "    # ---- Progress Report ----\n",
    "    print(f\"Processing channel {ch+1}/{num_channels}...\")\n",
    "\n",
    "    # Extract data for current channel from x_test_e and x_test_v\n",
    "    channel_data_e = x_test_e[:, ch, :]  # shape (N, L)\n",
    "    channel_data_v = x_test_v[:, ch, :]  # shape (M, L)\n",
    "    channel_data_n = x_neg_r[:, ch, :]\n",
    "    \n",
    "    # 3A. Fit and transform x_test_e for this channel\n",
    "    scaler_ch = StandardScaler()\n",
    "    channel_data_e_scaled = scaler_ch.fit_transform(channel_data_e)\n",
    "    channel_data_v_scaled = scaler_ch.transform(channel_data_v)\n",
    "    channel_data_n_scaled =  scaler_ch.transform(channel_data_n)\n",
    "\n",
    "    pca_ch = PCA(n_components=5)\n",
    "    channel_data_e_pca = pca_ch.fit_transform(channel_data_e_scaled)\n",
    "    channel_data_v_pca = pca_ch.transform(channel_data_v_scaled)\n",
    "    channel_data_n_pca = pca_ch.transform(channel_data_n_scaled)\n",
    "    \n",
    "    # 3C. Save the scaler and PCA objects if needed later (for other data)\n",
    "    #scalers.append(scaler_ch)\n",
    "    #pcas.append(pca_ch)\n",
    "    \n",
    "    # 3D. Collect the PCA-transformed data for each channel\n",
    "    x_test_e_pca_list.append(channel_data_e_pca)\n",
    "    x_test_v_pca_list.append(channel_data_v_pca)\n",
    "    x_test_n_pca_list.append(channel_data_n_pca)\n",
    "\n",
    "############################\n",
    "# Change 4: Stack the list back into single arrays.\n",
    "# Now x_test_e has shape (N, C, 5) and x_test_v has shape (M, C, 5).\n",
    "############################\n",
    "\n",
    "\n",
    "x_test_e = np.stack(x_test_e_pca_list, axis=1)\n",
    "x_test_v = np.stack(x_test_v_pca_list, axis=1)\n",
    "x_test_n = np.stack(x_test_n_pca_list, axis=1)\n",
    "############################\n",
    "# Optional: Inspect explained variance ratio per channel if needed\n",
    "############################\n",
    "# for i, pca_ch in enumerate(pcas):\n",
    "#     print(f\"Channel {i}, PCA explained variance ratio: {pca_ch.explained_variance_ratio_}\")\n",
    "\n",
    "def compute_embedding_batch_two(x_test_batch, embedding_network=None):\n",
    "    print(x_test_batch.shape)\n",
    "    return x_test_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd31a68-7c05-4a91-8781-421c96ce576a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 93, 5), (80643, 93, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_e.shape, x_test_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebcb4fc2-7a49-4626-92c9-196cefd40966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_data_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eda8e94-7ad3-4b72-9e70-4113c61baa8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84408, 93, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "743650c9-91f0-47a1-97d4-6359755a11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "\n",
    "def EERf(resutls):\n",
    "    resutls= np.array(resutls)\n",
    "    genuine  = resutls[resutls[:, 1] == 1][:, 0]\n",
    "    impostor = resutls[resutls[:, 1] == 0][:, 0]\n",
    "    stats_a = get_eer_stats(genuine, impostor)\n",
    "    return(stats_a.eer,stats_a.fmr100)\n",
    "\n",
    "def calculate_and_print_averages(y_train, resutls3):\n",
    "    u, counts = np.unique(y_train, return_counts=True)\n",
    "    eer_values = []\n",
    "    ii = 0\n",
    "\n",
    "    for i in resutls3.keys():\n",
    "        re = EERf(resutls3[i])\n",
    "        eer = re[0]\n",
    "        print(f\"{i}: EER = {re[0]:.4f}, FMR100 = {re[1]:.4f}, Count = {counts[ii]}\")\n",
    "        eer_values.append(eer)\n",
    "        ii += 1\n",
    "\n",
    "    average_eer = np.mean(eer_values) * 100\n",
    "    std_eer = np.std(eer_values) * 100\n",
    "    \n",
    "    print(f\"Final Average EER: {average_eer:.4f}\")\n",
    "    print(f\"Final EER Standard Deviation: {std_eer:.4f}\")\n",
    "    print(f\"${average_eer:.2f} \\\\pm {std_eer:.2f}$\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def calculate_similarity_scores_two(enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance):\n",
    "    similarity_results = []\n",
    "    similarity_results_by_class = []\n",
    "    similarity_results_by_class_dict = defaultdict(list)\n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    class_indices = [np.where(y_enrollment == cls)[0] for cls in unique_classes]\n",
    "    print(verification_embeddings.shape, enrollment_embeddings.shape)\n",
    "    if distance == \"cd\":\n",
    "        similarity_matrix = -1 * cd(verification_embeddings, enrollment_embeddings)\n",
    "    elif distance == \"ed\":\n",
    "        similarity_matrix = -1 * ed(verification_embeddings, enrollment_embeddings)\n",
    "\n",
    "    for i in range(similarity_matrix.shape[0]):\n",
    "        current_class = y_verification[i]\n",
    "        predicted_scores = similarity_matrix[i]\n",
    "        same_class_indices = class_indices[np.where(unique_classes == current_class)[0][0]]\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            same_class_indices = class_indices[np.where(unique_classes == cls)[0][0]]\n",
    "            max_score = sum(sorted(predicted_scores[same_class_indices], reverse=True)[:10]) / 10\n",
    "            if current_class == cls:\n",
    "                similarity_results_by_class.append([max_score, 1, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 1, current_class, cls, i, cls])\n",
    "            else:\n",
    "                similarity_results_by_class.append([max_score, 0, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 0, current_class, cls, i, cls])\n",
    "\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def assessment_model_data_two(enrollment_data, ye, verification_data, yv, e_network, distance):\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    similarity_results_by_class, similarity_results_by_class_dict = calculate_similarity_scores_two(\n",
    "        enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance\n",
    "    )\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def compute_embedding_batch_two(x_test_batch, embedding_network=None):\n",
    "    print(x_test_batch.shape)\n",
    "    return x_test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d5743e-32f4-40bc-a92e-443523aa59e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70: EER = 0.5200, FMR100 = 0.9983, Count = 100\n",
      "86: EER = 0.4474, FMR100 = 0.9983, Count = 100\n",
      "96: EER = 0.5631, FMR100 = 1.0000, Count = 100\n",
      "125: EER = 0.3474, FMR100 = 0.9844, Count = 100\n",
      "129: EER = 0.4083, FMR100 = 1.0000, Count = 100\n",
      "167: EER = 0.7601, FMR100 = 1.0000, Count = 100\n",
      "174: EER = 0.5575, FMR100 = 0.9983, Count = 100\n",
      "175: EER = 0.8660, FMR100 = 1.0000, Count = 100\n",
      "183: EER = 0.3740, FMR100 = 0.8700, Count = 100\n",
      "194: EER = 0.5664, FMR100 = 0.9994, Count = 100\n",
      "197: EER = 0.4633, FMR100 = 0.9917, Count = 100\n",
      "199: EER = 0.4106, FMR100 = 0.9950, Count = 100\n",
      "201: EER = 0.5944, FMR100 = 1.0000, Count = 100\n",
      "203: EER = 0.4820, FMR100 = 0.9620, Count = 100\n",
      "206: EER = 0.8202, FMR100 = 1.0000, Count = 100\n",
      "207: EER = 0.4518, FMR100 = 0.9995, Count = 100\n",
      "214: EER = 0.4378, FMR100 = 0.9607, Count = 100\n",
      "219: EER = 0.5539, FMR100 = 0.9957, Count = 100\n",
      "230: EER = 0.5340, FMR100 = 0.9840, Count = 100\n",
      "236: EER = 0.5610, FMR100 = 0.9998, Count = 100\n",
      "245: EER = 0.6385, FMR100 = 1.0000, Count = 100\n",
      "250: EER = 0.5965, FMR100 = 0.9995, Count = 100\n",
      "257: EER = 0.4842, FMR100 = 0.9940, Count = 100\n",
      "260: EER = 0.4471, FMR100 = 0.9740, Count = 100\n",
      "261: EER = 0.4189, FMR100 = 0.9800, Count = 100\n",
      "262: EER = 0.4200, FMR100 = 0.9980, Count = 100\n",
      "265: EER = 0.3157, FMR100 = 0.8521, Count = 100\n",
      "268: EER = 0.5546, FMR100 = 0.9972, Count = 100\n",
      "270: EER = 0.3067, FMR100 = 0.8983, Count = 100\n",
      "281: EER = 0.3239, FMR100 = 0.9078, Count = 100\n",
      "291: EER = 0.5256, FMR100 = 1.0000, Count = 100\n",
      "296: EER = 0.5950, FMR100 = 1.0000, Count = 100\n",
      "299: EER = 0.4767, FMR100 = 1.0000, Count = 100\n",
      "303: EER = 0.7016, FMR100 = 1.0000, Count = 100\n",
      "306: EER = 0.2745, FMR100 = 0.9545, Count = 100\n",
      "314: EER = 0.5763, FMR100 = 1.0000, Count = 100\n",
      "322: EER = 0.6650, FMR100 = 0.9995, Count = 100\n",
      "325: EER = 0.3852, FMR100 = 1.0000, Count = 100\n",
      "342: EER = 0.4405, FMR100 = 1.0000, Count = 100\n",
      "348: EER = 0.5765, FMR100 = 0.9995, Count = 100\n",
      "357: EER = 0.4609, FMR100 = 0.9990, Count = 100\n",
      "364: EER = 0.5062, FMR100 = 1.0000, Count = 100\n",
      "374: EER = 0.3117, FMR100 = 0.9995, Count = 100\n",
      "407: EER = 0.7503, FMR100 = 1.0000, Count = 100\n",
      "414: EER = 0.4067, FMR100 = 0.9775, Count = 100\n",
      "415: EER = 0.4137, FMR100 = 0.9950, Count = 100\n",
      "418: EER = 0.5539, FMR100 = 1.0000, Count = 100\n",
      "419: EER = 0.5200, FMR100 = 0.9988, Count = 100\n",
      "422: EER = 0.3300, FMR100 = 1.0000, Count = 100\n",
      "436: EER = 0.3950, FMR100 = 0.9843, Count = 100\n",
      "Final Average EER: 50.1808\n",
      "Final EER Standard Deviation: 13.1536\n",
      "$50.18 \\pm 13.15$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"ed\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2777931b-417c-4537-81bd-ba298c885fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70: EER = 0.5389, FMR100 = 0.9883, Count = 100\n",
      "86: EER = 0.3550, FMR100 = 0.8817, Count = 100\n",
      "96: EER = 0.5018, FMR100 = 0.9541, Count = 100\n",
      "125: EER = 0.4033, FMR100 = 0.9828, Count = 100\n",
      "129: EER = 0.3962, FMR100 = 0.9775, Count = 100\n",
      "167: EER = 0.3000, FMR100 = 0.9800, Count = 100\n",
      "174: EER = 0.4128, FMR100 = 0.9050, Count = 100\n",
      "175: EER = 0.1980, FMR100 = 0.5220, Count = 100\n",
      "183: EER = 0.2480, FMR100 = 0.8880, Count = 100\n",
      "194: EER = 0.5633, FMR100 = 0.9928, Count = 100\n",
      "197: EER = 0.4802, FMR100 = 0.9794, Count = 100\n",
      "199: EER = 0.4361, FMR100 = 0.9561, Count = 100\n",
      "201: EER = 0.4561, FMR100 = 0.8661, Count = 100\n",
      "203: EER = 0.1440, FMR100 = 0.4840, Count = 100\n",
      "206: EER = 0.0883, FMR100 = 0.8200, Count = 100\n",
      "207: EER = 0.4708, FMR100 = 0.9845, Count = 100\n",
      "214: EER = 0.4302, FMR100 = 0.9774, Count = 100\n",
      "219: EER = 0.4677, FMR100 = 1.0000, Count = 100\n",
      "230: EER = 0.5924, FMR100 = 0.9940, Count = 100\n",
      "236: EER = 0.4921, FMR100 = 0.9695, Count = 100\n",
      "245: EER = 0.3506, FMR100 = 0.8920, Count = 100\n",
      "250: EER = 0.4860, FMR100 = 0.9740, Count = 100\n",
      "257: EER = 0.4548, FMR100 = 1.0000, Count = 100\n",
      "260: EER = 0.4325, FMR100 = 0.9767, Count = 100\n",
      "261: EER = 0.5111, FMR100 = 0.9778, Count = 100\n",
      "262: EER = 0.2627, FMR100 = 0.9840, Count = 100\n",
      "265: EER = 0.3749, FMR100 = 0.9349, Count = 100\n",
      "268: EER = 0.3778, FMR100 = 0.9606, Count = 100\n",
      "270: EER = 0.4634, FMR100 = 0.9756, Count = 100\n",
      "281: EER = 0.3640, FMR100 = 0.9444, Count = 100\n",
      "291: EER = 0.4296, FMR100 = 0.9944, Count = 100\n",
      "296: EER = 0.3982, FMR100 = 0.9386, Count = 100\n",
      "299: EER = 0.3386, FMR100 = 0.9581, Count = 100\n",
      "303: EER = 0.4021, FMR100 = 0.9785, Count = 100\n",
      "306: EER = 0.2619, FMR100 = 0.6182, Count = 100\n",
      "314: EER = 0.4706, FMR100 = 0.9980, Count = 100\n",
      "322: EER = 0.3130, FMR100 = 0.8945, Count = 100\n",
      "325: EER = 0.2552, FMR100 = 0.9529, Count = 100\n",
      "342: EER = 0.3905, FMR100 = 0.9955, Count = 100\n",
      "348: EER = 0.3150, FMR100 = 0.9114, Count = 100\n",
      "357: EER = 0.3540, FMR100 = 0.9814, Count = 100\n",
      "364: EER = 0.3849, FMR100 = 0.9867, Count = 100\n",
      "374: EER = 0.2895, FMR100 = 0.9558, Count = 100\n",
      "407: EER = 0.5014, FMR100 = 0.9637, Count = 100\n",
      "414: EER = 0.2850, FMR100 = 0.9650, Count = 100\n",
      "415: EER = 0.1463, FMR100 = 0.5513, Count = 100\n",
      "418: EER = 0.2687, FMR100 = 0.8337, Count = 100\n",
      "419: EER = 0.2788, FMR100 = 0.7250, Count = 100\n",
      "422: EER = 0.2057, FMR100 = 0.8586, Count = 100\n",
      "436: EER = 0.1750, FMR100 = 0.7786, Count = 100\n",
      "Final Average EER: 37.0338\n",
      "Final EER Standard Deviation: 11.4614\n",
      "$37.03 \\pm 11.46$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"cd\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d6238-6ab4-4907-899c-452199065860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a044fd-4897-4c89-80f8-7c9de3f794b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c169d80d-2c6a-451f-8014-ad58ae358173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each array from 3D to 2D\n",
    "x_test_e = x_test_e.reshape(x_test_e.shape[0], -1)\n",
    "x_test_v= x_test_v.reshape(x_test_v.shape[0], -1)\n",
    "x_test_n = x_test_n.reshape(x_test_n.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e318bd-774b-4957-8d9d-57a0be1bfb09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(84408, 465)\n",
      "Unique classes:  [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\n",
      " 230 236 245 250 257 260 261 262 265 268 270 281 291 296 299 303 306 314\n",
      " 322 325 342 348 357 364 374 407 414 415 418 419 422 436]\n",
      "genuine_scores:  1800 0.005633333333333296 impostor_scores 78843 0.0012864807275218767\n",
      "Class 70: RandomForest EER = 0.4205\n",
      "genuine_scores:  1800 0.0266277777777778 impostor_scores 78843 0.0013147647857134675\n",
      "Class 86: RandomForest EER = 0.3525\n",
      "genuine_scores:  1700 0.001470588235294116 impostor_scores 78943 0.0007860101592287981\n",
      "Class 96: RandomForest EER = 0.4815\n",
      "genuine_scores:  1800 0.004911111111111086 impostor_scores 78843 0.0007612597186814144\n",
      "Class 125: RandomForest EER = 0.4369\n",
      "genuine_scores:  400 0.004900000000000003 impostor_scores 80243 0.0015197587328490986\n",
      "Class 129: RandomForest EER = 0.3991\n",
      "genuine_scores:  100 0.005300000000000003 impostor_scores 80543 0.001179866655078727\n",
      "Class 167: RandomForest EER = 0.3517\n",
      "genuine_scores:  1800 0.005133333333333299 impostor_scores 78843 0.0008605710082061798\n",
      "Class 174: RandomForest EER = 0.4123\n",
      "genuine_scores:  500 0.04552000000000004 impostor_scores 80143 0.00036709381979712345\n",
      "Class 175: RandomForest EER = 0.1362\n",
      "genuine_scores:  500 0.030099999999999932 impostor_scores 80143 0.000815542218284801\n",
      "Class 183: RandomForest EER = 0.3049\n",
      "genuine_scores:  1800 0.008349999999999969 impostor_scores 78843 0.0008122471240312868\n",
      "Class 194: RandomForest EER = 0.4219\n",
      "genuine_scores:  1800 0.003816666666666653 impostor_scores 78843 0.0012611138591885752\n",
      "Class 197: RandomForest EER = 0.4665\n",
      "genuine_scores:  1800 0.00751666666666664 impostor_scores 78843 0.0014363989193714915\n",
      "Class 199: RandomForest EER = 0.4391\n",
      "genuine_scores:  1800 0.006322222222222183 impostor_scores 78843 0.0013308727471051174\n",
      "Class 201: RandomForest EER = 0.4131\n",
      "genuine_scores:  500 0.19828000000000004 impostor_scores 80143 0.0013643112935628468\n",
      "Class 203: RandomForest EER = 0.1520\n",
      "genuine_scores:  500 0.011959999999999932 impostor_scores 80143 0.0014456658722534496\n",
      "Class 206: RandomForest EER = 0.2657\n",
      "genuine_scores:  4000 0.002099999999999984 impostor_scores 76643 0.0013223647299819615\n",
      "Class 207: RandomForest EER = 0.4839\n",
      "genuine_scores:  1679 0.011715306730196553 impostor_scores 78964 0.0010625094979991238\n",
      "Class 214: RandomForest EER = 0.4237\n",
      "genuine_scores:  464 0.007435344827586184 impostor_scores 80179 0.001761309070953824\n",
      "Class 219: RandomForest EER = 0.3605\n",
      "genuine_scores:  500 0.0032600000000000016 impostor_scores 80143 0.0011070211996057578\n",
      "Class 230: RandomForest EER = 0.4660\n",
      "genuine_scores:  4100 0.003012195121951183 impostor_scores 76543 0.001459963680545731\n",
      "Class 236: RandomForest EER = 0.4615\n",
      "genuine_scores:  500 0.008159999999999968 impostor_scores 80143 0.001456022360031617\n",
      "Class 245: RandomForest EER = 0.3201\n",
      "genuine_scores:  4000 0.0044049999999999844 impostor_scores 76643 0.0021054760382552846\n",
      "Class 250: RandomForest EER = 0.4563\n",
      "genuine_scores:  500 0.0006400000000000002 impostor_scores 80143 0.0008350074242291903\n",
      "Class 257: RandomForest EER = 0.4941\n",
      "genuine_scores:  4800 0.00734166666666671 impostor_scores 75843 0.0012192291971573556\n",
      "Class 260: RandomForest EER = 0.4232\n",
      "genuine_scores:  900 0.004088888888888883 impostor_scores 79743 0.0014062676347768098\n",
      "Class 261: RandomForest EER = 0.4767\n",
      "genuine_scores:  500 0.028699999999999923 impostor_scores 80143 0.0012488926044695906\n",
      "Class 262: RandomForest EER = 0.2575\n",
      "genuine_scores:  3900 0.014589743589743557 impostor_scores 76743 0.0012699529598791403\n",
      "Class 265: RandomForest EER = 0.4481\n",
      "genuine_scores:  1800 0.005433333333333309 impostor_scores 78843 0.0011323770023972143\n",
      "Class 268: RandomForest EER = 0.4377\n",
      "genuine_scores:  1800 0.007216666666666663 impostor_scores 78843 0.0007216874040815249\n",
      "Class 270: RandomForest EER = 0.4905\n",
      "genuine_scores:  1800 0.014627777777777814 impostor_scores 78843 0.0005013761526070829\n",
      "Class 281: RandomForest EER = 0.4197\n",
      "genuine_scores:  1800 0.0031333333333333217 impostor_scores 78843 0.0007116674910898784\n",
      "Class 291: RandomForest EER = 0.4644\n",
      "genuine_scores:  2200 0.000931818181818182 impostor_scores 78443 0.0010953176191630053\n",
      "Class 296: RandomForest EER = 0.4948\n",
      "genuine_scores:  2100 0.010166666666666685 impostor_scores 78543 0.001575570069898153\n",
      "Class 299: RandomForest EER = 0.3809\n",
      "genuine_scores:  2000 0.011830000000000038 impostor_scores 78643 0.0014551835509836548\n",
      "Class 303: RandomForest EER = 0.3938\n",
      "genuine_scores:  2200 0.028104545454545507 impostor_scores 78443 0.0003107989240595127\n",
      "Class 306: RandomForest EER = 0.3464\n",
      "genuine_scores:  500 0.002880000000000002 impostor_scores 80143 0.0014797299826561708\n",
      "Class 314: RandomForest EER = 0.4402\n",
      "genuine_scores:  2000 0.011070000000000055 impostor_scores 78643 0.0017256462749388273\n",
      "Class 322: RandomForest EER = 0.2962\n",
      "genuine_scores:  2100 0.015371428571428643 impostor_scores 78543 0.001159364933857937\n",
      "Class 325: RandomForest EER = 0.3592\n",
      "genuine_scores:  2200 0.014436363636363726 impostor_scores 78443 0.0009614624631898459\n",
      "Class 342: RandomForest EER = 0.3619\n",
      "genuine_scores:  2200 0.00730454545454539 impostor_scores 78443 0.0011158420764122332\n",
      "Class 348: RandomForest EER = 0.3677\n",
      "genuine_scores:  2100 0.013304761904761948 impostor_scores 78543 0.001678698292655079\n",
      "Class 357: RandomForest EER = 0.3598\n",
      "genuine_scores:  2100 0.020580952380952436 impostor_scores 78543 0.0008159861477152464\n",
      "Class 364: RandomForest EER = 0.3273\n",
      "genuine_scores:  1900 0.02227894736842111 impostor_scores 78743 0.0010609197007988356\n",
      "Class 374: RandomForest EER = 0.3044\n",
      "genuine_scores:  800 0.005462499999999973 impostor_scores 79843 0.0016687749708804596\n",
      "Class 407: RandomForest EER = 0.3817\n",
      "genuine_scores:  800 0.026662499999999992 impostor_scores 79843 0.0009826785065691738\n",
      "Class 414: RandomForest EER = 0.2455\n",
      "genuine_scores:  800 0.13851250000000007 impostor_scores 79843 0.0007007502223112728\n",
      "Class 415: RandomForest EER = 0.0917\n",
      "genuine_scores:  800 0.004137499999999993 impostor_scores 79843 0.0005125057926180152\n",
      "Class 418: RandomForest EER = 0.4601\n",
      "genuine_scores:  800 0.021124999999999967 impostor_scores 79843 0.0013133274050324611\n",
      "Class 419: RandomForest EER = 0.3412\n",
      "genuine_scores:  700 0.040514285714285794 impostor_scores 79943 0.0011201731233504448\n",
      "Class 422: RandomForest EER = 0.1346\n",
      "genuine_scores:  700 0.019114285714285653 impostor_scores 79943 0.0007075040966688641\n",
      "Class 436: RandomForest EER = 0.3287\n",
      "Final Average EER RandomForest: 37.5076\n",
      "Final EER Standard Deviation RandomForest: 9.7201\n",
      "$37.51 \\pm 9.72$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'mean': 37.50757238037513, 'std': 9.720110703193214}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c502ff97-a4ac-426c-a03c-38ed5256ef16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371b869a-1185-4cb3-85ca-c6c2c4edd79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(84408, 465)\n",
      "Unique classes:  [ 70  86  96 125 129 167 174 175 183 194 197 199 201 203 206 207 214 219\n",
      " 230 236 245 250 257 260 261 262 265 268 270 281 291 296 299 303 306 314\n",
      " 322 325 342 348 357 364 374 407 414 415 418 419 422 436]\n",
      "genuine_scores:  1800 0.17052172603045931 impostor_scores 78843 0.16550966227282235\n",
      "Class 70: Linear SVM with Kernel Approximation EER = 0.4995\n",
      "genuine_scores:  1800 0.14423023959587097 impostor_scores 78843 0.14802465224013794\n",
      "Class 86: Linear SVM with Kernel Approximation EER = 0.5041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1700 0.17604926424243902 impostor_scores 78943 0.1827498559054428\n",
      "Class 96: Linear SVM with Kernel Approximation EER = 0.4960\n",
      "genuine_scores:  1800 0.14407845501057345 impostor_scores 78843 0.13967734170685572\n",
      "Class 125: Linear SVM with Kernel Approximation EER = 0.4967\n",
      "genuine_scores:  400 0.1901334928159374 impostor_scores 80243 0.18331502936635627\n",
      "Class 129: Linear SVM with Kernel Approximation EER = 0.4953\n",
      "genuine_scores:  100 0.15373587741245667 impostor_scores 80543 0.190962773781969\n",
      "Class 167: Linear SVM with Kernel Approximation EER = 0.5423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.1874090915307937 impostor_scores 78843 0.1810154247947474\n",
      "Class 174: Linear SVM with Kernel Approximation EER = 0.4997\n",
      "genuine_scores:  500 0.245076185783983 impostor_scores 80143 0.2377920864810562\n",
      "Class 175: Linear SVM with Kernel Approximation EER = 0.4780\n",
      "genuine_scores:  500 0.15609924395924774 impostor_scores 80143 0.1460208069524503\n",
      "Class 183: Linear SVM with Kernel Approximation EER = 0.4945\n",
      "genuine_scores:  1800 0.12979508868635004 impostor_scores 78843 0.13315623721628875\n",
      "Class 194: Linear SVM with Kernel Approximation EER = 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.16600409364692886 impostor_scores 78843 0.16802996988844426\n",
      "Class 197: Linear SVM with Kernel Approximation EER = 0.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.15331566531367738 impostor_scores 78843 0.14975119218419505\n",
      "Class 199: Linear SVM with Kernel Approximation EER = 0.4922\n",
      "genuine_scores:  1800 0.18790701115251512 impostor_scores 78843 0.1844243614966745\n",
      "Class 201: Linear SVM with Kernel Approximation EER = 0.5000\n",
      "genuine_scores:  500 0.2568955477959234 impostor_scores 80143 0.25630765472812383\n",
      "Class 203: Linear SVM with Kernel Approximation EER = 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  500 0.21731799585702613 impostor_scores 80143 0.23348852489947855\n",
      "Class 206: Linear SVM with Kernel Approximation EER = 0.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  4000 0.13110539717404543 impostor_scores 76643 0.132819650482842\n",
      "Class 207: Linear SVM with Kernel Approximation EER = 0.5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1679 0.20001149589155773 impostor_scores 78964 0.19943775781019127\n",
      "Class 214: Linear SVM with Kernel Approximation EER = 0.5039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  464 0.10524687575268239 impostor_scores 80179 0.12315632002988128\n",
      "Class 219: Linear SVM with Kernel Approximation EER = 0.5002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  500 0.09470634794664898 impostor_scores 80143 0.09955066112595246\n",
      "Class 230: Linear SVM with Kernel Approximation EER = 0.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  4100 0.1702634490111629 impostor_scores 76543 0.17107358683959728\n",
      "Class 236: Linear SVM with Kernel Approximation EER = 0.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  500 0.18413219894263738 impostor_scores 80143 0.1915170882542318\n",
      "Class 245: Linear SVM with Kernel Approximation EER = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  4000 0.20884986667759736 impostor_scores 76643 0.20631616451167237\n",
      "Class 250: Linear SVM with Kernel Approximation EER = 0.4978\n",
      "genuine_scores:  500 0.20987319200680926 impostor_scores 80143 0.2020441662543979\n",
      "Class 257: Linear SVM with Kernel Approximation EER = 0.4840\n",
      "genuine_scores:  4800 0.20555868558395096 impostor_scores 75843 0.20828217141333272\n",
      "Class 260: Linear SVM with Kernel Approximation EER = 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  900 0.14172110543408584 impostor_scores 79743 0.13733555694031324\n",
      "Class 261: Linear SVM with Kernel Approximation EER = 0.5067\n",
      "genuine_scores:  500 0.14128476968819562 impostor_scores 80143 0.13155135976026028\n",
      "Class 262: Linear SVM with Kernel Approximation EER = 0.4920\n",
      "genuine_scores:  3900 0.3333799050258963 impostor_scores 76743 0.3374123250267818\n",
      "Class 265: Linear SVM with Kernel Approximation EER = 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.12978105992134298 impostor_scores 78843 0.13038822187792393\n",
      "Class 268: Linear SVM with Kernel Approximation EER = 0.4961\n",
      "genuine_scores:  1800 0.08515007798798266 impostor_scores 78843 0.08198916900576762\n",
      "Class 270: Linear SVM with Kernel Approximation EER = 0.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1800 0.10338130307463 impostor_scores 78843 0.10026241355410606\n",
      "Class 281: Linear SVM with Kernel Approximation EER = 0.4878\n",
      "genuine_scores:  1800 0.2059306175495985 impostor_scores 78843 0.20204611417028498\n",
      "Class 291: Linear SVM with Kernel Approximation EER = 0.4896\n",
      "genuine_scores:  2200 0.1624934585680656 impostor_scores 78443 0.15838981006184397\n",
      "Class 296: Linear SVM with Kernel Approximation EER = 0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  2100 0.1306898362399905 impostor_scores 78543 0.1268850867006085\n",
      "Class 299: Linear SVM with Kernel Approximation EER = 0.4992\n",
      "genuine_scores:  2000 0.1543680361451335 impostor_scores 78643 0.1539477247460496\n",
      "Class 303: Linear SVM with Kernel Approximation EER = 0.4987\n",
      "genuine_scores:  2200 0.14037171685216188 impostor_scores 78443 0.1347447885094663\n",
      "Class 306: Linear SVM with Kernel Approximation EER = 0.4988\n",
      "genuine_scores:  500 0.3253344236141189 impostor_scores 80143 0.3296069596972207\n",
      "Class 314: Linear SVM with Kernel Approximation EER = 0.5003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  2000 0.14909549101373337 impostor_scores 78643 0.13798701783303297\n",
      "Class 322: Linear SVM with Kernel Approximation EER = 0.4952\n",
      "genuine_scores:  2100 0.1929508996510085 impostor_scores 78543 0.20240872048671826\n",
      "Class 325: Linear SVM with Kernel Approximation EER = 0.5039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  2200 0.15061483450936405 impostor_scores 78443 0.15108464115363654\n",
      "Class 342: Linear SVM with Kernel Approximation EER = 0.4991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  2200 0.16755194158245157 impostor_scores 78443 0.16323846689349736\n",
      "Class 348: Linear SVM with Kernel Approximation EER = 0.4932\n",
      "genuine_scores:  2100 0.2209070695184864 impostor_scores 78543 0.21190597079408438\n",
      "Class 357: Linear SVM with Kernel Approximation EER = 0.4910\n",
      "genuine_scores:  2100 0.2520084257350607 impostor_scores 78543 0.25231484383793923\n",
      "Class 364: Linear SVM with Kernel Approximation EER = 0.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  1900 0.18409018483130515 impostor_scores 78743 0.19127206289890494\n",
      "Class 374: Linear SVM with Kernel Approximation EER = 0.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  800 0.13241001712403352 impostor_scores 79843 0.13209127994699035\n",
      "Class 407: Linear SVM with Kernel Approximation EER = 0.5000\n",
      "genuine_scores:  800 0.08336407964617991 impostor_scores 79843 0.08900585055279098\n",
      "Class 414: Linear SVM with Kernel Approximation EER = 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  800 0.17674488505999103 impostor_scores 79843 0.19063386249846134\n",
      "Class 415: Linear SVM with Kernel Approximation EER = 0.5050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  800 0.3262235303449446 impostor_scores 79843 0.3456210699468808\n",
      "Class 418: Linear SVM with Kernel Approximation EER = 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  800 0.2191261891983875 impostor_scores 79843 0.2166426658042181\n",
      "Class 419: Linear SVM with Kernel Approximation EER = 0.4966\n",
      "genuine_scores:  700 0.14678625772065987 impostor_scores 79943 0.16382242623774007\n",
      "Class 422: Linear SVM with Kernel Approximation EER = 0.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/lib/python3.12/site-packages/pyeer/eer_stats.py:220: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genuine_scores:  700 0.2322644287143284 impostor_scores 79943 0.23408711483281577\n",
      "Class 436: Linear SVM with Kernel Approximation EER = 0.5043\n",
      "Final Average EER RandomForest: 49.9875\n",
      "Final EER Standard Deviation RandomForest: 0.8593\n",
      "$49.99 \\pm 0.86$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForest': {'mean': 49.987478205764674, 'std': 0.8592612187510199}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b43e08-0681-41f3-9254-c95088aae85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da01cb0-eb65-4dcc-9e33-0d3611f3cb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "852bcf25-9d1a-47d5-bba2-7c06351fc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        # Replace RandomForest with Linear SVM + Kernel Approximation\n",
    "        pipeline = Pipeline([\n",
    "            #('scaler', StandardScaler()),\n",
    "            ('kernel_approximation', RBFSampler(gamma=1, random_state=42, n_components=500)),  # Approximate RBF kernel\n",
    "            ('classifier', SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, class_weight='balanced', random_state=42, n_jobs=20))\n",
    "        ])\n",
    "        \n",
    "        # Shuffle and split the data\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        \n",
    "        # Train the pipeline\n",
    "        pipeline.fit(X, y)\n",
    "        \n",
    "        # Predict probabilities for the test set\n",
    "        # Note: SGDClassifier doesn't provide probabilities directly, so we use decision_function\n",
    "        decision_scores = pipeline.decision_function(test_embeddings)\n",
    "        probabilities = 1 / (1 + np.exp(-decision_scores))  # Sigmoid function to map decision scores to probabilities\n",
    "        \n",
    "        # Calculate EER\n",
    "        svm_eer = calculate_eer(test_labels, probabilities)\n",
    "        \n",
    "        print(f\"Class {cls}: Linear SVM with Kernel Approximation EER = {svm_eer:.4f}\")\n",
    "        \n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': svm_eer}\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a443e2-2b15-49f8-9fe9-78b8df937c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def calculate_eer(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Calculate the Equal Error Rate (EER) and FMR100 using pyeer.\n",
    "    \"\"\"\n",
    "    # Separate genuine and impostor scores\n",
    "    genuine_scores = y_scores[y_true == 1]\n",
    "    impostor_scores = y_scores[y_true == 0]\n",
    "    #print(y_true, y_scores)\n",
    "\n",
    "    #print(genuine_scores, impostor_scores)\n",
    "    print(\"genuine_scores: \", len(genuine_scores), sum(genuine_scores)/len(genuine_scores), \"impostor_scores\", len(impostor_scores), sum(impostor_scores)/len(impostor_scores))\n",
    "    \n",
    "    # Use pyeer to compute EER stats\n",
    "    stats = get_eer_stats(genuine_scores, impostor_scores)\n",
    "    \n",
    "    return stats.eer\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            #('scaler', StandardScaler()),\n",
    "            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=20))\n",
    "            #('classifier', SVC(probability=True, random_state=42, class_weight='balanced'))\n",
    "            #('classifier', KNeighborsClassifier(n_neighbors=20, weights='distance'))\n",
    "        ])\n",
    "        #svm_model = SVC(probability=True, random_state=42, class_weight='balanced')\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        pipeline.fit(X, y)\n",
    "        probabilities = pipeline.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "        # Calculate EER\n",
    "        rf_eer = calculate_eer(test_labels, probabilities)\n",
    "\n",
    "        print(f\"Class {cls}: RandomForest EER = {rf_eer:.4f}\")\n",
    "\n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': rf_eer}\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_mean_std(results):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of EER values for each model in the results dictionary.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): A dictionary where keys are classes, and values are dictionaries containing model metrics.\n",
    "                        Example: {cls: {'RandomForest': {'EER': value}}}\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing mean and std for each model across all classes.\n",
    "    \"\"\"\n",
    "    # Extract EER values for each model\n",
    "    model_eer_values = {}\n",
    "    for cls, metrics in results.items():\n",
    "        for model, model_metrics in metrics.items():\n",
    "            if model not in model_eer_values:\n",
    "                model_eer_values[model] = []\n",
    "            model_eer_values[model].append(model_metrics['EER'])\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    model_stats = {}\n",
    "    for model, eer_values in model_eer_values.items():\n",
    "        mean = np.mean(eer_values) * 100\n",
    "        std = np.std(eer_values) * 100\n",
    "        model_stats[model] = {'mean': mean, 'std': std}\n",
    "        print(f\"Final Average EER {model}: {mean:.4f}\")\n",
    "        print(f\"Final EER Standard Deviation {model}: {std:.4f}\")\n",
    "        print(f\"${mean:.2f} \\\\pm {std:.2f}$\") \n",
    "        \n",
    "   \n",
    "    return model_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c59424-2982-4306-9b6c-93a4e38ff894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9024c31-cf31-4f78-9ca1-a496e1f43307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
