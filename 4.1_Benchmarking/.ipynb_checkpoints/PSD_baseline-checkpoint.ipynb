{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d848a9e-99aa-439c-9830-743f2a258de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 70, Number of unique sessions: 19\n",
      "Subject 86, Number of unique sessions: 19\n",
      "Subject 96, Number of unique sessions: 18\n",
      "Subject 125, Number of unique sessions: 19\n",
      "Subject 129, Number of unique sessions: 5\n",
      "Subject 167, Number of unique sessions: 2\n",
      "Subject 174, Number of unique sessions: 19\n",
      "Subject 175, Number of unique sessions: 6\n",
      "Subject 183, Number of unique sessions: 6\n",
      "Subject 194, Number of unique sessions: 19\n",
      "Subject 197, Number of unique sessions: 19\n",
      "Subject 199, Number of unique sessions: 19\n",
      "Subject 201, Number of unique sessions: 19\n",
      "Subject 203, Number of unique sessions: 6\n",
      "Subject 206, Number of unique sessions: 6\n",
      "Subject 207, Number of unique sessions: 41\n",
      "Subject 214, Number of unique sessions: 18\n",
      "Subject 219, Number of unique sessions: 5\n",
      "Subject 230, Number of unique sessions: 6\n",
      "Subject 236, Number of unique sessions: 42\n",
      "Subject 245, Number of unique sessions: 6\n",
      "Subject 250, Number of unique sessions: 41\n",
      "Subject 257, Number of unique sessions: 6\n",
      "Subject 260, Number of unique sessions: 49\n",
      "Subject 261, Number of unique sessions: 10\n",
      "Subject 262, Number of unique sessions: 6\n",
      "Subject 265, Number of unique sessions: 40\n",
      "Subject 268, Number of unique sessions: 19\n",
      "Subject 270, Number of unique sessions: 19\n",
      "Subject 281, Number of unique sessions: 19\n",
      "Subject 291, Number of unique sessions: 19\n",
      "Subject 296, Number of unique sessions: 23\n",
      "Subject 299, Number of unique sessions: 22\n",
      "Subject 303, Number of unique sessions: 21\n",
      "Subject 306, Number of unique sessions: 23\n",
      "Subject 314, Number of unique sessions: 6\n",
      "Subject 322, Number of unique sessions: 21\n",
      "Subject 325, Number of unique sessions: 22\n",
      "Subject 342, Number of unique sessions: 23\n",
      "Subject 348, Number of unique sessions: 23\n",
      "Subject 357, Number of unique sessions: 22\n",
      "Subject 364, Number of unique sessions: 22\n",
      "Subject 374, Number of unique sessions: 20\n",
      "Subject 407, Number of unique sessions: 9\n",
      "Subject 414, Number of unique sessions: 9\n",
      "Subject 415, Number of unique sessions: 9\n",
      "Subject 418, Number of unique sessions: 9\n",
      "Subject 419, Number of unique sessions: 9\n",
      "Subject 422, Number of unique sessions: 8\n",
      "Subject 436, Number of unique sessions: 8\n"
     ]
    }
   ],
   "source": [
    "# import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Load test data from test_raw.h5\n",
    "with h5py.File(\"./data/test_psd_bins.h5\", \"r\") as f_test:\n",
    "    X_test = f_test['data'][:]\n",
    "    Y_test = f_test['labels'][:]\n",
    "    S_test = f_test['sessions'][:]\n",
    "    #H_test = f_test['hardwares'][:]  # Load the 'hardwares' dataset as h_test\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, S_combined, and h_combined contain the merged data\n",
    "\n",
    "\n",
    "# Now, X_combined, Y_combined, and S_combined contain the merged data\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Reorder the arrays according to the shuffled indices\n",
    "x_test = X_test[indices]\n",
    "y_test = Y_test[indices]\n",
    "s_test = S_test[indices]\n",
    "#h_test = H_test[indices]\n",
    "\n",
    "\n",
    "# Find unique subjects\n",
    "unique_subjects = np.unique(y_test)\n",
    "\n",
    "# Initialize lists to hold the data for x_test_e and x_test_v\n",
    "x_test_e_list = []\n",
    "y_test_e_list = []\n",
    "s_test_e_list = []\n",
    "h_test_e_list = []\n",
    "\n",
    "x_test_v_list = []\n",
    "y_test_v_list = []\n",
    "s_test_v_list = []\n",
    "h_test_v_list = []\n",
    "\n",
    "# Assign the minimum session for each subject to x_test_e and the rest to x_test_v\n",
    "for subject in unique_subjects:\n",
    "    subject_indices = np.where(y_test == subject)[0]\n",
    "    subject_sessions = s_test[subject_indices]\n",
    "    \n",
    "    # Skip subjects with fewer than two unique sessions\n",
    "    if len(np.unique(subject_sessions)) < 2:\n",
    "        continue\n",
    "\n",
    "    print(f\"Subject {subject}, Number of unique sessions: {len(np.unique(subject_sessions))}\")\n",
    "    \n",
    "    # Assign the minimum session to the evaluation set (x_test_e)\n",
    "    min_session = np.min(subject_sessions)\n",
    "    \n",
    "    # Append data to the evaluation set (min session)\n",
    "    x_test_e_list.extend(x_test[subject_indices][subject_sessions == min_session])\n",
    "    y_test_e_list.extend(y_test[subject_indices][subject_sessions == min_session])\n",
    "    s_test_e_list.extend(s_test[subject_indices][subject_sessions == min_session])\n",
    "    #h_test_e_list.extend(h_test[subject_indices][subject_sessions == min_session])\n",
    "\n",
    "    # Append remaining sessions to the validation set (x_test_v)\n",
    "    x_test_v_list.extend(x_test[subject_indices][subject_sessions != min_session])\n",
    "    y_test_v_list.extend(y_test[subject_indices][subject_sessions != min_session])\n",
    "    s_test_v_list.extend(s_test[subject_indices][subject_sessions != min_session])\n",
    "    #h_test_v_list.extend(h_test[subject_indices][subject_sessions != min_session])\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_e\n",
    "indices_e = np.arange(len(x_test_e_list))\n",
    "np.random.shuffle(indices_e)\n",
    "\n",
    "x_test_e = np.array(x_test_e_list)[indices_e]\n",
    "y_test_e = np.array(y_test_e_list)[indices_e]\n",
    "s_test_e = np.array(s_test_e_list)[indices_e]\n",
    "#h_test_e = np.array(h_test_v_list)[indices_e]\n",
    "\n",
    "# Shuffle and convert lists back to numpy arrays for x_test_v\n",
    "indices_v = np.arange(len(x_test_v_list))\n",
    "np.random.shuffle(indices_v)\n",
    "\n",
    "x_test_v = np.array(x_test_v_list)[indices_v]\n",
    "y_test_v = np.array(y_test_v_list)[indices_v]\n",
    "s_test_v = np.array(s_test_v_list)[indices_v]\n",
    "#h_test_v = np.array(h_test_v_list)[indices_v]\n",
    "# Optional: Save the new test evaluation and validation sets to npy files (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef094d6-7a5d-4a6d-932b-8a1a54b43162",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"./data/neg_psd_bins.h5\", \"r\") as f:\n",
    "    x_neg_r = f['data'][:]\n",
    "    y_neg = f['labels'][:]\n",
    "    s_neg = f['sessions'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da2da3f-5365-46c3-bcd4-8b632d9331ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics.pairwise import cosine_distances as cd\n",
    "from collections import defaultdict\n",
    "from pyeer.eer_info import get_eer_stats\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "\n",
    "def EERf(resutls):\n",
    "    resutls= np.array(resutls)\n",
    "    genuine  = resutls[resutls[:, 1] == 1][:, 0]\n",
    "    impostor = resutls[resutls[:, 1] == 0][:, 0]\n",
    "    stats_a = get_eer_stats(genuine, impostor)\n",
    "    return(stats_a.eer,stats_a.fmr100)\n",
    "\n",
    "def calculate_and_print_averages(y_train, resutls3):\n",
    "    u, counts = np.unique(y_train, return_counts=True)\n",
    "    eer_values = []\n",
    "    ii = 0\n",
    "\n",
    "    for i in resutls3.keys():\n",
    "        re = EERf(resutls3[i])\n",
    "        eer = re[0]\n",
    "        print(f\"{i}: EER = {re[0]:.4f}, FMR100 = {re[1]:.4f}, Count = {counts[ii]}\")\n",
    "        eer_values.append(eer)\n",
    "        ii += 1\n",
    "\n",
    "    average_eer = np.mean(eer_values) * 100\n",
    "    std_eer = np.std(eer_values) * 100\n",
    "    \n",
    "    print(f\"Final Average EER: {average_eer:.4f}\")\n",
    "    print(f\"Final EER Standard Deviation: {std_eer:.4f}\")\n",
    "    print(f\"${average_eer:.2f} \\\\pm {std_eer:.2f}$\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def calculate_similarity_scores_two(enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance):\n",
    "    similarity_results = []\n",
    "    similarity_results_by_class = []\n",
    "    similarity_results_by_class_dict = defaultdict(list)\n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    class_indices = [np.where(y_enrollment == cls)[0] for cls in unique_classes]\n",
    "    print(verification_embeddings.shape, enrollment_embeddings.shape)\n",
    "    if distance == \"cd\":\n",
    "        similarity_matrix = -1 * cd(verification_embeddings, enrollment_embeddings)\n",
    "    elif distance == \"ed\":\n",
    "        similarity_matrix = -1 * ed(verification_embeddings, enrollment_embeddings)\n",
    "\n",
    "    for i in range(similarity_matrix.shape[0]):\n",
    "        current_class = y_verification[i]\n",
    "        predicted_scores = similarity_matrix[i]\n",
    "        same_class_indices = class_indices[np.where(unique_classes == current_class)[0][0]]\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            same_class_indices = class_indices[np.where(unique_classes == cls)[0][0]]\n",
    "            max_score = sum(sorted(predicted_scores[same_class_indices], reverse=True)[:10]) / 10\n",
    "            if current_class == cls:\n",
    "                similarity_results_by_class.append([max_score, 1, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 1, current_class, cls, i, cls])\n",
    "            else:\n",
    "                similarity_results_by_class.append([max_score, 0, current_class, cls, i])\n",
    "                similarity_results_by_class_dict[cls].append([max_score, 0, current_class, cls, i, cls])\n",
    "\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def assessment_model_data_two(enrollment_data, ye, verification_data, yv, e_network, distance):\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    similarity_results_by_class, similarity_results_by_class_dict = calculate_similarity_scores_two(\n",
    "        enrollment_embeddings, y_enrollment, verification_embeddings, y_verification,distance\n",
    "    )\n",
    "    return similarity_results_by_class, similarity_results_by_class_dict\n",
    "\n",
    "def compute_embedding_batch_two(x_test_batch, embedding_network=None):\n",
    "    print(x_test_batch.shape)\n",
    "    return x_test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65862e33-7848-4c83-96b4-b17bafaa11a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n",
      "70: EER = 0.5285, FMR100 = 0.9578, Count = 100\n",
      "86: EER = 0.4719, FMR100 = 0.9461, Count = 100\n",
      "96: EER = 0.4361, FMR100 = 0.9718, Count = 100\n",
      "125: EER = 0.2878, FMR100 = 0.8328, Count = 100\n",
      "129: EER = 0.3725, FMR100 = 0.9575, Count = 100\n",
      "167: EER = 0.6544, FMR100 = 0.9900, Count = 100\n",
      "174: EER = 0.5573, FMR100 = 0.9339, Count = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175: EER = 0.8200, FMR100 = 0.8200, Count = 100\n",
      "183: EER = 0.4600, FMR100 = 0.9600, Count = 100\n",
      "194: EER = 0.5739, FMR100 = 0.9017, Count = 100\n",
      "197: EER = 0.5046, FMR100 = 0.9911, Count = 100\n",
      "199: EER = 0.4414, FMR100 = 0.9922, Count = 100\n",
      "201: EER = 0.6172, FMR100 = 0.9839, Count = 100\n",
      "203: EER = 0.4320, FMR100 = 0.8720, Count = 100\n",
      "206: EER = 0.8800, FMR100 = 0.9960, Count = 100\n",
      "207: EER = 0.4924, FMR100 = 0.9788, Count = 100\n",
      "214: EER = 0.4127, FMR100 = 0.9178, Count = 100\n",
      "219: EER = 0.5646, FMR100 = 1.0000, Count = 100\n",
      "230: EER = 0.5407, FMR100 = 0.9180, Count = 100\n",
      "236: EER = 0.5957, FMR100 = 0.9839, Count = 100\n",
      "245: EER = 0.5907, FMR100 = 0.9940, Count = 100\n",
      "250: EER = 0.5677, FMR100 = 0.9885, Count = 100\n",
      "257: EER = 0.3686, FMR100 = 0.9960, Count = 100\n",
      "260: EER = 0.5029, FMR100 = 0.9481, Count = 100\n",
      "261: EER = 0.4890, FMR100 = 0.9956, Count = 100\n",
      "262: EER = 0.3845, FMR100 = 0.7220, Count = 100\n",
      "265: EER = 0.4349, FMR100 = 0.9492, Count = 100\n",
      "268: EER = 0.4761, FMR100 = 0.9583, Count = 100\n",
      "270: EER = 0.6233, FMR100 = 0.9894, Count = 100\n",
      "281: EER = 0.3189, FMR100 = 0.8694, Count = 100\n",
      "291: EER = 0.5044, FMR100 = 0.9872, Count = 100\n",
      "296: EER = 0.5437, FMR100 = 1.0000, Count = 100\n",
      "299: EER = 0.4957, FMR100 = 0.9824, Count = 100\n",
      "303: EER = 0.6431, FMR100 = 0.9685, Count = 100\n",
      "306: EER = 0.3264, FMR100 = 0.9150, Count = 100\n",
      "314: EER = 0.6260, FMR100 = 0.9960, Count = 100\n",
      "322: EER = 0.5475, FMR100 = 0.9405, Count = 100\n",
      "325: EER = 0.3495, FMR100 = 0.8619, Count = 100\n",
      "342: EER = 0.4006, FMR100 = 0.9364, Count = 100\n",
      "348: EER = 0.4860, FMR100 = 0.9364, Count = 100\n",
      "357: EER = 0.4448, FMR100 = 0.9110, Count = 100\n",
      "364: EER = 0.3426, FMR100 = 0.9481, Count = 100\n",
      "374: EER = 0.3938, FMR100 = 0.9853, Count = 100\n",
      "407: EER = 0.7112, FMR100 = 0.9950, Count = 100\n",
      "414: EER = 0.4912, FMR100 = 0.8375, Count = 100\n",
      "415: EER = 0.3175, FMR100 = 0.9425, Count = 100\n",
      "418: EER = 0.3812, FMR100 = 0.9625, Count = 100\n",
      "419: EER = 0.3900, FMR100 = 0.9437, Count = 100\n",
      "422: EER = 0.6329, FMR100 = 0.9929, Count = 100\n",
      "436: EER = 0.3471, FMR100 = 0.8229, Count = 100\n",
      "Final Average EER: 49.5519\n",
      "Final EER Standard Deviation: 12.4545\n",
      "$49.55 \\pm 12.45$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"ed\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213fd628-779c-4b5b-8079-e3f0e1b916c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 465)\n",
      "(80643, 465)\n",
      "(80643, 465) (5000, 465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallahi/anaconda3/envs/oml/lib/python3.9/site-packages/pyeer/eer_stats.py:219: UserWarning: It is possible that you had set the wrong score type. Please consider reviewing if you are using dissimilarity or similarity scores\n",
      "  warn(\"It is possible that you had set the wrong score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70: EER = 0.5429, FMR100 = 0.9839, Count = 100\n",
      "86: EER = 0.2979, FMR100 = 0.8167, Count = 100\n",
      "96: EER = 0.5247, FMR100 = 0.9935, Count = 100\n",
      "125: EER = 0.3533, FMR100 = 0.7839, Count = 100\n",
      "129: EER = 0.1700, FMR100 = 0.6975, Count = 100\n",
      "167: EER = 0.3300, FMR100 = 1.0000, Count = 100\n",
      "174: EER = 0.4289, FMR100 = 0.8867, Count = 100\n",
      "175: EER = 0.2243, FMR100 = 0.5460, Count = 100\n",
      "183: EER = 0.2900, FMR100 = 0.6440, Count = 100\n",
      "194: EER = 0.4731, FMR100 = 0.8633, Count = 100\n",
      "197: EER = 0.4341, FMR100 = 0.9267, Count = 100\n",
      "199: EER = 0.3472, FMR100 = 0.8994, Count = 100\n",
      "201: EER = 0.4583, FMR100 = 0.7550, Count = 100\n",
      "203: EER = 0.3180, FMR100 = 0.7960, Count = 100\n",
      "206: EER = 0.3220, FMR100 = 0.8160, Count = 100\n",
      "207: EER = 0.4707, FMR100 = 0.9173, Count = 100\n",
      "214: EER = 0.3800, FMR100 = 0.9559, Count = 100\n",
      "219: EER = 0.6814, FMR100 = 1.0000, Count = 100\n",
      "230: EER = 0.5740, FMR100 = 0.9640, Count = 100\n",
      "236: EER = 0.5428, FMR100 = 0.9754, Count = 100\n",
      "245: EER = 0.4082, FMR100 = 0.9220, Count = 100\n",
      "250: EER = 0.6025, FMR100 = 0.9788, Count = 100\n",
      "257: EER = 0.6600, FMR100 = 0.9920, Count = 100\n",
      "260: EER = 0.4285, FMR100 = 0.9485, Count = 100\n",
      "261: EER = 0.3433, FMR100 = 0.9644, Count = 100\n",
      "262: EER = 0.2340, FMR100 = 0.9980, Count = 100\n",
      "265: EER = 0.4013, FMR100 = 0.9318, Count = 100\n",
      "268: EER = 0.4628, FMR100 = 0.9394, Count = 100\n",
      "270: EER = 0.5806, FMR100 = 0.9661, Count = 100\n",
      "281: EER = 0.2974, FMR100 = 0.7678, Count = 100\n",
      "291: EER = 0.5161, FMR100 = 0.9811, Count = 100\n",
      "296: EER = 0.3910, FMR100 = 0.9277, Count = 100\n",
      "299: EER = 0.2833, FMR100 = 0.7733, Count = 100\n",
      "303: EER = 0.4600, FMR100 = 0.9260, Count = 100\n",
      "306: EER = 0.2187, FMR100 = 0.8277, Count = 100\n",
      "314: EER = 0.4620, FMR100 = 0.9540, Count = 100\n",
      "322: EER = 0.4555, FMR100 = 0.9590, Count = 100\n",
      "325: EER = 0.2314, FMR100 = 0.4843, Count = 100\n",
      "342: EER = 0.2227, FMR100 = 0.8768, Count = 100\n",
      "348: EER = 0.3800, FMR100 = 0.9473, Count = 100\n",
      "357: EER = 0.2452, FMR100 = 0.8586, Count = 100\n",
      "364: EER = 0.3768, FMR100 = 0.9690, Count = 100\n",
      "374: EER = 0.2532, FMR100 = 0.8711, Count = 100\n",
      "407: EER = 0.5087, FMR100 = 0.8838, Count = 100\n",
      "414: EER = 0.2000, FMR100 = 0.6100, Count = 100\n",
      "415: EER = 0.1555, FMR100 = 0.7987, Count = 100\n",
      "418: EER = 0.1969, FMR100 = 0.9125, Count = 100\n",
      "419: EER = 0.3500, FMR100 = 0.8875, Count = 100\n",
      "422: EER = 0.0560, FMR100 = 0.3300, Count = 100\n",
      "436: EER = 0.2157, FMR100 = 0.7543, Count = 100\n",
      "Final Average EER: 37.5222\n",
      "Final EER Standard Deviation: 13.7990\n",
      "$37.52 \\pm 13.80$\n"
     ]
    }
   ],
   "source": [
    "#HEREAA\n",
    "\n",
    "# Generate a sequence of indices from 0 to the length of one of the arrays\n",
    "\n",
    "\n",
    "\n",
    "#, s_test_b\n",
    "resutls2,resutls3=assessment_model_data_two(x_test_e.reshape(x_test_e.shape[0], -1), y_test_e, x_test_v.reshape(x_test_v.shape[0], -1), y_test_v, None, distance = \"cd\")\n",
    "#print(\"simple\",EERf(resutls))\n",
    "calculate_and_print_averages(y_test_e, resutls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8fc2c-2bc8-40c9-b56d-dc0528dc3a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70473412-ab01-4892-ae03-bdc02f67c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9f24ae-287f-4c3e-abfd-48e72277089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each array from 3D to 2D\n",
    "x_test_e = x_test_e.reshape(x_test_e.shape[0], -1)\n",
    "x_test_v= x_test_v.reshape(x_test_v.shape[0], -1)\n",
    "x_test_n = x_neg_r.reshape(x_neg_r.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48ca50-a3f0-447d-a7cc-a3059540ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def calculate_eer(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Calculate the Equal Error Rate (EER) and FMR100 using pyeer.\n",
    "    \"\"\"\n",
    "    # Separate genuine and impostor scores\n",
    "    genuine_scores = y_scores[y_true == 1]\n",
    "    impostor_scores = y_scores[y_true == 0]\n",
    "    #print(y_true, y_scores)\n",
    "\n",
    "    #print(genuine_scores, impostor_scores)\n",
    "    print(\"genuine_scores: \", len(genuine_scores), sum(genuine_scores)/len(genuine_scores), \"impostor_scores\", len(impostor_scores), sum(impostor_scores)/len(impostor_scores))\n",
    "    \n",
    "    # Use pyeer to compute EER stats\n",
    "    stats = get_eer_stats(genuine_scores, impostor_scores)\n",
    "    \n",
    "    return stats.eer\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=20))\n",
    "            #('classifier', SVC(probability=True, random_state=42, class_weight='balanced'))\n",
    "            #('classifier', KNeighborsClassifier(n_neighbors=20, weights='distance'))\n",
    "        ])\n",
    "        #svm_model = SVC(probability=True, random_state=42, class_weight='balanced')\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        pipeline.fit(X, y)\n",
    "        probabilities = pipeline.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "        # Calculate EER\n",
    "        rf_eer = calculate_eer(test_labels, probabilities)\n",
    "\n",
    "        print(f\"Class {cls}: RandomForest EER = {rf_eer:.4f}\")\n",
    "\n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': rf_eer}\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_mean_std(results):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of EER values for each model in the results dictionary.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): A dictionary where keys are classes, and values are dictionaries containing model metrics.\n",
    "                        Example: {cls: {'RandomForest': {'EER': value}}}\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing mean and std for each model across all classes.\n",
    "    \"\"\"\n",
    "    # Extract EER values for each model\n",
    "    model_eer_values = {}\n",
    "    for cls, metrics in results.items():\n",
    "        for model, model_metrics in metrics.items():\n",
    "            if model not in model_eer_values:\n",
    "                model_eer_values[model] = []\n",
    "            model_eer_values[model].append(model_metrics['EER'])\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    model_stats = {}\n",
    "    for model, eer_values in model_eer_values.items():\n",
    "        mean = np.mean(eer_values) * 100\n",
    "        std = np.std(eer_values) * 100\n",
    "        model_stats[model] = {'mean': mean, 'std': std}\n",
    "        print(f\"Final Average EER {model}: {mean:.4f}\")\n",
    "        print(f\"Final EER Standard Deviation {model}: {std:.4f}\")\n",
    "        print(f\"${mean:.2f} \\\\pm {std:.2f}$\") \n",
    "        \n",
    "   \n",
    "    return model_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a00601-2b7c-4345-9d08-3faabbb294a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e5b6d-587c-450e-a4ef-a0b70b1cc162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a9349-089e-4f08-88c5-faf0fa7ea0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cbdcc-b16b-4152-9442-843333c6bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def classifiers_learn(enrollment_data, ye, verification_data, yv, e_network, negative_raw):\n",
    "    \"\"\"\n",
    "    Learn classifiers per unique subject and evaluate using EER.\n",
    "    \"\"\"\n",
    "    x_enrollment, y_enrollment = enrollment_data, ye\n",
    "    x_verification, y_verification = verification_data, yv\n",
    "    \n",
    "    # Compute embeddings\n",
    "    enrollment_embeddings = compute_embedding_batch_two(x_enrollment, e_network)\n",
    "    verification_embeddings = compute_embedding_batch_two(x_verification, e_network)\n",
    "    negative_embeddings = compute_embedding_batch_two(negative_raw, e_network)\n",
    "    \n",
    "    unique_classes = np.unique(y_enrollment)\n",
    "    results = {}\n",
    "\n",
    "    print(\"Unique classes: \", unique_classes)\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # Prepare training data\n",
    "        positive_indices = np.where(y_enrollment == cls)[0]\n",
    "        negative_indices = np.arange(len(negative_embeddings))\n",
    "        \n",
    "        train_embeddings = np.concatenate([enrollment_embeddings[positive_indices], negative_embeddings])\n",
    "        train_labels = np.concatenate([np.ones(len(positive_indices)), np.zeros(len(negative_indices))])\n",
    "\n",
    "        # Prepare testing data\n",
    "        test_embeddings = verification_embeddings\n",
    "        test_labels =(y_verification == cls).astype(int)\n",
    "\n",
    "\n",
    "        # Initialize Incremental PCA\n",
    "        #pca = IncrementalPCA(n_components=50)  # Retain 80% of variance or specify a fixed number of components\n",
    "        \n",
    "\n",
    "        #batch_size = 5000  # Define batch size\n",
    "        #for i in range(0, train_embeddings.shape[0], batch_size):\n",
    "            #batch = train_embeddings[i:i + batch_size]\n",
    "            #pca.partial_fit(batch)  \n",
    "        #train_embeddings_reduced = pca.transform(train_embeddings)\n",
    "        #print(\"Reduced Training Shape:\", train_embeddings_reduced.shape)\n",
    "        #test_embeddings_reduced = pca.transform(test_embeddings)\n",
    "        #print(\"Reduced Test Shape:\", test_embeddings_reduced.shape)\n",
    "\n",
    "        # Train Random Forest model\n",
    "        #rf_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        #rf_model.fit(train_embeddings, train_labels)\n",
    "        #rf_probabilities = rf_model.predict_proba(test_embeddings)[:, 1]  # Use probabilities for EER calculation\n",
    "\n",
    "        \n",
    "        # Replace RandomForest with Linear SVM + Kernel Approximation\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('kernel_approximation', RBFSampler(gamma=1, random_state=42, n_components=500)),  # Approximate RBF kernel\n",
    "            ('classifier', SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, class_weight='balanced', random_state=42, n_jobs=20))\n",
    "        ])\n",
    "        \n",
    "        # Shuffle and split the data\n",
    "        X, y = shuffle(train_embeddings, train_labels, random_state=42)\n",
    "        \n",
    "        # Train the pipeline\n",
    "        pipeline.fit(X, y)\n",
    "        \n",
    "        # Predict probabilities for the test set\n",
    "        # Note: SGDClassifier doesn't provide probabilities directly, so we use decision_function\n",
    "        decision_scores = pipeline.decision_function(test_embeddings)\n",
    "        probabilities = 1 / (1 + np.exp(-decision_scores))  # Sigmoid function to map decision scores to probabilities\n",
    "        \n",
    "        # Calculate EER\n",
    "        svm_eer = calculate_eer(test_labels, probabilities)\n",
    "        \n",
    "        print(f\"Class {cls}: Linear SVM with Kernel Approximation EER = {svm_eer:.4f}\")\n",
    "        \n",
    "        results[cls] = {\n",
    "            'RandomForest': {'EER': svm_eer}\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0bda30-abc5-44ca-9100-a343bc53089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your pipeline with synthetic data\n",
    "\n",
    "\n",
    "\n",
    "resutls = classifiers_learn(\n",
    "    x_test_e, y_test_e, x_test_v, y_test_v, None, x_test_n\n",
    ")\n",
    "# Print results\n",
    "#print(\"EER:\", EERf(resutls))\n",
    "\n",
    "calculate_mean_std(resutls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc002b35-6858-4314-90f2-712bd4899c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "oml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
